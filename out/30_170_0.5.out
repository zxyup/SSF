/home/zxy21/miniconda3/envs/ssfn/lib/python3.10/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Training with a single process on 1 GPUs.
Data processing configuration for current model + dataset:
	input_size: (3, 224, 224)
	interpolation: bicubic
	mean: (0.5, 0.5, 0.5)
	std: (0.5, 0.5, 0.5)
	crop_pct: 0.9
/home/zxy21/miniconda3/envs/ssfn/lib/python3.10/site-packages/torch_pruning/dependency.py:360: UserWarning: Unwrapped parameters detected: ['blocks.3.mlp.ssf_shift_2', 'blocks.6.ssf_shift_2', 'blocks.8.attn.ssf_shift_1', 'blocks.10.ssf_shift_2', 'ssf_scale_1', 'blocks.1.mlp.ssf_scale_1', 'blocks.4.attn.ssf_scale_2', 'blocks.5.mlp.ssf_scale_1', 'blocks.8.ssf_scale_1', 'blocks.0.ssf_shift_1', 'blocks.4.ssf_shift_1', 'blocks.6.mlp.ssf_shift_1', 'blocks.9.attn.ssf_shift_2', 'blocks.10.mlp.ssf_shift_1', 'blocks.2.mlp.ssf_scale_2', 'blocks.7.attn.ssf_scale_1', 'blocks.9.ssf_scale_2', 'blocks.11.attn.ssf_scale_1', 'blocks.5.ssf_shift_2', 'blocks.0.attn.ssf_shift_2', 'blocks.1.ssf_shift_2', 'blocks.3.attn.ssf_shift_1', 'blocks.7.mlp.ssf_shift_2', 'blocks.11.mlp.ssf_shift_2', 'blocks.3.ssf_scale_1', 'blocks.8.attn.ssf_scale_2', 'blocks.9.mlp.ssf_scale_1', 'blocks.5.mlp.ssf_shift_1', 'ssf_shift_1', 'blocks.1.mlp.ssf_shift_1', 'blocks.4.attn.ssf_shift_2', 'blocks.8.ssf_shift_1', 'blocks.0.ssf_scale_2', 'blocks.2.attn.ssf_scale_1', 'blocks.4.ssf_scale_2', 'blocks.6.attn.ssf_scale_1', 'blocks.6.mlp.ssf_scale_2', 'blocks.10.mlp.ssf_scale_2', 'blocks.2.mlp.ssf_shift_2', 'blocks.7.attn.ssf_shift_1', 'blocks.9.ssf_shift_2', 'blocks.11.attn.ssf_shift_1', 'blocks.0.mlp.ssf_scale_1', 'blocks.3.attn.ssf_scale_2', 'blocks.4.mlp.ssf_scale_1', 'blocks.7.ssf_scale_1', 'blocks.11.ssf_scale_1', 'blocks.3.ssf_shift_1', 'blocks.8.attn.ssf_shift_2', 'blocks.9.mlp.ssf_shift_1', 'blocks.1.mlp.ssf_scale_2', 'blocks.5.mlp.ssf_scale_2', 'blocks.8.ssf_scale_2', 'blocks.10.attn.ssf_scale_1', 'blocks.0.ssf_shift_2', 'blocks.2.attn.ssf_shift_1', 'blocks.4.ssf_shift_2', 'blocks.6.attn.ssf_shift_1', 'blocks.6.mlp.ssf_shift_2', 'blocks.10.mlp.ssf_shift_2', 'blocks.2.ssf_scale_1', 'blocks.7.attn.ssf_scale_2', 'blocks.8.mlp.ssf_scale_1', 'blocks.11.attn.ssf_scale_2', 'blocks.0.mlp.ssf_shift_1', 'blocks.3.attn.ssf_shift_2', 'blocks.4.mlp.ssf_shift_1', 'blocks.7.ssf_shift_1', 'blocks.11.ssf_shift_1', 'blocks.5.attn.ssf_scale_1', 'blocks.1.attn.ssf_scale_1', 'blocks.3.ssf_scale_2', 'blocks.9.mlp.ssf_scale_2', 'blocks.1.mlp.ssf_shift_2', 'blocks.5.mlp.ssf_shift_2', 'blocks.8.ssf_shift_2', 'blocks.10.attn.ssf_shift_1', 'blocks.2.attn.ssf_scale_2', 'blocks.3.mlp.ssf_scale_1', 'blocks.6.ssf_scale_1', 'blocks.6.attn.ssf_scale_2', 'blocks.10.ssf_scale_1', 'patch_embed.ssf_scale_1', 'blocks.2.ssf_shift_1', 'blocks.7.attn.ssf_shift_2', 'blocks.8.mlp.ssf_shift_1', 'blocks.11.attn.ssf_shift_2', 'blocks.0.mlp.ssf_scale_2', 'blocks.4.mlp.ssf_scale_2', 'blocks.7.ssf_scale_2', 'blocks.9.attn.ssf_scale_1', 'blocks.11.ssf_scale_2', 'blocks.1.attn.ssf_shift_1', 'blocks.3.ssf_shift_2', 'blocks.5.attn.ssf_shift_1', 'blocks.9.mlp.ssf_shift_2', 'blocks.0.attn.ssf_scale_1', 'blocks.1.ssf_scale_1', 'blocks.5.ssf_scale_1', 'blocks.7.mlp.ssf_scale_1', 'blocks.10.attn.ssf_scale_2', 'blocks.11.mlp.ssf_scale_1', 'blocks.2.attn.ssf_shift_2', 'blocks.3.mlp.ssf_shift_1', 'blocks.6.ssf_shift_1', 'blocks.6.attn.ssf_shift_2', 'blocks.10.ssf_shift_1', 'blocks.4.attn.ssf_scale_1', 'patch_embed.ssf_shift_1', 'blocks.2.ssf_scale_2', 'blocks.8.mlp.ssf_scale_2', 'blocks.0.mlp.ssf_shift_2', 'blocks.4.mlp.ssf_shift_2', 'blocks.7.ssf_shift_2', 'blocks.9.attn.ssf_shift_1', 'blocks.11.ssf_shift_2', 'blocks.5.attn.ssf_scale_2', 'blocks.1.attn.ssf_scale_2', 'blocks.2.mlp.ssf_scale_1', 'blocks.9.ssf_scale_1', 'blocks.0.attn.ssf_shift_1', 'blocks.1.ssf_shift_1', 'blocks.5.ssf_shift_1', 'blocks.7.mlp.ssf_shift_1', 'blocks.10.attn.ssf_shift_2', 'blocks.11.mlp.ssf_shift_1', 'blocks.3.mlp.ssf_scale_2', 'blocks.6.ssf_scale_2', 'blocks.8.attn.ssf_scale_1', 'blocks.10.ssf_scale_2', 'blocks.4.attn.ssf_shift_1', 'blocks.2.ssf_shift_2', 'blocks.8.mlp.ssf_shift_2', 'blocks.0.ssf_scale_1', 'blocks.4.ssf_scale_1', 'blocks.6.mlp.ssf_scale_1', 'blocks.9.attn.ssf_scale_2', 'blocks.10.mlp.ssf_scale_1', 'blocks.5.attn.ssf_shift_2', 'blocks.1.attn.ssf_shift_2', 'blocks.2.mlp.ssf_shift_1', 'blocks.9.ssf_shift_1', 'blocks.5.ssf_scale_2', 'blocks.0.attn.ssf_scale_2', 'blocks.1.ssf_scale_2', 'blocks.3.attn.ssf_scale_1', 'blocks.7.mlp.ssf_scale_2', 'blocks.11.mlp.ssf_scale_2'].
 Torch-Pruning will prune the last non-singleton dimension of a parameter. If you wish to customize this behavior, please provide an unwrapped_parameters argument.
  warnings.warn("Unwrapped parameters detected: {}.\n Torch-Pruning will prune the last non-singleton dimension of a parameter. If you wish to customize this behavior, please provide an unwrapped_parameters argument.".format([_param_to_name[p] for p in unwrapped_detected]))
Params: 86.0814 M
ops: 16.8553 G
ssf_scale_1
ssf_shift_1
patch_embed.ssf_scale_1
patch_embed.ssf_shift_1
blocks.0.ssf_scale_1
blocks.0.ssf_shift_1
blocks.0.ssf_scale_2
blocks.0.ssf_shift_2
blocks.0.attn.ssf_scale_1
blocks.0.attn.ssf_shift_1
blocks.0.attn.ssf_scale_2
blocks.0.attn.ssf_shift_2
blocks.0.mlp.ssf_scale_1
blocks.0.mlp.ssf_shift_1
blocks.0.mlp.ssf_scale_2
blocks.0.mlp.ssf_shift_2
blocks.1.ssf_scale_1
blocks.1.ssf_shift_1
blocks.1.ssf_scale_2
blocks.1.ssf_shift_2
blocks.1.attn.ssf_scale_1
blocks.1.attn.ssf_shift_1
blocks.1.attn.ssf_scale_2
blocks.1.attn.ssf_shift_2
blocks.1.mlp.ssf_scale_1
blocks.1.mlp.ssf_shift_1
blocks.1.mlp.ssf_scale_2
blocks.1.mlp.ssf_shift_2
blocks.2.ssf_scale_1
blocks.2.ssf_shift_1
blocks.2.ssf_scale_2
blocks.2.ssf_shift_2
blocks.2.attn.ssf_scale_1
blocks.2.attn.ssf_shift_1
blocks.2.attn.ssf_scale_2
blocks.2.attn.ssf_shift_2
blocks.2.mlp.ssf_scale_1
blocks.2.mlp.ssf_shift_1
blocks.2.mlp.ssf_scale_2
blocks.2.mlp.ssf_shift_2
blocks.3.ssf_scale_1
blocks.3.ssf_shift_1
blocks.3.ssf_scale_2
blocks.3.ssf_shift_2
blocks.3.attn.ssf_scale_1
blocks.3.attn.ssf_shift_1
blocks.3.attn.ssf_scale_2
blocks.3.attn.ssf_shift_2
blocks.3.mlp.ssf_scale_1
blocks.3.mlp.ssf_shift_1
blocks.3.mlp.ssf_scale_2
blocks.3.mlp.ssf_shift_2
blocks.4.ssf_scale_1
blocks.4.ssf_shift_1
blocks.4.ssf_scale_2
blocks.4.ssf_shift_2
blocks.4.attn.ssf_scale_1
blocks.4.attn.ssf_shift_1
blocks.4.attn.ssf_scale_2
blocks.4.attn.ssf_shift_2
blocks.4.mlp.ssf_scale_1
blocks.4.mlp.ssf_shift_1
blocks.4.mlp.ssf_scale_2
blocks.4.mlp.ssf_shift_2
blocks.5.ssf_scale_1
blocks.5.ssf_shift_1
blocks.5.ssf_scale_2
blocks.5.ssf_shift_2
blocks.5.attn.ssf_scale_1
blocks.5.attn.ssf_shift_1
blocks.5.attn.ssf_scale_2
blocks.5.attn.ssf_shift_2
blocks.5.mlp.ssf_scale_1
blocks.5.mlp.ssf_shift_1
blocks.5.mlp.ssf_scale_2
blocks.5.mlp.ssf_shift_2
blocks.6.ssf_scale_1
blocks.6.ssf_shift_1
blocks.6.ssf_scale_2
blocks.6.ssf_shift_2
blocks.6.attn.ssf_scale_1
blocks.6.attn.ssf_shift_1
blocks.6.attn.ssf_scale_2
blocks.6.attn.ssf_shift_2
blocks.6.mlp.ssf_scale_1
blocks.6.mlp.ssf_shift_1
blocks.6.mlp.ssf_scale_2
blocks.6.mlp.ssf_shift_2
blocks.7.ssf_scale_1
blocks.7.ssf_shift_1
blocks.7.ssf_scale_2
blocks.7.ssf_shift_2
blocks.7.attn.ssf_scale_1
blocks.7.attn.ssf_shift_1
blocks.7.attn.ssf_scale_2
blocks.7.attn.ssf_shift_2
blocks.7.mlp.ssf_scale_1
blocks.7.mlp.ssf_shift_1
blocks.7.mlp.ssf_scale_2
blocks.7.mlp.ssf_shift_2
blocks.8.ssf_scale_1
blocks.8.ssf_shift_1
blocks.8.ssf_scale_2
blocks.8.ssf_shift_2
blocks.8.attn.ssf_scale_1
blocks.8.attn.ssf_shift_1
blocks.8.attn.ssf_scale_2
blocks.8.attn.ssf_shift_2
blocks.8.mlp.ssf_scale_1
blocks.8.mlp.ssf_shift_1
blocks.8.mlp.ssf_scale_2
blocks.8.mlp.ssf_shift_2
blocks.9.ssf_scale_1
blocks.9.ssf_shift_1
blocks.9.ssf_scale_2
blocks.9.ssf_shift_2
blocks.9.attn.ssf_scale_1
blocks.9.attn.ssf_shift_1
blocks.9.attn.ssf_scale_2
blocks.9.attn.ssf_shift_2
blocks.9.mlp.ssf_scale_1
blocks.9.mlp.ssf_shift_1
blocks.9.mlp.ssf_scale_2
blocks.9.mlp.ssf_shift_2
blocks.10.ssf_scale_1
blocks.10.ssf_shift_1
blocks.10.ssf_scale_2
blocks.10.ssf_shift_2
blocks.10.attn.ssf_scale_1
blocks.10.attn.ssf_shift_1
blocks.10.attn.ssf_scale_2
blocks.10.attn.ssf_shift_2
blocks.10.mlp.ssf_scale_1
blocks.10.mlp.ssf_shift_1
blocks.10.mlp.ssf_scale_2
blocks.10.mlp.ssf_shift_2
blocks.11.ssf_scale_1
blocks.11.ssf_shift_1
blocks.11.ssf_scale_2
blocks.11.ssf_shift_2
blocks.11.attn.ssf_scale_1
blocks.11.attn.ssf_shift_1
blocks.11.attn.ssf_scale_2
blocks.11.attn.ssf_shift_2
blocks.11.mlp.ssf_scale_1
blocks.11.mlp.ssf_shift_1
blocks.11.mlp.ssf_scale_2
blocks.11.mlp.ssf_shift_2
head.weight
head.bias
freezing parameters finished!
Model vit_base_patch16_224_in21k created, param count:86081380
number of params for requires grad: 282724
Using native Torch AMP. Training in mixed precision.
Scheduled epochs: 180
Train: 0 [   0/390 (  0%)]  Loss: 5.723 (5.72)  Time: 7.174s,   17.84/s  (7.174s,   17.84/s)  LR: 1.000e-03  Data: 1.568 (1.568)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.498 (3.71)  Time: 0.313s,  409.51/s  (0.382s,  335.49/s)  LR: 1.000e-03  Data: 0.012 (0.028)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.159 (3.36)  Time: 0.316s,  405.42/s  (0.349s,  367.13/s)  LR: 1.000e-03  Data: 0.013 (0.021)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.063 (3.18)  Time: 0.316s,  404.60/s  (0.338s,  378.79/s)  LR: 1.000e-03  Data: 0.014 (0.018)
Train: 0 [ 389/390 (100%)]  Loss: 3.413 (3.10)  Time: 0.305s,  419.54/s  (0.333s,  383.93/s)  LR: 1.000e-03  Data: 0.000 (0.017)
Train: 0 [   0/390 (  0%)]  Loss: 2.019 (2.02)  Time: 0.719s,  178.13/s  (0.719s,  178.13/s)  LR: 1.000e-03  Data: 0.413 (0.413)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.835 (2.79)  Time: 0.316s,  405.11/s  (0.321s,  398.60/s)  LR: 1.000e-03  Data: 0.012 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.461 (2.76)  Time: 0.315s,  406.69/s  (0.320s,  399.59/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.191 (2.79)  Time: 0.319s,  401.40/s  (0.320s,  400.43/s)  LR: 1.000e-03  Data: 0.013 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 2.223 (2.79)  Time: 0.306s,  418.70/s  (0.319s,  400.66/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 2.995 (2.99)  Time: 0.822s,  155.76/s  (0.822s,  155.76/s)  LR: 1.000e-03  Data: 0.518 (0.518)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.177 (2.76)  Time: 0.320s,  400.40/s  (0.326s,  393.08/s)  LR: 1.000e-03  Data: 0.014 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.077 (2.73)  Time: 0.318s,  402.86/s  (0.323s,  396.85/s)  LR: 1.000e-03  Data: 0.012 (0.016)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.471 (2.74)  Time: 0.315s,  405.95/s  (0.322s,  397.72/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 389/390 (100%)]  Loss: 2.704 (2.74)  Time: 0.305s,  419.92/s  (0.322s,  397.77/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.374 (3.37)  Time: 0.829s,  154.39/s  (0.829s,  154.39/s)  LR: 1.000e-03  Data: 0.523 (0.523)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.151 (2.68)  Time: 0.317s,  404.14/s  (0.328s,  390.66/s)  LR: 1.000e-03  Data: 0.013 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.519 (2.71)  Time: 0.315s,  406.13/s  (0.322s,  397.16/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.246 (2.71)  Time: 0.314s,  408.01/s  (0.321s,  399.31/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 2.637 (2.72)  Time: 0.302s,  423.73/s  (0.320s,  400.39/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.136 (3.14)  Time: 0.721s,  177.43/s  (0.721s,  177.43/s)  LR: 1.000e-03  Data: 0.416 (0.416)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.969 (2.75)  Time: 0.317s,  403.93/s  (0.321s,  399.30/s)  LR: 1.000e-03  Data: 0.014 (0.016)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.421 (2.76)  Time: 0.314s,  407.22/s  (0.319s,  400.78/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.323 (2.78)  Time: 0.314s,  408.08/s  (0.318s,  402.20/s)  LR: 1.000e-03  Data: 0.011 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.196 (2.78)  Time: 0.316s,  404.68/s  (0.318s,  402.41/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 2.996 (3.00)  Time: 0.710s,  180.39/s  (0.710s,  180.39/s)  LR: 1.000e-03  Data: 0.405 (0.405)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.031 (2.83)  Time: 0.312s,  409.81/s  (0.321s,  398.72/s)  LR: 1.000e-03  Data: 0.011 (0.016)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.446 (2.80)  Time: 0.314s,  407.80/s  (0.318s,  402.12/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.279 (2.78)  Time: 0.313s,  409.24/s  (0.317s,  403.83/s)  LR: 1.000e-03  Data: 0.011 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 3.012 (2.79)  Time: 0.302s,  423.35/s  (0.316s,  404.62/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 2.244 (2.24)  Time: 0.753s,  169.89/s  (0.753s,  169.89/s)  LR: 1.000e-03  Data: 0.449 (0.449)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.126 (2.86)  Time: 0.314s,  408.07/s  (0.319s,  401.88/s)  LR: 1.000e-03  Data: 0.011 (0.016)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.177 (2.87)  Time: 0.318s,  403.04/s  (0.317s,  403.83/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.445 (2.84)  Time: 0.313s,  408.86/s  (0.318s,  402.43/s)  LR: 1.000e-03  Data: 0.011 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 2.406 (2.84)  Time: 0.304s,  421.37/s  (0.317s,  403.28/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 2.966 (2.97)  Time: 0.768s,  166.67/s  (0.768s,  166.67/s)  LR: 1.000e-03  Data: 0.462 (0.462)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.293 (2.82)  Time: 0.314s,  407.26/s  (0.322s,  397.92/s)  LR: 1.000e-03  Data: 0.011 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 1.866 (2.82)  Time: 0.317s,  403.66/s  (0.318s,  401.99/s)  LR: 1.000e-03  Data: 0.015 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.936 (2.83)  Time: 0.313s,  408.50/s  (0.317s,  403.83/s)  LR: 1.000e-03  Data: 0.011 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.286 (2.86)  Time: 0.302s,  423.72/s  (0.317s,  404.24/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 1.870 (1.87)  Time: 0.746s,  171.54/s  (0.746s,  171.54/s)  LR: 1.000e-03  Data: 0.439 (0.439)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.454 (2.86)  Time: 0.314s,  408.02/s  (0.321s,  399.00/s)  LR: 1.000e-03  Data: 0.012 (0.016)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.265 (2.86)  Time: 0.313s,  408.77/s  (0.317s,  403.24/s)  LR: 1.000e-03  Data: 0.011 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.580 (2.89)  Time: 0.314s,  407.44/s  (0.316s,  404.72/s)  LR: 1.000e-03  Data: 0.012 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 2.044 (2.89)  Time: 0.303s,  422.71/s  (0.316s,  405.52/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 3.453 (3.45)  Time: 0.783s,  163.55/s  (0.783s,  163.55/s)  LR: 1.000e-03  Data: 0.479 (0.479)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.282 (2.85)  Time: 0.314s,  408.13/s  (0.319s,  401.81/s)  LR: 1.000e-03  Data: 0.013 (0.016)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.031 (2.87)  Time: 0.329s,  389.36/s  (0.318s,  403.11/s)  LR: 1.000e-03  Data: 0.013 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 1.905 (2.88)  Time: 0.314s,  407.43/s  (0.318s,  403.07/s)  LR: 1.000e-03  Data: 0.012 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 2.089 (2.88)  Time: 0.302s,  423.66/s  (0.317s,  404.01/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 2.747 (2.75)  Time: 0.796s,  160.82/s  (0.796s,  160.82/s)  LR: 1.000e-03  Data: 0.480 (0.480)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.395 (2.92)  Time: 0.313s,  408.39/s  (0.320s,  400.52/s)  LR: 1.000e-03  Data: 0.012 (0.016)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.521 (2.92)  Time: 0.313s,  409.39/s  (0.317s,  404.09/s)  LR: 1.000e-03  Data: 0.011 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.835 (2.93)  Time: 0.318s,  402.51/s  (0.316s,  404.93/s)  LR: 1.000e-03  Data: 0.016 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 3.195 (2.94)  Time: 0.302s,  423.71/s  (0.316s,  405.60/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 2.997 (3.00)  Time: 0.749s,  170.96/s  (0.749s,  170.96/s)  LR: 1.000e-03  Data: 0.424 (0.424)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.940 (2.92)  Time: 0.314s,  408.07/s  (0.320s,  399.88/s)  LR: 1.000e-03  Data: 0.012 (0.016)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.668 (2.90)  Time: 0.315s,  406.99/s  (0.317s,  403.66/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.686 (2.90)  Time: 0.313s,  408.71/s  (0.316s,  405.25/s)  LR: 1.000e-03  Data: 0.012 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 1.886 (2.89)  Time: 0.302s,  424.25/s  (0.315s,  405.87/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 3.589 (3.59)  Time: 0.760s,  168.44/s  (0.760s,  168.44/s)  LR: 1.000e-03  Data: 0.456 (0.456)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.434 (3.03)  Time: 0.314s,  407.06/s  (0.318s,  402.86/s)  LR: 1.000e-03  Data: 0.012 (0.016)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.476 (2.99)  Time: 0.314s,  407.55/s  (0.316s,  404.93/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.472 (2.98)  Time: 0.313s,  409.19/s  (0.315s,  405.90/s)  LR: 1.000e-03  Data: 0.011 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 3.471 (2.96)  Time: 0.316s,  405.47/s  (0.315s,  405.97/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 2.108 (2.11)  Time: 0.746s,  171.65/s  (0.746s,  171.65/s)  LR: 1.000e-03  Data: 0.444 (0.444)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.859 (3.00)  Time: 0.314s,  407.49/s  (0.319s,  401.33/s)  LR: 1.000e-03  Data: 0.012 (0.016)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.350 (2.99)  Time: 0.315s,  406.68/s  (0.317s,  404.08/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.857 (2.98)  Time: 0.314s,  407.97/s  (0.316s,  405.31/s)  LR: 1.000e-03  Data: 0.011 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 3.481 (2.98)  Time: 0.303s,  423.13/s  (0.315s,  405.96/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 3.182 (3.18)  Time: 0.798s,  160.35/s  (0.798s,  160.35/s)  LR: 1.000e-03  Data: 0.497 (0.497)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.944 (2.87)  Time: 0.315s,  406.70/s  (0.319s,  401.15/s)  LR: 1.000e-03  Data: 0.012 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.157 (2.94)  Time: 0.313s,  409.10/s  (0.319s,  401.41/s)  LR: 1.000e-03  Data: 0.011 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.515 (2.95)  Time: 0.313s,  408.61/s  (0.317s,  403.65/s)  LR: 1.000e-03  Data: 0.011 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 2.683 (2.95)  Time: 0.305s,  419.67/s  (0.316s,  404.63/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 3.351 (3.35)  Time: 0.814s,  157.18/s  (0.814s,  157.18/s)  LR: 1.000e-03  Data: 0.498 (0.498)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.303 (3.06)  Time: 0.315s,  405.91/s  (0.323s,  396.60/s)  LR: 1.000e-03  Data: 0.013 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.287 (3.02)  Time: 0.313s,  409.49/s  (0.321s,  398.51/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.213 (3.02)  Time: 0.331s,  386.26/s  (0.320s,  400.60/s)  LR: 1.000e-03  Data: 0.013 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.085 (3.02)  Time: 0.303s,  422.01/s  (0.318s,  402.05/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 3.557 (3.56)  Time: 0.773s,  165.50/s  (0.773s,  165.50/s)  LR: 1.000e-03  Data: 0.470 (0.470)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.150 (3.00)  Time: 0.315s,  406.50/s  (0.320s,  399.88/s)  LR: 1.000e-03  Data: 0.012 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.031 (3.02)  Time: 0.315s,  406.42/s  (0.318s,  402.78/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.386 (3.03)  Time: 0.318s,  402.36/s  (0.318s,  402.53/s)  LR: 1.000e-03  Data: 0.013 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 2.912 (3.04)  Time: 0.304s,  421.35/s  (0.317s,  403.30/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 3.135 (3.14)  Time: 0.880s,  145.41/s  (0.880s,  145.41/s)  LR: 1.000e-03  Data: 0.569 (0.569)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.451 (3.09)  Time: 0.316s,  405.45/s  (0.325s,  393.96/s)  LR: 1.000e-03  Data: 0.013 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.319 (3.07)  Time: 0.316s,  405.41/s  (0.321s,  399.15/s)  LR: 1.000e-03  Data: 0.013 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.871 (3.02)  Time: 0.315s,  405.95/s  (0.319s,  400.67/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.339 (3.01)  Time: 0.303s,  422.61/s  (0.319s,  401.48/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.296 (3.30)  Time: 0.798s,  160.31/s  (0.798s,  160.31/s)  LR: 1.000e-03  Data: 0.485 (0.485)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.699 (3.13)  Time: 0.319s,  401.69/s  (0.325s,  393.78/s)  LR: 1.000e-03  Data: 0.014 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.080 (3.13)  Time: 0.319s,  401.76/s  (0.322s,  398.06/s)  LR: 1.000e-03  Data: 0.015 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.352 (3.11)  Time: 0.316s,  404.73/s  (0.320s,  399.79/s)  LR: 1.000e-03  Data: 0.013 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.319 (3.11)  Time: 0.308s,  416.10/s  (0.320s,  399.80/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 2.458 (2.46)  Time: 0.906s,  141.24/s  (0.906s,  141.24/s)  LR: 1.000e-03  Data: 0.590 (0.590)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.480 (3.09)  Time: 0.314s,  407.58/s  (0.322s,  397.52/s)  LR: 1.000e-03  Data: 0.011 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.762 (3.06)  Time: 0.317s,  404.16/s  (0.320s,  400.62/s)  LR: 1.000e-03  Data: 0.014 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.782 (3.06)  Time: 0.315s,  406.66/s  (0.319s,  401.72/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 2.695 (3.07)  Time: 0.305s,  419.18/s  (0.318s,  402.36/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.942 (3.94)  Time: 0.857s,  149.32/s  (0.857s,  149.32/s)  LR: 1.000e-03  Data: 0.536 (0.536)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.094 (3.09)  Time: 0.315s,  405.84/s  (0.322s,  397.15/s)  LR: 1.000e-03  Data: 0.012 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.424 (3.06)  Time: 0.318s,  402.11/s  (0.319s,  400.87/s)  LR: 1.000e-03  Data: 0.013 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.519 (3.07)  Time: 0.315s,  406.62/s  (0.319s,  401.77/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.435 (3.07)  Time: 0.307s,  416.51/s  (0.319s,  401.65/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.078 (3.08)  Time: 0.773s,  165.67/s  (0.773s,  165.67/s)  LR: 1.000e-03  Data: 0.469 (0.469)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.736 (3.11)  Time: 0.315s,  406.06/s  (0.326s,  392.42/s)  LR: 1.000e-03  Data: 0.011 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.856 (3.07)  Time: 0.334s,  382.96/s  (0.321s,  398.48/s)  LR: 1.000e-03  Data: 0.017 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.809 (3.10)  Time: 0.330s,  387.66/s  (0.322s,  397.78/s)  LR: 1.000e-03  Data: 0.013 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.485 (3.12)  Time: 0.302s,  423.44/s  (0.322s,  397.81/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 2.335 (2.34)  Time: 0.753s,  169.99/s  (0.753s,  169.99/s)  LR: 1.000e-03  Data: 0.450 (0.450)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.452 (3.13)  Time: 0.315s,  405.76/s  (0.323s,  396.83/s)  LR: 1.000e-03  Data: 0.012 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.749 (3.14)  Time: 0.313s,  408.60/s  (0.320s,  399.84/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.811 (3.16)  Time: 0.314s,  407.26/s  (0.319s,  400.75/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 2.917 (3.16)  Time: 0.303s,  422.58/s  (0.319s,  401.71/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.577 (3.58)  Time: 0.758s,  168.94/s  (0.758s,  168.94/s)  LR: 1.000e-03  Data: 0.453 (0.453)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.588 (3.10)  Time: 0.315s,  405.96/s  (0.322s,  397.61/s)  LR: 1.000e-03  Data: 0.013 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.448 (3.15)  Time: 0.314s,  407.45/s  (0.321s,  398.22/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.058 (3.17)  Time: 0.331s,  387.25/s  (0.320s,  399.42/s)  LR: 1.000e-03  Data: 0.014 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.745 (3.17)  Time: 0.307s,  417.20/s  (0.320s,  400.28/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.563 (3.56)  Time: 0.794s,  161.16/s  (0.794s,  161.16/s)  LR: 1.000e-03  Data: 0.486 (0.486)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.741 (3.21)  Time: 0.316s,  404.79/s  (0.322s,  397.37/s)  LR: 1.000e-03  Data: 0.012 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.601 (3.17)  Time: 0.327s,  391.22/s  (0.320s,  400.60/s)  LR: 1.000e-03  Data: 0.024 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.756 (3.18)  Time: 0.314s,  407.72/s  (0.319s,  401.15/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 2.394 (3.17)  Time: 0.304s,  421.04/s  (0.319s,  401.54/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.496 (3.50)  Time: 0.800s,  160.09/s  (0.800s,  160.09/s)  LR: 1.000e-03  Data: 0.478 (0.478)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.653 (3.16)  Time: 0.318s,  402.92/s  (0.321s,  398.59/s)  LR: 1.000e-03  Data: 0.014 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.373 (3.16)  Time: 0.318s,  402.48/s  (0.319s,  401.68/s)  LR: 1.000e-03  Data: 0.013 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.526 (3.17)  Time: 0.314s,  407.11/s  (0.318s,  401.92/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.749 (3.16)  Time: 0.317s,  403.59/s  (0.319s,  401.21/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.851 (3.85)  Time: 0.783s,  163.45/s  (0.783s,  163.45/s)  LR: 1.000e-03  Data: 0.481 (0.481)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.091 (3.20)  Time: 0.314s,  407.18/s  (0.322s,  397.68/s)  LR: 1.000e-03  Data: 0.011 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.580 (3.21)  Time: 0.316s,  404.71/s  (0.320s,  399.50/s)  LR: 1.000e-03  Data: 0.013 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.451 (3.22)  Time: 0.318s,  402.62/s  (0.320s,  400.57/s)  LR: 1.000e-03  Data: 0.015 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.103 (3.23)  Time: 0.303s,  422.67/s  (0.319s,  401.67/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.648 (3.65)  Time: 0.760s,  168.36/s  (0.760s,  168.36/s)  LR: 1.000e-03  Data: 0.457 (0.457)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.437 (3.24)  Time: 0.317s,  403.75/s  (0.323s,  395.90/s)  LR: 1.000e-03  Data: 0.013 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.536 (3.21)  Time: 0.318s,  402.76/s  (0.320s,  400.15/s)  LR: 1.000e-03  Data: 0.014 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.433 (3.21)  Time: 0.315s,  406.99/s  (0.320s,  400.56/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.721 (3.22)  Time: 0.303s,  422.03/s  (0.319s,  401.72/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.514 (3.51)  Time: 0.802s,  159.63/s  (0.802s,  159.63/s)  LR: 1.000e-03  Data: 0.497 (0.497)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.467 (3.21)  Time: 0.317s,  403.44/s  (0.321s,  398.28/s)  LR: 1.000e-03  Data: 0.012 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.754 (3.21)  Time: 0.338s,  378.56/s  (0.320s,  400.27/s)  LR: 1.000e-03  Data: 0.013 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.738 (3.22)  Time: 0.318s,  402.68/s  (0.320s,  400.48/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 389/390 (100%)]  Loss: 3.610 (3.22)  Time: 0.304s,  420.43/s  (0.319s,  401.57/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.644 (3.64)  Time: 0.788s,  162.35/s  (0.788s,  162.35/s)  LR: 1.000e-03  Data: 0.483 (0.483)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.556 (3.29)  Time: 0.318s,  402.86/s  (0.323s,  396.52/s)  LR: 1.000e-03  Data: 0.014 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.870 (3.30)  Time: 0.314s,  407.91/s  (0.320s,  400.29/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.162 (3.29)  Time: 0.331s,  386.23/s  (0.321s,  398.66/s)  LR: 1.000e-03  Data: 0.015 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.683 (3.27)  Time: 0.304s,  420.62/s  (0.320s,  399.77/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Test: [   0/78]  Time: 1.138 (1.138)  Loss:  4.6797 (4.6797)  Acc@1:  4.6875 ( 4.6875)  Acc@5: 10.1562 (10.1562)
Test: [  78/78]  Time: 0.074 (0.132)  Loss:  4.5977 (4.7510)  Acc@1:  6.2500 ( 1.3500)  Acc@5: 12.5000 ( 5.7200)
Test: [Whole Val]  Time: 10.390  Loss: 4.7510  Acc@1:  1.3500 Pruned: 54.14% 
*** Pruned results: OrderedDict([('loss', 4.75100625), ('top1', 1.35), ('top5', 5.72), ('pruned', 0.5413848725124378)])
Pruned: 50.00%
Train: 0 [   0/390 (  0%)]  Loss: 4.702 (4.70)  Time: 0.868s,  147.50/s  (0.868s,  147.50/s)  LR: 1.000e-07  Data: 0.555 (0.555)
Train: 0 [ 100/390 ( 26%)]  Loss: 4.814 (4.77)  Time: 0.315s,  406.47/s  (0.322s,  397.56/s)  LR: 1.000e-07  Data: 0.015 (0.019)
Train: 0 [ 200/390 ( 51%)]  Loss: 4.787 (4.77)  Time: 0.313s,  409.51/s  (0.318s,  402.43/s)  LR: 1.000e-07  Data: 0.011 (0.016)
Train: 0 [ 300/390 ( 77%)]  Loss: 4.739 (4.77)  Time: 0.314s,  407.74/s  (0.319s,  401.27/s)  LR: 1.000e-07  Data: 0.013 (0.015)
Train: 0 [ 389/390 (100%)]  Loss: 4.847 (4.77)  Time: 0.300s,  426.14/s  (0.318s,  402.83/s)  LR: 1.000e-07  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.384 (0.384)  Loss:  4.6758 (4.6758)  Acc@1:  4.6875 ( 4.6875)  Acc@5: 10.1562 (10.1562)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  4.5938 (4.7473)  Acc@1:  6.2500 ( 1.3500)  Acc@5: 12.5000 ( 5.7300)
Test: [Whole Val]  Time: 9.616  Loss: 4.7473  Acc@1:  1.3500 Pruned: 54.14% 
Test (EMA): [   0/78]  Time: 0.360 (0.360)  Loss:  4.6758 (4.6758)  Acc@1:  4.6875 ( 4.6875)  Acc@5: 10.1562 (10.1562)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  4.5938 (4.7473)  Acc@1:  6.2500 ( 1.3500)  Acc@5: 12.5000 ( 5.7300)
Test (EMA): [Whole Val]  Time: 9.604  Loss: 4.7473  Acc@1:  1.3500 Pruned: 54.14% 
Train: 1 [   0/390 (  0%)]  Loss: 4.781 (4.78)  Time: 0.919s,  139.35/s  (0.919s,  139.35/s)  LR: 1.001e-04  Data: 0.617 (0.617)
Train: 1 [ 100/390 ( 26%)]  Loss: 4.598 (4.63)  Time: 0.315s,  406.67/s  (0.320s,  400.54/s)  LR: 1.001e-04  Data: 0.013 (0.018)
Train: 1 [ 200/390 ( 51%)]  Loss: 4.611 (4.62)  Time: 0.316s,  404.74/s  (0.318s,  403.06/s)  LR: 1.001e-04  Data: 0.014 (0.016)
Train: 1 [ 300/390 ( 77%)]  Loss: 4.598 (4.61)  Time: 0.314s,  408.29/s  (0.316s,  404.51/s)  LR: 1.001e-04  Data: 0.014 (0.015)
Train: 1 [ 389/390 (100%)]  Loss: 4.597 (4.61)  Time: 0.300s,  427.07/s  (0.316s,  404.94/s)  LR: 1.001e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.363 (0.363)  Loss:  4.5742 (4.5742)  Acc@1:  1.5625 ( 1.5625)  Acc@5:  9.3750 ( 9.3750)
Test: [  78/78]  Time: 0.022 (0.121)  Loss:  4.5234 (4.5706)  Acc@1:  6.2500 ( 2.3300)  Acc@5: 18.7500 ( 9.2000)
Test: [Whole Val]  Time: 9.581  Loss: 4.5706  Acc@1:  2.3300 Pruned: 54.13% 
Test (EMA): [   0/78]  Time: 0.419 (0.419)  Loss:  4.5742 (4.5742)  Acc@1:  1.5625 ( 1.5625)  Acc@5: 11.7188 (11.7188)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  4.5352 (4.5702)  Acc@1:  6.2500 ( 2.1700)  Acc@5: 12.5000 (10.3800)
Test (EMA): [Whole Val]  Time: 9.645  Loss: 4.5702  Acc@1:  2.1700 Pruned: 54.13% 
Train: 2 [   0/390 (  0%)]  Loss: 4.578 (4.58)  Time: 0.788s,  162.39/s  (0.788s,  162.39/s)  LR: 2.001e-04  Data: 0.472 (0.472)
Train: 2 [ 100/390 ( 26%)]  Loss: 4.610 (4.60)  Time: 0.312s,  410.53/s  (0.319s,  401.34/s)  LR: 2.001e-04  Data: 0.012 (0.017)
Train: 2 [ 200/390 ( 51%)]  Loss: 4.593 (4.60)  Time: 0.312s,  410.12/s  (0.316s,  405.08/s)  LR: 2.001e-04  Data: 0.012 (0.015)
Train: 2 [ 300/390 ( 77%)]  Loss: 4.586 (4.60)  Time: 0.311s,  411.25/s  (0.315s,  406.44/s)  LR: 2.001e-04  Data: 0.011 (0.014)
Train: 2 [ 389/390 (100%)]  Loss: 4.580 (4.60)  Time: 0.300s,  426.25/s  (0.315s,  406.85/s)  LR: 2.001e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.421 (0.421)  Loss:  4.5664 (4.5664)  Acc@1:  0.7812 ( 0.7812)  Acc@5: 11.7188 (11.7188)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  4.5391 (4.5564)  Acc@1: 18.7500 ( 2.5700)  Acc@5: 18.7500 (11.0900)
Test: [Whole Val]  Time: 9.665  Loss: 4.5564  Acc@1:  2.5700 Pruned: 54.12% 
Test (EMA): [   0/78]  Time: 0.324 (0.324)  Loss:  4.5664 (4.5664)  Acc@1:  0.0000 ( 0.0000)  Acc@5:  8.5938 ( 8.5938)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  4.5391 (4.5550)  Acc@1: 12.5000 ( 2.8900)  Acc@5: 12.5000 (11.2300)
Test (EMA): [Whole Val]  Time: 9.546  Loss: 4.5550  Acc@1:  2.8900 Pruned: 54.13% 
Train: 3 [   0/390 (  0%)]  Loss: 4.614 (4.61)  Time: 0.864s,  148.15/s  (0.864s,  148.15/s)  LR: 3.001e-04  Data: 0.563 (0.563)
Train: 3 [ 100/390 ( 26%)]  Loss: 4.603 (4.59)  Time: 0.313s,  408.88/s  (0.320s,  399.97/s)  LR: 3.001e-04  Data: 0.013 (0.018)
Train: 3 [ 200/390 ( 51%)]  Loss: 4.585 (4.59)  Time: 0.312s,  410.82/s  (0.317s,  404.30/s)  LR: 3.001e-04  Data: 0.012 (0.015)
Train: 3 [ 300/390 ( 77%)]  Loss: 4.578 (4.59)  Time: 0.311s,  411.42/s  (0.316s,  405.54/s)  LR: 3.001e-04  Data: 0.012 (0.015)
Train: 3 [ 389/390 (100%)]  Loss: 4.585 (4.59)  Time: 0.300s,  426.24/s  (0.315s,  405.91/s)  LR: 3.001e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.420 (0.420)  Loss:  4.5078 (4.5078)  Acc@1:  1.5625 ( 1.5625)  Acc@5: 12.5000 (12.5000)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  4.4531 (4.4908)  Acc@1: 12.5000 ( 3.5200)  Acc@5: 37.5000 (14.9800)
Test: [Whole Val]  Time: 9.627  Loss: 4.4908  Acc@1:  3.5200 Pruned: 53.95% 
Test (EMA): [   0/78]  Time: 0.316 (0.316)  Loss:  4.5039 (4.5039)  Acc@1:  2.3438 ( 2.3438)  Acc@5: 15.6250 (15.6250)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  4.4609 (4.4908)  Acc@1: 18.7500 ( 4.2600)  Acc@5: 31.2500 (15.4600)
Test (EMA): [Whole Val]  Time: 9.557  Loss: 4.4908  Acc@1:  4.2600 Pruned: 53.96% 
Train: 4 [   0/390 (  0%)]  Loss: 4.554 (4.55)  Time: 0.800s,  159.91/s  (0.800s,  159.91/s)  LR: 4.001e-04  Data: 0.500 (0.500)
Train: 4 [ 100/390 ( 26%)]  Loss: 4.574 (4.57)  Time: 0.312s,  410.34/s  (0.321s,  398.95/s)  LR: 4.001e-04  Data: 0.012 (0.017)
Train: 4 [ 200/390 ( 51%)]  Loss: 4.551 (4.55)  Time: 0.313s,  408.91/s  (0.318s,  403.13/s)  LR: 4.001e-04  Data: 0.012 (0.015)
Train: 4 [ 300/390 ( 77%)]  Loss: 4.515 (4.53)  Time: 0.323s,  396.27/s  (0.317s,  403.71/s)  LR: 4.001e-04  Data: 0.011 (0.014)
Train: 4 [ 389/390 (100%)]  Loss: 4.421 (4.50)  Time: 0.301s,  425.05/s  (0.317s,  404.29/s)  LR: 4.001e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.397 (0.397)  Loss:  3.7285 (3.7285)  Acc@1: 18.7500 (18.7500)  Acc@5: 40.6250 (40.6250)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  3.5742 (3.7869)  Acc@1: 18.7500 (15.5700)  Acc@5: 56.2500 (39.9600)
Test: [Whole Val]  Time: 9.641  Loss: 3.7869  Acc@1: 15.5700 Pruned: 53.36% 
Test (EMA): [   0/78]  Time: 0.429 (0.429)  Loss:  3.7090 (3.7090)  Acc@1: 20.3125 (20.3125)  Acc@5: 41.4062 (41.4062)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  3.6445 (3.7813)  Acc@1: 18.7500 (15.6500)  Acc@5: 50.0000 (40.5200)
Test (EMA): [Whole Val]  Time: 9.677  Loss: 3.7813  Acc@1: 15.6500 Pruned: 53.36% 
Train: 5 [   0/390 (  0%)]  Loss: 4.487 (4.49)  Time: 0.926s,  138.16/s  (0.926s,  138.16/s)  LR: 5.000e-04  Data: 0.613 (0.613)
Train: 5 [ 100/390 ( 26%)]  Loss: 4.238 (4.32)  Time: 0.321s,  398.81/s  (0.323s,  396.62/s)  LR: 5.000e-04  Data: 0.017 (0.020)
Train: 5 [ 200/390 ( 51%)]  Loss: 4.239 (4.27)  Time: 0.315s,  406.41/s  (0.322s,  397.15/s)  LR: 5.000e-04  Data: 0.014 (0.016)
Train: 5 [ 300/390 ( 77%)]  Loss: 4.336 (4.21)  Time: 0.314s,  407.34/s  (0.320s,  400.26/s)  LR: 5.000e-04  Data: 0.014 (0.015)
Train: 5 [ 389/390 (100%)]  Loss: 4.126 (4.16)  Time: 0.301s,  424.80/s  (0.319s,  401.35/s)  LR: 5.000e-04  Data: 0.000 (0.015)
Test: [   0/78]  Time: 0.417 (0.417)  Loss:  2.2012 (2.2012)  Acc@1: 52.3438 (52.3438)  Acc@5: 78.9062 (78.9062)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  2.1562 (2.3086)  Acc@1: 43.7500 (45.1800)  Acc@5: 75.0000 (77.2600)
Test: [Whole Val]  Time: 9.655  Loss: 2.3086  Acc@1: 45.1800 Pruned: 52.71% 
Test (EMA): [   0/78]  Time: 0.440 (0.440)  Loss:  2.1738 (2.1738)  Acc@1: 50.7812 (50.7812)  Acc@5: 83.5938 (83.5938)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  1.9980 (2.2758)  Acc@1: 56.2500 (48.2600)  Acc@5: 81.2500 (78.9700)
Test (EMA): [Whole Val]  Time: 9.713  Loss: 2.2758  Acc@1: 48.2600 Pruned: 52.72% 
Train: 6 [   0/390 (  0%)]  Loss: 4.109 (4.11)  Time: 0.760s,  168.44/s  (0.760s,  168.44/s)  LR: 6.000e-04  Data: 0.458 (0.458)
Train: 6 [ 100/390 ( 26%)]  Loss: 4.138 (3.96)  Time: 0.313s,  409.49/s  (0.320s,  399.71/s)  LR: 6.000e-04  Data: 0.013 (0.018)
Train: 6 [ 200/390 ( 51%)]  Loss: 3.750 (3.93)  Time: 0.311s,  411.39/s  (0.317s,  403.36/s)  LR: 6.000e-04  Data: 0.012 (0.015)
Train: 6 [ 300/390 ( 77%)]  Loss: 3.263 (3.92)  Time: 0.315s,  406.28/s  (0.317s,  403.25/s)  LR: 6.000e-04  Data: 0.012 (0.014)
Train: 6 [ 389/390 (100%)]  Loss: 4.352 (3.91)  Time: 0.300s,  426.88/s  (0.317s,  404.12/s)  LR: 6.000e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.328 (0.328)  Loss:  1.7920 (1.7920)  Acc@1: 53.1250 (53.1250)  Acc@5: 85.9375 (85.9375)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  1.5273 (1.8730)  Acc@1: 62.5000 (54.6300)  Acc@5: 93.7500 (84.1000)
Test: [Whole Val]  Time: 9.519  Loss: 1.8730  Acc@1: 54.6300 Pruned: 52.40% 
Test (EMA): [   0/78]  Time: 0.414 (0.414)  Loss:  1.7676 (1.7676)  Acc@1: 53.1250 (53.1250)  Acc@5: 84.3750 (84.3750)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.5020 (1.8517)  Acc@1: 62.5000 (55.5800)  Acc@5: 93.7500 (85.0300)
Test (EMA): [Whole Val]  Time: 9.598  Loss: 1.8517  Acc@1: 55.5800 Pruned: 52.42% 
Train: 7 [   0/390 (  0%)]  Loss: 3.901 (3.90)  Time: 0.943s,  135.77/s  (0.943s,  135.77/s)  LR: 7.000e-04  Data: 0.628 (0.628)
Train: 7 [ 100/390 ( 26%)]  Loss: 3.676 (3.80)  Time: 0.314s,  407.96/s  (0.323s,  395.92/s)  LR: 7.000e-04  Data: 0.012 (0.019)
Train: 7 [ 200/390 ( 51%)]  Loss: 3.662 (3.79)  Time: 0.314s,  408.17/s  (0.319s,  401.53/s)  LR: 7.000e-04  Data: 0.014 (0.015)
Train: 7 [ 300/390 ( 77%)]  Loss: 3.979 (3.78)  Time: 0.313s,  409.28/s  (0.318s,  402.48/s)  LR: 7.000e-04  Data: 0.012 (0.014)
Train: 7 [ 389/390 (100%)]  Loss: 3.099 (3.77)  Time: 0.313s,  408.96/s  (0.317s,  403.47/s)  LR: 7.000e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.320 (0.320)  Loss:  1.7012 (1.7012)  Acc@1: 63.2812 (63.2812)  Acc@5: 86.7188 (86.7188)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.5186 (1.7985)  Acc@1: 68.7500 (58.0000)  Acc@5: 93.7500 (85.6000)
Test: [Whole Val]  Time: 9.523  Loss: 1.7985  Acc@1: 58.0000 Pruned: 52.21% 
Test (EMA): [   0/78]  Time: 0.326 (0.326)  Loss:  1.6514 (1.6514)  Acc@1: 61.7188 (61.7188)  Acc@5: 85.1562 (85.1562)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.3711 (1.7278)  Acc@1: 68.7500 (59.9200)  Acc@5: 93.7500 (87.0000)
Test (EMA): [Whole Val]  Time: 9.542  Loss: 1.7278  Acc@1: 59.9200 Pruned: 52.20% 
Train: 8 [   0/390 (  0%)]  Loss: 3.004 (3.00)  Time: 0.896s,  142.85/s  (0.896s,  142.85/s)  LR: 8.000e-04  Data: 0.593 (0.593)
Train: 8 [ 100/390 ( 26%)]  Loss: 4.021 (3.73)  Time: 0.318s,  402.35/s  (0.322s,  397.44/s)  LR: 8.000e-04  Data: 0.017 (0.018)
Train: 8 [ 200/390 ( 51%)]  Loss: 4.015 (3.70)  Time: 0.315s,  405.88/s  (0.318s,  402.70/s)  LR: 8.000e-04  Data: 0.014 (0.015)
Train: 8 [ 300/390 ( 77%)]  Loss: 3.757 (3.72)  Time: 0.312s,  410.80/s  (0.316s,  404.45/s)  LR: 8.000e-04  Data: 0.011 (0.014)
Train: 8 [ 389/390 (100%)]  Loss: 4.206 (3.74)  Time: 0.301s,  425.03/s  (0.316s,  405.54/s)  LR: 8.000e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.418 (0.418)  Loss:  1.7256 (1.7256)  Acc@1: 60.9375 (60.9375)  Acc@5: 85.1562 (85.1562)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.4883 (1.7135)  Acc@1: 75.0000 (59.1800)  Acc@5: 87.5000 (87.1400)
Test: [Whole Val]  Time: 9.616  Loss: 1.7135  Acc@1: 59.1800 Pruned: 52.09% 
Test (EMA): [   0/78]  Time: 0.356 (0.356)  Loss:  1.6787 (1.6787)  Acc@1: 57.8125 (57.8125)  Acc@5: 88.2812 (88.2812)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.4121 (1.6930)  Acc@1: 81.2500 (60.8000)  Acc@5: 93.7500 (88.4300)
Test (EMA): [Whole Val]  Time: 9.563  Loss: 1.6930  Acc@1: 60.8000 Pruned: 52.09% 
Train: 9 [   0/390 (  0%)]  Loss: 4.010 (4.01)  Time: 0.868s,  147.45/s  (0.868s,  147.45/s)  LR: 9.000e-04  Data: 0.526 (0.526)
Train: 9 [ 100/390 ( 26%)]  Loss: 3.727 (3.74)  Time: 0.313s,  409.29/s  (0.319s,  400.96/s)  LR: 9.000e-04  Data: 0.012 (0.017)
Train: 9 [ 200/390 ( 51%)]  Loss: 3.226 (3.71)  Time: 0.314s,  407.77/s  (0.318s,  402.94/s)  LR: 9.000e-04  Data: 0.013 (0.015)
Train: 9 [ 300/390 ( 77%)]  Loss: 3.126 (3.71)  Time: 0.314s,  408.10/s  (0.316s,  404.86/s)  LR: 9.000e-04  Data: 0.011 (0.014)
Train: 9 [ 389/390 (100%)]  Loss: 3.220 (3.73)  Time: 0.301s,  425.64/s  (0.316s,  404.85/s)  LR: 9.000e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.341 (0.341)  Loss:  1.6885 (1.6885)  Acc@1: 58.5938 (58.5938)  Acc@5: 85.9375 (85.9375)
Test: [  78/78]  Time: 0.023 (0.121)  Loss:  1.2285 (1.7172)  Acc@1: 81.2500 (58.6500)  Acc@5: 87.5000 (86.8100)
Test: [Whole Val]  Time: 9.554  Loss: 1.7172  Acc@1: 58.6500 Pruned: 52.00% 
Test (EMA): [   0/78]  Time: 0.403 (0.403)  Loss:  1.6113 (1.6113)  Acc@1: 60.9375 (60.9375)  Acc@5: 88.2812 (88.2812)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  1.2031 (1.6534)  Acc@1: 75.0000 (61.1600)  Acc@5: 93.7500 (88.5400)
Test (EMA): [Whole Val]  Time: 9.600  Loss: 1.6534  Acc@1: 61.1600 Pruned: 52.00% 
Train: 10 [   0/390 (  0%)]  Loss: 4.042 (4.04)  Time: 0.803s,  159.32/s  (0.803s,  159.32/s)  LR: 9.915e-04  Data: 0.491 (0.491)
Train: 10 [ 100/390 ( 26%)]  Loss: 3.816 (3.71)  Time: 0.314s,  407.83/s  (0.318s,  402.32/s)  LR: 9.915e-04  Data: 0.012 (0.017)
Train: 10 [ 200/390 ( 51%)]  Loss: 3.671 (3.67)  Time: 0.314s,  407.72/s  (0.316s,  404.67/s)  LR: 9.915e-04  Data: 0.012 (0.015)
Train: 10 [ 300/390 ( 77%)]  Loss: 3.350 (3.67)  Time: 0.312s,  410.06/s  (0.316s,  405.71/s)  LR: 9.915e-04  Data: 0.013 (0.014)
Train: 10 [ 389/390 (100%)]  Loss: 3.273 (3.66)  Time: 0.301s,  424.55/s  (0.315s,  406.33/s)  LR: 9.915e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.414 (0.414)  Loss:  1.5215 (1.5215)  Acc@1: 65.6250 (65.6250)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.1533 (1.6019)  Acc@1: 87.5000 (61.4200)  Acc@5: 87.5000 (88.7500)
Test: [Whole Val]  Time: 9.611  Loss: 1.6019  Acc@1: 61.4200 Pruned: 51.88% 
Test (EMA): [   0/78]  Time: 0.386 (0.386)  Loss:  1.4834 (1.4834)  Acc@1: 62.5000 (62.5000)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.0859 (1.5149)  Acc@1: 87.5000 (63.1700)  Acc@5: 87.5000 (89.5100)
Test (EMA): [Whole Val]  Time: 9.592  Loss: 1.5149  Acc@1: 63.1700 Pruned: 51.89% 
Train: 11 [   0/390 (  0%)]  Loss: 4.153 (4.15)  Time: 0.920s,  139.08/s  (0.920s,  139.08/s)  LR: 9.897e-04  Data: 0.615 (0.615)
Train: 11 [ 100/390 ( 26%)]  Loss: 3.214 (3.65)  Time: 0.311s,  412.13/s  (0.323s,  395.77/s)  LR: 9.897e-04  Data: 0.011 (0.019)
Train: 11 [ 200/390 ( 51%)]  Loss: 3.823 (3.64)  Time: 0.330s,  387.90/s  (0.320s,  400.39/s)  LR: 9.897e-04  Data: 0.015 (0.016)
Train: 11 [ 300/390 ( 77%)]  Loss: 4.130 (3.63)  Time: 0.312s,  410.64/s  (0.318s,  402.46/s)  LR: 9.897e-04  Data: 0.012 (0.015)
Train: 11 [ 389/390 (100%)]  Loss: 3.959 (3.65)  Time: 0.301s,  425.21/s  (0.317s,  403.55/s)  LR: 9.897e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.390 (0.390)  Loss:  1.4941 (1.4941)  Acc@1: 64.8438 (64.8438)  Acc@5: 89.0625 (89.0625)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.1357 (1.5667)  Acc@1: 68.7500 (62.3300)  Acc@5: 100.0000 (88.9600)
Test: [Whole Val]  Time: 9.634  Loss: 1.5667  Acc@1: 62.3300 Pruned: 51.82% 
Test (EMA): [   0/78]  Time: 0.396 (0.396)  Loss:  1.4961 (1.4961)  Acc@1: 67.1875 (67.1875)  Acc@5: 89.0625 (89.0625)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  1.1465 (1.5367)  Acc@1: 68.7500 (64.3900)  Acc@5: 93.7500 (89.8700)
Test (EMA): [Whole Val]  Time: 9.604  Loss: 1.5367  Acc@1: 64.3900 Pruned: 51.84% 
Train: 12 [   0/390 (  0%)]  Loss: 4.125 (4.12)  Time: 0.795s,  161.11/s  (0.795s,  161.11/s)  LR: 9.878e-04  Data: 0.489 (0.489)
Train: 12 [ 100/390 ( 26%)]  Loss: 3.784 (3.67)  Time: 0.330s,  387.98/s  (0.321s,  399.11/s)  LR: 9.878e-04  Data: 0.016 (0.017)
Train: 12 [ 200/390 ( 51%)]  Loss: 3.187 (3.67)  Time: 0.314s,  408.09/s  (0.319s,  401.86/s)  LR: 9.878e-04  Data: 0.012 (0.015)
Train: 12 [ 300/390 ( 77%)]  Loss: 3.011 (3.67)  Time: 0.313s,  408.59/s  (0.318s,  402.76/s)  LR: 9.878e-04  Data: 0.012 (0.014)
Train: 12 [ 389/390 (100%)]  Loss: 3.210 (3.65)  Time: 0.301s,  425.09/s  (0.317s,  404.00/s)  LR: 9.878e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.416 (0.416)  Loss:  1.5537 (1.5537)  Acc@1: 65.6250 (65.6250)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  1.2793 (1.5943)  Acc@1: 75.0000 (63.4700)  Acc@5: 81.2500 (89.5900)
Test: [Whole Val]  Time: 9.634  Loss: 1.5943  Acc@1: 63.4700 Pruned: 51.78% 
Test (EMA): [   0/78]  Time: 0.308 (0.308)  Loss:  1.4902 (1.4902)  Acc@1: 64.8438 (64.8438)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.1611 (1.5104)  Acc@1: 75.0000 (64.8900)  Acc@5: 87.5000 (90.3100)
Test (EMA): [Whole Val]  Time: 9.563  Loss: 1.5104  Acc@1: 64.8900 Pruned: 51.78% 
Train: 13 [   0/390 (  0%)]  Loss: 2.935 (2.93)  Time: 0.796s,  160.75/s  (0.796s,  160.75/s)  LR: 9.856e-04  Data: 0.485 (0.485)
Train: 13 [ 100/390 ( 26%)]  Loss: 3.812 (3.57)  Time: 0.315s,  405.95/s  (0.318s,  402.27/s)  LR: 9.856e-04  Data: 0.014 (0.017)
Train: 13 [ 200/390 ( 51%)]  Loss: 3.054 (3.58)  Time: 0.313s,  408.39/s  (0.317s,  404.28/s)  LR: 9.856e-04  Data: 0.013 (0.015)
Train: 13 [ 300/390 ( 77%)]  Loss: 3.947 (3.58)  Time: 0.313s,  409.58/s  (0.316s,  404.91/s)  LR: 9.856e-04  Data: 0.012 (0.014)
Train: 13 [ 389/390 (100%)]  Loss: 3.749 (3.59)  Time: 0.302s,  423.67/s  (0.316s,  405.58/s)  LR: 9.856e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.318 (0.318)  Loss:  1.4834 (1.4834)  Acc@1: 66.4062 (66.4062)  Acc@5: 89.0625 (89.0625)
Test: [  78/78]  Time: 0.018 (0.121)  Loss:  1.1387 (1.5287)  Acc@1: 81.2500 (64.6000)  Acc@5: 81.2500 (90.1100)
Test: [Whole Val]  Time: 9.551  Loss: 1.5287  Acc@1: 64.6000 Pruned: 51.72% 
Test (EMA): [   0/78]  Time: 0.319 (0.319)  Loss:  1.4766 (1.4766)  Acc@1: 65.6250 (65.6250)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  1.1211 (1.5177)  Acc@1: 81.2500 (65.8700)  Acc@5: 93.7500 (90.6700)
Test (EMA): [Whole Val]  Time: 9.516  Loss: 1.5177  Acc@1: 65.8700 Pruned: 51.72% 
Train: 14 [   0/390 (  0%)]  Loss: 3.035 (3.03)  Time: 0.755s,  169.53/s  (0.755s,  169.53/s)  LR: 9.834e-04  Data: 0.452 (0.452)
Train: 14 [ 100/390 ( 26%)]  Loss: 4.007 (3.59)  Time: 0.314s,  407.21/s  (0.319s,  401.63/s)  LR: 9.834e-04  Data: 0.014 (0.017)
Train: 14 [ 200/390 ( 51%)]  Loss: 3.744 (3.58)  Time: 0.314s,  408.18/s  (0.318s,  402.97/s)  LR: 9.834e-04  Data: 0.012 (0.015)
Train: 14 [ 300/390 ( 77%)]  Loss: 3.482 (3.56)  Time: 0.328s,  390.47/s  (0.317s,  404.05/s)  LR: 9.834e-04  Data: 0.013 (0.014)
Train: 14 [ 389/390 (100%)]  Loss: 3.647 (3.57)  Time: 0.302s,  423.50/s  (0.316s,  404.70/s)  LR: 9.834e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.374 (0.374)  Loss:  1.4180 (1.4180)  Acc@1: 65.6250 (65.6250)  Acc@5: 88.2812 (88.2812)
Test: [  78/78]  Time: 0.018 (0.121)  Loss:  1.0947 (1.4629)  Acc@1: 81.2500 (64.6300)  Acc@5: 87.5000 (89.5500)
Test: [Whole Val]  Time: 9.578  Loss: 1.4629  Acc@1: 64.6300 Pruned: 51.65% 
Test (EMA): [   0/78]  Time: 0.415 (0.415)  Loss:  1.3672 (1.3672)  Acc@1: 65.6250 (65.6250)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  1.0508 (1.4150)  Acc@1: 81.2500 (66.6300)  Acc@5: 87.5000 (91.2200)
Test (EMA): [Whole Val]  Time: 9.610  Loss: 1.4150  Acc@1: 66.6300 Pruned: 51.66% 
Train: 15 [   0/390 (  0%)]  Loss: 3.011 (3.01)  Time: 0.840s,  152.33/s  (0.840s,  152.33/s)  LR: 9.809e-04  Data: 0.512 (0.512)
Train: 15 [ 100/390 ( 26%)]  Loss: 3.111 (3.53)  Time: 0.313s,  409.20/s  (0.326s,  392.35/s)  LR: 9.809e-04  Data: 0.013 (0.018)
Train: 15 [ 200/390 ( 51%)]  Loss: 3.957 (3.54)  Time: 0.315s,  405.72/s  (0.320s,  399.65/s)  LR: 9.809e-04  Data: 0.014 (0.015)
Train: 15 [ 300/390 ( 77%)]  Loss: 3.293 (3.52)  Time: 0.316s,  405.60/s  (0.318s,  402.26/s)  LR: 9.809e-04  Data: 0.013 (0.014)
Train: 15 [ 389/390 (100%)]  Loss: 3.799 (3.53)  Time: 0.301s,  425.20/s  (0.318s,  402.89/s)  LR: 9.809e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.434 (0.434)  Loss:  1.4385 (1.4385)  Acc@1: 65.6250 (65.6250)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.3164 (1.4875)  Acc@1: 68.7500 (65.0200)  Acc@5: 81.2500 (90.2000)
Test: [Whole Val]  Time: 9.638  Loss: 1.4875  Acc@1: 65.0200 Pruned: 51.61% 
Test (EMA): [   0/78]  Time: 0.361 (0.361)  Loss:  1.3975 (1.3975)  Acc@1: 67.9688 (67.9688)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.021 (0.121)  Loss:  1.1465 (1.4110)  Acc@1: 75.0000 (66.9100)  Acc@5: 87.5000 (91.3400)
Test (EMA): [Whole Val]  Time: 9.586  Loss: 1.4110  Acc@1: 66.9100 Pruned: 51.62% 
Train: 16 [   0/390 (  0%)]  Loss: 3.747 (3.75)  Time: 0.824s,  155.27/s  (0.824s,  155.27/s)  LR: 9.783e-04  Data: 0.512 (0.512)
Train: 16 [ 100/390 ( 26%)]  Loss: 3.801 (3.54)  Time: 0.320s,  399.89/s  (0.318s,  402.18/s)  LR: 9.783e-04  Data: 0.012 (0.017)
Train: 16 [ 200/390 ( 51%)]  Loss: 3.919 (3.53)  Time: 0.313s,  408.47/s  (0.316s,  404.88/s)  LR: 9.783e-04  Data: 0.011 (0.015)
Train: 16 [ 300/390 ( 77%)]  Loss: 4.043 (3.54)  Time: 0.324s,  394.71/s  (0.315s,  405.77/s)  LR: 9.783e-04  Data: 0.022 (0.014)
Train: 16 [ 389/390 (100%)]  Loss: 2.820 (3.54)  Time: 0.315s,  406.67/s  (0.315s,  405.81/s)  LR: 9.783e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.413 (0.413)  Loss:  1.4629 (1.4629)  Acc@1: 63.2812 (63.2812)  Acc@5: 89.8438 (89.8438)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  1.0527 (1.5138)  Acc@1: 81.2500 (63.7700)  Acc@5: 93.7500 (90.0900)
Test: [Whole Val]  Time: 9.618  Loss: 1.5138  Acc@1: 63.7700 Pruned: 51.55% 
Test (EMA): [   0/78]  Time: 0.315 (0.315)  Loss:  1.4092 (1.4092)  Acc@1: 66.4062 (66.4062)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9165 (1.4165)  Acc@1: 81.2500 (66.3400)  Acc@5: 93.7500 (91.3900)
Test (EMA): [Whole Val]  Time: 9.546  Loss: 1.4165  Acc@1: 66.3400 Pruned: 51.56% 
Train: 17 [   0/390 (  0%)]  Loss: 4.076 (4.08)  Time: 0.948s,  135.01/s  (0.948s,  135.01/s)  LR: 9.755e-04  Data: 0.644 (0.644)
Train: 17 [ 100/390 ( 26%)]  Loss: 3.587 (3.57)  Time: 0.313s,  408.82/s  (0.322s,  397.95/s)  LR: 9.755e-04  Data: 0.012 (0.019)
Train: 17 [ 200/390 ( 51%)]  Loss: 3.415 (3.54)  Time: 0.313s,  408.79/s  (0.318s,  402.38/s)  LR: 9.755e-04  Data: 0.012 (0.016)
Train: 17 [ 300/390 ( 77%)]  Loss: 2.780 (3.53)  Time: 0.310s,  412.29/s  (0.319s,  401.69/s)  LR: 9.755e-04  Data: 0.011 (0.015)
Train: 17 [ 389/390 (100%)]  Loss: 3.652 (3.52)  Time: 0.301s,  425.64/s  (0.318s,  402.75/s)  LR: 9.755e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.369 (0.369)  Loss:  1.3516 (1.3516)  Acc@1: 65.6250 (65.6250)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.021 (0.122)  Loss:  0.9277 (1.4056)  Acc@1: 81.2500 (65.7600)  Acc@5: 93.7500 (90.9800)
Test: [Whole Val]  Time: 9.615  Loss: 1.4056  Acc@1: 65.7600 Pruned: 51.50% 
Test (EMA): [   0/78]  Time: 0.299 (0.299)  Loss:  1.3154 (1.3154)  Acc@1: 68.7500 (68.7500)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9170 (1.3601)  Acc@1: 81.2500 (67.2700)  Acc@5: 93.7500 (91.5700)
Test (EMA): [Whole Val]  Time: 9.520  Loss: 1.3601  Acc@1: 67.2700 Pruned: 51.50% 
Train: 18 [   0/390 (  0%)]  Loss: 3.289 (3.29)  Time: 0.841s,  152.20/s  (0.841s,  152.20/s)  LR: 9.726e-04  Data: 0.501 (0.501)
Train: 18 [ 100/390 ( 26%)]  Loss: 3.645 (3.52)  Time: 0.312s,  410.69/s  (0.320s,  400.45/s)  LR: 9.726e-04  Data: 0.012 (0.018)
Train: 18 [ 200/390 ( 51%)]  Loss: 3.876 (3.51)  Time: 0.314s,  407.55/s  (0.317s,  403.82/s)  LR: 9.726e-04  Data: 0.013 (0.015)
Train: 18 [ 300/390 ( 77%)]  Loss: 3.776 (3.52)  Time: 0.332s,  385.97/s  (0.317s,  403.33/s)  LR: 9.726e-04  Data: 0.017 (0.014)
Train: 18 [ 389/390 (100%)]  Loss: 3.784 (3.52)  Time: 0.301s,  424.59/s  (0.317s,  404.28/s)  LR: 9.726e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.422 (0.422)  Loss:  1.3564 (1.3564)  Acc@1: 67.1875 (67.1875)  Acc@5: 89.0625 (89.0625)
Test: [  78/78]  Time: 0.021 (0.122)  Loss:  1.0361 (1.3780)  Acc@1: 87.5000 (66.2800)  Acc@5: 87.5000 (91.1600)
Test: [Whole Val]  Time: 9.659  Loss: 1.3780  Acc@1: 66.2800 Pruned: 51.47% 
Test (EMA): [   0/78]  Time: 0.371 (0.371)  Loss:  1.3291 (1.3291)  Acc@1: 66.4062 (66.4062)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  1.0029 (1.3298)  Acc@1: 81.2500 (67.9600)  Acc@5: 87.5000 (91.8900)
Test (EMA): [Whole Val]  Time: 9.601  Loss: 1.3298  Acc@1: 67.9600 Pruned: 51.48% 
Train: 19 [   0/390 (  0%)]  Loss: 3.698 (3.70)  Time: 0.861s,  148.63/s  (0.861s,  148.63/s)  LR: 9.695e-04  Data: 0.548 (0.548)
Train: 19 [ 100/390 ( 26%)]  Loss: 3.505 (3.52)  Time: 0.314s,  408.02/s  (0.321s,  399.36/s)  LR: 9.695e-04  Data: 0.013 (0.018)
Train: 19 [ 200/390 ( 51%)]  Loss: 3.276 (3.52)  Time: 0.311s,  411.49/s  (0.317s,  403.56/s)  LR: 9.695e-04  Data: 0.012 (0.015)
Train: 19 [ 300/390 ( 77%)]  Loss: 3.973 (3.53)  Time: 0.314s,  407.42/s  (0.316s,  404.50/s)  LR: 9.695e-04  Data: 0.013 (0.014)
Train: 19 [ 389/390 (100%)]  Loss: 3.968 (3.52)  Time: 0.314s,  407.86/s  (0.317s,  403.51/s)  LR: 9.695e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.369 (0.369)  Loss:  1.3809 (1.3809)  Acc@1: 66.4062 (66.4062)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.021 (0.122)  Loss:  1.1182 (1.4464)  Acc@1: 81.2500 (66.2500)  Acc@5: 87.5000 (91.6100)
Test: [Whole Val]  Time: 9.628  Loss: 1.4464  Acc@1: 66.2500 Pruned: 51.41% 
Test (EMA): [   0/78]  Time: 0.408 (0.408)  Loss:  1.3359 (1.3359)  Acc@1: 67.1875 (67.1875)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  1.0352 (1.3721)  Acc@1: 81.2500 (67.4000)  Acc@5: 93.7500 (92.0300)
Test (EMA): [Whole Val]  Time: 9.619  Loss: 1.3721  Acc@1: 67.4000 Pruned: 51.43% 
Train: 20 [   0/390 (  0%)]  Loss: 3.768 (3.77)  Time: 0.797s,  160.53/s  (0.797s,  160.53/s)  LR: 9.662e-04  Data: 0.479 (0.479)
Train: 20 [ 100/390 ( 26%)]  Loss: 2.763 (3.50)  Time: 0.312s,  410.12/s  (0.319s,  400.70/s)  LR: 9.662e-04  Data: 0.012 (0.017)
Train: 20 [ 200/390 ( 51%)]  Loss: 3.810 (3.45)  Time: 0.311s,  411.61/s  (0.317s,  403.79/s)  LR: 9.662e-04  Data: 0.011 (0.015)
Train: 20 [ 300/390 ( 77%)]  Loss: 2.976 (3.47)  Time: 0.314s,  407.08/s  (0.316s,  405.23/s)  LR: 9.662e-04  Data: 0.012 (0.014)
Train: 20 [ 389/390 (100%)]  Loss: 2.856 (3.49)  Time: 0.314s,  407.66/s  (0.316s,  405.18/s)  LR: 9.662e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.340 (0.340)  Loss:  1.3252 (1.3252)  Acc@1: 66.4062 (66.4062)  Acc@5: 89.0625 (89.0625)
Test: [  78/78]  Time: 0.018 (0.121)  Loss:  1.0117 (1.3336)  Acc@1: 75.0000 (67.5600)  Acc@5: 87.5000 (91.9300)
Test: [Whole Val]  Time: 9.571  Loss: 1.3336  Acc@1: 67.5600 Pruned: 51.41% 
Test (EMA): [   0/78]  Time: 0.350 (0.350)  Loss:  1.2852 (1.2852)  Acc@1: 66.4062 (66.4062)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.9775 (1.3084)  Acc@1: 75.0000 (68.5500)  Acc@5: 93.7500 (92.4600)
Test (EMA): [Whole Val]  Time: 9.634  Loss: 1.3084  Acc@1: 68.5500 Pruned: 51.41% 
Train: 21 [   0/390 (  0%)]  Loss: 3.694 (3.69)  Time: 0.756s,  169.27/s  (0.756s,  169.27/s)  LR: 9.628e-04  Data: 0.455 (0.455)
Train: 21 [ 100/390 ( 26%)]  Loss: 3.705 (3.49)  Time: 0.314s,  407.79/s  (0.321s,  398.87/s)  LR: 9.628e-04  Data: 0.012 (0.018)
Train: 21 [ 200/390 ( 51%)]  Loss: 3.652 (3.48)  Time: 0.331s,  386.17/s  (0.318s,  403.10/s)  LR: 9.628e-04  Data: 0.015 (0.015)
Train: 21 [ 300/390 ( 77%)]  Loss: 3.749 (3.47)  Time: 0.328s,  389.96/s  (0.317s,  404.33/s)  LR: 9.628e-04  Data: 0.013 (0.014)
Train: 21 [ 389/390 (100%)]  Loss: 3.694 (3.47)  Time: 0.300s,  426.46/s  (0.316s,  404.47/s)  LR: 9.628e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.364 (0.364)  Loss:  1.3057 (1.3057)  Acc@1: 66.4062 (66.4062)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.0361 (1.3374)  Acc@1: 75.0000 (67.3800)  Acc@5: 87.5000 (91.6100)
Test: [Whole Val]  Time: 9.589  Loss: 1.3374  Acc@1: 67.3800 Pruned: 51.39% 
Test (EMA): [   0/78]  Time: 0.337 (0.337)  Loss:  1.2998 (1.2998)  Acc@1: 69.5312 (69.5312)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.121)  Loss:  0.9824 (1.3276)  Acc@1: 81.2500 (68.9000)  Acc@5: 93.7500 (92.1900)
Test (EMA): [Whole Val]  Time: 9.558  Loss: 1.3276  Acc@1: 68.9000 Pruned: 51.39% 
Train: 22 [   0/390 (  0%)]  Loss: 2.994 (2.99)  Time: 0.934s,  137.00/s  (0.934s,  137.00/s)  LR: 9.592e-04  Data: 0.632 (0.632)
Train: 22 [ 100/390 ( 26%)]  Loss: 3.552 (3.48)  Time: 0.312s,  410.78/s  (0.323s,  396.82/s)  LR: 9.592e-04  Data: 0.012 (0.019)
Train: 22 [ 200/390 ( 51%)]  Loss: 3.643 (3.45)  Time: 0.313s,  408.93/s  (0.319s,  401.44/s)  LR: 9.592e-04  Data: 0.012 (0.016)
Train: 22 [ 300/390 ( 77%)]  Loss: 3.735 (3.47)  Time: 0.312s,  409.85/s  (0.317s,  403.56/s)  LR: 9.592e-04  Data: 0.012 (0.015)
Train: 22 [ 389/390 (100%)]  Loss: 3.132 (3.46)  Time: 0.304s,  420.41/s  (0.316s,  404.75/s)  LR: 9.592e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.438 (0.438)  Loss:  1.3232 (1.3232)  Acc@1: 64.8438 (64.8438)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.017 (0.123)  Loss:  1.1357 (1.3974)  Acc@1: 75.0000 (66.4300)  Acc@5: 81.2500 (91.5700)
Test: [Whole Val]  Time: 9.702  Loss: 1.3974  Acc@1: 66.4300 Pruned: 51.36% 
Test (EMA): [   0/78]  Time: 0.331 (0.331)  Loss:  1.2979 (1.2979)  Acc@1: 64.8438 (64.8438)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9727 (1.3025)  Acc@1: 81.2500 (67.9100)  Acc@5: 93.7500 (92.4300)
Test (EMA): [Whole Val]  Time: 9.593  Loss: 1.3025  Acc@1: 67.9100 Pruned: 51.37% 
Train: 23 [   0/390 (  0%)]  Loss: 3.949 (3.95)  Time: 0.846s,  151.35/s  (0.846s,  151.35/s)  LR: 9.555e-04  Data: 0.543 (0.543)
Train: 23 [ 100/390 ( 26%)]  Loss: 3.885 (3.51)  Time: 0.315s,  406.80/s  (0.321s,  398.19/s)  LR: 9.555e-04  Data: 0.013 (0.018)
Train: 23 [ 200/390 ( 51%)]  Loss: 3.488 (3.51)  Time: 0.313s,  408.98/s  (0.319s,  401.61/s)  LR: 9.555e-04  Data: 0.012 (0.016)
Train: 23 [ 300/390 ( 77%)]  Loss: 3.366 (3.48)  Time: 0.314s,  408.03/s  (0.318s,  402.79/s)  LR: 9.555e-04  Data: 0.012 (0.015)
Train: 23 [ 389/390 (100%)]  Loss: 3.978 (3.47)  Time: 0.303s,  422.02/s  (0.317s,  403.81/s)  LR: 9.555e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.315 (0.315)  Loss:  1.3135 (1.3135)  Acc@1: 67.1875 (67.1875)  Acc@5: 89.8438 (89.8438)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.8975 (1.2771)  Acc@1: 87.5000 (68.4500)  Acc@5: 93.7500 (92.2800)
Test: [Whole Val]  Time: 9.554  Loss: 1.2771  Acc@1: 68.4500 Pruned: 51.33% 
Test (EMA): [   0/78]  Time: 0.427 (0.427)  Loss:  1.2861 (1.2861)  Acc@1: 67.1875 (67.1875)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.9312 (1.2531)  Acc@1: 81.2500 (69.3200)  Acc@5: 87.5000 (92.7000)
Test (EMA): [Whole Val]  Time: 9.672  Loss: 1.2531  Acc@1: 69.3200 Pruned: 51.33% 
Train: 24 [   0/390 (  0%)]  Loss: 3.627 (3.63)  Time: 0.807s,  158.59/s  (0.807s,  158.59/s)  LR: 9.516e-04  Data: 0.503 (0.503)
Train: 24 [ 100/390 ( 26%)]  Loss: 3.126 (3.43)  Time: 0.311s,  411.08/s  (0.319s,  401.10/s)  LR: 9.516e-04  Data: 0.012 (0.018)
Train: 24 [ 200/390 ( 51%)]  Loss: 2.683 (3.42)  Time: 0.313s,  409.39/s  (0.317s,  404.32/s)  LR: 9.516e-04  Data: 0.012 (0.015)
Train: 24 [ 300/390 ( 77%)]  Loss: 3.403 (3.42)  Time: 0.313s,  408.70/s  (0.315s,  405.75/s)  LR: 9.516e-04  Data: 0.013 (0.014)
Train: 24 [ 389/390 (100%)]  Loss: 3.873 (3.43)  Time: 0.301s,  425.39/s  (0.315s,  406.46/s)  LR: 9.516e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.336 (0.336)  Loss:  1.3701 (1.3701)  Acc@1: 69.5312 (69.5312)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.0898 (1.4061)  Acc@1: 62.5000 (67.1300)  Acc@5: 93.7500 (90.8400)
Test: [Whole Val]  Time: 9.526  Loss: 1.4061  Acc@1: 67.1300 Pruned: 51.30% 
Test (EMA): [   0/78]  Time: 0.427 (0.427)  Loss:  1.2598 (1.2598)  Acc@1: 69.5312 (69.5312)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.8682 (1.2689)  Acc@1: 87.5000 (69.7200)  Acc@5: 93.7500 (92.3000)
Test (EMA): [Whole Val]  Time: 9.654  Loss: 1.2689  Acc@1: 69.7200 Pruned: 51.30% 
Train: 25 [   0/390 (  0%)]  Loss: 3.497 (3.50)  Time: 0.730s,  175.38/s  (0.730s,  175.38/s)  LR: 9.476e-04  Data: 0.424 (0.424)
Train: 25 [ 100/390 ( 26%)]  Loss: 3.128 (3.45)  Time: 0.314s,  408.26/s  (0.321s,  398.45/s)  LR: 9.476e-04  Data: 0.012 (0.016)
Train: 25 [ 200/390 ( 51%)]  Loss: 3.898 (3.46)  Time: 0.313s,  409.10/s  (0.318s,  402.30/s)  LR: 9.476e-04  Data: 0.012 (0.014)
Train: 25 [ 300/390 ( 77%)]  Loss: 3.873 (3.44)  Time: 0.313s,  408.53/s  (0.317s,  404.28/s)  LR: 9.476e-04  Data: 0.012 (0.014)
Train: 25 [ 389/390 (100%)]  Loss: 3.571 (3.45)  Time: 0.302s,  424.51/s  (0.316s,  405.30/s)  LR: 9.476e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.424 (0.424)  Loss:  1.2930 (1.2930)  Acc@1: 70.3125 (70.3125)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.9014 (1.2953)  Acc@1: 81.2500 (67.3000)  Acc@5: 87.5000 (91.3700)
Test: [Whole Val]  Time: 9.615  Loss: 1.2953  Acc@1: 67.3000 Pruned: 51.27% 
Test (EMA): [   0/78]  Time: 0.434 (0.434)  Loss:  1.2803 (1.2803)  Acc@1: 71.0938 (71.0938)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.9492 (1.2850)  Acc@1: 75.0000 (68.8300)  Acc@5: 93.7500 (92.1300)
Test (EMA): [Whole Val]  Time: 9.660  Loss: 1.2850  Acc@1: 68.8300 Pruned: 51.28% 
Train: 26 [   0/390 (  0%)]  Loss: 3.071 (3.07)  Time: 0.810s,  157.97/s  (0.810s,  157.97/s)  LR: 9.434e-04  Data: 0.498 (0.498)
Train: 26 [ 100/390 ( 26%)]  Loss: 3.633 (3.38)  Time: 0.314s,  408.11/s  (0.320s,  400.58/s)  LR: 9.434e-04  Data: 0.012 (0.017)
Train: 26 [ 200/390 ( 51%)]  Loss: 2.772 (3.40)  Time: 0.312s,  409.89/s  (0.317s,  403.82/s)  LR: 9.434e-04  Data: 0.012 (0.015)
Train: 26 [ 300/390 ( 77%)]  Loss: 3.738 (3.43)  Time: 0.315s,  406.03/s  (0.316s,  404.95/s)  LR: 9.434e-04  Data: 0.012 (0.014)
Train: 26 [ 389/390 (100%)]  Loss: 3.809 (3.42)  Time: 0.300s,  427.15/s  (0.316s,  405.42/s)  LR: 9.434e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.341 (0.341)  Loss:  1.3740 (1.3740)  Acc@1: 67.9688 (67.9688)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.9829 (1.3754)  Acc@1: 75.0000 (68.2300)  Acc@5: 100.0000 (91.8100)
Test: [Whole Val]  Time: 9.554  Loss: 1.3754  Acc@1: 68.2300 Pruned: 51.25% 
Test (EMA): [   0/78]  Time: 0.306 (0.306)  Loss:  1.2715 (1.2715)  Acc@1: 68.7500 (68.7500)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.9331 (1.2672)  Acc@1: 75.0000 (69.4000)  Acc@5: 93.7500 (92.3400)
Test (EMA): [Whole Val]  Time: 9.519  Loss: 1.2672  Acc@1: 69.4000 Pruned: 51.26% 
Train: 27 [   0/390 (  0%)]  Loss: 2.628 (2.63)  Time: 0.804s,  159.30/s  (0.804s,  159.30/s)  LR: 9.390e-04  Data: 0.501 (0.501)
Train: 27 [ 100/390 ( 26%)]  Loss: 2.563 (3.44)  Time: 0.317s,  404.12/s  (0.319s,  401.15/s)  LR: 9.390e-04  Data: 0.013 (0.017)
Train: 27 [ 200/390 ( 51%)]  Loss: 3.641 (3.45)  Time: 0.314s,  407.91/s  (0.317s,  404.38/s)  LR: 9.390e-04  Data: 0.013 (0.015)
Train: 27 [ 300/390 ( 77%)]  Loss: 3.339 (3.46)  Time: 0.317s,  403.74/s  (0.316s,  404.56/s)  LR: 9.390e-04  Data: 0.015 (0.014)
Train: 27 [ 389/390 (100%)]  Loss: 3.901 (3.48)  Time: 0.300s,  426.25/s  (0.316s,  405.22/s)  LR: 9.390e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.302 (0.302)  Loss:  1.2881 (1.2881)  Acc@1: 69.5312 (69.5312)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  1.0596 (1.3167)  Acc@1: 75.0000 (69.9700)  Acc@5: 93.7500 (92.9800)
Test: [Whole Val]  Time: 9.495  Loss: 1.3167  Acc@1: 69.9700 Pruned: 51.22% 
Test (EMA): [   0/78]  Time: 0.417 (0.417)  Loss:  1.2998 (1.2998)  Acc@1: 67.9688 (67.9688)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.021 (0.122)  Loss:  1.0342 (1.3074)  Acc@1: 81.2500 (70.1000)  Acc@5: 93.7500 (93.0200)
Test (EMA): [Whole Val]  Time: 9.651  Loss: 1.3074  Acc@1: 70.1000 Pruned: 51.22% 
Train: 28 [   0/390 (  0%)]  Loss: 2.998 (3.00)  Time: 0.906s,  141.23/s  (0.906s,  141.23/s)  LR: 9.346e-04  Data: 0.592 (0.592)
Train: 28 [ 100/390 ( 26%)]  Loss: 3.943 (3.43)  Time: 0.313s,  409.14/s  (0.320s,  399.54/s)  LR: 9.346e-04  Data: 0.012 (0.018)
Train: 28 [ 200/390 ( 51%)]  Loss: 3.906 (3.45)  Time: 0.313s,  408.87/s  (0.319s,  401.57/s)  LR: 9.346e-04  Data: 0.012 (0.015)
Train: 28 [ 300/390 ( 77%)]  Loss: 3.451 (3.44)  Time: 0.314s,  407.56/s  (0.318s,  402.02/s)  LR: 9.346e-04  Data: 0.013 (0.014)
Train: 28 [ 389/390 (100%)]  Loss: 3.420 (3.45)  Time: 0.301s,  424.89/s  (0.317s,  403.42/s)  LR: 9.346e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.403 (0.403)  Loss:  1.3086 (1.3086)  Acc@1: 67.9688 (67.9688)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.0879 (1.3283)  Acc@1: 75.0000 (68.4300)  Acc@5: 87.5000 (92.2100)
Test: [Whole Val]  Time: 9.589  Loss: 1.3283  Acc@1: 68.4300 Pruned: 51.18% 
Test (EMA): [   0/78]  Time: 0.404 (0.404)  Loss:  1.2627 (1.2627)  Acc@1: 70.3125 (70.3125)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  1.0342 (1.2887)  Acc@1: 75.0000 (70.0600)  Acc@5: 87.5000 (93.0900)
Test (EMA): [Whole Val]  Time: 9.604  Loss: 1.2887  Acc@1: 70.0600 Pruned: 51.18% 
Train: 29 [   0/390 (  0%)]  Loss: 3.490 (3.49)  Time: 0.929s,  137.72/s  (0.929s,  137.72/s)  LR: 9.299e-04  Data: 0.628 (0.628)
Train: 29 [ 100/390 ( 26%)]  Loss: 3.621 (3.41)  Time: 0.315s,  406.93/s  (0.320s,  400.15/s)  LR: 9.299e-04  Data: 0.011 (0.018)
Train: 29 [ 200/390 ( 51%)]  Loss: 3.897 (3.40)  Time: 0.313s,  408.92/s  (0.317s,  403.30/s)  LR: 9.299e-04  Data: 0.012 (0.015)
Train: 29 [ 300/390 ( 77%)]  Loss: 3.713 (3.42)  Time: 0.313s,  409.08/s  (0.316s,  404.65/s)  LR: 9.299e-04  Data: 0.012 (0.014)
Train: 29 [ 389/390 (100%)]  Loss: 3.996 (3.44)  Time: 0.302s,  424.08/s  (0.316s,  404.68/s)  LR: 9.299e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.366 (0.366)  Loss:  1.2725 (1.2725)  Acc@1: 68.7500 (68.7500)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.018 (0.121)  Loss:  1.0254 (1.2797)  Acc@1: 68.7500 (69.0500)  Acc@5: 93.7500 (92.6100)
Test: [Whole Val]  Time: 9.588  Loss: 1.2797  Acc@1: 69.0500 Pruned: 51.12% 
Test (EMA): [   0/78]  Time: 0.313 (0.313)  Loss:  1.2607 (1.2607)  Acc@1: 67.9688 (67.9688)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.0244 (1.2730)  Acc@1: 68.7500 (69.7200)  Acc@5: 93.7500 (92.8000)
Test (EMA): [Whole Val]  Time: 9.536  Loss: 1.2730  Acc@1: 69.7200 Pruned: 51.12% 
Train: 30 [   0/390 (  0%)]  Loss: 3.642 (3.64)  Time: 0.835s,  153.23/s  (0.835s,  153.23/s)  LR: 9.251e-04  Data: 0.514 (0.514)
Train: 30 [ 100/390 ( 26%)]  Loss: 3.086 (3.45)  Time: 0.317s,  403.21/s  (0.322s,  397.06/s)  LR: 9.251e-04  Data: 0.012 (0.018)
Train: 30 [ 200/390 ( 51%)]  Loss: 3.978 (3.44)  Time: 0.319s,  401.56/s  (0.318s,  402.36/s)  LR: 9.251e-04  Data: 0.012 (0.015)
Train: 30 [ 300/390 ( 77%)]  Loss: 3.597 (3.45)  Time: 0.313s,  408.74/s  (0.317s,  403.99/s)  LR: 9.251e-04  Data: 0.013 (0.014)
Train: 30 [ 389/390 (100%)]  Loss: 3.827 (3.45)  Time: 0.301s,  425.18/s  (0.316s,  404.84/s)  LR: 9.251e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.298 (0.298)  Loss:  1.2842 (1.2842)  Acc@1: 70.3125 (70.3125)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  1.0391 (1.2942)  Acc@1: 75.0000 (68.5600)  Acc@5: 81.2500 (92.3000)
Test: [Whole Val]  Time: 9.517  Loss: 1.2942  Acc@1: 68.5600 Pruned: 51.10% 
Test (EMA): [   0/78]  Time: 0.368 (0.368)  Loss:  1.2002 (1.2002)  Acc@1: 68.7500 (68.7500)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9473 (1.2259)  Acc@1: 81.2500 (70.2900)  Acc@5: 87.5000 (93.0100)
Test (EMA): [Whole Val]  Time: 9.575  Loss: 1.2259  Acc@1: 70.2900 Pruned: 51.09% 
Train: 31 [   0/390 (  0%)]  Loss: 2.912 (2.91)  Time: 0.725s,  176.46/s  (0.725s,  176.46/s)  LR: 9.202e-04  Data: 0.422 (0.422)
Train: 31 [ 100/390 ( 26%)]  Loss: 3.316 (3.41)  Time: 0.313s,  408.39/s  (0.318s,  402.13/s)  LR: 9.202e-04  Data: 0.012 (0.017)
Train: 31 [ 200/390 ( 51%)]  Loss: 4.002 (3.41)  Time: 0.311s,  410.92/s  (0.316s,  405.31/s)  LR: 9.202e-04  Data: 0.011 (0.014)
Train: 31 [ 300/390 ( 77%)]  Loss: 3.900 (3.43)  Time: 0.312s,  410.22/s  (0.315s,  406.18/s)  LR: 9.202e-04  Data: 0.012 (0.014)
Train: 31 [ 389/390 (100%)]  Loss: 3.177 (3.39)  Time: 0.315s,  406.92/s  (0.315s,  406.33/s)  LR: 9.202e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.330 (0.330)  Loss:  1.1807 (1.1807)  Acc@1: 73.4375 (73.4375)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.9565 (1.2437)  Acc@1: 75.0000 (70.0700)  Acc@5: 93.7500 (92.7200)
Test: [Whole Val]  Time: 9.545  Loss: 1.2437  Acc@1: 70.0700 Pruned: 51.06% 
Test (EMA): [   0/78]  Time: 0.416 (0.416)  Loss:  1.1787 (1.1787)  Acc@1: 72.6562 (72.6562)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.9116 (1.2181)  Acc@1: 81.2500 (70.3800)  Acc@5: 93.7500 (93.1500)
Test (EMA): [Whole Val]  Time: 9.635  Loss: 1.2181  Acc@1: 70.3800 Pruned: 51.07% 
Train: 32 [   0/390 (  0%)]  Loss: 3.604 (3.60)  Time: 0.800s,  160.01/s  (0.800s,  160.01/s)  LR: 9.151e-04  Data: 0.492 (0.492)
Train: 32 [ 100/390 ( 26%)]  Loss: 2.693 (3.37)  Time: 0.311s,  411.63/s  (0.318s,  402.15/s)  LR: 9.151e-04  Data: 0.011 (0.017)
Train: 32 [ 200/390 ( 51%)]  Loss: 3.743 (3.40)  Time: 0.316s,  405.60/s  (0.316s,  405.00/s)  LR: 9.151e-04  Data: 0.015 (0.015)
Train: 32 [ 300/390 ( 77%)]  Loss: 2.753 (3.42)  Time: 0.314s,  407.69/s  (0.316s,  405.65/s)  LR: 9.151e-04  Data: 0.013 (0.014)
Train: 32 [ 389/390 (100%)]  Loss: 3.621 (3.41)  Time: 0.302s,  423.57/s  (0.315s,  406.32/s)  LR: 9.151e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.414 (0.414)  Loss:  1.2627 (1.2627)  Acc@1: 69.5312 (69.5312)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.0967 (1.2699)  Acc@1: 68.7500 (69.3600)  Acc@5: 87.5000 (92.8000)
Test: [Whole Val]  Time: 9.620  Loss: 1.2699  Acc@1: 69.3600 Pruned: 51.02% 
Test (EMA): [   0/78]  Time: 0.404 (0.404)  Loss:  1.2197 (1.2197)  Acc@1: 69.5312 (69.5312)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  1.0459 (1.2307)  Acc@1: 68.7500 (70.8300)  Acc@5: 87.5000 (93.2900)
Test (EMA): [Whole Val]  Time: 9.635  Loss: 1.2307  Acc@1: 70.8300 Pruned: 51.02% 
Train: 33 [   0/390 (  0%)]  Loss: 3.849 (3.85)  Time: 0.792s,  161.60/s  (0.792s,  161.60/s)  LR: 9.099e-04  Data: 0.486 (0.486)
Train: 33 [ 100/390 ( 26%)]  Loss: 2.663 (3.44)  Time: 0.314s,  407.57/s  (0.320s,  400.56/s)  LR: 9.099e-04  Data: 0.012 (0.017)
Train: 33 [ 200/390 ( 51%)]  Loss: 3.341 (3.42)  Time: 0.316s,  405.18/s  (0.319s,  401.59/s)  LR: 9.099e-04  Data: 0.016 (0.015)
Train: 33 [ 300/390 ( 77%)]  Loss: 3.572 (3.42)  Time: 0.314s,  407.70/s  (0.317s,  403.21/s)  LR: 9.099e-04  Data: 0.013 (0.014)
Train: 33 [ 389/390 (100%)]  Loss: 3.577 (3.42)  Time: 0.314s,  407.15/s  (0.317s,  403.40/s)  LR: 9.099e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.307 (0.307)  Loss:  1.2451 (1.2451)  Acc@1: 65.6250 (65.6250)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.9492 (1.2615)  Acc@1: 68.7500 (69.5500)  Acc@5: 93.7500 (93.0100)
Test: [Whole Val]  Time: 9.525  Loss: 1.2615  Acc@1: 69.5500 Pruned: 51.01% 
Test (EMA): [   0/78]  Time: 0.337 (0.337)  Loss:  1.2275 (1.2275)  Acc@1: 69.5312 (69.5312)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.9976 (1.2328)  Acc@1: 68.7500 (70.8000)  Acc@5: 93.7500 (93.4800)
Test (EMA): [Whole Val]  Time: 9.640  Loss: 1.2328  Acc@1: 70.8000 Pruned: 51.00% 
Train: 34 [   0/390 (  0%)]  Loss: 3.561 (3.56)  Time: 0.723s,  177.10/s  (0.723s,  177.10/s)  LR: 9.045e-04  Data: 0.413 (0.413)
Train: 34 [ 100/390 ( 26%)]  Loss: 2.552 (3.39)  Time: 0.313s,  409.17/s  (0.319s,  401.79/s)  LR: 9.045e-04  Data: 0.012 (0.017)
Train: 34 [ 200/390 ( 51%)]  Loss: 3.793 (3.44)  Time: 0.314s,  407.04/s  (0.316s,  404.83/s)  LR: 9.045e-04  Data: 0.015 (0.015)
Train: 34 [ 300/390 ( 77%)]  Loss: 3.534 (3.43)  Time: 0.312s,  410.77/s  (0.316s,  405.68/s)  LR: 9.045e-04  Data: 0.011 (0.014)
Train: 34 [ 389/390 (100%)]  Loss: 3.967 (3.42)  Time: 0.301s,  425.00/s  (0.315s,  406.31/s)  LR: 9.045e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.375 (0.375)  Loss:  1.2314 (1.2314)  Acc@1: 67.1875 (67.1875)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.9277 (1.2499)  Acc@1: 75.0000 (69.6900)  Acc@5: 100.0000 (92.3000)
Test: [Whole Val]  Time: 9.629  Loss: 1.2499  Acc@1: 69.6900 Pruned: 50.96% 
Test (EMA): [   0/78]  Time: 0.312 (0.312)  Loss:  1.2227 (1.2227)  Acc@1: 69.5312 (69.5312)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9097 (1.2137)  Acc@1: 68.7500 (70.7300)  Acc@5: 93.7500 (93.4300)
Test (EMA): [Whole Val]  Time: 9.552  Loss: 1.2137  Acc@1: 70.7300 Pruned: 50.96% 
Train: 35 [   0/390 (  0%)]  Loss: 3.264 (3.26)  Time: 0.863s,  148.32/s  (0.863s,  148.32/s)  LR: 8.990e-04  Data: 0.551 (0.551)
Train: 35 [ 100/390 ( 26%)]  Loss: 3.088 (3.35)  Time: 0.312s,  410.21/s  (0.322s,  397.41/s)  LR: 8.990e-04  Data: 0.012 (0.018)
Train: 35 [ 200/390 ( 51%)]  Loss: 3.218 (3.37)  Time: 0.313s,  408.55/s  (0.320s,  399.58/s)  LR: 8.990e-04  Data: 0.012 (0.015)
Train: 35 [ 300/390 ( 77%)]  Loss: 3.495 (3.39)  Time: 0.315s,  406.64/s  (0.318s,  402.14/s)  LR: 8.990e-04  Data: 0.011 (0.014)
Train: 35 [ 389/390 (100%)]  Loss: 3.710 (3.42)  Time: 0.301s,  425.05/s  (0.317s,  403.69/s)  LR: 8.990e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.307 (0.307)  Loss:  1.2129 (1.2129)  Acc@1: 68.7500 (68.7500)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.1152 (1.2554)  Acc@1: 68.7500 (70.6200)  Acc@5: 87.5000 (93.3600)
Test: [Whole Val]  Time: 9.523  Loss: 1.2554  Acc@1: 70.6200 Pruned: 50.96% 
Test (EMA): [   0/78]  Time: 0.306 (0.306)  Loss:  1.2061 (1.2061)  Acc@1: 69.5312 (69.5312)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.0684 (1.2479)  Acc@1: 75.0000 (70.9700)  Acc@5: 87.5000 (93.4200)
Test (EMA): [Whole Val]  Time: 9.551  Loss: 1.2479  Acc@1: 70.9700 Pruned: 50.95% 
Train: 36 [   0/390 (  0%)]  Loss: 3.671 (3.67)  Time: 0.773s,  165.65/s  (0.773s,  165.65/s)  LR: 8.934e-04  Data: 0.469 (0.469)
Train: 36 [ 100/390 ( 26%)]  Loss: 3.901 (3.45)  Time: 0.312s,  410.78/s  (0.319s,  401.54/s)  LR: 8.934e-04  Data: 0.011 (0.017)
Train: 36 [ 200/390 ( 51%)]  Loss: 3.935 (3.44)  Time: 0.313s,  408.70/s  (0.320s,  400.56/s)  LR: 8.934e-04  Data: 0.012 (0.015)
Train: 36 [ 300/390 ( 77%)]  Loss: 2.608 (3.44)  Time: 0.313s,  408.63/s  (0.318s,  402.49/s)  LR: 8.934e-04  Data: 0.013 (0.014)
Train: 36 [ 389/390 (100%)]  Loss: 3.856 (3.45)  Time: 0.301s,  424.78/s  (0.317s,  403.87/s)  LR: 8.934e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.385 (0.385)  Loss:  1.2471 (1.2471)  Acc@1: 69.5312 (69.5312)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.0176 (1.2597)  Acc@1: 75.0000 (70.0700)  Acc@5: 93.7500 (93.3200)
Test: [Whole Val]  Time: 9.614  Loss: 1.2597  Acc@1: 70.0700 Pruned: 50.91% 
Test (EMA): [   0/78]  Time: 0.378 (0.378)  Loss:  1.2305 (1.2305)  Acc@1: 68.7500 (68.7500)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.022 (0.122)  Loss:  1.0371 (1.2465)  Acc@1: 75.0000 (71.2800)  Acc@5: 93.7500 (93.7100)
Test (EMA): [Whole Val]  Time: 9.622  Loss: 1.2465  Acc@1: 71.2800 Pruned: 50.92% 
Train: 37 [   0/390 (  0%)]  Loss: 3.770 (3.77)  Time: 0.809s,  158.28/s  (0.809s,  158.28/s)  LR: 8.876e-04  Data: 0.503 (0.503)
Train: 37 [ 100/390 ( 26%)]  Loss: 2.629 (3.36)  Time: 0.312s,  409.96/s  (0.319s,  401.58/s)  LR: 8.876e-04  Data: 0.012 (0.017)
Train: 37 [ 200/390 ( 51%)]  Loss: 3.691 (3.37)  Time: 0.314s,  407.36/s  (0.317s,  403.72/s)  LR: 8.876e-04  Data: 0.012 (0.015)
Train: 37 [ 300/390 ( 77%)]  Loss: 3.515 (3.36)  Time: 0.314s,  407.78/s  (0.316s,  405.09/s)  LR: 8.876e-04  Data: 0.013 (0.014)
Train: 37 [ 389/390 (100%)]  Loss: 2.877 (3.38)  Time: 0.302s,  423.94/s  (0.316s,  405.67/s)  LR: 8.876e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.363 (0.363)  Loss:  1.2959 (1.2959)  Acc@1: 69.5312 (69.5312)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.0459 (1.2863)  Acc@1: 75.0000 (70.0300)  Acc@5: 93.7500 (92.8100)
Test: [Whole Val]  Time: 9.584  Loss: 1.2863  Acc@1: 70.0300 Pruned: 50.90% 
Test (EMA): [   0/78]  Time: 0.397 (0.397)  Loss:  1.2607 (1.2607)  Acc@1: 67.9688 (67.9688)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  1.0127 (1.2512)  Acc@1: 75.0000 (70.5000)  Acc@5: 93.7500 (93.1700)
Test (EMA): [Whole Val]  Time: 9.610  Loss: 1.2512  Acc@1: 70.5000 Pruned: 50.91% 
Train: 38 [   0/390 (  0%)]  Loss: 3.560 (3.56)  Time: 0.799s,  160.13/s  (0.799s,  160.13/s)  LR: 8.817e-04  Data: 0.483 (0.483)
Train: 38 [ 100/390 ( 26%)]  Loss: 3.326 (3.40)  Time: 0.313s,  409.47/s  (0.318s,  402.15/s)  LR: 8.817e-04  Data: 0.012 (0.017)
Train: 38 [ 200/390 ( 51%)]  Loss: 3.104 (3.38)  Time: 0.330s,  387.69/s  (0.316s,  404.84/s)  LR: 8.817e-04  Data: 0.012 (0.015)
Train: 38 [ 300/390 ( 77%)]  Loss: 3.788 (3.40)  Time: 0.312s,  409.95/s  (0.316s,  405.05/s)  LR: 8.817e-04  Data: 0.012 (0.014)
Train: 38 [ 389/390 (100%)]  Loss: 2.700 (3.41)  Time: 0.300s,  427.28/s  (0.315s,  405.91/s)  LR: 8.817e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.371 (0.371)  Loss:  1.2715 (1.2715)  Acc@1: 71.0938 (71.0938)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.021 (0.122)  Loss:  0.9854 (1.3033)  Acc@1: 68.7500 (70.1900)  Acc@5: 87.5000 (92.9700)
Test: [Whole Val]  Time: 9.600  Loss: 1.3033  Acc@1: 70.1900 Pruned: 50.89% 
Test (EMA): [   0/78]  Time: 0.312 (0.312)  Loss:  1.2314 (1.2314)  Acc@1: 69.5312 (69.5312)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9453 (1.2575)  Acc@1: 87.5000 (71.2400)  Acc@5: 93.7500 (93.5300)
Test (EMA): [Whole Val]  Time: 9.558  Loss: 1.2575  Acc@1: 71.2400 Pruned: 50.89% 
Train: 39 [   0/390 (  0%)]  Loss: 2.770 (2.77)  Time: 0.723s,  177.16/s  (0.723s,  177.16/s)  LR: 8.757e-04  Data: 0.420 (0.420)
Train: 39 [ 100/390 ( 26%)]  Loss: 2.915 (3.28)  Time: 0.313s,  408.42/s  (0.318s,  402.48/s)  LR: 8.757e-04  Data: 0.012 (0.016)
Train: 39 [ 200/390 ( 51%)]  Loss: 3.400 (3.32)  Time: 0.314s,  407.62/s  (0.316s,  404.66/s)  LR: 8.757e-04  Data: 0.012 (0.014)
Train: 39 [ 300/390 ( 77%)]  Loss: 2.893 (3.31)  Time: 0.312s,  410.45/s  (0.316s,  405.65/s)  LR: 8.757e-04  Data: 0.012 (0.014)
Train: 39 [ 389/390 (100%)]  Loss: 3.173 (3.35)  Time: 0.317s,  404.31/s  (0.316s,  405.16/s)  LR: 8.757e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.409 (0.409)  Loss:  1.1816 (1.1816)  Acc@1: 72.6562 (72.6562)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.9268 (1.1877)  Acc@1: 75.0000 (71.2000)  Acc@5: 93.7500 (93.3500)
Test: [Whole Val]  Time: 9.658  Loss: 1.1877  Acc@1: 71.2000 Pruned: 50.91% 
Test (EMA): [   0/78]  Time: 0.395 (0.395)  Loss:  1.2227 (1.2227)  Acc@1: 71.8750 (71.8750)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.9912 (1.2285)  Acc@1: 68.7500 (70.9000)  Acc@5: 93.7500 (93.4500)
Test (EMA): [Whole Val]  Time: 9.643  Loss: 1.2285  Acc@1: 70.9000 Pruned: 50.91% 
Train: 40 [   0/390 (  0%)]  Loss: 3.789 (3.79)  Time: 0.934s,  137.02/s  (0.934s,  137.02/s)  LR: 8.695e-04  Data: 0.631 (0.631)
Train: 40 [ 100/390 ( 26%)]  Loss: 3.674 (3.44)  Time: 0.315s,  406.38/s  (0.321s,  398.53/s)  LR: 8.695e-04  Data: 0.012 (0.019)
Train: 40 [ 200/390 ( 51%)]  Loss: 3.927 (3.44)  Time: 0.312s,  410.71/s  (0.320s,  400.13/s)  LR: 8.695e-04  Data: 0.011 (0.016)
Train: 40 [ 300/390 ( 77%)]  Loss: 3.689 (3.44)  Time: 0.311s,  411.22/s  (0.319s,  401.27/s)  LR: 8.695e-04  Data: 0.012 (0.015)
Train: 40 [ 389/390 (100%)]  Loss: 3.637 (3.42)  Time: 0.298s,  428.89/s  (0.317s,  403.37/s)  LR: 8.695e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.396 (0.396)  Loss:  1.2373 (1.2373)  Acc@1: 70.3125 (70.3125)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.020 (0.123)  Loss:  0.9629 (1.2661)  Acc@1: 81.2500 (70.3700)  Acc@5: 93.7500 (92.8300)
Test: [Whole Val]  Time: 9.693  Loss: 1.2661  Acc@1: 70.3700 Pruned: 50.90% 
Test (EMA): [   0/78]  Time: 0.414 (0.414)  Loss:  1.1562 (1.1562)  Acc@1: 71.8750 (71.8750)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.8921 (1.1664)  Acc@1: 81.2500 (71.9300)  Acc@5: 93.7500 (93.6700)
Test (EMA): [Whole Val]  Time: 9.665  Loss: 1.1664  Acc@1: 71.9300 Pruned: 50.90% 
Train: 41 [   0/390 (  0%)]  Loss: 2.846 (2.85)  Time: 0.810s,  157.94/s  (0.810s,  157.94/s)  LR: 8.632e-04  Data: 0.495 (0.495)
Train: 41 [ 100/390 ( 26%)]  Loss: 2.946 (3.40)  Time: 0.313s,  409.51/s  (0.319s,  400.90/s)  LR: 8.632e-04  Data: 0.011 (0.017)
Train: 41 [ 200/390 ( 51%)]  Loss: 3.533 (3.42)  Time: 0.324s,  394.65/s  (0.317s,  403.46/s)  LR: 8.632e-04  Data: 0.020 (0.015)
Train: 41 [ 300/390 ( 77%)]  Loss: 3.028 (3.41)  Time: 0.313s,  408.75/s  (0.317s,  404.27/s)  LR: 8.632e-04  Data: 0.012 (0.014)
Train: 41 [ 389/390 (100%)]  Loss: 3.692 (3.38)  Time: 0.301s,  424.97/s  (0.316s,  404.69/s)  LR: 8.632e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.378 (0.378)  Loss:  1.1719 (1.1719)  Acc@1: 68.7500 (68.7500)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.8950 (1.1698)  Acc@1: 81.2500 (70.7100)  Acc@5: 93.7500 (93.4100)
Test: [Whole Val]  Time: 9.665  Loss: 1.1698  Acc@1: 70.7100 Pruned: 50.87% 
Test (EMA): [   0/78]  Time: 0.350 (0.350)  Loss:  1.1504 (1.1504)  Acc@1: 70.3125 (70.3125)  Acc@5: 89.8438 (89.8438)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.8696 (1.1458)  Acc@1: 75.0000 (71.7300)  Acc@5: 100.0000 (93.9500)
Test (EMA): [Whole Val]  Time: 9.635  Loss: 1.1458  Acc@1: 71.7300 Pruned: 50.87% 
Train: 42 [   0/390 (  0%)]  Loss: 2.511 (2.51)  Time: 0.867s,  147.63/s  (0.867s,  147.63/s)  LR: 8.568e-04  Data: 0.564 (0.564)
Train: 42 [ 100/390 ( 26%)]  Loss: 3.635 (3.42)  Time: 0.315s,  405.97/s  (0.321s,  399.35/s)  LR: 8.568e-04  Data: 0.014 (0.018)
Train: 42 [ 200/390 ( 51%)]  Loss: 4.043 (3.41)  Time: 0.315s,  405.89/s  (0.317s,  403.29/s)  LR: 8.568e-04  Data: 0.012 (0.016)
Train: 42 [ 300/390 ( 77%)]  Loss: 3.007 (3.40)  Time: 0.320s,  400.17/s  (0.319s,  401.85/s)  LR: 8.568e-04  Data: 0.012 (0.015)
Train: 42 [ 389/390 (100%)]  Loss: 3.200 (3.38)  Time: 0.314s,  407.62/s  (0.318s,  402.37/s)  LR: 8.568e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.318 (0.318)  Loss:  1.1943 (1.1943)  Acc@1: 67.1875 (67.1875)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.121)  Loss:  0.9492 (1.1923)  Acc@1: 81.2500 (70.6300)  Acc@5: 93.7500 (93.5300)
Test: [Whole Val]  Time: 9.566  Loss: 1.1923  Acc@1: 70.6300 Pruned: 50.89% 
Test (EMA): [   0/78]  Time: 0.329 (0.329)  Loss:  1.1611 (1.1611)  Acc@1: 68.7500 (68.7500)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.020 (0.122)  Loss:  0.9136 (1.1618)  Acc@1: 75.0000 (71.7800)  Acc@5: 93.7500 (94.0700)
Test (EMA): [Whole Val]  Time: 9.630  Loss: 1.1618  Acc@1: 71.7800 Pruned: 50.88% 
Train: 43 [   0/390 (  0%)]  Loss: 3.759 (3.76)  Time: 0.792s,  161.70/s  (0.792s,  161.70/s)  LR: 8.503e-04  Data: 0.474 (0.474)
Train: 43 [ 100/390 ( 26%)]  Loss: 2.959 (3.29)  Time: 0.314s,  407.91/s  (0.320s,  399.96/s)  LR: 8.503e-04  Data: 0.011 (0.017)
Train: 43 [ 200/390 ( 51%)]  Loss: 3.287 (3.34)  Time: 0.315s,  406.82/s  (0.319s,  401.28/s)  LR: 8.503e-04  Data: 0.012 (0.015)
Train: 43 [ 300/390 ( 77%)]  Loss: 3.510 (3.36)  Time: 0.313s,  408.49/s  (0.319s,  401.19/s)  LR: 8.503e-04  Data: 0.012 (0.015)
Train: 43 [ 389/390 (100%)]  Loss: 3.457 (3.37)  Time: 0.300s,  426.58/s  (0.318s,  402.93/s)  LR: 8.503e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.416 (0.416)  Loss:  1.1689 (1.1689)  Acc@1: 67.9688 (67.9688)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.023 (0.123)  Loss:  1.0430 (1.2188)  Acc@1: 75.0000 (70.9900)  Acc@5: 87.5000 (93.4900)
Test: [Whole Val]  Time: 9.682  Loss: 1.2188  Acc@1: 70.9900 Pruned: 50.85% 
Test (EMA): [   0/78]  Time: 0.318 (0.318)  Loss:  1.1680 (1.1680)  Acc@1: 68.7500 (68.7500)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.021 (0.121)  Loss:  1.0283 (1.1976)  Acc@1: 68.7500 (71.0900)  Acc@5: 93.7500 (93.8700)
Test (EMA): [Whole Val]  Time: 9.552  Loss: 1.1976  Acc@1: 71.0900 Pruned: 50.85% 
Train: 44 [   0/390 (  0%)]  Loss: 3.603 (3.60)  Time: 0.806s,  158.85/s  (0.806s,  158.85/s)  LR: 8.436e-04  Data: 0.500 (0.500)
Train: 44 [ 100/390 ( 26%)]  Loss: 2.511 (3.26)  Time: 0.313s,  409.16/s  (0.319s,  400.83/s)  LR: 8.436e-04  Data: 0.012 (0.017)
Train: 44 [ 200/390 ( 51%)]  Loss: 3.539 (3.36)  Time: 0.313s,  408.47/s  (0.318s,  403.00/s)  LR: 8.436e-04  Data: 0.014 (0.015)
Train: 44 [ 300/390 ( 77%)]  Loss: 3.765 (3.34)  Time: 0.312s,  409.72/s  (0.316s,  404.77/s)  LR: 8.436e-04  Data: 0.012 (0.014)
Train: 44 [ 389/390 (100%)]  Loss: 3.971 (3.36)  Time: 0.314s,  408.03/s  (0.316s,  404.43/s)  LR: 8.436e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.380 (0.380)  Loss:  1.1768 (1.1768)  Acc@1: 71.8750 (71.8750)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  1.1133 (1.2187)  Acc@1: 75.0000 (70.7000)  Acc@5: 87.5000 (93.1700)
Test: [Whole Val]  Time: 9.630  Loss: 1.2187  Acc@1: 70.7000 Pruned: 50.85% 
Test (EMA): [   0/78]  Time: 0.313 (0.313)  Loss:  1.1514 (1.1514)  Acc@1: 70.3125 (70.3125)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.0557 (1.1803)  Acc@1: 75.0000 (71.6700)  Acc@5: 87.5000 (93.8500)
Test (EMA): [Whole Val]  Time: 9.584  Loss: 1.1803  Acc@1: 71.6700 Pruned: 50.84% 
Train: 45 [   0/390 (  0%)]  Loss: 3.860 (3.86)  Time: 0.799s,  160.26/s  (0.799s,  160.26/s)  LR: 8.369e-04  Data: 0.480 (0.480)
Train: 45 [ 100/390 ( 26%)]  Loss: 3.821 (3.38)  Time: 0.312s,  409.68/s  (0.321s,  398.51/s)  LR: 8.369e-04  Data: 0.012 (0.017)
Train: 45 [ 200/390 ( 51%)]  Loss: 3.551 (3.36)  Time: 0.316s,  404.94/s  (0.317s,  403.16/s)  LR: 8.369e-04  Data: 0.015 (0.015)
Train: 45 [ 300/390 ( 77%)]  Loss: 3.795 (3.36)  Time: 0.316s,  405.44/s  (0.316s,  404.51/s)  LR: 8.369e-04  Data: 0.016 (0.014)
Train: 45 [ 389/390 (100%)]  Loss: 3.553 (3.37)  Time: 0.300s,  426.70/s  (0.316s,  405.14/s)  LR: 8.369e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.342 (0.342)  Loss:  1.2393 (1.2393)  Acc@1: 71.0938 (71.0938)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.1201 (1.2854)  Acc@1: 75.0000 (70.2600)  Acc@5: 87.5000 (92.9900)
Test: [Whole Val]  Time: 9.611  Loss: 1.2854  Acc@1: 70.2600 Pruned: 50.82% 
Test (EMA): [   0/78]  Time: 0.335 (0.335)  Loss:  1.2041 (1.2041)  Acc@1: 72.6562 (72.6562)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.0273 (1.2146)  Acc@1: 75.0000 (72.2200)  Acc@5: 93.7500 (93.7500)
Test (EMA): [Whole Val]  Time: 9.585  Loss: 1.2146  Acc@1: 72.2200 Pruned: 50.83% 
Train: 46 [   0/390 (  0%)]  Loss: 3.686 (3.69)  Time: 0.856s,  149.49/s  (0.856s,  149.49/s)  LR: 8.300e-04  Data: 0.544 (0.544)
Train: 46 [ 100/390 ( 26%)]  Loss: 2.748 (3.37)  Time: 0.311s,  411.39/s  (0.320s,  400.17/s)  LR: 8.300e-04  Data: 0.012 (0.018)
Train: 46 [ 200/390 ( 51%)]  Loss: 3.430 (3.38)  Time: 0.311s,  411.55/s  (0.318s,  402.18/s)  LR: 8.300e-04  Data: 0.011 (0.015)
Train: 46 [ 300/390 ( 77%)]  Loss: 3.719 (3.37)  Time: 0.328s,  390.40/s  (0.317s,  403.95/s)  LR: 8.300e-04  Data: 0.014 (0.014)
Train: 46 [ 389/390 (100%)]  Loss: 3.587 (3.37)  Time: 0.316s,  405.56/s  (0.317s,  404.16/s)  LR: 8.300e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.396 (0.396)  Loss:  1.1768 (1.1768)  Acc@1: 71.8750 (71.8750)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.9165 (1.1945)  Acc@1: 81.2500 (71.5000)  Acc@5: 93.7500 (93.6900)
Test: [Whole Val]  Time: 9.615  Loss: 1.1945  Acc@1: 71.5000 Pruned: 50.83% 
Test (EMA): [   0/78]  Time: 0.423 (0.423)  Loss:  1.1719 (1.1719)  Acc@1: 71.0938 (71.0938)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.9380 (1.1931)  Acc@1: 81.2500 (72.0000)  Acc@5: 93.7500 (93.9000)
Test (EMA): [Whole Val]  Time: 9.638  Loss: 1.1931  Acc@1: 72.0000 Pruned: 50.83% 
Train: 47 [   0/390 (  0%)]  Loss: 3.698 (3.70)  Time: 0.753s,  169.96/s  (0.753s,  169.96/s)  LR: 8.230e-04  Data: 0.445 (0.445)
Train: 47 [ 100/390 ( 26%)]  Loss: 3.033 (3.39)  Time: 0.310s,  412.41/s  (0.322s,  397.09/s)  LR: 8.230e-04  Data: 0.011 (0.017)
Train: 47 [ 200/390 ( 51%)]  Loss: 2.691 (3.41)  Time: 0.313s,  408.50/s  (0.318s,  402.78/s)  LR: 8.230e-04  Data: 0.012 (0.015)
Train: 47 [ 300/390 ( 77%)]  Loss: 3.086 (3.41)  Time: 0.314s,  407.46/s  (0.316s,  404.63/s)  LR: 8.230e-04  Data: 0.011 (0.014)
Train: 47 [ 389/390 (100%)]  Loss: 3.322 (3.39)  Time: 0.315s,  405.87/s  (0.316s,  404.90/s)  LR: 8.230e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.318 (0.318)  Loss:  1.1963 (1.1963)  Acc@1: 72.6562 (72.6562)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.121)  Loss:  0.9028 (1.2168)  Acc@1: 81.2500 (71.5900)  Acc@5: 93.7500 (93.7900)
Test: [Whole Val]  Time: 9.544  Loss: 1.2168  Acc@1: 71.5900 Pruned: 50.82% 
Test (EMA): [   0/78]  Time: 0.434 (0.434)  Loss:  1.1572 (1.1572)  Acc@1: 73.4375 (73.4375)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.8989 (1.1884)  Acc@1: 81.2500 (72.2500)  Acc@5: 93.7500 (94.0100)
Test (EMA): [Whole Val]  Time: 9.666  Loss: 1.1884  Acc@1: 72.2500 Pruned: 50.81% 
Train: 48 [   0/390 (  0%)]  Loss: 3.366 (3.37)  Time: 0.928s,  137.88/s  (0.928s,  137.88/s)  LR: 8.159e-04  Data: 0.627 (0.627)
Train: 48 [ 100/390 ( 26%)]  Loss: 3.838 (3.41)  Time: 0.314s,  408.28/s  (0.325s,  393.44/s)  LR: 8.159e-04  Data: 0.012 (0.019)
Train: 48 [ 200/390 ( 51%)]  Loss: 3.360 (3.40)  Time: 0.312s,  409.65/s  (0.319s,  400.68/s)  LR: 8.159e-04  Data: 0.011 (0.016)
Train: 48 [ 300/390 ( 77%)]  Loss: 3.109 (3.39)  Time: 0.312s,  409.79/s  (0.317s,  403.15/s)  LR: 8.159e-04  Data: 0.012 (0.014)
Train: 48 [ 389/390 (100%)]  Loss: 2.779 (3.37)  Time: 0.301s,  425.54/s  (0.317s,  404.37/s)  LR: 8.159e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.411 (0.411)  Loss:  1.1680 (1.1680)  Acc@1: 71.0938 (71.0938)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.9531 (1.1836)  Acc@1: 75.0000 (71.7900)  Acc@5: 93.7500 (93.5100)
Test: [Whole Val]  Time: 9.641  Loss: 1.1836  Acc@1: 71.7900 Pruned: 50.79% 
Test (EMA): [   0/78]  Time: 0.382 (0.382)  Loss:  1.1367 (1.1367)  Acc@1: 70.3125 (70.3125)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.022 (0.122)  Loss:  0.9829 (1.1601)  Acc@1: 75.0000 (72.1200)  Acc@5: 87.5000 (93.8100)
Test (EMA): [Whole Val]  Time: 9.660  Loss: 1.1601  Acc@1: 72.1200 Pruned: 50.80% 
Train: 49 [   0/390 (  0%)]  Loss: 3.629 (3.63)  Time: 0.836s,  153.17/s  (0.836s,  153.17/s)  LR: 8.087e-04  Data: 0.532 (0.532)
Train: 49 [ 100/390 ( 26%)]  Loss: 3.672 (3.34)  Time: 0.314s,  407.99/s  (0.321s,  398.56/s)  LR: 8.087e-04  Data: 0.012 (0.018)
Train: 49 [ 200/390 ( 51%)]  Loss: 2.600 (3.37)  Time: 0.314s,  407.46/s  (0.318s,  402.26/s)  LR: 8.087e-04  Data: 0.012 (0.015)
Train: 49 [ 300/390 ( 77%)]  Loss: 3.601 (3.35)  Time: 0.313s,  409.36/s  (0.317s,  403.61/s)  LR: 8.087e-04  Data: 0.013 (0.014)
Train: 49 [ 389/390 (100%)]  Loss: 3.910 (3.35)  Time: 0.300s,  426.05/s  (0.317s,  403.87/s)  LR: 8.087e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.307 (0.307)  Loss:  1.0928 (1.0928)  Acc@1: 75.0000 (75.0000)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.022 (0.121)  Loss:  0.9102 (1.1392)  Acc@1: 75.0000 (72.0100)  Acc@5: 100.0000 (94.1600)
Test: [Whole Val]  Time: 9.547  Loss: 1.1392  Acc@1: 72.0100 Pruned: 50.79% 
Test (EMA): [   0/78]  Time: 0.375 (0.375)  Loss:  1.1113 (1.1113)  Acc@1: 71.8750 (71.8750)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.8872 (1.1379)  Acc@1: 81.2500 (72.3300)  Acc@5: 100.0000 (94.0000)
Test (EMA): [Whole Val]  Time: 9.588  Loss: 1.1379  Acc@1: 72.3300 Pruned: 50.79% 
Train: 50 [   0/390 (  0%)]  Loss: 3.227 (3.23)  Time: 0.796s,  160.80/s  (0.796s,  160.80/s)  LR: 8.013e-04  Data: 0.483 (0.483)
Train: 50 [ 100/390 ( 26%)]  Loss: 3.694 (3.35)  Time: 0.313s,  409.49/s  (0.320s,  399.64/s)  LR: 8.013e-04  Data: 0.012 (0.018)
Train: 50 [ 200/390 ( 51%)]  Loss: 3.928 (3.34)  Time: 0.315s,  406.72/s  (0.318s,  402.18/s)  LR: 8.013e-04  Data: 0.013 (0.015)
Train: 50 [ 300/390 ( 77%)]  Loss: 3.314 (3.35)  Time: 0.314s,  407.60/s  (0.317s,  404.20/s)  LR: 8.013e-04  Data: 0.012 (0.014)
Train: 50 [ 389/390 (100%)]  Loss: 3.741 (3.36)  Time: 0.300s,  426.22/s  (0.316s,  405.11/s)  LR: 8.013e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.366 (0.366)  Loss:  1.0557 (1.0557)  Acc@1: 70.3125 (70.3125)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.024 (0.122)  Loss:  0.9336 (1.1272)  Acc@1: 81.2500 (71.8100)  Acc@5: 93.7500 (93.8900)
Test: [Whole Val]  Time: 9.608  Loss: 1.1272  Acc@1: 71.8100 Pruned: 50.76% 
Test (EMA): [   0/78]  Time: 0.360 (0.360)  Loss:  1.0996 (1.0996)  Acc@1: 70.3125 (70.3125)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.9517 (1.1529)  Acc@1: 81.2500 (71.9000)  Acc@5: 93.7500 (94.1500)
Test (EMA): [Whole Val]  Time: 9.602  Loss: 1.1529  Acc@1: 71.9000 Pruned: 50.77% 
Train: 51 [   0/390 (  0%)]  Loss: 2.531 (2.53)  Time: 0.857s,  149.33/s  (0.857s,  149.33/s)  LR: 7.939e-04  Data: 0.555 (0.555)
Train: 51 [ 100/390 ( 26%)]  Loss: 3.775 (3.36)  Time: 0.314s,  407.87/s  (0.320s,  399.54/s)  LR: 7.939e-04  Data: 0.014 (0.018)
Train: 51 [ 200/390 ( 51%)]  Loss: 3.425 (3.36)  Time: 0.313s,  408.94/s  (0.317s,  404.05/s)  LR: 7.939e-04  Data: 0.012 (0.015)
Train: 51 [ 300/390 ( 77%)]  Loss: 3.686 (3.36)  Time: 0.315s,  406.43/s  (0.316s,  405.07/s)  LR: 7.939e-04  Data: 0.012 (0.014)
Train: 51 [ 389/390 (100%)]  Loss: 3.696 (3.35)  Time: 0.312s,  409.86/s  (0.316s,  405.33/s)  LR: 7.939e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.426 (0.426)  Loss:  1.1396 (1.1396)  Acc@1: 72.6562 (72.6562)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.9561 (1.1364)  Acc@1: 81.2500 (71.5900)  Acc@5: 93.7500 (93.7700)
Test: [Whole Val]  Time: 9.648  Loss: 1.1364  Acc@1: 71.5900 Pruned: 50.76% 
Test (EMA): [   0/78]  Time: 0.405 (0.405)  Loss:  1.1240 (1.1240)  Acc@1: 71.0938 (71.0938)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.9478 (1.1487)  Acc@1: 81.2500 (72.4700)  Acc@5: 100.0000 (94.1400)
Test (EMA): [Whole Val]  Time: 9.630  Loss: 1.1487  Acc@1: 72.4700 Pruned: 50.75% 
Train: 52 [   0/390 (  0%)]  Loss: 3.552 (3.55)  Time: 0.816s,  156.85/s  (0.816s,  156.85/s)  LR: 7.864e-04  Data: 0.513 (0.513)
Train: 52 [ 100/390 ( 26%)]  Loss: 3.247 (3.30)  Time: 0.315s,  406.11/s  (0.320s,  399.48/s)  LR: 7.864e-04  Data: 0.014 (0.018)
Train: 52 [ 200/390 ( 51%)]  Loss: 3.802 (3.35)  Time: 0.313s,  408.77/s  (0.317s,  403.42/s)  LR: 7.864e-04  Data: 0.013 (0.015)
Train: 52 [ 300/390 ( 77%)]  Loss: 3.648 (3.34)  Time: 0.318s,  402.06/s  (0.316s,  404.95/s)  LR: 7.864e-04  Data: 0.018 (0.014)
Train: 52 [ 389/390 (100%)]  Loss: 3.708 (3.35)  Time: 0.301s,  424.70/s  (0.316s,  405.22/s)  LR: 7.864e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.399 (0.399)  Loss:  1.1943 (1.1943)  Acc@1: 71.8750 (71.8750)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.0049 (1.2199)  Acc@1: 68.7500 (71.5500)  Acc@5: 100.0000 (93.5900)
Test: [Whole Val]  Time: 9.631  Loss: 1.2199  Acc@1: 71.5500 Pruned: 50.75% 
Test (EMA): [   0/78]  Time: 0.431 (0.431)  Loss:  1.1436 (1.1436)  Acc@1: 72.6562 (72.6562)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  0.9844 (1.1745)  Acc@1: 75.0000 (72.4600)  Acc@5: 93.7500 (93.9700)
Test (EMA): [Whole Val]  Time: 9.679  Loss: 1.1745  Acc@1: 72.4600 Pruned: 50.75% 
Train: 53 [   0/390 (  0%)]  Loss: 2.997 (3.00)  Time: 0.820s,  156.07/s  (0.820s,  156.07/s)  LR: 7.788e-04  Data: 0.519 (0.519)
Train: 53 [ 100/390 ( 26%)]  Loss: 3.657 (3.33)  Time: 0.314s,  407.79/s  (0.320s,  399.78/s)  LR: 7.788e-04  Data: 0.013 (0.018)
Train: 53 [ 200/390 ( 51%)]  Loss: 3.533 (3.32)  Time: 0.314s,  408.03/s  (0.317s,  404.05/s)  LR: 7.788e-04  Data: 0.012 (0.015)
Train: 53 [ 300/390 ( 77%)]  Loss: 3.643 (3.34)  Time: 0.313s,  409.04/s  (0.317s,  404.08/s)  LR: 7.788e-04  Data: 0.013 (0.014)
Train: 53 [ 389/390 (100%)]  Loss: 3.867 (3.34)  Time: 0.301s,  425.25/s  (0.316s,  404.50/s)  LR: 7.788e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.315 (0.315)  Loss:  1.1230 (1.1230)  Acc@1: 69.5312 (69.5312)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.0234 (1.1636)  Acc@1: 68.7500 (72.0400)  Acc@5: 93.7500 (93.7400)
Test: [Whole Val]  Time: 9.588  Loss: 1.1636  Acc@1: 72.0400 Pruned: 50.75% 
Test (EMA): [   0/78]  Time: 0.311 (0.311)  Loss:  1.1094 (1.1094)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9688 (1.1558)  Acc@1: 75.0000 (72.9000)  Acc@5: 93.7500 (94.1100)
Test (EMA): [Whole Val]  Time: 9.542  Loss: 1.1558  Acc@1: 72.9000 Pruned: 50.75% 
Train: 54 [   0/390 (  0%)]  Loss: 3.145 (3.14)  Time: 0.844s,  151.68/s  (0.844s,  151.68/s)  LR: 7.710e-04  Data: 0.541 (0.541)
Train: 54 [ 100/390 ( 26%)]  Loss: 3.312 (3.41)  Time: 0.312s,  410.26/s  (0.320s,  399.64/s)  LR: 7.710e-04  Data: 0.011 (0.018)
Train: 54 [ 200/390 ( 51%)]  Loss: 2.585 (3.39)  Time: 0.315s,  406.19/s  (0.318s,  402.42/s)  LR: 7.710e-04  Data: 0.012 (0.015)
Train: 54 [ 300/390 ( 77%)]  Loss: 3.975 (3.39)  Time: 0.313s,  409.12/s  (0.316s,  404.46/s)  LR: 7.710e-04  Data: 0.012 (0.014)
Train: 54 [ 389/390 (100%)]  Loss: 3.951 (3.39)  Time: 0.301s,  425.39/s  (0.316s,  405.31/s)  LR: 7.710e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.407 (0.407)  Loss:  1.2080 (1.2080)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.0068 (1.2422)  Acc@1: 81.2500 (71.9200)  Acc@5: 87.5000 (93.5800)
Test: [Whole Val]  Time: 9.664  Loss: 1.2422  Acc@1: 71.9200 Pruned: 50.74% 
Test (EMA): [   0/78]  Time: 0.323 (0.323)  Loss:  1.1826 (1.1826)  Acc@1: 75.7812 (75.7812)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.0176 (1.2266)  Acc@1: 81.2500 (72.3900)  Acc@5: 93.7500 (94.0300)
Test (EMA): [Whole Val]  Time: 9.578  Loss: 1.2266  Acc@1: 72.3900 Pruned: 50.74% 
Train: 55 [   0/390 (  0%)]  Loss: 3.248 (3.25)  Time: 0.777s,  164.76/s  (0.777s,  164.76/s)  LR: 7.632e-04  Data: 0.472 (0.472)
Train: 55 [ 100/390 ( 26%)]  Loss: 3.959 (3.39)  Time: 0.313s,  408.52/s  (0.320s,  399.89/s)  LR: 7.632e-04  Data: 0.012 (0.017)
Train: 55 [ 200/390 ( 51%)]  Loss: 2.303 (3.36)  Time: 0.312s,  410.15/s  (0.319s,  401.64/s)  LR: 7.632e-04  Data: 0.012 (0.015)
Train: 55 [ 300/390 ( 77%)]  Loss: 3.658 (3.33)  Time: 0.312s,  410.65/s  (0.317s,  403.72/s)  LR: 7.632e-04  Data: 0.011 (0.014)
Train: 55 [ 389/390 (100%)]  Loss: 3.703 (3.33)  Time: 0.302s,  423.43/s  (0.316s,  404.76/s)  LR: 7.632e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.332 (0.332)  Loss:  1.2100 (1.2100)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.0137 (1.2039)  Acc@1: 75.0000 (72.0600)  Acc@5: 93.7500 (93.9000)
Test: [Whole Val]  Time: 9.594  Loss: 1.2039  Acc@1: 72.0600 Pruned: 50.73% 
Test (EMA): [   0/78]  Time: 0.329 (0.329)  Loss:  1.1533 (1.1533)  Acc@1: 71.0938 (71.0938)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.9761 (1.1693)  Acc@1: 81.2500 (72.6200)  Acc@5: 93.7500 (93.9800)
Test (EMA): [Whole Val]  Time: 9.617  Loss: 1.1693  Acc@1: 72.6200 Pruned: 50.73% 
Train: 56 [   0/390 (  0%)]  Loss: 3.091 (3.09)  Time: 0.856s,  149.55/s  (0.856s,  149.55/s)  LR: 7.553e-04  Data: 0.536 (0.536)
Train: 56 [ 100/390 ( 26%)]  Loss: 3.540 (3.38)  Time: 0.312s,  410.63/s  (0.322s,  397.78/s)  LR: 7.553e-04  Data: 0.012 (0.018)
Train: 56 [ 200/390 ( 51%)]  Loss: 2.783 (3.35)  Time: 0.315s,  406.80/s  (0.318s,  402.61/s)  LR: 7.553e-04  Data: 0.012 (0.015)
Train: 56 [ 300/390 ( 77%)]  Loss: 2.837 (3.33)  Time: 0.313s,  409.27/s  (0.317s,  404.03/s)  LR: 7.553e-04  Data: 0.011 (0.014)
Train: 56 [ 389/390 (100%)]  Loss: 2.859 (3.36)  Time: 0.301s,  425.36/s  (0.316s,  404.89/s)  LR: 7.553e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.406 (0.406)  Loss:  1.1416 (1.1416)  Acc@1: 69.5312 (69.5312)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.9844 (1.1533)  Acc@1: 68.7500 (72.0300)  Acc@5: 93.7500 (93.9700)
Test: [Whole Val]  Time: 9.658  Loss: 1.1533  Acc@1: 72.0300 Pruned: 50.73% 
Test (EMA): [   0/78]  Time: 0.326 (0.326)  Loss:  1.1445 (1.1445)  Acc@1: 71.0938 (71.0938)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.021 (0.122)  Loss:  0.9912 (1.1679)  Acc@1: 75.0000 (72.1400)  Acc@5: 93.7500 (94.1600)
Test (EMA): [Whole Val]  Time: 9.601  Loss: 1.1679  Acc@1: 72.1400 Pruned: 50.72% 
Train: 57 [   0/390 (  0%)]  Loss: 3.718 (3.72)  Time: 0.756s,  169.22/s  (0.756s,  169.22/s)  LR: 7.474e-04  Data: 0.452 (0.452)
Train: 57 [ 100/390 ( 26%)]  Loss: 2.642 (3.37)  Time: 0.314s,  407.69/s  (0.319s,  401.56/s)  LR: 7.474e-04  Data: 0.012 (0.017)
Train: 57 [ 200/390 ( 51%)]  Loss: 3.541 (3.36)  Time: 0.334s,  383.78/s  (0.316s,  404.46/s)  LR: 7.474e-04  Data: 0.011 (0.015)
Train: 57 [ 300/390 ( 77%)]  Loss: 2.675 (3.37)  Time: 0.315s,  405.88/s  (0.316s,  404.81/s)  LR: 7.474e-04  Data: 0.014 (0.014)
Train: 57 [ 389/390 (100%)]  Loss: 3.104 (3.37)  Time: 0.301s,  425.17/s  (0.316s,  404.75/s)  LR: 7.474e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.397 (0.397)  Loss:  1.1064 (1.1064)  Acc@1: 70.3125 (70.3125)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.9351 (1.1095)  Acc@1: 75.0000 (71.9800)  Acc@5: 87.5000 (93.6100)
Test: [Whole Val]  Time: 9.639  Loss: 1.1095  Acc@1: 71.9800 Pruned: 50.71% 
Test (EMA): [   0/78]  Time: 0.387 (0.387)  Loss:  1.1152 (1.1152)  Acc@1: 70.3125 (70.3125)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.9536 (1.1367)  Acc@1: 81.2500 (72.4400)  Acc@5: 93.7500 (94.0900)
Test (EMA): [Whole Val]  Time: 9.677  Loss: 1.1367  Acc@1: 72.4400 Pruned: 50.71% 
Train: 58 [   0/390 (  0%)]  Loss: 2.841 (2.84)  Time: 0.806s,  158.84/s  (0.806s,  158.84/s)  LR: 7.393e-04  Data: 0.500 (0.500)
Train: 58 [ 100/390 ( 26%)]  Loss: 2.914 (3.34)  Time: 0.315s,  406.66/s  (0.319s,  401.11/s)  LR: 7.393e-04  Data: 0.012 (0.017)
Train: 58 [ 200/390 ( 51%)]  Loss: 3.421 (3.30)  Time: 0.317s,  404.22/s  (0.317s,  403.91/s)  LR: 7.393e-04  Data: 0.013 (0.015)
Train: 58 [ 300/390 ( 77%)]  Loss: 3.622 (3.28)  Time: 0.314s,  407.22/s  (0.318s,  403.06/s)  LR: 7.393e-04  Data: 0.013 (0.014)
Train: 58 [ 389/390 (100%)]  Loss: 3.718 (3.29)  Time: 0.300s,  427.28/s  (0.318s,  402.24/s)  LR: 7.393e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.312 (0.312)  Loss:  1.1807 (1.1807)  Acc@1: 69.5312 (69.5312)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  0.8955 (1.1882)  Acc@1: 81.2500 (71.9900)  Acc@5: 100.0000 (93.9300)
Test: [Whole Val]  Time: 9.516  Loss: 1.1882  Acc@1: 71.9900 Pruned: 50.70% 
Test (EMA): [   0/78]  Time: 0.341 (0.341)  Loss:  1.1357 (1.1357)  Acc@1: 71.8750 (71.8750)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  0.9062 (1.1424)  Acc@1: 75.0000 (72.8700)  Acc@5: 93.7500 (94.3000)
Test (EMA): [Whole Val]  Time: 9.678  Loss: 1.1424  Acc@1: 72.8700 Pruned: 50.70% 
Train: 59 [   0/390 (  0%)]  Loss: 2.908 (2.91)  Time: 0.757s,  169.16/s  (0.757s,  169.16/s)  LR: 7.311e-04  Data: 0.453 (0.453)
Train: 59 [ 100/390 ( 26%)]  Loss: 3.558 (3.31)  Time: 0.316s,  405.35/s  (0.320s,  400.38/s)  LR: 7.311e-04  Data: 0.014 (0.017)
Train: 59 [ 200/390 ( 51%)]  Loss: 3.429 (3.35)  Time: 0.313s,  409.43/s  (0.319s,  401.20/s)  LR: 7.311e-04  Data: 0.011 (0.015)
Train: 59 [ 300/390 ( 77%)]  Loss: 3.884 (3.36)  Time: 0.313s,  408.85/s  (0.317s,  403.30/s)  LR: 7.311e-04  Data: 0.012 (0.014)
Train: 59 [ 389/390 (100%)]  Loss: 3.660 (3.37)  Time: 0.300s,  426.70/s  (0.317s,  403.97/s)  LR: 7.311e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.383 (0.383)  Loss:  1.0947 (1.0947)  Acc@1: 70.3125 (70.3125)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.9023 (1.1352)  Acc@1: 75.0000 (71.8900)  Acc@5: 93.7500 (93.7800)
Test: [Whole Val]  Time: 9.639  Loss: 1.1352  Acc@1: 71.8900 Pruned: 50.70% 
Test (EMA): [   0/78]  Time: 0.432 (0.432)  Loss:  1.1084 (1.1084)  Acc@1: 71.8750 (71.8750)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  0.9473 (1.1248)  Acc@1: 68.7500 (72.7000)  Acc@5: 93.7500 (94.1900)
Test (EMA): [Whole Val]  Time: 9.682  Loss: 1.1248  Acc@1: 72.7000 Pruned: 50.70% 
Train: 60 [   0/390 (  0%)]  Loss: 3.363 (3.36)  Time: 0.990s,  129.23/s  (0.990s,  129.23/s)  LR: 7.229e-04  Data: 0.689 (0.689)
Train: 60 [ 100/390 ( 26%)]  Loss: 3.853 (3.42)  Time: 0.315s,  405.81/s  (0.322s,  397.40/s)  LR: 7.229e-04  Data: 0.013 (0.020)
Train: 60 [ 200/390 ( 51%)]  Loss: 3.265 (3.39)  Time: 0.316s,  405.31/s  (0.318s,  402.71/s)  LR: 7.229e-04  Data: 0.012 (0.016)
Train: 60 [ 300/390 ( 77%)]  Loss: 3.686 (3.37)  Time: 0.316s,  405.51/s  (0.316s,  404.57/s)  LR: 7.229e-04  Data: 0.014 (0.015)
Train: 60 [ 389/390 (100%)]  Loss: 3.727 (3.38)  Time: 0.301s,  425.16/s  (0.316s,  405.51/s)  LR: 7.229e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.321 (0.321)  Loss:  1.1562 (1.1562)  Acc@1: 71.8750 (71.8750)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.021 (0.121)  Loss:  0.9419 (1.1871)  Acc@1: 75.0000 (72.5500)  Acc@5: 93.7500 (94.0000)
Test: [Whole Val]  Time: 9.569  Loss: 1.1871  Acc@1: 72.5500 Pruned: 50.70% 
Test (EMA): [   0/78]  Time: 0.455 (0.455)  Loss:  1.1357 (1.1357)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  0.9429 (1.1553)  Acc@1: 75.0000 (73.1900)  Acc@5: 93.7500 (94.2000)
Test (EMA): [Whole Val]  Time: 9.689  Loss: 1.1553  Acc@1: 73.1900 Pruned: 50.71% 
Train: 61 [   0/390 (  0%)]  Loss: 3.053 (3.05)  Time: 0.797s,  160.69/s  (0.797s,  160.69/s)  LR: 7.146e-04  Data: 0.494 (0.494)
Train: 61 [ 100/390 ( 26%)]  Loss: 2.992 (3.34)  Time: 0.329s,  389.50/s  (0.320s,  399.81/s)  LR: 7.146e-04  Data: 0.014 (0.017)
Train: 61 [ 200/390 ( 51%)]  Loss: 3.294 (3.36)  Time: 0.314s,  408.16/s  (0.322s,  397.84/s)  LR: 7.146e-04  Data: 0.012 (0.015)
Train: 61 [ 300/390 ( 77%)]  Loss: 2.445 (3.35)  Time: 0.313s,  409.45/s  (0.319s,  401.22/s)  LR: 7.146e-04  Data: 0.012 (0.014)
Train: 61 [ 389/390 (100%)]  Loss: 3.792 (3.35)  Time: 0.301s,  425.59/s  (0.318s,  403.01/s)  LR: 7.146e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.320 (0.320)  Loss:  1.1348 (1.1348)  Acc@1: 68.7500 (68.7500)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.024 (0.121)  Loss:  0.9873 (1.1542)  Acc@1: 75.0000 (72.3000)  Acc@5: 93.7500 (94.1400)
Test: [Whole Val]  Time: 9.560  Loss: 1.1542  Acc@1: 72.3000 Pruned: 50.69% 
Test (EMA): [   0/78]  Time: 0.325 (0.325)  Loss:  1.1240 (1.1240)  Acc@1: 69.5312 (69.5312)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9478 (1.1381)  Acc@1: 81.2500 (72.8200)  Acc@5: 100.0000 (94.2700)
Test (EMA): [Whole Val]  Time: 9.565  Loss: 1.1381  Acc@1: 72.8200 Pruned: 50.69% 
Train: 62 [   0/390 (  0%)]  Loss: 3.503 (3.50)  Time: 0.923s,  138.69/s  (0.923s,  138.69/s)  LR: 7.062e-04  Data: 0.621 (0.621)
Train: 62 [ 100/390 ( 26%)]  Loss: 3.783 (3.40)  Time: 0.317s,  403.48/s  (0.322s,  397.69/s)  LR: 7.062e-04  Data: 0.014 (0.018)
Train: 62 [ 200/390 ( 51%)]  Loss: 3.748 (3.40)  Time: 0.312s,  410.01/s  (0.318s,  402.62/s)  LR: 7.062e-04  Data: 0.011 (0.015)
Train: 62 [ 300/390 ( 77%)]  Loss: 3.301 (3.37)  Time: 0.314s,  407.33/s  (0.317s,  404.01/s)  LR: 7.062e-04  Data: 0.013 (0.014)
Train: 62 [ 389/390 (100%)]  Loss: 3.659 (3.37)  Time: 0.301s,  424.73/s  (0.316s,  404.82/s)  LR: 7.062e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.301 (0.301)  Loss:  1.1094 (1.1094)  Acc@1: 71.0938 (71.0938)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.9541 (1.1384)  Acc@1: 68.7500 (73.0500)  Acc@5: 100.0000 (94.4200)
Test: [Whole Val]  Time: 9.566  Loss: 1.1384  Acc@1: 73.0500 Pruned: 50.69% 
Test (EMA): [   0/78]  Time: 0.416 (0.416)  Loss:  1.0879 (1.0879)  Acc@1: 72.6562 (72.6562)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.9800 (1.1150)  Acc@1: 68.7500 (73.1300)  Acc@5: 100.0000 (94.5000)
Test (EMA): [Whole Val]  Time: 9.675  Loss: 1.1150  Acc@1: 73.1300 Pruned: 50.69% 
Train: 63 [   0/390 (  0%)]  Loss: 3.589 (3.59)  Time: 0.833s,  153.58/s  (0.833s,  153.58/s)  LR: 6.978e-04  Data: 0.527 (0.527)
Train: 63 [ 100/390 ( 26%)]  Loss: 3.434 (3.36)  Time: 0.327s,  391.01/s  (0.321s,  398.29/s)  LR: 6.978e-04  Data: 0.013 (0.018)
Train: 63 [ 200/390 ( 51%)]  Loss: 3.217 (3.38)  Time: 0.313s,  409.35/s  (0.318s,  402.84/s)  LR: 6.978e-04  Data: 0.012 (0.015)
Train: 63 [ 300/390 ( 77%)]  Loss: 3.609 (3.36)  Time: 0.326s,  392.47/s  (0.317s,  404.30/s)  LR: 6.978e-04  Data: 0.012 (0.014)
Train: 63 [ 389/390 (100%)]  Loss: 3.299 (3.34)  Time: 0.313s,  408.63/s  (0.317s,  403.96/s)  LR: 6.978e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.423 (0.423)  Loss:  1.1055 (1.1055)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.9150 (1.1485)  Acc@1: 81.2500 (72.5900)  Acc@5: 93.7500 (93.8200)
Test: [Whole Val]  Time: 9.646  Loss: 1.1485  Acc@1: 72.5900 Pruned: 50.68% 
Test (EMA): [   0/78]  Time: 0.348 (0.348)  Loss:  1.0889 (1.0889)  Acc@1: 72.6562 (72.6562)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9023 (1.1108)  Acc@1: 75.0000 (73.3000)  Acc@5: 93.7500 (94.2600)
Test (EMA): [Whole Val]  Time: 9.585  Loss: 1.1108  Acc@1: 73.3000 Pruned: 50.68% 
Train: 64 [   0/390 (  0%)]  Loss: 2.994 (2.99)  Time: 0.744s,  172.04/s  (0.744s,  172.04/s)  LR: 6.892e-04  Data: 0.433 (0.433)
Train: 64 [ 100/390 ( 26%)]  Loss: 3.744 (3.27)  Time: 0.314s,  407.34/s  (0.318s,  402.58/s)  LR: 6.892e-04  Data: 0.012 (0.016)
Train: 64 [ 200/390 ( 51%)]  Loss: 3.784 (3.30)  Time: 0.312s,  410.23/s  (0.316s,  405.13/s)  LR: 6.892e-04  Data: 0.012 (0.014)
Train: 64 [ 300/390 ( 77%)]  Loss: 2.632 (3.33)  Time: 0.319s,  401.70/s  (0.315s,  406.06/s)  LR: 6.892e-04  Data: 0.016 (0.014)
Train: 64 [ 389/390 (100%)]  Loss: 3.847 (3.32)  Time: 0.301s,  424.77/s  (0.315s,  406.66/s)  LR: 6.892e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.401 (0.401)  Loss:  1.1309 (1.1309)  Acc@1: 71.0938 (71.0938)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.9961 (1.1814)  Acc@1: 68.7500 (72.1900)  Acc@5: 93.7500 (93.7900)
Test: [Whole Val]  Time: 9.629  Loss: 1.1814  Acc@1: 72.1900 Pruned: 50.65% 
Test (EMA): [   0/78]  Time: 0.409 (0.409)  Loss:  1.0996 (1.0996)  Acc@1: 71.8750 (71.8750)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.9551 (1.1368)  Acc@1: 75.0000 (72.8400)  Acc@5: 100.0000 (94.4400)
Test (EMA): [Whole Val]  Time: 9.637  Loss: 1.1368  Acc@1: 72.8400 Pruned: 50.65% 
Train: 65 [   0/390 (  0%)]  Loss: 3.748 (3.75)  Time: 0.785s,  163.04/s  (0.785s,  163.04/s)  LR: 6.807e-04  Data: 0.483 (0.483)
Train: 65 [ 100/390 ( 26%)]  Loss: 2.611 (3.35)  Time: 0.313s,  408.30/s  (0.319s,  401.75/s)  LR: 6.807e-04  Data: 0.012 (0.017)
Train: 65 [ 200/390 ( 51%)]  Loss: 3.031 (3.35)  Time: 0.313s,  408.87/s  (0.316s,  404.76/s)  LR: 6.807e-04  Data: 0.012 (0.015)
Train: 65 [ 300/390 ( 77%)]  Loss: 2.882 (3.35)  Time: 0.316s,  404.73/s  (0.316s,  404.95/s)  LR: 6.807e-04  Data: 0.016 (0.014)
Train: 65 [ 389/390 (100%)]  Loss: 2.871 (3.33)  Time: 0.301s,  424.61/s  (0.316s,  405.61/s)  LR: 6.807e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.388 (0.388)  Loss:  1.1309 (1.1309)  Acc@1: 72.6562 (72.6562)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.9531 (1.1630)  Acc@1: 75.0000 (72.5800)  Acc@5: 93.7500 (93.9700)
Test: [Whole Val]  Time: 9.609  Loss: 1.1630  Acc@1: 72.5800 Pruned: 50.66% 
Test (EMA): [   0/78]  Time: 0.323 (0.323)  Loss:  1.1045 (1.1045)  Acc@1: 71.8750 (71.8750)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9087 (1.1370)  Acc@1: 81.2500 (72.9700)  Acc@5: 93.7500 (94.2100)
Test (EMA): [Whole Val]  Time: 9.543  Loss: 1.1370  Acc@1: 72.9700 Pruned: 50.66% 
Train: 66 [   0/390 (  0%)]  Loss: 3.389 (3.39)  Time: 0.746s,  171.55/s  (0.746s,  171.55/s)  LR: 6.720e-04  Data: 0.426 (0.426)
Train: 66 [ 100/390 ( 26%)]  Loss: 3.122 (3.37)  Time: 0.313s,  409.17/s  (0.321s,  398.15/s)  LR: 6.720e-04  Data: 0.012 (0.017)
Train: 66 [ 200/390 ( 51%)]  Loss: 2.628 (3.34)  Time: 0.311s,  411.06/s  (0.318s,  402.50/s)  LR: 6.720e-04  Data: 0.011 (0.015)
Train: 66 [ 300/390 ( 77%)]  Loss: 2.575 (3.34)  Time: 0.315s,  406.90/s  (0.317s,  403.51/s)  LR: 6.720e-04  Data: 0.014 (0.014)
Train: 66 [ 389/390 (100%)]  Loss: 2.530 (3.33)  Time: 0.300s,  426.04/s  (0.316s,  404.65/s)  LR: 6.720e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.326 (0.326)  Loss:  1.1494 (1.1494)  Acc@1: 71.8750 (71.8750)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.9062 (1.1465)  Acc@1: 75.0000 (73.0600)  Acc@5: 93.7500 (94.1600)
Test: [Whole Val]  Time: 9.537  Loss: 1.1465  Acc@1: 73.0600 Pruned: 50.65% 
Test (EMA): [   0/78]  Time: 0.448 (0.448)  Loss:  1.1162 (1.1162)  Acc@1: 70.3125 (70.3125)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  0.9243 (1.1343)  Acc@1: 75.0000 (73.1300)  Acc@5: 100.0000 (94.3400)
Test (EMA): [Whole Val]  Time: 9.680  Loss: 1.1343  Acc@1: 73.1300 Pruned: 50.65% 
Train: 67 [   0/390 (  0%)]  Loss: 3.563 (3.56)  Time: 0.871s,  146.93/s  (0.871s,  146.93/s)  LR: 6.633e-04  Data: 0.570 (0.570)
Train: 67 [ 100/390 ( 26%)]  Loss: 2.878 (3.41)  Time: 0.313s,  409.16/s  (0.319s,  401.60/s)  LR: 6.633e-04  Data: 0.012 (0.018)
Train: 67 [ 200/390 ( 51%)]  Loss: 3.348 (3.33)  Time: 0.316s,  405.30/s  (0.316s,  404.97/s)  LR: 6.633e-04  Data: 0.015 (0.015)
Train: 67 [ 300/390 ( 77%)]  Loss: 2.464 (3.30)  Time: 0.323s,  396.59/s  (0.315s,  406.16/s)  LR: 6.633e-04  Data: 0.022 (0.014)
Train: 67 [ 389/390 (100%)]  Loss: 3.716 (3.32)  Time: 0.300s,  426.57/s  (0.315s,  406.37/s)  LR: 6.633e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.358 (0.358)  Loss:  1.2188 (1.2188)  Acc@1: 71.0938 (71.0938)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.121)  Loss:  0.9639 (1.2170)  Acc@1: 81.2500 (71.9100)  Acc@5: 93.7500 (93.5900)
Test: [Whole Val]  Time: 9.542  Loss: 1.2170  Acc@1: 71.9100 Pruned: 50.65% 
Test (EMA): [   0/78]  Time: 0.418 (0.418)  Loss:  1.1230 (1.1230)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.8984 (1.1351)  Acc@1: 81.2500 (73.0000)  Acc@5: 100.0000 (94.3700)
Test (EMA): [Whole Val]  Time: 9.649  Loss: 1.1351  Acc@1: 73.0000 Pruned: 50.66% 
Train: 68 [   0/390 (  0%)]  Loss: 3.666 (3.67)  Time: 0.917s,  139.65/s  (0.917s,  139.65/s)  LR: 6.545e-04  Data: 0.616 (0.616)
Train: 68 [ 100/390 ( 26%)]  Loss: 3.315 (3.34)  Time: 0.314s,  408.21/s  (0.322s,  397.23/s)  LR: 6.545e-04  Data: 0.013 (0.019)
Train: 68 [ 200/390 ( 51%)]  Loss: 3.426 (3.32)  Time: 0.313s,  409.44/s  (0.319s,  401.77/s)  LR: 6.545e-04  Data: 0.013 (0.016)
Train: 68 [ 300/390 ( 77%)]  Loss: 3.726 (3.32)  Time: 0.312s,  410.48/s  (0.318s,  402.55/s)  LR: 6.545e-04  Data: 0.012 (0.014)
Train: 68 [ 389/390 (100%)]  Loss: 2.752 (3.32)  Time: 0.301s,  424.87/s  (0.317s,  403.82/s)  LR: 6.545e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.337 (0.337)  Loss:  1.2031 (1.2031)  Acc@1: 71.8750 (71.8750)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.9585 (1.2203)  Acc@1: 75.0000 (72.8900)  Acc@5: 100.0000 (94.0300)
Test: [Whole Val]  Time: 9.546  Loss: 1.2203  Acc@1: 72.8900 Pruned: 50.65% 
Test (EMA): [   0/78]  Time: 0.311 (0.311)  Loss:  1.1533 (1.1533)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.8809 (1.1480)  Acc@1: 75.0000 (73.3700)  Acc@5: 100.0000 (94.2000)
Test (EMA): [Whole Val]  Time: 9.513  Loss: 1.1480  Acc@1: 73.3700 Pruned: 50.65% 
Train: 69 [   0/390 (  0%)]  Loss: 2.692 (2.69)  Time: 0.769s,  166.46/s  (0.769s,  166.46/s)  LR: 6.457e-04  Data: 0.466 (0.466)
Train: 69 [ 100/390 ( 26%)]  Loss: 3.681 (3.30)  Time: 0.315s,  406.49/s  (0.321s,  398.84/s)  LR: 6.457e-04  Data: 0.012 (0.017)
Train: 69 [ 200/390 ( 51%)]  Loss: 2.799 (3.32)  Time: 0.313s,  409.36/s  (0.321s,  399.00/s)  LR: 6.457e-04  Data: 0.012 (0.015)
Train: 69 [ 300/390 ( 77%)]  Loss: 3.912 (3.34)  Time: 0.315s,  406.25/s  (0.319s,  401.49/s)  LR: 6.457e-04  Data: 0.014 (0.014)
Train: 69 [ 389/390 (100%)]  Loss: 3.858 (3.33)  Time: 0.302s,  423.75/s  (0.318s,  402.66/s)  LR: 6.457e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.432 (0.432)  Loss:  1.1230 (1.1230)  Acc@1: 71.0938 (71.0938)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.9009 (1.1661)  Acc@1: 75.0000 (72.3400)  Acc@5: 100.0000 (93.6200)
Test: [Whole Val]  Time: 9.628  Loss: 1.1661  Acc@1: 72.3400 Pruned: 50.64% 
Test (EMA): [   0/78]  Time: 0.370 (0.370)  Loss:  1.1143 (1.1143)  Acc@1: 72.6562 (72.6562)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9277 (1.1436)  Acc@1: 75.0000 (73.4400)  Acc@5: 100.0000 (94.3100)
Test (EMA): [Whole Val]  Time: 9.593  Loss: 1.1436  Acc@1: 73.4400 Pruned: 50.64% 
Train: 70 [   0/390 (  0%)]  Loss: 3.126 (3.13)  Time: 0.836s,  153.13/s  (0.836s,  153.13/s)  LR: 6.369e-04  Data: 0.519 (0.519)
Train: 70 [ 100/390 ( 26%)]  Loss: 3.503 (3.28)  Time: 0.312s,  410.70/s  (0.319s,  401.09/s)  LR: 6.369e-04  Data: 0.012 (0.017)
Train: 70 [ 200/390 ( 51%)]  Loss: 3.996 (3.28)  Time: 0.311s,  411.16/s  (0.318s,  402.85/s)  LR: 6.369e-04  Data: 0.011 (0.015)
Train: 70 [ 300/390 ( 77%)]  Loss: 3.607 (3.29)  Time: 0.313s,  408.66/s  (0.316s,  404.63/s)  LR: 6.369e-04  Data: 0.012 (0.014)
Train: 70 [ 389/390 (100%)]  Loss: 3.635 (3.30)  Time: 0.302s,  424.43/s  (0.316s,  405.55/s)  LR: 6.369e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.420 (0.420)  Loss:  1.1621 (1.1621)  Acc@1: 71.8750 (71.8750)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.9414 (1.1786)  Acc@1: 75.0000 (72.5700)  Acc@5: 93.7500 (94.2200)
Test: [Whole Val]  Time: 9.600  Loss: 1.1786  Acc@1: 72.5700 Pruned: 50.63% 
Test (EMA): [   0/78]  Time: 0.409 (0.409)  Loss:  1.1494 (1.1494)  Acc@1: 71.0938 (71.0938)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.021 (0.122)  Loss:  0.9316 (1.1640)  Acc@1: 81.2500 (73.1500)  Acc@5: 93.7500 (94.3300)
Test (EMA): [Whole Val]  Time: 9.632  Loss: 1.1640  Acc@1: 73.1500 Pruned: 50.63% 
Train: 71 [   0/390 (  0%)]  Loss: 3.372 (3.37)  Time: 0.806s,  158.81/s  (0.806s,  158.81/s)  LR: 6.280e-04  Data: 0.506 (0.506)
Train: 71 [ 100/390 ( 26%)]  Loss: 3.028 (3.29)  Time: 0.314s,  407.99/s  (0.318s,  402.31/s)  LR: 6.280e-04  Data: 0.012 (0.017)
Train: 71 [ 200/390 ( 51%)]  Loss: 3.638 (3.31)  Time: 0.314s,  407.31/s  (0.316s,  405.27/s)  LR: 6.280e-04  Data: 0.012 (0.015)
Train: 71 [ 300/390 ( 77%)]  Loss: 3.501 (3.33)  Time: 0.326s,  392.65/s  (0.316s,  404.43/s)  LR: 6.280e-04  Data: 0.012 (0.014)
Train: 71 [ 389/390 (100%)]  Loss: 3.641 (3.31)  Time: 0.301s,  424.61/s  (0.316s,  405.30/s)  LR: 6.280e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.414 (0.414)  Loss:  1.0781 (1.0781)  Acc@1: 71.8750 (71.8750)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.9092 (1.0790)  Acc@1: 81.2500 (73.0200)  Acc@5: 93.7500 (94.2300)
Test: [Whole Val]  Time: 9.609  Loss: 1.0790  Acc@1: 73.0200 Pruned: 50.64% 
Test (EMA): [   0/78]  Time: 0.321 (0.321)  Loss:  1.0654 (1.0654)  Acc@1: 72.6562 (72.6562)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.021 (0.121)  Loss:  0.8813 (1.0756)  Acc@1: 81.2500 (73.6200)  Acc@5: 93.7500 (94.4400)
Test (EMA): [Whole Val]  Time: 9.540  Loss: 1.0756  Acc@1: 73.6200 Pruned: 50.63% 
Train: 72 [   0/390 (  0%)]  Loss: 3.717 (3.72)  Time: 0.722s,  177.23/s  (0.722s,  177.23/s)  LR: 6.190e-04  Data: 0.422 (0.422)
Train: 72 [ 100/390 ( 26%)]  Loss: 3.825 (3.35)  Time: 0.314s,  408.01/s  (0.318s,  402.62/s)  LR: 6.190e-04  Data: 0.011 (0.017)
Train: 72 [ 200/390 ( 51%)]  Loss: 3.459 (3.36)  Time: 0.313s,  409.51/s  (0.318s,  403.00/s)  LR: 6.190e-04  Data: 0.011 (0.014)
Train: 72 [ 300/390 ( 77%)]  Loss: 3.030 (3.34)  Time: 0.327s,  391.76/s  (0.317s,  403.71/s)  LR: 6.190e-04  Data: 0.013 (0.014)
Train: 72 [ 389/390 (100%)]  Loss: 2.791 (3.31)  Time: 0.299s,  427.39/s  (0.317s,  404.25/s)  LR: 6.190e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.393 (0.393)  Loss:  1.0801 (1.0801)  Acc@1: 73.4375 (73.4375)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.8965 (1.0837)  Acc@1: 68.7500 (73.6200)  Acc@5: 93.7500 (94.4000)
Test: [Whole Val]  Time: 9.591  Loss: 1.0837  Acc@1: 73.6200 Pruned: 50.63% 
Test (EMA): [   0/78]  Time: 0.312 (0.312)  Loss:  1.0635 (1.0635)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.8945 (1.0651)  Acc@1: 68.7500 (73.7900)  Acc@5: 93.7500 (94.5400)
Test (EMA): [Whole Val]  Time: 9.517  Loss: 1.0651  Acc@1: 73.7900 Pruned: 50.63% 
Train: 73 [   0/390 (  0%)]  Loss: 2.788 (2.79)  Time: 0.854s,  149.87/s  (0.854s,  149.87/s)  LR: 6.100e-04  Data: 0.553 (0.553)
Train: 73 [ 100/390 ( 26%)]  Loss: 2.603 (3.28)  Time: 0.312s,  409.98/s  (0.320s,  400.48/s)  LR: 6.100e-04  Data: 0.012 (0.018)
Train: 73 [ 200/390 ( 51%)]  Loss: 3.537 (3.26)  Time: 0.314s,  408.24/s  (0.317s,  404.19/s)  LR: 6.100e-04  Data: 0.013 (0.015)
Train: 73 [ 300/390 ( 77%)]  Loss: 3.812 (3.29)  Time: 0.312s,  410.67/s  (0.316s,  405.37/s)  LR: 6.100e-04  Data: 0.012 (0.014)
Train: 73 [ 389/390 (100%)]  Loss: 3.340 (3.29)  Time: 0.301s,  425.22/s  (0.316s,  405.38/s)  LR: 6.100e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.391 (0.391)  Loss:  1.0967 (1.0967)  Acc@1: 75.7812 (75.7812)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.8896 (1.1501)  Acc@1: 87.5000 (73.2100)  Acc@5: 93.7500 (94.2200)
Test: [Whole Val]  Time: 9.621  Loss: 1.1501  Acc@1: 73.2100 Pruned: 50.62% 
Test (EMA): [   0/78]  Time: 0.308 (0.308)  Loss:  1.0723 (1.0723)  Acc@1: 73.4375 (73.4375)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.8921 (1.1074)  Acc@1: 75.0000 (73.9900)  Acc@5: 93.7500 (94.6700)
Test (EMA): [Whole Val]  Time: 9.486  Loss: 1.1074  Acc@1: 73.9900 Pruned: 50.62% 
Train: 74 [   0/390 (  0%)]  Loss: 3.495 (3.50)  Time: 0.805s,  159.06/s  (0.805s,  159.06/s)  LR: 6.010e-04  Data: 0.502 (0.502)
Train: 74 [ 100/390 ( 26%)]  Loss: 3.536 (3.34)  Time: 0.315s,  405.71/s  (0.319s,  401.08/s)  LR: 6.010e-04  Data: 0.013 (0.017)
Train: 74 [ 200/390 ( 51%)]  Loss: 3.741 (3.32)  Time: 0.313s,  409.16/s  (0.316s,  404.50/s)  LR: 6.010e-04  Data: 0.012 (0.015)
Train: 74 [ 300/390 ( 77%)]  Loss: 2.789 (3.32)  Time: 0.314s,  408.26/s  (0.316s,  405.67/s)  LR: 6.010e-04  Data: 0.013 (0.014)
Train: 74 [ 389/390 (100%)]  Loss: 3.903 (3.33)  Time: 0.304s,  420.42/s  (0.315s,  406.27/s)  LR: 6.010e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.414 (0.414)  Loss:  1.1504 (1.1504)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.0244 (1.1446)  Acc@1: 75.0000 (73.6700)  Acc@5: 87.5000 (94.1900)
Test: [Whole Val]  Time: 9.635  Loss: 1.1446  Acc@1: 73.6700 Pruned: 50.62% 
Test (EMA): [   0/78]  Time: 0.420 (0.420)  Loss:  1.1113 (1.1113)  Acc@1: 72.6562 (72.6562)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  1.0391 (1.1089)  Acc@1: 68.7500 (74.1600)  Acc@5: 93.7500 (94.6200)
Test (EMA): [Whole Val]  Time: 9.627  Loss: 1.1089  Acc@1: 74.1600 Pruned: 50.62% 
Train: 75 [   0/390 (  0%)]  Loss: 2.715 (2.71)  Time: 0.827s,  154.82/s  (0.827s,  154.82/s)  LR: 5.919e-04  Data: 0.512 (0.512)
Train: 75 [ 100/390 ( 26%)]  Loss: 3.478 (3.23)  Time: 0.313s,  409.01/s  (0.319s,  401.57/s)  LR: 5.919e-04  Data: 0.013 (0.017)
Train: 75 [ 200/390 ( 51%)]  Loss: 2.542 (3.25)  Time: 0.315s,  406.66/s  (0.318s,  402.17/s)  LR: 5.919e-04  Data: 0.012 (0.015)
Train: 75 [ 300/390 ( 77%)]  Loss: 3.789 (3.28)  Time: 0.313s,  408.41/s  (0.318s,  403.05/s)  LR: 5.919e-04  Data: 0.012 (0.014)
Train: 75 [ 389/390 (100%)]  Loss: 3.697 (3.27)  Time: 0.302s,  423.75/s  (0.317s,  403.82/s)  LR: 5.919e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.401 (0.401)  Loss:  1.1855 (1.1855)  Acc@1: 71.0938 (71.0938)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.022 (0.122)  Loss:  1.0977 (1.1685)  Acc@1: 68.7500 (72.9100)  Acc@5: 87.5000 (94.2800)
Test: [Whole Val]  Time: 9.641  Loss: 1.1685  Acc@1: 72.9100 Pruned: 50.60% 
Test (EMA): [   0/78]  Time: 0.434 (0.434)  Loss:  1.1309 (1.1309)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  1.0000 (1.1174)  Acc@1: 68.7500 (73.5100)  Acc@5: 93.7500 (94.5300)
Test (EMA): [Whole Val]  Time: 9.667  Loss: 1.1174  Acc@1: 73.5100 Pruned: 50.61% 
Train: 76 [   0/390 (  0%)]  Loss: 3.761 (3.76)  Time: 0.797s,  160.66/s  (0.797s,  160.66/s)  LR: 5.828e-04  Data: 0.494 (0.494)
Train: 76 [ 100/390 ( 26%)]  Loss: 2.833 (3.27)  Time: 0.313s,  409.29/s  (0.321s,  399.20/s)  LR: 5.828e-04  Data: 0.012 (0.017)
Train: 76 [ 200/390 ( 51%)]  Loss: 2.902 (3.32)  Time: 0.315s,  406.16/s  (0.318s,  402.81/s)  LR: 5.828e-04  Data: 0.013 (0.015)
Train: 76 [ 300/390 ( 77%)]  Loss: 3.002 (3.30)  Time: 0.313s,  409.15/s  (0.317s,  403.41/s)  LR: 5.828e-04  Data: 0.012 (0.014)
Train: 76 [ 389/390 (100%)]  Loss: 3.496 (3.32)  Time: 0.302s,  424.53/s  (0.317s,  404.27/s)  LR: 5.828e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.333 (0.333)  Loss:  1.1055 (1.1055)  Acc@1: 71.0938 (71.0938)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.0215 (1.1506)  Acc@1: 75.0000 (72.7500)  Acc@5: 93.7500 (94.0600)
Test: [Whole Val]  Time: 9.530  Loss: 1.1506  Acc@1: 72.7500 Pruned: 50.61% 
Test (EMA): [   0/78]  Time: 0.304 (0.304)  Loss:  1.0732 (1.0732)  Acc@1: 72.6562 (72.6562)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  1.0176 (1.0967)  Acc@1: 75.0000 (73.6000)  Acc@5: 87.5000 (94.5200)
Test (EMA): [Whole Val]  Time: 9.480  Loss: 1.0967  Acc@1: 73.6000 Pruned: 50.61% 
Train: 77 [   0/390 (  0%)]  Loss: 3.530 (3.53)  Time: 0.824s,  155.36/s  (0.824s,  155.36/s)  LR: 5.737e-04  Data: 0.516 (0.516)
Train: 77 [ 100/390 ( 26%)]  Loss: 3.158 (3.23)  Time: 0.318s,  402.22/s  (0.321s,  398.21/s)  LR: 5.737e-04  Data: 0.015 (0.018)
Train: 77 [ 200/390 ( 51%)]  Loss: 3.642 (3.28)  Time: 0.314s,  408.21/s  (0.318s,  402.57/s)  LR: 5.737e-04  Data: 0.013 (0.015)
Train: 77 [ 300/390 ( 77%)]  Loss: 3.080 (3.28)  Time: 0.314s,  407.81/s  (0.317s,  404.02/s)  LR: 5.737e-04  Data: 0.013 (0.015)
Train: 77 [ 389/390 (100%)]  Loss: 3.287 (3.29)  Time: 0.301s,  424.85/s  (0.317s,  403.85/s)  LR: 5.737e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.397 (0.397)  Loss:  1.0605 (1.0605)  Acc@1: 73.4375 (73.4375)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.9683 (1.0983)  Acc@1: 68.7500 (73.8800)  Acc@5: 93.7500 (94.6000)
Test: [Whole Val]  Time: 9.673  Loss: 1.0983  Acc@1: 73.8800 Pruned: 50.61% 
Test (EMA): [   0/78]  Time: 0.407 (0.407)  Loss:  1.0742 (1.0742)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.9512 (1.0907)  Acc@1: 75.0000 (73.9900)  Acc@5: 93.7500 (94.5700)
Test (EMA): [Whole Val]  Time: 9.638  Loss: 1.0907  Acc@1: 73.9900 Pruned: 50.60% 
Train: 78 [   0/390 (  0%)]  Loss: 3.464 (3.46)  Time: 0.765s,  167.40/s  (0.765s,  167.40/s)  LR: 5.645e-04  Data: 0.462 (0.462)
Train: 78 [ 100/390 ( 26%)]  Loss: 3.875 (3.32)  Time: 0.315s,  406.89/s  (0.321s,  398.38/s)  LR: 5.645e-04  Data: 0.012 (0.017)
Train: 78 [ 200/390 ( 51%)]  Loss: 3.386 (3.32)  Time: 0.313s,  408.95/s  (0.317s,  403.22/s)  LR: 5.645e-04  Data: 0.014 (0.015)
Train: 78 [ 300/390 ( 77%)]  Loss: 3.517 (3.30)  Time: 0.313s,  408.72/s  (0.318s,  403.09/s)  LR: 5.645e-04  Data: 0.012 (0.014)
Train: 78 [ 389/390 (100%)]  Loss: 2.602 (3.30)  Time: 0.300s,  426.07/s  (0.317s,  404.42/s)  LR: 5.645e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.369 (0.369)  Loss:  1.1318 (1.1318)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.0674 (1.1735)  Acc@1: 75.0000 (72.8800)  Acc@5: 93.7500 (94.1600)
Test: [Whole Val]  Time: 9.573  Loss: 1.1735  Acc@1: 72.8800 Pruned: 50.60% 
Test (EMA): [   0/78]  Time: 0.406 (0.406)  Loss:  1.0859 (1.0859)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.0137 (1.1188)  Acc@1: 68.7500 (73.9300)  Acc@5: 93.7500 (94.5800)
Test (EMA): [Whole Val]  Time: 9.595  Loss: 1.1188  Acc@1: 73.9300 Pruned: 50.60% 
Train: 79 [   0/390 (  0%)]  Loss: 3.627 (3.63)  Time: 1.002s,  127.78/s  (1.002s,  127.78/s)  LR: 5.554e-04  Data: 0.692 (0.692)
Train: 79 [ 100/390 ( 26%)]  Loss: 3.158 (3.36)  Time: 0.311s,  411.04/s  (0.320s,  399.82/s)  LR: 5.554e-04  Data: 0.011 (0.019)
Train: 79 [ 200/390 ( 51%)]  Loss: 3.407 (3.34)  Time: 0.315s,  406.80/s  (0.317s,  404.19/s)  LR: 5.554e-04  Data: 0.012 (0.016)
Train: 79 [ 300/390 ( 77%)]  Loss: 3.608 (3.34)  Time: 0.314s,  407.14/s  (0.316s,  405.26/s)  LR: 5.554e-04  Data: 0.013 (0.014)
Train: 79 [ 389/390 (100%)]  Loss: 3.658 (3.30)  Time: 0.315s,  406.43/s  (0.316s,  404.90/s)  LR: 5.554e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.404 (0.404)  Loss:  1.0625 (1.0625)  Acc@1: 72.6562 (72.6562)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.0156 (1.0856)  Acc@1: 68.7500 (74.2500)  Acc@5: 93.7500 (94.4600)
Test: [Whole Val]  Time: 9.644  Loss: 1.0856  Acc@1: 74.2500 Pruned: 50.60% 
Test (EMA): [   0/78]  Time: 0.391 (0.391)  Loss:  1.0801 (1.0801)  Acc@1: 72.6562 (72.6562)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  1.0195 (1.0887)  Acc@1: 68.7500 (74.4700)  Acc@5: 93.7500 (94.6900)
Test (EMA): [Whole Val]  Time: 9.600  Loss: 1.0887  Acc@1: 74.4700 Pruned: 50.60% 
Train: 80 [   0/390 (  0%)]  Loss: 2.997 (3.00)  Time: 0.827s,  154.79/s  (0.827s,  154.79/s)  LR: 5.462e-04  Data: 0.526 (0.526)
Train: 80 [ 100/390 ( 26%)]  Loss: 3.275 (3.21)  Time: 0.312s,  410.83/s  (0.323s,  395.88/s)  LR: 5.462e-04  Data: 0.011 (0.017)
Train: 80 [ 200/390 ( 51%)]  Loss: 3.694 (3.27)  Time: 0.312s,  410.10/s  (0.318s,  402.08/s)  LR: 5.462e-04  Data: 0.011 (0.015)
Train: 80 [ 300/390 ( 77%)]  Loss: 2.576 (3.31)  Time: 0.314s,  407.09/s  (0.317s,  403.37/s)  LR: 5.462e-04  Data: 0.013 (0.014)
Train: 80 [ 389/390 (100%)]  Loss: 3.484 (3.31)  Time: 0.301s,  424.93/s  (0.316s,  404.57/s)  LR: 5.462e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.412 (0.412)  Loss:  1.0645 (1.0645)  Acc@1: 73.4375 (73.4375)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  1.0039 (1.1146)  Acc@1: 75.0000 (73.2600)  Acc@5: 93.7500 (94.4500)
Test: [Whole Val]  Time: 9.635  Loss: 1.1146  Acc@1: 73.2600 Pruned: 50.59% 
Test (EMA): [   0/78]  Time: 0.405 (0.405)  Loss:  1.0566 (1.0566)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  1.0010 (1.0974)  Acc@1: 75.0000 (73.9200)  Acc@5: 93.7500 (94.6000)
Test (EMA): [Whole Val]  Time: 9.630  Loss: 1.0974  Acc@1: 73.9200 Pruned: 50.59% 
Train: 81 [   0/390 (  0%)]  Loss: 3.646 (3.65)  Time: 0.864s,  148.14/s  (0.864s,  148.14/s)  LR: 5.370e-04  Data: 0.548 (0.548)
Train: 81 [ 100/390 ( 26%)]  Loss: 2.929 (3.23)  Time: 0.313s,  409.42/s  (0.323s,  396.54/s)  LR: 5.370e-04  Data: 0.012 (0.018)
Train: 81 [ 200/390 ( 51%)]  Loss: 3.205 (3.28)  Time: 0.315s,  405.96/s  (0.318s,  402.02/s)  LR: 5.370e-04  Data: 0.015 (0.015)
Train: 81 [ 300/390 ( 77%)]  Loss: 3.079 (3.29)  Time: 0.311s,  411.14/s  (0.319s,  401.84/s)  LR: 5.370e-04  Data: 0.012 (0.014)
Train: 81 [ 389/390 (100%)]  Loss: 2.969 (3.31)  Time: 0.301s,  424.64/s  (0.318s,  402.97/s)  LR: 5.370e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.353 (0.353)  Loss:  1.1777 (1.1777)  Acc@1: 71.0938 (71.0938)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.121)  Loss:  1.0186 (1.1765)  Acc@1: 75.0000 (73.1700)  Acc@5: 93.7500 (94.0600)
Test: [Whole Val]  Time: 9.580  Loss: 1.1765  Acc@1: 73.1700 Pruned: 50.59% 
Test (EMA): [   0/78]  Time: 0.314 (0.314)  Loss:  1.1025 (1.1025)  Acc@1: 70.3125 (70.3125)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9341 (1.1107)  Acc@1: 75.0000 (73.9600)  Acc@5: 93.7500 (94.6200)
Test (EMA): [Whole Val]  Time: 9.561  Loss: 1.1107  Acc@1: 73.9600 Pruned: 50.59% 
Train: 82 [   0/390 (  0%)]  Loss: 3.586 (3.59)  Time: 0.865s,  147.96/s  (0.865s,  147.96/s)  LR: 5.278e-04  Data: 0.564 (0.564)
Train: 82 [ 100/390 ( 26%)]  Loss: 3.819 (3.32)  Time: 0.312s,  409.79/s  (0.320s,  400.46/s)  LR: 5.278e-04  Data: 0.011 (0.018)
Train: 82 [ 200/390 ( 51%)]  Loss: 3.729 (3.28)  Time: 0.314s,  408.10/s  (0.317s,  403.58/s)  LR: 5.278e-04  Data: 0.012 (0.015)
Train: 82 [ 300/390 ( 77%)]  Loss: 3.360 (3.30)  Time: 0.314s,  408.27/s  (0.317s,  403.55/s)  LR: 5.278e-04  Data: 0.012 (0.014)
Train: 82 [ 389/390 (100%)]  Loss: 3.521 (3.30)  Time: 0.303s,  423.10/s  (0.317s,  404.09/s)  LR: 5.278e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.362 (0.362)  Loss:  1.0723 (1.0723)  Acc@1: 71.8750 (71.8750)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.9072 (1.1200)  Acc@1: 75.0000 (73.6300)  Acc@5: 93.7500 (94.6000)
Test: [Whole Val]  Time: 9.588  Loss: 1.1200  Acc@1: 73.6300 Pruned: 50.58% 
Test (EMA): [   0/78]  Time: 0.396 (0.396)  Loss:  1.0469 (1.0469)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.9116 (1.0867)  Acc@1: 75.0000 (73.9600)  Acc@5: 93.7500 (94.7700)
Test (EMA): [Whole Val]  Time: 9.618  Loss: 1.0867  Acc@1: 73.9600 Pruned: 50.58% 
Train: 83 [   0/390 (  0%)]  Loss: 3.206 (3.21)  Time: 0.760s,  168.47/s  (0.760s,  168.47/s)  LR: 5.185e-04  Data: 0.446 (0.446)
Train: 83 [ 100/390 ( 26%)]  Loss: 2.705 (3.26)  Time: 0.313s,  409.48/s  (0.321s,  398.80/s)  LR: 5.185e-04  Data: 0.012 (0.017)
Train: 83 [ 200/390 ( 51%)]  Loss: 3.746 (3.27)  Time: 0.312s,  409.80/s  (0.318s,  403.00/s)  LR: 5.185e-04  Data: 0.012 (0.015)
Train: 83 [ 300/390 ( 77%)]  Loss: 3.141 (3.27)  Time: 0.312s,  410.24/s  (0.317s,  403.92/s)  LR: 5.185e-04  Data: 0.011 (0.014)
Train: 83 [ 389/390 (100%)]  Loss: 3.198 (3.26)  Time: 0.301s,  424.62/s  (0.316s,  404.86/s)  LR: 5.185e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.410 (0.410)  Loss:  1.0908 (1.0908)  Acc@1: 71.0938 (71.0938)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.9185 (1.1133)  Acc@1: 75.0000 (73.2000)  Acc@5: 93.7500 (94.5500)
Test: [Whole Val]  Time: 9.627  Loss: 1.1133  Acc@1: 73.2000 Pruned: 50.59% 
Test (EMA): [   0/78]  Time: 0.389 (0.389)  Loss:  1.0732 (1.0732)  Acc@1: 72.6562 (72.6562)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.9009 (1.0701)  Acc@1: 75.0000 (74.3100)  Acc@5: 93.7500 (94.7900)
Test (EMA): [Whole Val]  Time: 9.610  Loss: 1.0701  Acc@1: 74.3100 Pruned: 50.58% 
Train: 84 [   0/390 (  0%)]  Loss: 3.222 (3.22)  Time: 0.814s,  157.33/s  (0.814s,  157.33/s)  LR: 5.093e-04  Data: 0.489 (0.489)
Train: 84 [ 100/390 ( 26%)]  Loss: 2.656 (3.34)  Time: 0.314s,  408.17/s  (0.319s,  401.17/s)  LR: 5.093e-04  Data: 0.013 (0.017)
Train: 84 [ 200/390 ( 51%)]  Loss: 2.561 (3.33)  Time: 0.314s,  408.02/s  (0.317s,  403.70/s)  LR: 5.093e-04  Data: 0.013 (0.015)
Train: 84 [ 300/390 ( 77%)]  Loss: 3.820 (3.31)  Time: 0.314s,  407.80/s  (0.316s,  405.10/s)  LR: 5.093e-04  Data: 0.012 (0.014)
Train: 84 [ 389/390 (100%)]  Loss: 3.624 (3.30)  Time: 0.301s,  425.30/s  (0.315s,  405.88/s)  LR: 5.093e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.395 (0.395)  Loss:  1.0078 (1.0078)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.9790 (1.0500)  Acc@1: 68.7500 (73.7100)  Acc@5: 81.2500 (94.5300)
Test: [Whole Val]  Time: 9.606  Loss: 1.0500  Acc@1: 73.7100 Pruned: 50.59% 
Test (EMA): [   0/78]  Time: 0.317 (0.317)  Loss:  1.0391 (1.0391)  Acc@1: 72.6562 (72.6562)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9419 (1.0692)  Acc@1: 68.7500 (74.1500)  Acc@5: 93.7500 (94.9000)
Test (EMA): [Whole Val]  Time: 9.551  Loss: 1.0692  Acc@1: 74.1500 Pruned: 50.59% 
Train: 85 [   0/390 (  0%)]  Loss: 3.533 (3.53)  Time: 0.818s,  156.40/s  (0.818s,  156.40/s)  LR: 5.000e-04  Data: 0.514 (0.514)
Train: 85 [ 100/390 ( 26%)]  Loss: 2.705 (3.29)  Time: 0.326s,  392.58/s  (0.324s,  394.70/s)  LR: 5.000e-04  Data: 0.012 (0.018)
Train: 85 [ 200/390 ( 51%)]  Loss: 3.084 (3.28)  Time: 0.316s,  405.25/s  (0.319s,  401.08/s)  LR: 5.000e-04  Data: 0.012 (0.015)
Train: 85 [ 300/390 ( 77%)]  Loss: 3.882 (3.25)  Time: 0.311s,  411.10/s  (0.319s,  401.21/s)  LR: 5.000e-04  Data: 0.011 (0.014)
Train: 85 [ 389/390 (100%)]  Loss: 3.533 (3.25)  Time: 0.303s,  422.46/s  (0.318s,  402.70/s)  LR: 5.000e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.387 (0.387)  Loss:  1.1104 (1.1104)  Acc@1: 76.5625 (76.5625)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.021 (0.122)  Loss:  0.9565 (1.1684)  Acc@1: 81.2500 (72.5000)  Acc@5: 93.7500 (94.1700)
Test: [Whole Val]  Time: 9.655  Loss: 1.1684  Acc@1: 72.5000 Pruned: 50.59% 
Test (EMA): [   0/78]  Time: 0.365 (0.365)  Loss:  1.0615 (1.0615)  Acc@1: 74.2188 (74.2188)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.021 (0.122)  Loss:  0.9761 (1.0868)  Acc@1: 81.2500 (74.4000)  Acc@5: 93.7500 (94.8800)
Test (EMA): [Whole Val]  Time: 9.611  Loss: 1.0868  Acc@1: 74.4000 Pruned: 50.59% 
Train: 86 [   0/390 (  0%)]  Loss: 3.640 (3.64)  Time: 0.892s,  143.57/s  (0.892s,  143.57/s)  LR: 4.908e-04  Data: 0.587 (0.587)
Train: 86 [ 100/390 ( 26%)]  Loss: 2.982 (3.28)  Time: 0.313s,  408.52/s  (0.319s,  400.71/s)  LR: 4.908e-04  Data: 0.012 (0.018)
Train: 86 [ 200/390 ( 51%)]  Loss: 3.649 (3.28)  Time: 0.318s,  402.62/s  (0.317s,  404.04/s)  LR: 4.908e-04  Data: 0.013 (0.015)
Train: 86 [ 300/390 ( 77%)]  Loss: 3.381 (3.29)  Time: 0.320s,  399.47/s  (0.316s,  405.47/s)  LR: 4.908e-04  Data: 0.013 (0.014)
Train: 86 [ 389/390 (100%)]  Loss: 3.007 (3.31)  Time: 0.301s,  425.43/s  (0.315s,  405.95/s)  LR: 4.908e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.457 (0.457)  Loss:  1.1191 (1.1191)  Acc@1: 75.7812 (75.7812)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.123)  Loss:  1.0176 (1.1510)  Acc@1: 75.0000 (73.8100)  Acc@5: 87.5000 (94.7000)
Test: [Whole Val]  Time: 9.710  Loss: 1.1510  Acc@1: 73.8100 Pruned: 50.58% 
Test (EMA): [   0/78]  Time: 0.297 (0.297)  Loss:  1.0967 (1.0967)  Acc@1: 71.8750 (71.8750)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9922 (1.1338)  Acc@1: 75.0000 (74.1900)  Acc@5: 93.7500 (94.6500)
Test (EMA): [Whole Val]  Time: 9.588  Loss: 1.1338  Acc@1: 74.1900 Pruned: 50.58% 
Train: 87 [   0/390 (  0%)]  Loss: 3.640 (3.64)  Time: 0.818s,  156.43/s  (0.818s,  156.43/s)  LR: 4.816e-04  Data: 0.503 (0.503)
Train: 87 [ 100/390 ( 26%)]  Loss: 3.169 (3.26)  Time: 0.313s,  408.81/s  (0.320s,  400.56/s)  LR: 4.816e-04  Data: 0.011 (0.018)
Train: 87 [ 200/390 ( 51%)]  Loss: 3.739 (3.26)  Time: 0.312s,  410.40/s  (0.318s,  402.22/s)  LR: 4.816e-04  Data: 0.012 (0.015)
Train: 87 [ 300/390 ( 77%)]  Loss: 4.008 (3.28)  Time: 0.319s,  401.54/s  (0.319s,  401.61/s)  LR: 4.816e-04  Data: 0.016 (0.014)
Train: 87 [ 389/390 (100%)]  Loss: 2.897 (3.29)  Time: 0.301s,  425.89/s  (0.318s,  403.07/s)  LR: 4.816e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.307 (0.307)  Loss:  1.1201 (1.1201)  Acc@1: 72.6562 (72.6562)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.0557 (1.1545)  Acc@1: 75.0000 (73.1700)  Acc@5: 93.7500 (94.3400)
Test: [Whole Val]  Time: 9.558  Loss: 1.1545  Acc@1: 73.1700 Pruned: 50.57% 
Test (EMA): [   0/78]  Time: 0.359 (0.359)  Loss:  1.0859 (1.0859)  Acc@1: 73.4375 (73.4375)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  1.0332 (1.1199)  Acc@1: 75.0000 (73.8900)  Acc@5: 93.7500 (94.7800)
Test (EMA): [Whole Val]  Time: 9.609  Loss: 1.1199  Acc@1: 73.8900 Pruned: 50.58% 
Train: 88 [   0/390 (  0%)]  Loss: 3.409 (3.41)  Time: 0.905s,  141.43/s  (0.905s,  141.43/s)  LR: 4.723e-04  Data: 0.568 (0.568)
Train: 88 [ 100/390 ( 26%)]  Loss: 3.348 (3.28)  Time: 0.315s,  405.97/s  (0.324s,  394.58/s)  LR: 4.723e-04  Data: 0.014 (0.018)
Train: 88 [ 200/390 ( 51%)]  Loss: 3.336 (3.28)  Time: 0.314s,  407.01/s  (0.320s,  399.61/s)  LR: 4.723e-04  Data: 0.012 (0.015)
Train: 88 [ 300/390 ( 77%)]  Loss: 3.227 (3.27)  Time: 0.314s,  407.80/s  (0.318s,  402.29/s)  LR: 4.723e-04  Data: 0.012 (0.014)
Train: 88 [ 389/390 (100%)]  Loss: 3.551 (3.27)  Time: 0.302s,  423.76/s  (0.317s,  403.76/s)  LR: 4.723e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.397 (0.397)  Loss:  1.0859 (1.0859)  Acc@1: 74.2188 (74.2188)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.0039 (1.0819)  Acc@1: 75.0000 (74.4100)  Acc@5: 87.5000 (94.8100)
Test: [Whole Val]  Time: 9.626  Loss: 1.0819  Acc@1: 74.4100 Pruned: 50.57% 
Test (EMA): [   0/78]  Time: 0.429 (0.429)  Loss:  1.1016 (1.1016)  Acc@1: 73.4375 (73.4375)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  1.0273 (1.1056)  Acc@1: 75.0000 (74.4200)  Acc@5: 93.7500 (94.8000)
Test (EMA): [Whole Val]  Time: 9.649  Loss: 1.1056  Acc@1: 74.4200 Pruned: 50.57% 
Train: 89 [   0/390 (  0%)]  Loss: 2.932 (2.93)  Time: 0.752s,  170.21/s  (0.752s,  170.21/s)  LR: 4.631e-04  Data: 0.449 (0.449)
Train: 89 [ 100/390 ( 26%)]  Loss: 2.721 (3.31)  Time: 0.312s,  410.39/s  (0.321s,  398.40/s)  LR: 4.631e-04  Data: 0.011 (0.017)
Train: 89 [ 200/390 ( 51%)]  Loss: 2.894 (3.29)  Time: 0.312s,  409.82/s  (0.317s,  403.17/s)  LR: 4.631e-04  Data: 0.012 (0.015)
Train: 89 [ 300/390 ( 77%)]  Loss: 2.955 (3.31)  Time: 0.314s,  408.12/s  (0.318s,  402.42/s)  LR: 4.631e-04  Data: 0.012 (0.014)
Train: 89 [ 389/390 (100%)]  Loss: 3.571 (3.31)  Time: 0.300s,  426.10/s  (0.317s,  403.50/s)  LR: 4.631e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.407 (0.407)  Loss:  1.1191 (1.1191)  Acc@1: 71.8750 (71.8750)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.0430 (1.1394)  Acc@1: 75.0000 (73.6400)  Acc@5: 93.7500 (94.5000)
Test: [Whole Val]  Time: 9.633  Loss: 1.1394  Acc@1: 73.6400 Pruned: 50.55% 
Test (EMA): [   0/78]  Time: 0.333 (0.333)  Loss:  1.1045 (1.1045)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9458 (1.1089)  Acc@1: 75.0000 (74.4600)  Acc@5: 93.7500 (94.6600)
Test (EMA): [Whole Val]  Time: 9.583  Loss: 1.1089  Acc@1: 74.4600 Pruned: 50.56% 
Train: 90 [   0/390 (  0%)]  Loss: 3.558 (3.56)  Time: 0.794s,  161.21/s  (0.794s,  161.21/s)  LR: 4.539e-04  Data: 0.493 (0.493)
Train: 90 [ 100/390 ( 26%)]  Loss: 2.578 (3.30)  Time: 0.313s,  409.22/s  (0.319s,  401.67/s)  LR: 4.539e-04  Data: 0.012 (0.017)
Train: 90 [ 200/390 ( 51%)]  Loss: 2.530 (3.31)  Time: 0.312s,  410.50/s  (0.316s,  404.89/s)  LR: 4.539e-04  Data: 0.012 (0.015)
Train: 90 [ 300/390 ( 77%)]  Loss: 2.885 (3.29)  Time: 0.317s,  404.17/s  (0.315s,  405.95/s)  LR: 4.539e-04  Data: 0.012 (0.014)
Train: 90 [ 389/390 (100%)]  Loss: 2.879 (3.28)  Time: 0.303s,  422.30/s  (0.316s,  405.16/s)  LR: 4.539e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.313 (0.313)  Loss:  0.9961 (0.9961)  Acc@1: 72.6562 (72.6562)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.8486 (1.0249)  Acc@1: 75.0000 (74.1400)  Acc@5: 100.0000 (94.5400)
Test: [Whole Val]  Time: 9.552  Loss: 1.0249  Acc@1: 74.1400 Pruned: 50.56% 
Test (EMA): [   0/78]  Time: 0.390 (0.390)  Loss:  1.0137 (1.0137)  Acc@1: 74.2188 (74.2188)  Acc@5: 96.0938 (96.0938)
Test (EMA): [  78/78]  Time: 0.019 (0.122)  Loss:  0.8770 (1.0303)  Acc@1: 75.0000 (74.8200)  Acc@5: 93.7500 (94.7700)
Test (EMA): [Whole Val]  Time: 9.611  Loss: 1.0303  Acc@1: 74.8200 Pruned: 50.56% 
Train: 91 [   0/390 (  0%)]  Loss: 3.886 (3.89)  Time: 0.774s,  165.40/s  (0.774s,  165.40/s)  LR: 4.447e-04  Data: 0.461 (0.461)
Train: 91 [ 100/390 ( 26%)]  Loss: 3.958 (3.27)  Time: 0.314s,  408.17/s  (0.318s,  402.18/s)  LR: 4.447e-04  Data: 0.012 (0.017)
Train: 91 [ 200/390 ( 51%)]  Loss: 3.493 (3.26)  Time: 0.312s,  410.85/s  (0.318s,  402.12/s)  LR: 4.447e-04  Data: 0.012 (0.015)
Train: 91 [ 300/390 ( 77%)]  Loss: 3.814 (3.25)  Time: 0.329s,  389.60/s  (0.318s,  402.19/s)  LR: 4.447e-04  Data: 0.013 (0.014)
Train: 91 [ 389/390 (100%)]  Loss: 3.303 (3.26)  Time: 0.303s,  423.10/s  (0.317s,  403.40/s)  LR: 4.447e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.422 (0.422)  Loss:  1.1182 (1.1182)  Acc@1: 73.4375 (73.4375)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.0068 (1.1545)  Acc@1: 75.0000 (73.9900)  Acc@5: 93.7500 (94.1700)
Test: [Whole Val]  Time: 9.645  Loss: 1.1545  Acc@1: 73.9900 Pruned: 50.55% 
Test (EMA): [   0/78]  Time: 0.425 (0.425)  Loss:  1.0791 (1.0791)  Acc@1: 72.6562 (72.6562)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.9346 (1.1058)  Acc@1: 75.0000 (74.4400)  Acc@5: 93.7500 (94.5500)
Test (EMA): [Whole Val]  Time: 9.659  Loss: 1.1058  Acc@1: 74.4400 Pruned: 50.56% 
Train: 92 [   0/390 (  0%)]  Loss: 3.367 (3.37)  Time: 0.943s,  135.69/s  (0.943s,  135.69/s)  LR: 4.356e-04  Data: 0.629 (0.629)
Train: 92 [ 100/390 ( 26%)]  Loss: 2.585 (3.27)  Time: 0.314s,  407.85/s  (0.322s,  397.90/s)  LR: 4.356e-04  Data: 0.012 (0.019)
Train: 92 [ 200/390 ( 51%)]  Loss: 2.211 (3.26)  Time: 0.313s,  408.61/s  (0.319s,  401.51/s)  LR: 4.356e-04  Data: 0.012 (0.016)
Train: 92 [ 300/390 ( 77%)]  Loss: 2.904 (3.26)  Time: 0.314s,  407.53/s  (0.318s,  402.84/s)  LR: 4.356e-04  Data: 0.012 (0.015)
Train: 92 [ 389/390 (100%)]  Loss: 3.612 (3.27)  Time: 0.301s,  425.34/s  (0.317s,  403.46/s)  LR: 4.356e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.362 (0.362)  Loss:  1.0771 (1.0771)  Acc@1: 74.2188 (74.2188)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.018 (0.121)  Loss:  0.9077 (1.1163)  Acc@1: 81.2500 (73.9000)  Acc@5: 93.7500 (94.6300)
Test: [Whole Val]  Time: 9.598  Loss: 1.1163  Acc@1: 73.9000 Pruned: 50.56% 
Test (EMA): [   0/78]  Time: 0.430 (0.430)  Loss:  1.0586 (1.0586)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.8960 (1.0899)  Acc@1: 81.2500 (74.5800)  Acc@5: 93.7500 (94.7200)
Test (EMA): [Whole Val]  Time: 9.665  Loss: 1.0899  Acc@1: 74.5800 Pruned: 50.56% 
Train: 93 [   0/390 (  0%)]  Loss: 3.805 (3.80)  Time: 0.754s,  169.87/s  (0.754s,  169.87/s)  LR: 4.264e-04  Data: 0.452 (0.452)
Train: 93 [ 100/390 ( 26%)]  Loss: 3.811 (3.23)  Time: 0.312s,  410.19/s  (0.318s,  402.64/s)  LR: 4.264e-04  Data: 0.012 (0.016)
Train: 93 [ 200/390 ( 51%)]  Loss: 3.633 (3.27)  Time: 0.314s,  407.38/s  (0.316s,  405.13/s)  LR: 4.264e-04  Data: 0.013 (0.015)
Train: 93 [ 300/390 ( 77%)]  Loss: 3.449 (3.26)  Time: 0.322s,  397.93/s  (0.315s,  405.93/s)  LR: 4.264e-04  Data: 0.012 (0.014)
Train: 93 [ 389/390 (100%)]  Loss: 2.605 (3.27)  Time: 0.301s,  424.55/s  (0.315s,  406.42/s)  LR: 4.264e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.415 (0.415)  Loss:  1.0537 (1.0537)  Acc@1: 70.3125 (70.3125)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.021 (0.122)  Loss:  0.9058 (1.0935)  Acc@1: 75.0000 (73.9400)  Acc@5: 100.0000 (94.3900)
Test: [Whole Val]  Time: 9.675  Loss: 1.0935  Acc@1: 73.9400 Pruned: 50.56% 
Test (EMA): [   0/78]  Time: 0.433 (0.433)  Loss:  1.0605 (1.0605)  Acc@1: 72.6562 (72.6562)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  0.9473 (1.1042)  Acc@1: 75.0000 (74.2600)  Acc@5: 87.5000 (94.5600)
Test (EMA): [Whole Val]  Time: 9.694  Loss: 1.1042  Acc@1: 74.2600 Pruned: 50.56% 
Train: 94 [   0/390 (  0%)]  Loss: 2.368 (2.37)  Time: 0.751s,  170.54/s  (0.751s,  170.54/s)  LR: 4.173e-04  Data: 0.447 (0.447)
Train: 94 [ 100/390 ( 26%)]  Loss: 2.910 (3.25)  Time: 0.312s,  409.70/s  (0.319s,  401.29/s)  LR: 4.173e-04  Data: 0.012 (0.017)
Train: 94 [ 200/390 ( 51%)]  Loss: 2.861 (3.26)  Time: 0.328s,  389.90/s  (0.317s,  403.19/s)  LR: 4.173e-04  Data: 0.013 (0.015)
Train: 94 [ 300/390 ( 77%)]  Loss: 3.443 (3.25)  Time: 0.312s,  409.66/s  (0.316s,  404.48/s)  LR: 4.173e-04  Data: 0.012 (0.014)
Train: 94 [ 389/390 (100%)]  Loss: 3.613 (3.26)  Time: 0.300s,  427.33/s  (0.316s,  405.01/s)  LR: 4.173e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.325 (0.325)  Loss:  0.9995 (0.9995)  Acc@1: 75.0000 (75.0000)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.018 (0.121)  Loss:  0.9507 (1.0668)  Acc@1: 68.7500 (74.5800)  Acc@5: 100.0000 (94.8900)
Test: [Whole Val]  Time: 9.555  Loss: 1.0668  Acc@1: 74.5800 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.408 (0.408)  Loss:  1.0166 (1.0166)  Acc@1: 74.2188 (74.2188)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.020 (0.122)  Loss:  0.9443 (1.0698)  Acc@1: 75.0000 (75.0200)  Acc@5: 93.7500 (94.8300)
Test (EMA): [Whole Val]  Time: 9.606  Loss: 1.0698  Acc@1: 75.0200 Pruned: 50.55% 
Train: 95 [   0/390 (  0%)]  Loss: 3.767 (3.77)  Time: 0.769s,  166.53/s  (0.769s,  166.53/s)  LR: 4.082e-04  Data: 0.466 (0.466)
Train: 95 [ 100/390 ( 26%)]  Loss: 3.167 (3.22)  Time: 0.315s,  406.80/s  (0.324s,  394.72/s)  LR: 4.082e-04  Data: 0.014 (0.018)
Train: 95 [ 200/390 ( 51%)]  Loss: 3.737 (3.21)  Time: 0.315s,  406.23/s  (0.320s,  399.74/s)  LR: 4.082e-04  Data: 0.014 (0.015)
Train: 95 [ 300/390 ( 77%)]  Loss: 3.553 (3.25)  Time: 0.314s,  407.37/s  (0.319s,  401.47/s)  LR: 4.082e-04  Data: 0.013 (0.015)
Train: 95 [ 389/390 (100%)]  Loss: 3.664 (3.28)  Time: 0.301s,  424.60/s  (0.318s,  402.72/s)  LR: 4.082e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.359 (0.359)  Loss:  1.0518 (1.0518)  Acc@1: 74.2188 (74.2188)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.8911 (1.0853)  Acc@1: 81.2500 (74.4100)  Acc@5: 93.7500 (94.6600)
Test: [Whole Val]  Time: 9.598  Loss: 1.0853  Acc@1: 74.4100 Pruned: 50.55% 
Test (EMA): [   0/78]  Time: 0.428 (0.428)  Loss:  1.0684 (1.0684)  Acc@1: 73.4375 (73.4375)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.021 (0.123)  Loss:  0.9409 (1.0950)  Acc@1: 81.2500 (75.0000)  Acc@5: 93.7500 (94.8700)
Test (EMA): [Whole Val]  Time: 9.681  Loss: 1.0950  Acc@1: 75.0000 Pruned: 50.55% 
Train: 96 [   0/390 (  0%)]  Loss: 3.781 (3.78)  Time: 0.828s,  154.54/s  (0.828s,  154.54/s)  LR: 3.991e-04  Data: 0.524 (0.524)
Train: 96 [ 100/390 ( 26%)]  Loss: 3.928 (3.32)  Time: 0.315s,  406.69/s  (0.323s,  396.62/s)  LR: 3.991e-04  Data: 0.013 (0.018)
Train: 96 [ 200/390 ( 51%)]  Loss: 3.196 (3.33)  Time: 0.316s,  405.04/s  (0.319s,  401.81/s)  LR: 3.991e-04  Data: 0.014 (0.015)
Train: 96 [ 300/390 ( 77%)]  Loss: 3.554 (3.30)  Time: 0.326s,  392.12/s  (0.318s,  402.62/s)  LR: 3.991e-04  Data: 0.013 (0.015)
Train: 96 [ 389/390 (100%)]  Loss: 2.547 (3.29)  Time: 0.300s,  426.69/s  (0.318s,  402.57/s)  LR: 3.991e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.401 (0.401)  Loss:  0.9854 (0.9854)  Acc@1: 75.7812 (75.7812)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.9077 (1.0606)  Acc@1: 75.0000 (74.0100)  Acc@5: 93.7500 (94.6600)
Test: [Whole Val]  Time: 9.645  Loss: 1.0606  Acc@1: 74.0100 Pruned: 50.55% 
Test (EMA): [   0/78]  Time: 0.311 (0.311)  Loss:  1.0127 (1.0127)  Acc@1: 76.5625 (76.5625)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.022 (0.121)  Loss:  0.9233 (1.0529)  Acc@1: 81.2500 (74.6700)  Acc@5: 93.7500 (94.9100)
Test (EMA): [Whole Val]  Time: 9.550  Loss: 1.0529  Acc@1: 74.6700 Pruned: 50.55% 
Train: 97 [   0/390 (  0%)]  Loss: 3.546 (3.55)  Time: 0.896s,  142.79/s  (0.896s,  142.79/s)  LR: 3.901e-04  Data: 0.594 (0.594)
Train: 97 [ 100/390 ( 26%)]  Loss: 2.933 (3.16)  Time: 0.313s,  409.41/s  (0.320s,  399.99/s)  LR: 3.901e-04  Data: 0.012 (0.018)
Train: 97 [ 200/390 ( 51%)]  Loss: 2.484 (3.24)  Time: 0.312s,  410.80/s  (0.317s,  403.91/s)  LR: 3.901e-04  Data: 0.012 (0.015)
Train: 97 [ 300/390 ( 77%)]  Loss: 3.522 (3.27)  Time: 0.315s,  406.88/s  (0.316s,  404.92/s)  LR: 3.901e-04  Data: 0.014 (0.014)
Train: 97 [ 389/390 (100%)]  Loss: 2.572 (3.28)  Time: 0.300s,  426.14/s  (0.316s,  404.95/s)  LR: 3.901e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.349 (0.349)  Loss:  1.0967 (1.0967)  Acc@1: 75.0000 (75.0000)  Acc@5: 96.0938 (96.0938)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.9443 (1.1075)  Acc@1: 75.0000 (74.6900)  Acc@5: 93.7500 (94.7500)
Test: [Whole Val]  Time: 9.535  Loss: 1.1075  Acc@1: 74.6900 Pruned: 50.55% 
Test (EMA): [   0/78]  Time: 0.309 (0.309)  Loss:  1.0947 (1.0947)  Acc@1: 74.2188 (74.2188)  Acc@5: 96.0938 (96.0938)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9438 (1.1102)  Acc@1: 81.2500 (74.9100)  Acc@5: 93.7500 (94.9000)
Test (EMA): [Whole Val]  Time: 9.526  Loss: 1.1102  Acc@1: 74.9100 Pruned: 50.55% 
Train: 98 [   0/390 (  0%)]  Loss: 3.136 (3.14)  Time: 0.872s,  146.75/s  (0.872s,  146.75/s)  LR: 3.811e-04  Data: 0.571 (0.571)
Train: 98 [ 100/390 ( 26%)]  Loss: 3.842 (3.31)  Time: 0.313s,  408.53/s  (0.321s,  399.01/s)  LR: 3.811e-04  Data: 0.012 (0.018)
Train: 98 [ 200/390 ( 51%)]  Loss: 2.409 (3.27)  Time: 0.313s,  409.37/s  (0.318s,  402.96/s)  LR: 3.811e-04  Data: 0.012 (0.015)
Train: 98 [ 300/390 ( 77%)]  Loss: 3.486 (3.26)  Time: 0.313s,  409.51/s  (0.316s,  404.82/s)  LR: 3.811e-04  Data: 0.012 (0.014)
Train: 98 [ 389/390 (100%)]  Loss: 2.188 (3.28)  Time: 0.300s,  426.69/s  (0.316s,  405.19/s)  LR: 3.811e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.335 (0.335)  Loss:  1.0781 (1.0781)  Acc@1: 73.4375 (73.4375)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.9907 (1.1061)  Acc@1: 75.0000 (74.5000)  Acc@5: 87.5000 (94.8900)
Test: [Whole Val]  Time: 9.566  Loss: 1.1061  Acc@1: 74.5000 Pruned: 50.55% 
Test (EMA): [   0/78]  Time: 0.313 (0.313)  Loss:  1.0664 (1.0664)  Acc@1: 72.6562 (72.6562)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9546 (1.0794)  Acc@1: 75.0000 (74.7000)  Acc@5: 93.7500 (94.8100)
Test (EMA): [Whole Val]  Time: 9.525  Loss: 1.0794  Acc@1: 74.7000 Pruned: 50.56% 
Train: 99 [   0/390 (  0%)]  Loss: 3.525 (3.52)  Time: 0.749s,  170.81/s  (0.749s,  170.81/s)  LR: 3.721e-04  Data: 0.449 (0.449)
Train: 99 [ 100/390 ( 26%)]  Loss: 2.229 (3.37)  Time: 0.312s,  410.17/s  (0.320s,  400.34/s)  LR: 3.721e-04  Data: 0.012 (0.017)
Train: 99 [ 200/390 ( 51%)]  Loss: 3.241 (3.33)  Time: 0.320s,  399.53/s  (0.317s,  404.19/s)  LR: 3.721e-04  Data: 0.018 (0.015)
Train: 99 [ 300/390 ( 77%)]  Loss: 2.621 (3.29)  Time: 0.314s,  407.89/s  (0.317s,  403.86/s)  LR: 3.721e-04  Data: 0.013 (0.014)
Train: 99 [ 389/390 (100%)]  Loss: 2.229 (3.28)  Time: 0.301s,  425.09/s  (0.316s,  404.95/s)  LR: 3.721e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.417 (0.417)  Loss:  1.0742 (1.0742)  Acc@1: 71.0938 (71.0938)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.9268 (1.0793)  Acc@1: 81.2500 (74.3700)  Acc@5: 93.7500 (94.7100)
Test: [Whole Val]  Time: 9.615  Loss: 1.0793  Acc@1: 74.3700 Pruned: 50.55% 
Test (EMA): [   0/78]  Time: 0.429 (0.429)  Loss:  1.0889 (1.0889)  Acc@1: 71.0938 (71.0938)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.9346 (1.0898)  Acc@1: 81.2500 (74.6700)  Acc@5: 93.7500 (94.9100)
Test (EMA): [Whole Val]  Time: 9.655  Loss: 1.0898  Acc@1: 74.6700 Pruned: 50.55% 
Train: 100 [   0/390 (  0%)]  Loss: 3.689 (3.69)  Time: 0.816s,  156.80/s  (0.816s,  156.80/s)  LR: 3.632e-04  Data: 0.510 (0.510)
Train: 100 [ 100/390 ( 26%)]  Loss: 3.315 (3.30)  Time: 0.315s,  406.57/s  (0.318s,  402.46/s)  LR: 3.632e-04  Data: 0.012 (0.017)
Train: 100 [ 200/390 ( 51%)]  Loss: 3.776 (3.28)  Time: 0.311s,  411.21/s  (0.316s,  404.78/s)  LR: 3.632e-04  Data: 0.012 (0.015)
Train: 100 [ 300/390 ( 77%)]  Loss: 3.436 (3.29)  Time: 0.314s,  407.58/s  (0.315s,  406.03/s)  LR: 3.632e-04  Data: 0.013 (0.014)
Train: 100 [ 389/390 (100%)]  Loss: 3.573 (3.27)  Time: 0.316s,  404.60/s  (0.316s,  405.59/s)  LR: 3.632e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.399 (0.399)  Loss:  0.9741 (0.9741)  Acc@1: 75.7812 (75.7812)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.018 (0.121)  Loss:  0.8052 (1.0213)  Acc@1: 87.5000 (74.8500)  Acc@5: 93.7500 (94.7400)
Test: [Whole Val]  Time: 9.584  Loss: 1.0213  Acc@1: 74.8500 Pruned: 50.55% 
Test (EMA): [   0/78]  Time: 0.389 (0.389)  Loss:  0.9912 (0.9912)  Acc@1: 75.0000 (75.0000)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.8330 (1.0274)  Acc@1: 81.2500 (74.9000)  Acc@5: 93.7500 (94.9400)
Test (EMA): [Whole Val]  Time: 9.594  Loss: 1.0274  Acc@1: 74.9000 Pruned: 50.54% 
Train: 101 [   0/390 (  0%)]  Loss: 2.765 (2.77)  Time: 0.829s,  154.36/s  (0.829s,  154.36/s)  LR: 3.544e-04  Data: 0.522 (0.522)
Train: 101 [ 100/390 ( 26%)]  Loss: 3.484 (3.22)  Time: 0.319s,  401.66/s  (0.325s,  393.89/s)  LR: 3.544e-04  Data: 0.015 (0.018)
Train: 101 [ 200/390 ( 51%)]  Loss: 3.683 (3.22)  Time: 0.314s,  407.89/s  (0.320s,  399.55/s)  LR: 3.544e-04  Data: 0.013 (0.015)
Train: 101 [ 300/390 ( 77%)]  Loss: 2.523 (3.23)  Time: 0.317s,  403.88/s  (0.320s,  400.51/s)  LR: 3.544e-04  Data: 0.015 (0.015)
Train: 101 [ 389/390 (100%)]  Loss: 2.613 (3.24)  Time: 0.301s,  424.83/s  (0.318s,  402.37/s)  LR: 3.544e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.421 (0.421)  Loss:  1.0830 (1.0830)  Acc@1: 71.0938 (71.0938)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.9751 (1.0953)  Acc@1: 75.0000 (74.5200)  Acc@5: 93.7500 (94.7000)
Test: [Whole Val]  Time: 9.643  Loss: 1.0953  Acc@1: 74.5200 Pruned: 50.55% 
Test (EMA): [   0/78]  Time: 0.306 (0.306)  Loss:  1.0693 (1.0693)  Acc@1: 72.6562 (72.6562)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9390 (1.0814)  Acc@1: 75.0000 (74.9000)  Acc@5: 93.7500 (94.8500)
Test (EMA): [Whole Val]  Time: 9.526  Loss: 1.0814  Acc@1: 74.9000 Pruned: 50.55% 
Train: 102 [   0/390 (  0%)]  Loss: 2.770 (2.77)  Time: 0.862s,  148.57/s  (0.862s,  148.57/s)  LR: 3.456e-04  Data: 0.555 (0.555)
Train: 102 [ 100/390 ( 26%)]  Loss: 2.309 (3.22)  Time: 0.312s,  409.69/s  (0.324s,  394.61/s)  LR: 3.456e-04  Data: 0.012 (0.018)
Train: 102 [ 200/390 ( 51%)]  Loss: 3.550 (3.24)  Time: 0.314s,  408.22/s  (0.319s,  401.14/s)  LR: 3.456e-04  Data: 0.012 (0.015)
Train: 102 [ 300/390 ( 77%)]  Loss: 3.161 (3.24)  Time: 0.312s,  409.62/s  (0.317s,  403.33/s)  LR: 3.456e-04  Data: 0.012 (0.014)
Train: 102 [ 389/390 (100%)]  Loss: 3.003 (3.24)  Time: 0.301s,  424.83/s  (0.317s,  404.16/s)  LR: 3.456e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.414 (0.414)  Loss:  1.0928 (1.0928)  Acc@1: 74.2188 (74.2188)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.9521 (1.1088)  Acc@1: 68.7500 (74.7000)  Acc@5: 87.5000 (94.8300)
Test: [Whole Val]  Time: 9.614  Loss: 1.1088  Acc@1: 74.7000 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.324 (0.324)  Loss:  1.0752 (1.0752)  Acc@1: 74.2188 (74.2188)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9482 (1.1073)  Acc@1: 75.0000 (75.0300)  Acc@5: 93.7500 (94.8400)
Test (EMA): [Whole Val]  Time: 9.532  Loss: 1.1073  Acc@1: 75.0300 Pruned: 50.53% 
Train: 103 [   0/390 (  0%)]  Loss: 2.744 (2.74)  Time: 0.959s,  133.52/s  (0.959s,  133.52/s)  LR: 3.368e-04  Data: 0.643 (0.643)
Train: 103 [ 100/390 ( 26%)]  Loss: 2.431 (3.23)  Time: 0.326s,  392.64/s  (0.322s,  397.17/s)  LR: 3.368e-04  Data: 0.012 (0.019)
Train: 103 [ 200/390 ( 51%)]  Loss: 3.476 (3.21)  Time: 0.314s,  407.37/s  (0.318s,  402.64/s)  LR: 3.368e-04  Data: 0.013 (0.016)
Train: 103 [ 300/390 ( 77%)]  Loss: 3.461 (3.23)  Time: 0.314s,  407.72/s  (0.316s,  404.66/s)  LR: 3.368e-04  Data: 0.012 (0.014)
Train: 103 [ 389/390 (100%)]  Loss: 3.363 (3.24)  Time: 0.301s,  424.88/s  (0.316s,  405.56/s)  LR: 3.368e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.321 (0.321)  Loss:  1.0059 (1.0059)  Acc@1: 72.6562 (72.6562)  Acc@5: 96.0938 (96.0938)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.8701 (1.0414)  Acc@1: 75.0000 (74.7800)  Acc@5: 93.7500 (95.0800)
Test: [Whole Val]  Time: 9.529  Loss: 1.0414  Acc@1: 74.7800 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.361 (0.361)  Loss:  1.0322 (1.0322)  Acc@1: 73.4375 (73.4375)  Acc@5: 96.0938 (96.0938)
Test (EMA): [  78/78]  Time: 0.021 (0.121)  Loss:  0.9014 (1.0579)  Acc@1: 75.0000 (74.9400)  Acc@5: 93.7500 (95.0300)
Test (EMA): [Whole Val]  Time: 9.579  Loss: 1.0579  Acc@1: 74.9400 Pruned: 50.54% 
Train: 104 [   0/390 (  0%)]  Loss: 2.239 (2.24)  Time: 0.790s,  162.11/s  (0.790s,  162.11/s)  LR: 3.281e-04  Data: 0.452 (0.452)
Train: 104 [ 100/390 ( 26%)]  Loss: 3.754 (3.23)  Time: 0.317s,  403.80/s  (0.321s,  399.26/s)  LR: 3.281e-04  Data: 0.015 (0.017)
Train: 104 [ 200/390 ( 51%)]  Loss: 3.355 (3.24)  Time: 0.326s,  392.46/s  (0.319s,  401.34/s)  LR: 3.281e-04  Data: 0.012 (0.015)
Train: 104 [ 300/390 ( 77%)]  Loss: 3.751 (3.25)  Time: 0.312s,  410.45/s  (0.320s,  400.35/s)  LR: 3.281e-04  Data: 0.012 (0.014)
Train: 104 [ 389/390 (100%)]  Loss: 3.386 (3.25)  Time: 0.301s,  425.55/s  (0.318s,  402.16/s)  LR: 3.281e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.312 (0.312)  Loss:  1.0654 (1.0654)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.9678 (1.0791)  Acc@1: 75.0000 (75.0700)  Acc@5: 93.7500 (94.7800)
Test: [Whole Val]  Time: 9.536  Loss: 1.0791  Acc@1: 75.0700 Pruned: 50.56% 
Test (EMA): [   0/78]  Time: 0.402 (0.402)  Loss:  1.0527 (1.0527)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.9590 (1.0546)  Acc@1: 75.0000 (75.2300)  Acc@5: 87.5000 (95.0800)
Test (EMA): [Whole Val]  Time: 9.651  Loss: 1.0546  Acc@1: 75.2300 Pruned: 50.56% 
Train: 105 [   0/390 (  0%)]  Loss: 3.549 (3.55)  Time: 0.775s,  165.24/s  (0.775s,  165.24/s)  LR: 3.194e-04  Data: 0.469 (0.469)
Train: 105 [ 100/390 ( 26%)]  Loss: 3.832 (3.29)  Time: 0.313s,  408.64/s  (0.319s,  401.48/s)  LR: 3.194e-04  Data: 0.012 (0.017)
Train: 105 [ 200/390 ( 51%)]  Loss: 3.541 (3.26)  Time: 0.321s,  398.23/s  (0.317s,  403.27/s)  LR: 3.194e-04  Data: 0.018 (0.015)
Train: 105 [ 300/390 ( 77%)]  Loss: 3.736 (3.25)  Time: 0.311s,  411.46/s  (0.317s,  404.35/s)  LR: 3.194e-04  Data: 0.012 (0.014)
Train: 105 [ 389/390 (100%)]  Loss: 2.681 (3.25)  Time: 0.302s,  423.70/s  (0.316s,  405.24/s)  LR: 3.194e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.408 (0.408)  Loss:  1.0283 (1.0283)  Acc@1: 74.2188 (74.2188)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.025 (0.122)  Loss:  0.8823 (1.0847)  Acc@1: 81.2500 (74.5400)  Acc@5: 93.7500 (94.7100)
Test: [Whole Val]  Time: 9.654  Loss: 1.0847  Acc@1: 74.5400 Pruned: 50.55% 
Test (EMA): [   0/78]  Time: 0.419 (0.419)  Loss:  1.0254 (1.0254)  Acc@1: 73.4375 (73.4375)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.021 (0.122)  Loss:  0.8877 (1.0613)  Acc@1: 75.0000 (74.9500)  Acc@5: 93.7500 (95.0000)
Test (EMA): [Whole Val]  Time: 9.654  Loss: 1.0613  Acc@1: 74.9500 Pruned: 50.56% 
Train: 106 [   0/390 (  0%)]  Loss: 3.767 (3.77)  Time: 0.880s,  145.46/s  (0.880s,  145.46/s)  LR: 3.109e-04  Data: 0.564 (0.564)
Train: 106 [ 100/390 ( 26%)]  Loss: 3.785 (3.23)  Time: 0.313s,  408.80/s  (0.319s,  400.71/s)  LR: 3.109e-04  Data: 0.013 (0.018)
Train: 106 [ 200/390 ( 51%)]  Loss: 3.848 (3.26)  Time: 0.314s,  407.69/s  (0.318s,  403.04/s)  LR: 3.109e-04  Data: 0.013 (0.015)
Train: 106 [ 300/390 ( 77%)]  Loss: 2.240 (3.23)  Time: 0.314s,  407.18/s  (0.316s,  404.75/s)  LR: 3.109e-04  Data: 0.013 (0.014)
Train: 106 [ 389/390 (100%)]  Loss: 3.428 (3.24)  Time: 0.301s,  424.81/s  (0.316s,  405.61/s)  LR: 3.109e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.427 (0.427)  Loss:  1.0400 (1.0400)  Acc@1: 73.4375 (73.4375)  Acc@5: 96.0938 (96.0938)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.9263 (1.0530)  Acc@1: 75.0000 (74.8800)  Acc@5: 93.7500 (94.8100)
Test: [Whole Val]  Time: 9.642  Loss: 1.0530  Acc@1: 74.8800 Pruned: 50.55% 
Test (EMA): [   0/78]  Time: 0.313 (0.313)  Loss:  1.0303 (1.0303)  Acc@1: 72.6562 (72.6562)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9355 (1.0590)  Acc@1: 75.0000 (75.0200)  Acc@5: 93.7500 (94.9200)
Test (EMA): [Whole Val]  Time: 9.574  Loss: 1.0590  Acc@1: 75.0200 Pruned: 50.55% 
Train: 107 [   0/390 (  0%)]  Loss: 3.314 (3.31)  Time: 0.802s,  159.69/s  (0.802s,  159.69/s)  LR: 3.023e-04  Data: 0.491 (0.491)
Train: 107 [ 100/390 ( 26%)]  Loss: 3.844 (3.29)  Time: 0.317s,  403.31/s  (0.318s,  401.91/s)  LR: 3.023e-04  Data: 0.017 (0.017)
Train: 107 [ 200/390 ( 51%)]  Loss: 3.421 (3.28)  Time: 0.313s,  408.83/s  (0.316s,  404.94/s)  LR: 3.023e-04  Data: 0.012 (0.015)
Train: 107 [ 300/390 ( 77%)]  Loss: 2.583 (3.29)  Time: 0.311s,  411.30/s  (0.315s,  406.10/s)  LR: 3.023e-04  Data: 0.012 (0.014)
Train: 107 [ 389/390 (100%)]  Loss: 3.861 (3.29)  Time: 0.300s,  426.46/s  (0.315s,  406.30/s)  LR: 3.023e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.327 (0.327)  Loss:  1.0596 (1.0596)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.9106 (1.0850)  Acc@1: 81.2500 (74.8000)  Acc@5: 93.7500 (94.9000)
Test: [Whole Val]  Time: 9.542  Loss: 1.0850  Acc@1: 74.8000 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.308 (0.308)  Loss:  1.0381 (1.0381)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9165 (1.0590)  Acc@1: 75.0000 (75.1300)  Acc@5: 93.7500 (94.8800)
Test (EMA): [Whole Val]  Time: 9.546  Loss: 1.0590  Acc@1: 75.1300 Pruned: 50.54% 
Train: 108 [   0/390 (  0%)]  Loss: 2.947 (2.95)  Time: 0.794s,  161.22/s  (0.794s,  161.22/s)  LR: 2.939e-04  Data: 0.493 (0.493)
Train: 108 [ 100/390 ( 26%)]  Loss: 3.884 (3.27)  Time: 0.318s,  402.44/s  (0.318s,  402.09/s)  LR: 2.939e-04  Data: 0.011 (0.017)
Train: 108 [ 200/390 ( 51%)]  Loss: 3.285 (3.25)  Time: 0.312s,  410.22/s  (0.316s,  404.51/s)  LR: 2.939e-04  Data: 0.012 (0.015)
Train: 108 [ 300/390 ( 77%)]  Loss: 3.488 (3.23)  Time: 0.313s,  409.41/s  (0.315s,  405.85/s)  LR: 2.939e-04  Data: 0.012 (0.014)
Train: 108 [ 389/390 (100%)]  Loss: 3.484 (3.23)  Time: 0.300s,  426.33/s  (0.315s,  406.48/s)  LR: 2.939e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.421 (0.421)  Loss:  1.0596 (1.0596)  Acc@1: 75.7812 (75.7812)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.9580 (1.0683)  Acc@1: 75.0000 (75.0600)  Acc@5: 93.7500 (95.1300)
Test: [Whole Val]  Time: 9.639  Loss: 1.0683  Acc@1: 75.0600 Pruned: 50.53% 
Test (EMA): [   0/78]  Time: 0.348 (0.348)  Loss:  1.0381 (1.0381)  Acc@1: 74.2188 (74.2188)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.018 (0.121)  Loss:  0.9048 (1.0439)  Acc@1: 75.0000 (74.9600)  Acc@5: 93.7500 (95.0600)
Test (EMA): [Whole Val]  Time: 9.572  Loss: 1.0439  Acc@1: 74.9600 Pruned: 50.53% 
Train: 109 [   0/390 (  0%)]  Loss: 2.706 (2.71)  Time: 0.861s,  148.73/s  (0.861s,  148.73/s)  LR: 2.855e-04  Data: 0.535 (0.535)
Train: 109 [ 100/390 ( 26%)]  Loss: 3.314 (3.22)  Time: 0.329s,  389.08/s  (0.320s,  400.55/s)  LR: 2.855e-04  Data: 0.012 (0.018)
Train: 109 [ 200/390 ( 51%)]  Loss: 2.859 (3.21)  Time: 0.313s,  409.39/s  (0.319s,  401.16/s)  LR: 2.855e-04  Data: 0.012 (0.015)
Train: 109 [ 300/390 ( 77%)]  Loss: 3.455 (3.26)  Time: 0.312s,  410.52/s  (0.318s,  401.98/s)  LR: 2.855e-04  Data: 0.012 (0.014)
Train: 109 [ 389/390 (100%)]  Loss: 3.735 (3.26)  Time: 0.301s,  424.70/s  (0.318s,  402.25/s)  LR: 2.855e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.413 (0.413)  Loss:  1.0332 (1.0332)  Acc@1: 72.6562 (72.6562)  Acc@5: 96.0938 (96.0938)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.8789 (1.0592)  Acc@1: 81.2500 (74.9600)  Acc@5: 93.7500 (94.9700)
Test: [Whole Val]  Time: 9.645  Loss: 1.0592  Acc@1: 74.9600 Pruned: 50.53% 
Test (EMA): [   0/78]  Time: 0.358 (0.358)  Loss:  1.0312 (1.0312)  Acc@1: 72.6562 (72.6562)  Acc@5: 96.0938 (96.0938)
Test (EMA): [  78/78]  Time: 0.021 (0.122)  Loss:  0.8979 (1.0653)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (95.0000)
Test (EMA): [Whole Val]  Time: 9.630  Loss: 1.0653  Acc@1: 75.0000 Pruned: 50.53% 
Train: 110 [   0/390 (  0%)]  Loss: 3.598 (3.60)  Time: 0.931s,  137.42/s  (0.931s,  137.42/s)  LR: 2.772e-04  Data: 0.631 (0.631)
Train: 110 [ 100/390 ( 26%)]  Loss: 3.624 (3.23)  Time: 0.331s,  386.18/s  (0.320s,  400.00/s)  LR: 2.772e-04  Data: 0.017 (0.018)
Train: 110 [ 200/390 ( 51%)]  Loss: 3.783 (3.28)  Time: 0.312s,  409.73/s  (0.317s,  403.50/s)  LR: 2.772e-04  Data: 0.012 (0.015)
Train: 110 [ 300/390 ( 77%)]  Loss: 2.533 (3.26)  Time: 0.313s,  409.04/s  (0.318s,  402.85/s)  LR: 2.772e-04  Data: 0.013 (0.015)
Train: 110 [ 389/390 (100%)]  Loss: 3.424 (3.24)  Time: 0.301s,  425.46/s  (0.317s,  404.10/s)  LR: 2.772e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.326 (0.326)  Loss:  1.0645 (1.0645)  Acc@1: 73.4375 (73.4375)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.018 (0.121)  Loss:  0.9658 (1.0841)  Acc@1: 75.0000 (74.9100)  Acc@5: 87.5000 (94.8300)
Test: [Whole Val]  Time: 9.549  Loss: 1.0841  Acc@1: 74.9100 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.360 (0.360)  Loss:  1.0361 (1.0361)  Acc@1: 71.0938 (71.0938)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.9150 (1.0554)  Acc@1: 75.0000 (74.8800)  Acc@5: 93.7500 (94.9700)
Test (EMA): [Whole Val]  Time: 9.621  Loss: 1.0554  Acc@1: 74.8800 Pruned: 50.54% 
Train: 111 [   0/390 (  0%)]  Loss: 3.644 (3.64)  Time: 0.779s,  164.41/s  (0.779s,  164.41/s)  LR: 2.690e-04  Data: 0.466 (0.466)
Train: 111 [ 100/390 ( 26%)]  Loss: 3.465 (3.28)  Time: 0.326s,  392.48/s  (0.327s,  391.78/s)  LR: 2.690e-04  Data: 0.012 (0.017)
Train: 111 [ 200/390 ( 51%)]  Loss: 3.496 (3.26)  Time: 0.313s,  409.38/s  (0.321s,  398.84/s)  LR: 2.690e-04  Data: 0.012 (0.015)
Train: 111 [ 300/390 ( 77%)]  Loss: 3.182 (3.26)  Time: 0.328s,  390.07/s  (0.319s,  401.09/s)  LR: 2.690e-04  Data: 0.012 (0.014)
Train: 111 [ 389/390 (100%)]  Loss: 3.618 (3.25)  Time: 0.303s,  422.86/s  (0.318s,  402.24/s)  LR: 2.690e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.415 (0.415)  Loss:  1.0850 (1.0850)  Acc@1: 71.8750 (71.8750)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.9741 (1.0957)  Acc@1: 75.0000 (74.9900)  Acc@5: 93.7500 (94.8900)
Test: [Whole Val]  Time: 9.656  Loss: 1.0957  Acc@1: 74.9900 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.399 (0.399)  Loss:  1.0723 (1.0723)  Acc@1: 71.8750 (71.8750)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.9585 (1.0845)  Acc@1: 75.0000 (74.9200)  Acc@5: 93.7500 (94.8300)
Test (EMA): [Whole Val]  Time: 9.643  Loss: 1.0845  Acc@1: 74.9200 Pruned: 50.54% 
Train: 112 [   0/390 (  0%)]  Loss: 2.898 (2.90)  Time: 0.723s,  177.03/s  (0.723s,  177.03/s)  LR: 2.608e-04  Data: 0.412 (0.412)
Train: 112 [ 100/390 ( 26%)]  Loss: 3.622 (3.27)  Time: 0.314s,  407.07/s  (0.320s,  399.51/s)  LR: 2.608e-04  Data: 0.014 (0.017)
Train: 112 [ 200/390 ( 51%)]  Loss: 3.620 (3.28)  Time: 0.313s,  408.85/s  (0.318s,  402.23/s)  LR: 2.608e-04  Data: 0.012 (0.015)
Train: 112 [ 300/390 ( 77%)]  Loss: 3.599 (3.26)  Time: 0.314s,  407.80/s  (0.317s,  403.56/s)  LR: 2.608e-04  Data: 0.014 (0.014)
Train: 112 [ 389/390 (100%)]  Loss: 3.075 (3.26)  Time: 0.301s,  425.02/s  (0.316s,  404.70/s)  LR: 2.608e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.336 (0.336)  Loss:  1.1104 (1.1104)  Acc@1: 73.4375 (73.4375)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.0547 (1.1106)  Acc@1: 75.0000 (75.2000)  Acc@5: 87.5000 (94.9100)
Test: [Whole Val]  Time: 9.590  Loss: 1.1106  Acc@1: 75.2000 Pruned: 50.55% 
Test (EMA): [   0/78]  Time: 0.412 (0.412)  Loss:  1.0918 (1.0918)  Acc@1: 74.2188 (74.2188)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  1.0098 (1.1027)  Acc@1: 75.0000 (74.9100)  Acc@5: 87.5000 (94.8100)
Test (EMA): [Whole Val]  Time: 9.652  Loss: 1.1027  Acc@1: 74.9100 Pruned: 50.55% 
Train: 113 [   0/390 (  0%)]  Loss: 3.465 (3.46)  Time: 0.818s,  156.57/s  (0.818s,  156.57/s)  LR: 2.527e-04  Data: 0.499 (0.499)
Train: 113 [ 100/390 ( 26%)]  Loss: 2.802 (3.22)  Time: 0.317s,  403.15/s  (0.322s,  397.25/s)  LR: 2.527e-04  Data: 0.016 (0.018)
Train: 113 [ 200/390 ( 51%)]  Loss: 3.326 (3.23)  Time: 0.315s,  406.36/s  (0.318s,  402.09/s)  LR: 2.527e-04  Data: 0.014 (0.015)
Train: 113 [ 300/390 ( 77%)]  Loss: 2.956 (3.22)  Time: 0.330s,  387.81/s  (0.318s,  402.14/s)  LR: 2.527e-04  Data: 0.014 (0.014)
Train: 113 [ 389/390 (100%)]  Loss: 3.464 (3.22)  Time: 0.317s,  403.32/s  (0.318s,  402.88/s)  LR: 2.527e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.431 (0.431)  Loss:  1.0166 (1.0166)  Acc@1: 72.6562 (72.6562)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.123)  Loss:  0.9136 (1.0556)  Acc@1: 75.0000 (75.0600)  Acc@5: 93.7500 (94.8100)
Test: [Whole Val]  Time: 9.684  Loss: 1.0556  Acc@1: 75.0600 Pruned: 50.55% 
Test (EMA): [   0/78]  Time: 0.413 (0.413)  Loss:  1.0088 (1.0088)  Acc@1: 73.4375 (73.4375)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.9121 (1.0440)  Acc@1: 75.0000 (75.0200)  Acc@5: 93.7500 (94.8000)
Test (EMA): [Whole Val]  Time: 9.643  Loss: 1.0440  Acc@1: 75.0200 Pruned: 50.55% 
Train: 114 [   0/390 (  0%)]  Loss: 3.424 (3.42)  Time: 0.884s,  144.79/s  (0.884s,  144.79/s)  LR: 2.448e-04  Data: 0.580 (0.580)
Train: 114 [ 100/390 ( 26%)]  Loss: 3.498 (3.27)  Time: 0.314s,  407.53/s  (0.321s,  398.43/s)  LR: 2.448e-04  Data: 0.013 (0.018)
Train: 114 [ 200/390 ( 51%)]  Loss: 2.950 (3.25)  Time: 0.316s,  405.16/s  (0.319s,  401.07/s)  LR: 2.448e-04  Data: 0.014 (0.016)
Train: 114 [ 300/390 ( 77%)]  Loss: 2.656 (3.25)  Time: 0.317s,  403.84/s  (0.317s,  403.39/s)  LR: 2.448e-04  Data: 0.016 (0.015)
Train: 114 [ 389/390 (100%)]  Loss: 2.463 (3.26)  Time: 0.302s,  423.33/s  (0.316s,  404.54/s)  LR: 2.448e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.420 (0.420)  Loss:  1.0596 (1.0596)  Acc@1: 73.4375 (73.4375)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.9194 (1.0641)  Acc@1: 75.0000 (75.2700)  Acc@5: 87.5000 (95.0900)
Test: [Whole Val]  Time: 9.618  Loss: 1.0641  Acc@1: 75.2700 Pruned: 50.55% 
Test (EMA): [   0/78]  Time: 0.404 (0.404)  Loss:  1.0684 (1.0684)  Acc@1: 72.6562 (72.6562)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.9473 (1.0732)  Acc@1: 75.0000 (75.3400)  Acc@5: 87.5000 (94.9800)
Test (EMA): [Whole Val]  Time: 9.627  Loss: 1.0732  Acc@1: 75.3400 Pruned: 50.55% 
Train: 115 [   0/390 (  0%)]  Loss: 3.715 (3.71)  Time: 0.805s,  158.92/s  (0.805s,  158.92/s)  LR: 2.369e-04  Data: 0.504 (0.504)
Train: 115 [ 100/390 ( 26%)]  Loss: 3.482 (3.24)  Time: 0.316s,  405.68/s  (0.319s,  401.76/s)  LR: 2.369e-04  Data: 0.012 (0.017)
Train: 115 [ 200/390 ( 51%)]  Loss: 3.777 (3.23)  Time: 0.328s,  389.88/s  (0.317s,  403.35/s)  LR: 2.369e-04  Data: 0.014 (0.015)
Train: 115 [ 300/390 ( 77%)]  Loss: 2.928 (3.25)  Time: 0.312s,  410.26/s  (0.318s,  403.12/s)  LR: 2.369e-04  Data: 0.012 (0.014)
Train: 115 [ 389/390 (100%)]  Loss: 3.315 (3.25)  Time: 0.301s,  424.76/s  (0.316s,  404.43/s)  LR: 2.369e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.375 (0.375)  Loss:  1.0635 (1.0635)  Acc@1: 71.8750 (71.8750)  Acc@5: 96.0938 (96.0938)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.9814 (1.0970)  Acc@1: 75.0000 (74.7600)  Acc@5: 93.7500 (94.8900)
Test: [Whole Val]  Time: 9.587  Loss: 1.0970  Acc@1: 74.7600 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.340 (0.340)  Loss:  1.0449 (1.0449)  Acc@1: 71.8750 (71.8750)  Acc@5: 96.8750 (96.8750)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9624 (1.0805)  Acc@1: 75.0000 (74.9300)  Acc@5: 93.7500 (95.0400)
Test (EMA): [Whole Val]  Time: 9.559  Loss: 1.0805  Acc@1: 74.9300 Pruned: 50.54% 
Train: 116 [   0/390 (  0%)]  Loss: 2.784 (2.78)  Time: 0.814s,  157.17/s  (0.814s,  157.17/s)  LR: 2.291e-04  Data: 0.512 (0.512)
Train: 116 [ 100/390 ( 26%)]  Loss: 3.873 (3.27)  Time: 0.327s,  391.47/s  (0.321s,  398.94/s)  LR: 2.291e-04  Data: 0.013 (0.018)
Train: 116 [ 200/390 ( 51%)]  Loss: 3.560 (3.25)  Time: 0.327s,  391.04/s  (0.321s,  398.53/s)  LR: 2.291e-04  Data: 0.012 (0.015)
Train: 116 [ 300/390 ( 77%)]  Loss: 3.649 (3.26)  Time: 0.312s,  410.76/s  (0.319s,  401.52/s)  LR: 2.291e-04  Data: 0.012 (0.014)
Train: 116 [ 389/390 (100%)]  Loss: 2.219 (3.24)  Time: 0.300s,  426.73/s  (0.318s,  403.02/s)  LR: 2.291e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.366 (0.366)  Loss:  1.0186 (1.0186)  Acc@1: 73.4375 (73.4375)  Acc@5: 96.0938 (96.0938)
Test: [  78/78]  Time: 0.018 (0.121)  Loss:  0.8838 (1.0542)  Acc@1: 75.0000 (74.7700)  Acc@5: 93.7500 (94.8600)
Test: [Whole Val]  Time: 9.598  Loss: 1.0542  Acc@1: 74.7700 Pruned: 50.53% 
Test (EMA): [   0/78]  Time: 0.425 (0.425)  Loss:  1.0107 (1.0107)  Acc@1: 73.4375 (73.4375)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.8955 (1.0373)  Acc@1: 75.0000 (75.1700)  Acc@5: 93.7500 (95.1400)
Test (EMA): [Whole Val]  Time: 9.612  Loss: 1.0373  Acc@1: 75.1700 Pruned: 50.54% 
Train: 117 [   0/390 (  0%)]  Loss: 3.138 (3.14)  Time: 0.798s,  160.46/s  (0.798s,  160.46/s)  LR: 2.213e-04  Data: 0.484 (0.484)
Train: 117 [ 100/390 ( 26%)]  Loss: 3.610 (3.22)  Time: 0.319s,  401.23/s  (0.319s,  401.30/s)  LR: 2.213e-04  Data: 0.013 (0.018)
Train: 117 [ 200/390 ( 51%)]  Loss: 3.693 (3.22)  Time: 0.312s,  410.34/s  (0.318s,  403.01/s)  LR: 2.213e-04  Data: 0.011 (0.015)
Train: 117 [ 300/390 ( 77%)]  Loss: 2.868 (3.19)  Time: 0.314s,  407.20/s  (0.317s,  404.07/s)  LR: 2.213e-04  Data: 0.014 (0.014)
Train: 117 [ 389/390 (100%)]  Loss: 3.320 (3.20)  Time: 0.300s,  426.47/s  (0.316s,  405.03/s)  LR: 2.213e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.363 (0.363)  Loss:  1.0557 (1.0557)  Acc@1: 74.2188 (74.2188)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.022 (0.122)  Loss:  0.9072 (1.0608)  Acc@1: 75.0000 (74.7100)  Acc@5: 93.7500 (94.7400)
Test: [Whole Val]  Time: 9.602  Loss: 1.0608  Acc@1: 74.7100 Pruned: 50.55% 
Test (EMA): [   0/78]  Time: 0.379 (0.379)  Loss:  1.0400 (1.0400)  Acc@1: 73.4375 (73.4375)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.9404 (1.0528)  Acc@1: 75.0000 (75.1200)  Acc@5: 93.7500 (94.9800)
Test (EMA): [Whole Val]  Time: 9.602  Loss: 1.0528  Acc@1: 75.1200 Pruned: 50.55% 
Train: 118 [   0/390 (  0%)]  Loss: 3.479 (3.48)  Time: 0.897s,  142.66/s  (0.897s,  142.66/s)  LR: 2.137e-04  Data: 0.598 (0.598)
Train: 118 [ 100/390 ( 26%)]  Loss: 3.799 (3.26)  Time: 0.315s,  406.31/s  (0.321s,  398.73/s)  LR: 2.137e-04  Data: 0.014 (0.018)
Train: 118 [ 200/390 ( 51%)]  Loss: 2.335 (3.21)  Time: 0.316s,  405.25/s  (0.319s,  400.91/s)  LR: 2.137e-04  Data: 0.012 (0.016)
Train: 118 [ 300/390 ( 77%)]  Loss: 2.421 (3.23)  Time: 0.314s,  407.92/s  (0.318s,  402.62/s)  LR: 2.137e-04  Data: 0.014 (0.015)
Train: 118 [ 389/390 (100%)]  Loss: 2.563 (3.25)  Time: 0.302s,  424.03/s  (0.317s,  403.83/s)  LR: 2.137e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.418 (0.418)  Loss:  1.0186 (1.0186)  Acc@1: 71.8750 (71.8750)  Acc@5: 96.8750 (96.8750)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.8979 (1.0697)  Acc@1: 75.0000 (74.5400)  Acc@5: 93.7500 (95.1400)
Test: [Whole Val]  Time: 9.640  Loss: 1.0697  Acc@1: 74.5400 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.431 (0.431)  Loss:  1.0195 (1.0195)  Acc@1: 73.4375 (73.4375)  Acc@5: 96.0938 (96.0938)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.9395 (1.0644)  Acc@1: 75.0000 (74.9400)  Acc@5: 93.7500 (95.2100)
Test (EMA): [Whole Val]  Time: 9.633  Loss: 1.0644  Acc@1: 74.9400 Pruned: 50.54% 
Train: 119 [   0/390 (  0%)]  Loss: 3.814 (3.81)  Time: 0.891s,  143.66/s  (0.891s,  143.66/s)  LR: 2.062e-04  Data: 0.576 (0.576)
Train: 119 [ 100/390 ( 26%)]  Loss: 2.500 (3.23)  Time: 0.314s,  408.13/s  (0.320s,  400.50/s)  LR: 2.062e-04  Data: 0.014 (0.018)
Train: 119 [ 200/390 ( 51%)]  Loss: 2.938 (3.21)  Time: 0.315s,  406.54/s  (0.318s,  402.87/s)  LR: 2.062e-04  Data: 0.014 (0.015)
Train: 119 [ 300/390 ( 77%)]  Loss: 2.743 (3.21)  Time: 0.315s,  406.94/s  (0.316s,  404.52/s)  LR: 2.062e-04  Data: 0.012 (0.014)
Train: 119 [ 389/390 (100%)]  Loss: 3.136 (3.21)  Time: 0.302s,  423.27/s  (0.316s,  405.23/s)  LR: 2.062e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.425 (0.425)  Loss:  1.0293 (1.0293)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.8882 (1.0448)  Acc@1: 75.0000 (75.2100)  Acc@5: 100.0000 (94.8900)
Test: [Whole Val]  Time: 9.654  Loss: 1.0448  Acc@1: 75.2100 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.399 (0.399)  Loss:  1.0293 (1.0293)  Acc@1: 72.6562 (72.6562)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9155 (1.0515)  Acc@1: 75.0000 (75.2100)  Acc@5: 100.0000 (94.9400)
Test (EMA): [Whole Val]  Time: 9.598  Loss: 1.0515  Acc@1: 75.2100 Pruned: 50.54% 
Train: 120 [   0/390 (  0%)]  Loss: 3.522 (3.52)  Time: 0.782s,  163.75/s  (0.782s,  163.75/s)  LR: 1.988e-04  Data: 0.468 (0.468)
Train: 120 [ 100/390 ( 26%)]  Loss: 3.852 (3.20)  Time: 0.325s,  393.92/s  (0.320s,  399.83/s)  LR: 1.988e-04  Data: 0.014 (0.017)
Train: 120 [ 200/390 ( 51%)]  Loss: 3.368 (3.26)  Time: 0.314s,  407.70/s  (0.317s,  403.56/s)  LR: 1.988e-04  Data: 0.011 (0.015)
Train: 120 [ 300/390 ( 77%)]  Loss: 3.550 (3.25)  Time: 0.315s,  406.01/s  (0.316s,  405.11/s)  LR: 1.988e-04  Data: 0.012 (0.014)
Train: 120 [ 389/390 (100%)]  Loss: 3.118 (3.24)  Time: 0.301s,  425.89/s  (0.316s,  404.57/s)  LR: 1.988e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.395 (0.395)  Loss:  1.0557 (1.0557)  Acc@1: 73.4375 (73.4375)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.9355 (1.0896)  Acc@1: 81.2500 (75.2000)  Acc@5: 93.7500 (95.0500)
Test: [Whole Val]  Time: 9.627  Loss: 1.0896  Acc@1: 75.2000 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.418 (0.418)  Loss:  1.0498 (1.0498)  Acc@1: 73.4375 (73.4375)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.9346 (1.0701)  Acc@1: 75.0000 (75.2600)  Acc@5: 93.7500 (95.0800)
Test (EMA): [Whole Val]  Time: 9.653  Loss: 1.0701  Acc@1: 75.2600 Pruned: 50.54% 
Train: 121 [   0/390 (  0%)]  Loss: 3.304 (3.30)  Time: 0.875s,  146.32/s  (0.875s,  146.32/s)  LR: 1.914e-04  Data: 0.557 (0.557)
Train: 121 [ 100/390 ( 26%)]  Loss: 3.543 (3.11)  Time: 0.316s,  404.65/s  (0.320s,  400.57/s)  LR: 1.914e-04  Data: 0.015 (0.018)
Train: 121 [ 200/390 ( 51%)]  Loss: 3.659 (3.16)  Time: 0.310s,  412.27/s  (0.317s,  403.94/s)  LR: 1.914e-04  Data: 0.011 (0.015)
Train: 121 [ 300/390 ( 77%)]  Loss: 2.706 (3.18)  Time: 0.315s,  405.76/s  (0.316s,  405.18/s)  LR: 1.914e-04  Data: 0.014 (0.014)
Train: 121 [ 389/390 (100%)]  Loss: 3.302 (3.20)  Time: 0.304s,  421.71/s  (0.316s,  405.45/s)  LR: 1.914e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.410 (0.410)  Loss:  1.0322 (1.0322)  Acc@1: 72.6562 (72.6562)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.9473 (1.0863)  Acc@1: 75.0000 (75.1300)  Acc@5: 93.7500 (94.9400)
Test: [Whole Val]  Time: 9.643  Loss: 1.0863  Acc@1: 75.1300 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.350 (0.350)  Loss:  1.0283 (1.0283)  Acc@1: 72.6562 (72.6562)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9634 (1.0793)  Acc@1: 75.0000 (75.2300)  Acc@5: 93.7500 (94.9900)
Test (EMA): [Whole Val]  Time: 9.587  Loss: 1.0793  Acc@1: 75.2300 Pruned: 50.54% 
Train: 122 [   0/390 (  0%)]  Loss: 3.571 (3.57)  Time: 0.762s,  168.02/s  (0.762s,  168.02/s)  LR: 1.842e-04  Data: 0.454 (0.454)
Train: 122 [ 100/390 ( 26%)]  Loss: 3.081 (3.25)  Time: 0.329s,  389.65/s  (0.322s,  397.55/s)  LR: 1.842e-04  Data: 0.013 (0.017)
Train: 122 [ 200/390 ( 51%)]  Loss: 3.515 (3.23)  Time: 0.312s,  409.67/s  (0.321s,  398.48/s)  LR: 1.842e-04  Data: 0.012 (0.015)
Train: 122 [ 300/390 ( 77%)]  Loss: 2.795 (3.22)  Time: 0.315s,  406.92/s  (0.319s,  400.72/s)  LR: 1.842e-04  Data: 0.014 (0.014)
Train: 122 [ 389/390 (100%)]  Loss: 3.254 (3.22)  Time: 0.301s,  424.56/s  (0.318s,  402.26/s)  LR: 1.842e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.377 (0.377)  Loss:  1.0059 (1.0059)  Acc@1: 71.8750 (71.8750)  Acc@5: 96.0938 (96.0938)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.8823 (1.0223)  Acc@1: 75.0000 (75.4100)  Acc@5: 93.7500 (95.1500)
Test: [Whole Val]  Time: 9.585  Loss: 1.0223  Acc@1: 75.4100 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.317 (0.317)  Loss:  1.0088 (1.0088)  Acc@1: 71.8750 (71.8750)  Acc@5: 96.0938 (96.0938)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.8926 (1.0290)  Acc@1: 75.0000 (75.2900)  Acc@5: 93.7500 (95.0900)
Test (EMA): [Whole Val]  Time: 9.565  Loss: 1.0290  Acc@1: 75.2900 Pruned: 50.54% 
Train: 123 [   0/390 (  0%)]  Loss: 3.921 (3.92)  Time: 0.816s,  156.80/s  (0.816s,  156.80/s)  LR: 1.771e-04  Data: 0.511 (0.511)
Train: 123 [ 100/390 ( 26%)]  Loss: 2.905 (3.22)  Time: 0.312s,  410.20/s  (0.319s,  401.51/s)  LR: 1.771e-04  Data: 0.012 (0.018)
Train: 123 [ 200/390 ( 51%)]  Loss: 3.615 (3.21)  Time: 0.312s,  410.08/s  (0.319s,  401.13/s)  LR: 1.771e-04  Data: 0.012 (0.015)
Train: 123 [ 300/390 ( 77%)]  Loss: 3.748 (3.20)  Time: 0.316s,  404.75/s  (0.317s,  403.56/s)  LR: 1.771e-04  Data: 0.012 (0.014)
Train: 123 [ 389/390 (100%)]  Loss: 2.553 (3.22)  Time: 0.300s,  426.47/s  (0.316s,  404.74/s)  LR: 1.771e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.325 (0.325)  Loss:  1.0205 (1.0205)  Acc@1: 71.8750 (71.8750)  Acc@5: 96.0938 (96.0938)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.9316 (1.0627)  Acc@1: 75.0000 (75.0100)  Acc@5: 93.7500 (94.9500)
Test: [Whole Val]  Time: 9.629  Loss: 1.0627  Acc@1: 75.0100 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.423 (0.423)  Loss:  1.0127 (1.0127)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.9346 (1.0632)  Acc@1: 75.0000 (74.8100)  Acc@5: 93.7500 (94.9700)
Test (EMA): [Whole Val]  Time: 9.624  Loss: 1.0632  Acc@1: 74.8100 Pruned: 50.54% 
Train: 124 [   0/390 (  0%)]  Loss: 3.597 (3.60)  Time: 0.851s,  150.38/s  (0.851s,  150.38/s)  LR: 1.701e-04  Data: 0.538 (0.538)
Train: 124 [ 100/390 ( 26%)]  Loss: 3.598 (3.29)  Time: 0.328s,  390.27/s  (0.327s,  391.53/s)  LR: 1.701e-04  Data: 0.012 (0.018)
Train: 124 [ 200/390 ( 51%)]  Loss: 2.608 (3.24)  Time: 0.316s,  405.59/s  (0.322s,  397.77/s)  LR: 1.701e-04  Data: 0.013 (0.015)
Train: 124 [ 300/390 ( 77%)]  Loss: 2.674 (3.23)  Time: 0.311s,  410.95/s  (0.319s,  401.11/s)  LR: 1.701e-04  Data: 0.010 (0.014)
Train: 124 [ 389/390 (100%)]  Loss: 3.665 (3.23)  Time: 0.302s,  423.32/s  (0.318s,  402.56/s)  LR: 1.701e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.308 (0.308)  Loss:  1.0254 (1.0254)  Acc@1: 70.3125 (70.3125)  Acc@5: 96.8750 (96.8750)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.9385 (1.0578)  Acc@1: 75.0000 (75.2400)  Acc@5: 100.0000 (95.2800)
Test: [Whole Val]  Time: 9.566  Loss: 1.0578  Acc@1: 75.2400 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.427 (0.427)  Loss:  1.0312 (1.0312)  Acc@1: 69.5312 (69.5312)  Acc@5: 96.0938 (96.0938)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  0.9224 (1.0616)  Acc@1: 75.0000 (75.4300)  Acc@5: 100.0000 (95.2100)
Test (EMA): [Whole Val]  Time: 9.687  Loss: 1.0616  Acc@1: 75.4300 Pruned: 50.54% 
Train: 125 [   0/390 (  0%)]  Loss: 3.362 (3.36)  Time: 0.776s,  165.03/s  (0.776s,  165.03/s)  LR: 1.632e-04  Data: 0.471 (0.471)
Train: 125 [ 100/390 ( 26%)]  Loss: 3.652 (3.33)  Time: 0.327s,  392.02/s  (0.321s,  398.72/s)  LR: 1.632e-04  Data: 0.013 (0.017)
Train: 125 [ 200/390 ( 51%)]  Loss: 3.617 (3.26)  Time: 0.315s,  405.98/s  (0.318s,  402.16/s)  LR: 1.632e-04  Data: 0.013 (0.015)
Train: 125 [ 300/390 ( 77%)]  Loss: 3.269 (3.26)  Time: 0.315s,  406.75/s  (0.317s,  404.10/s)  LR: 1.632e-04  Data: 0.013 (0.014)
Train: 125 [ 389/390 (100%)]  Loss: 2.429 (3.26)  Time: 0.301s,  425.64/s  (0.317s,  403.93/s)  LR: 1.632e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.409 (0.409)  Loss:  1.0264 (1.0264)  Acc@1: 71.8750 (71.8750)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.9668 (1.0438)  Acc@1: 75.0000 (75.5500)  Acc@5: 87.5000 (94.9900)
Test: [Whole Val]  Time: 9.625  Loss: 1.0438  Acc@1: 75.5500 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.327 (0.327)  Loss:  1.0361 (1.0361)  Acc@1: 70.3125 (70.3125)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9609 (1.0652)  Acc@1: 75.0000 (75.1400)  Acc@5: 87.5000 (94.9900)
Test (EMA): [Whole Val]  Time: 9.545  Loss: 1.0652  Acc@1: 75.1400 Pruned: 50.54% 
Train: 126 [   0/390 (  0%)]  Loss: 3.293 (3.29)  Time: 0.834s,  153.54/s  (0.834s,  153.54/s)  LR: 1.565e-04  Data: 0.532 (0.532)
Train: 126 [ 100/390 ( 26%)]  Loss: 2.345 (3.20)  Time: 0.313s,  409.02/s  (0.320s,  399.38/s)  LR: 1.565e-04  Data: 0.012 (0.018)
Train: 126 [ 200/390 ( 51%)]  Loss: 2.994 (3.24)  Time: 0.313s,  408.97/s  (0.317s,  403.54/s)  LR: 1.565e-04  Data: 0.012 (0.015)
Train: 126 [ 300/390 ( 77%)]  Loss: 3.672 (3.21)  Time: 0.315s,  405.94/s  (0.317s,  403.75/s)  LR: 1.565e-04  Data: 0.013 (0.014)
Train: 126 [ 389/390 (100%)]  Loss: 2.758 (3.21)  Time: 0.301s,  425.37/s  (0.317s,  403.86/s)  LR: 1.565e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.400 (0.400)  Loss:  1.0117 (1.0117)  Acc@1: 74.2188 (74.2188)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.9141 (1.0230)  Acc@1: 75.0000 (75.7100)  Acc@5: 87.5000 (95.1400)
Test: [Whole Val]  Time: 9.609  Loss: 1.0230  Acc@1: 75.7100 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.375 (0.375)  Loss:  1.0029 (1.0029)  Acc@1: 73.4375 (73.4375)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.8945 (1.0223)  Acc@1: 75.0000 (75.5800)  Acc@5: 93.7500 (95.1900)
Test (EMA): [Whole Val]  Time: 9.667  Loss: 1.0223  Acc@1: 75.5800 Pruned: 50.54% 
Train: 127 [   0/390 (  0%)]  Loss: 3.633 (3.63)  Time: 0.959s,  133.45/s  (0.959s,  133.45/s)  LR: 1.498e-04  Data: 0.657 (0.657)
Train: 127 [ 100/390 ( 26%)]  Loss: 3.210 (3.26)  Time: 0.312s,  409.97/s  (0.322s,  397.64/s)  LR: 1.498e-04  Data: 0.012 (0.020)
Train: 127 [ 200/390 ( 51%)]  Loss: 2.866 (3.25)  Time: 0.318s,  402.34/s  (0.320s,  400.50/s)  LR: 1.498e-04  Data: 0.013 (0.016)
Train: 127 [ 300/390 ( 77%)]  Loss: 3.649 (3.27)  Time: 0.313s,  409.18/s  (0.318s,  402.78/s)  LR: 1.498e-04  Data: 0.013 (0.015)
Train: 127 [ 389/390 (100%)]  Loss: 3.000 (3.25)  Time: 0.301s,  425.40/s  (0.317s,  403.33/s)  LR: 1.498e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.350 (0.350)  Loss:  1.0137 (1.0137)  Acc@1: 72.6562 (72.6562)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.018 (0.121)  Loss:  0.8833 (1.0302)  Acc@1: 75.0000 (75.5900)  Acc@5: 93.7500 (95.0600)
Test: [Whole Val]  Time: 9.586  Loss: 1.0302  Acc@1: 75.5900 Pruned: 50.55% 
Test (EMA): [   0/78]  Time: 0.370 (0.370)  Loss:  1.0156 (1.0156)  Acc@1: 72.6562 (72.6562)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.8882 (1.0380)  Acc@1: 75.0000 (75.5400)  Acc@5: 93.7500 (95.0600)
Test (EMA): [Whole Val]  Time: 9.607  Loss: 1.0380  Acc@1: 75.5400 Pruned: 50.55% 
Train: 128 [   0/390 (  0%)]  Loss: 3.959 (3.96)  Time: 0.897s,  142.70/s  (0.897s,  142.70/s)  LR: 1.433e-04  Data: 0.596 (0.596)
Train: 128 [ 100/390 ( 26%)]  Loss: 2.526 (3.19)  Time: 0.314s,  407.66/s  (0.324s,  395.55/s)  LR: 1.433e-04  Data: 0.011 (0.018)
Train: 128 [ 200/390 ( 51%)]  Loss: 3.698 (3.23)  Time: 0.328s,  389.66/s  (0.319s,  400.66/s)  LR: 1.433e-04  Data: 0.014 (0.015)
Train: 128 [ 300/390 ( 77%)]  Loss: 3.571 (3.24)  Time: 0.312s,  410.14/s  (0.318s,  402.62/s)  LR: 1.433e-04  Data: 0.012 (0.014)
Train: 128 [ 389/390 (100%)]  Loss: 3.364 (3.23)  Time: 0.301s,  424.60/s  (0.318s,  402.55/s)  LR: 1.433e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.311 (0.311)  Loss:  1.0420 (1.0420)  Acc@1: 71.0938 (71.0938)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.9175 (1.0622)  Acc@1: 75.0000 (75.1800)  Acc@5: 93.7500 (94.8400)
Test: [Whole Val]  Time: 9.536  Loss: 1.0622  Acc@1: 75.1800 Pruned: 50.55% 
Test (EMA): [   0/78]  Time: 0.408 (0.408)  Loss:  1.0322 (1.0322)  Acc@1: 71.0938 (71.0938)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.9062 (1.0468)  Acc@1: 75.0000 (75.1900)  Acc@5: 93.7500 (95.0400)
Test (EMA): [Whole Val]  Time: 9.645  Loss: 1.0468  Acc@1: 75.1900 Pruned: 50.55% 
Train: 129 [   0/390 (  0%)]  Loss: 3.406 (3.41)  Time: 0.791s,  161.78/s  (0.791s,  161.78/s)  LR: 1.369e-04  Data: 0.475 (0.475)
Train: 129 [ 100/390 ( 26%)]  Loss: 2.443 (3.20)  Time: 0.313s,  408.93/s  (0.318s,  401.90/s)  LR: 1.369e-04  Data: 0.012 (0.017)
Train: 129 [ 200/390 ( 51%)]  Loss: 3.698 (3.23)  Time: 0.314s,  407.58/s  (0.316s,  404.83/s)  LR: 1.369e-04  Data: 0.013 (0.015)
Train: 129 [ 300/390 ( 77%)]  Loss: 2.555 (3.24)  Time: 0.312s,  410.23/s  (0.315s,  405.93/s)  LR: 1.369e-04  Data: 0.012 (0.014)
Train: 129 [ 389/390 (100%)]  Loss: 3.834 (3.24)  Time: 0.301s,  425.07/s  (0.315s,  406.18/s)  LR: 1.369e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.435 (0.435)  Loss:  1.0234 (1.0234)  Acc@1: 71.0938 (71.0938)  Acc@5: 96.0938 (96.0938)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  0.9521 (1.0266)  Acc@1: 75.0000 (75.4900)  Acc@5: 87.5000 (95.1200)
Test: [Whole Val]  Time: 9.695  Loss: 1.0266  Acc@1: 75.4900 Pruned: 50.55% 
Test (EMA): [   0/78]  Time: 0.379 (0.379)  Loss:  1.0352 (1.0352)  Acc@1: 71.8750 (71.8750)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.9575 (1.0386)  Acc@1: 75.0000 (75.4800)  Acc@5: 87.5000 (95.0500)
Test (EMA): [Whole Val]  Time: 9.609  Loss: 1.0386  Acc@1: 75.4800 Pruned: 50.55% 
Train: 130 [   0/390 (  0%)]  Loss: 3.581 (3.58)  Time: 0.792s,  161.62/s  (0.792s,  161.62/s)  LR: 1.306e-04  Data: 0.474 (0.474)
Train: 130 [ 100/390 ( 26%)]  Loss: 3.576 (3.20)  Time: 0.312s,  409.84/s  (0.319s,  400.70/s)  LR: 1.306e-04  Data: 0.012 (0.017)
Train: 130 [ 200/390 ( 51%)]  Loss: 3.500 (3.23)  Time: 0.316s,  405.70/s  (0.317s,  403.46/s)  LR: 1.306e-04  Data: 0.012 (0.015)
Train: 130 [ 300/390 ( 77%)]  Loss: 3.432 (3.24)  Time: 0.312s,  409.69/s  (0.318s,  403.10/s)  LR: 1.306e-04  Data: 0.012 (0.014)
Train: 130 [ 389/390 (100%)]  Loss: 3.556 (3.22)  Time: 0.301s,  425.67/s  (0.318s,  402.93/s)  LR: 1.306e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.305 (0.305)  Loss:  1.0127 (1.0127)  Acc@1: 73.4375 (73.4375)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.8613 (1.0068)  Acc@1: 75.0000 (75.5500)  Acc@5: 93.7500 (95.1900)
Test: [Whole Val]  Time: 9.574  Loss: 1.0068  Acc@1: 75.5500 Pruned: 50.55% 
Test (EMA): [   0/78]  Time: 0.395 (0.395)  Loss:  1.0166 (1.0166)  Acc@1: 72.6562 (72.6562)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.022 (0.122)  Loss:  0.8740 (1.0103)  Acc@1: 75.0000 (75.4900)  Acc@5: 93.7500 (95.3000)
Test (EMA): [Whole Val]  Time: 9.622  Loss: 1.0103  Acc@1: 75.4900 Pruned: 50.55% 
Train: 131 [   0/390 (  0%)]  Loss: 3.606 (3.61)  Time: 0.895s,  142.99/s  (0.895s,  142.99/s)  LR: 1.244e-04  Data: 0.587 (0.587)
Train: 131 [ 100/390 ( 26%)]  Loss: 3.753 (3.21)  Time: 0.319s,  401.58/s  (0.320s,  399.53/s)  LR: 1.244e-04  Data: 0.019 (0.018)
Train: 131 [ 200/390 ( 51%)]  Loss: 3.542 (3.23)  Time: 0.312s,  410.65/s  (0.318s,  403.06/s)  LR: 1.244e-04  Data: 0.012 (0.015)
Train: 131 [ 300/390 ( 77%)]  Loss: 2.546 (3.22)  Time: 0.312s,  410.06/s  (0.317s,  404.01/s)  LR: 1.244e-04  Data: 0.012 (0.014)
Train: 131 [ 389/390 (100%)]  Loss: 3.541 (3.23)  Time: 0.300s,  426.93/s  (0.316s,  405.33/s)  LR: 1.244e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.351 (0.351)  Loss:  1.0273 (1.0273)  Acc@1: 73.4375 (73.4375)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.9204 (1.0474)  Acc@1: 75.0000 (75.7500)  Acc@5: 87.5000 (95.1800)
Test: [Whole Val]  Time: 9.567  Loss: 1.0474  Acc@1: 75.7500 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.362 (0.362)  Loss:  1.0303 (1.0303)  Acc@1: 72.6562 (72.6562)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9263 (1.0551)  Acc@1: 75.0000 (75.5100)  Acc@5: 87.5000 (95.2000)
Test (EMA): [Whole Val]  Time: 9.579  Loss: 1.0551  Acc@1: 75.5100 Pruned: 50.54% 
Train: 132 [   0/390 (  0%)]  Loss: 2.946 (2.95)  Time: 0.720s,  177.71/s  (0.720s,  177.71/s)  LR: 1.184e-04  Data: 0.418 (0.418)
Train: 132 [ 100/390 ( 26%)]  Loss: 3.539 (3.28)  Time: 0.311s,  411.16/s  (0.317s,  403.90/s)  LR: 1.184e-04  Data: 0.012 (0.016)
Train: 132 [ 200/390 ( 51%)]  Loss: 3.482 (3.25)  Time: 0.315s,  406.18/s  (0.316s,  405.18/s)  LR: 1.184e-04  Data: 0.015 (0.014)
Train: 132 [ 300/390 ( 77%)]  Loss: 3.784 (3.23)  Time: 0.312s,  410.11/s  (0.317s,  403.44/s)  LR: 1.184e-04  Data: 0.012 (0.014)
Train: 132 [ 389/390 (100%)]  Loss: 2.607 (3.22)  Time: 0.300s,  426.30/s  (0.316s,  405.08/s)  LR: 1.184e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.312 (0.312)  Loss:  1.0166 (1.0166)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.018 (0.120)  Loss:  0.8843 (1.0340)  Acc@1: 75.0000 (75.7000)  Acc@5: 93.7500 (95.1000)
Test: [Whole Val]  Time: 9.502  Loss: 1.0340  Acc@1: 75.7000 Pruned: 50.55% 
Test (EMA): [   0/78]  Time: 0.371 (0.371)  Loss:  1.0146 (1.0146)  Acc@1: 70.3125 (70.3125)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.8896 (1.0419)  Acc@1: 75.0000 (75.5400)  Acc@5: 93.7500 (95.0700)
Test (EMA): [Whole Val]  Time: 9.555  Loss: 1.0419  Acc@1: 75.5400 Pruned: 50.55% 
Train: 133 [   0/390 (  0%)]  Loss: 3.527 (3.53)  Time: 0.833s,  153.61/s  (0.833s,  153.61/s)  LR: 1.125e-04  Data: 0.533 (0.533)
Train: 133 [ 100/390 ( 26%)]  Loss: 2.840 (3.22)  Time: 0.311s,  411.39/s  (0.319s,  401.54/s)  LR: 1.125e-04  Data: 0.011 (0.017)
Train: 133 [ 200/390 ( 51%)]  Loss: 2.451 (3.23)  Time: 0.324s,  395.65/s  (0.317s,  404.19/s)  LR: 1.125e-04  Data: 0.012 (0.015)
Train: 133 [ 300/390 ( 77%)]  Loss: 3.068 (3.24)  Time: 0.311s,  411.70/s  (0.317s,  403.58/s)  LR: 1.125e-04  Data: 0.012 (0.014)
Train: 133 [ 389/390 (100%)]  Loss: 2.493 (3.24)  Time: 0.299s,  427.40/s  (0.316s,  404.80/s)  LR: 1.125e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.408 (0.408)  Loss:  1.0225 (1.0225)  Acc@1: 72.6562 (72.6562)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.021 (0.122)  Loss:  0.9321 (1.0402)  Acc@1: 75.0000 (75.5300)  Acc@5: 93.7500 (95.0900)
Test: [Whole Val]  Time: 9.602  Loss: 1.0402  Acc@1: 75.5300 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.321 (0.321)  Loss:  1.0283 (1.0283)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9482 (1.0505)  Acc@1: 75.0000 (75.5000)  Acc@5: 93.7500 (95.1100)
Test (EMA): [Whole Val]  Time: 9.560  Loss: 1.0505  Acc@1: 75.5000 Pruned: 50.54% 
Train: 134 [   0/390 (  0%)]  Loss: 3.767 (3.77)  Time: 0.858s,  149.17/s  (0.858s,  149.17/s)  LR: 1.067e-04  Data: 0.558 (0.558)
Train: 134 [ 100/390 ( 26%)]  Loss: 3.469 (3.22)  Time: 0.311s,  411.63/s  (0.318s,  403.09/s)  LR: 1.067e-04  Data: 0.012 (0.017)
Train: 134 [ 200/390 ( 51%)]  Loss: 3.130 (3.22)  Time: 0.313s,  408.82/s  (0.315s,  406.37/s)  LR: 1.067e-04  Data: 0.013 (0.015)
Train: 134 [ 300/390 ( 77%)]  Loss: 2.758 (3.23)  Time: 0.313s,  408.75/s  (0.314s,  407.47/s)  LR: 1.067e-04  Data: 0.012 (0.014)
Train: 134 [ 389/390 (100%)]  Loss: 2.902 (3.25)  Time: 0.303s,  422.50/s  (0.315s,  406.48/s)  LR: 1.067e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.414 (0.414)  Loss:  1.0352 (1.0352)  Acc@1: 75.0000 (75.0000)  Acc@5: 96.0938 (96.0938)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.9653 (1.0815)  Acc@1: 75.0000 (75.5700)  Acc@5: 87.5000 (95.1200)
Test: [Whole Val]  Time: 9.620  Loss: 1.0815  Acc@1: 75.5700 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.314 (0.314)  Loss:  1.0225 (1.0225)  Acc@1: 75.0000 (75.0000)  Acc@5: 96.8750 (96.8750)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9551 (1.0673)  Acc@1: 75.0000 (75.6200)  Acc@5: 87.5000 (95.2200)
Test (EMA): [Whole Val]  Time: 9.520  Loss: 1.0673  Acc@1: 75.6200 Pruned: 50.54% 
Train: 135 [   0/390 (  0%)]  Loss: 2.803 (2.80)  Time: 0.838s,  152.67/s  (0.838s,  152.67/s)  LR: 1.011e-04  Data: 0.518 (0.518)
Train: 135 [ 100/390 ( 26%)]  Loss: 2.897 (3.21)  Time: 0.313s,  408.95/s  (0.317s,  403.24/s)  LR: 1.011e-04  Data: 0.014 (0.017)
Train: 135 [ 200/390 ( 51%)]  Loss: 3.683 (3.20)  Time: 0.314s,  407.26/s  (0.318s,  402.55/s)  LR: 1.011e-04  Data: 0.014 (0.015)
Train: 135 [ 300/390 ( 77%)]  Loss: 2.918 (3.21)  Time: 0.316s,  405.25/s  (0.316s,  405.09/s)  LR: 1.011e-04  Data: 0.012 (0.014)
Train: 135 [ 389/390 (100%)]  Loss: 3.755 (3.21)  Time: 0.299s,  427.44/s  (0.315s,  406.32/s)  LR: 1.011e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.362 (0.362)  Loss:  1.0234 (1.0234)  Acc@1: 72.6562 (72.6562)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.9438 (1.0479)  Acc@1: 75.0000 (75.6000)  Acc@5: 93.7500 (95.2500)
Test: [Whole Val]  Time: 9.547  Loss: 1.0479  Acc@1: 75.6000 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.306 (0.306)  Loss:  1.0186 (1.0186)  Acc@1: 72.6562 (72.6562)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.9429 (1.0393)  Acc@1: 75.0000 (75.8700)  Acc@5: 87.5000 (95.2800)
Test (EMA): [Whole Val]  Time: 9.516  Loss: 1.0393  Acc@1: 75.8700 Pruned: 50.55% 
Train: 136 [   0/390 (  0%)]  Loss: 3.721 (3.72)  Time: 0.766s,  167.16/s  (0.766s,  167.16/s)  LR: 9.558e-05  Data: 0.463 (0.463)
Train: 136 [ 100/390 ( 26%)]  Loss: 3.573 (3.17)  Time: 0.316s,  405.69/s  (0.317s,  404.10/s)  LR: 9.558e-05  Data: 0.011 (0.016)
Train: 136 [ 200/390 ( 51%)]  Loss: 3.523 (3.12)  Time: 0.312s,  410.43/s  (0.315s,  406.83/s)  LR: 9.558e-05  Data: 0.012 (0.014)
Train: 136 [ 300/390 ( 77%)]  Loss: 3.572 (3.15)  Time: 0.313s,  409.00/s  (0.314s,  408.02/s)  LR: 9.558e-05  Data: 0.012 (0.013)
Train: 136 [ 389/390 (100%)]  Loss: 3.283 (3.18)  Time: 0.300s,  426.91/s  (0.313s,  408.61/s)  LR: 9.558e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.348 (0.348)  Loss:  1.0234 (1.0234)  Acc@1: 73.4375 (73.4375)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.021 (0.121)  Loss:  0.9692 (1.0510)  Acc@1: 75.0000 (76.0100)  Acc@5: 87.5000 (95.1700)
Test: [Whole Val]  Time: 9.581  Loss: 1.0510  Acc@1: 76.0100 Pruned: 50.55% 
Test (EMA): [   0/78]  Time: 0.317 (0.317)  Loss:  1.0166 (1.0166)  Acc@1: 73.4375 (73.4375)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9585 (1.0444)  Acc@1: 75.0000 (75.9900)  Acc@5: 87.5000 (95.2400)
Test (EMA): [Whole Val]  Time: 9.527  Loss: 1.0444  Acc@1: 75.9900 Pruned: 50.55% 
Train: 137 [   0/390 (  0%)]  Loss: 3.642 (3.64)  Time: 0.861s,  148.70/s  (0.861s,  148.70/s)  LR: 9.022e-05  Data: 0.553 (0.553)
Train: 137 [ 100/390 ( 26%)]  Loss: 3.626 (3.22)  Time: 0.312s,  409.87/s  (0.320s,  399.43/s)  LR: 9.022e-05  Data: 0.012 (0.017)
Train: 137 [ 200/390 ( 51%)]  Loss: 3.625 (3.23)  Time: 0.314s,  408.17/s  (0.317s,  403.44/s)  LR: 9.022e-05  Data: 0.012 (0.015)
Train: 137 [ 300/390 ( 77%)]  Loss: 3.103 (3.20)  Time: 0.310s,  413.13/s  (0.316s,  405.64/s)  LR: 9.022e-05  Data: 0.011 (0.014)
Train: 137 [ 389/390 (100%)]  Loss: 3.525 (3.20)  Time: 0.299s,  427.48/s  (0.315s,  406.62/s)  LR: 9.022e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.342 (0.342)  Loss:  1.0225 (1.0225)  Acc@1: 71.0938 (71.0938)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.9204 (1.0354)  Acc@1: 75.0000 (75.7700)  Acc@5: 93.7500 (95.1100)
Test: [Whole Val]  Time: 9.556  Loss: 1.0354  Acc@1: 75.7700 Pruned: 50.55% 
Test (EMA): [   0/78]  Time: 0.311 (0.311)  Loss:  1.0107 (1.0107)  Acc@1: 71.8750 (71.8750)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.9087 (1.0288)  Acc@1: 75.0000 (75.7700)  Acc@5: 93.7500 (95.0600)
Test (EMA): [Whole Val]  Time: 9.501  Loss: 1.0288  Acc@1: 75.7700 Pruned: 50.55% 
Train: 138 [   0/390 (  0%)]  Loss: 2.838 (2.84)  Time: 0.826s,  154.90/s  (0.826s,  154.90/s)  LR: 8.500e-05  Data: 0.526 (0.526)
Train: 138 [ 100/390 ( 26%)]  Loss: 3.164 (3.18)  Time: 0.315s,  406.03/s  (0.322s,  397.55/s)  LR: 8.500e-05  Data: 0.011 (0.017)
Train: 138 [ 200/390 ( 51%)]  Loss: 2.993 (3.18)  Time: 0.313s,  408.85/s  (0.320s,  399.50/s)  LR: 8.500e-05  Data: 0.012 (0.015)
Train: 138 [ 300/390 ( 77%)]  Loss: 2.388 (3.20)  Time: 0.311s,  411.37/s  (0.318s,  402.59/s)  LR: 8.500e-05  Data: 0.012 (0.014)
Train: 138 [ 389/390 (100%)]  Loss: 3.798 (3.22)  Time: 0.298s,  429.38/s  (0.317s,  403.38/s)  LR: 8.500e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.306 (0.306)  Loss:  1.0293 (1.0293)  Acc@1: 72.6562 (72.6562)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  0.9375 (1.0528)  Acc@1: 75.0000 (75.7300)  Acc@5: 87.5000 (95.2600)
Test: [Whole Val]  Time: 9.488  Loss: 1.0528  Acc@1: 75.7300 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.312 (0.312)  Loss:  1.0352 (1.0352)  Acc@1: 72.6562 (72.6562)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.9370 (1.0556)  Acc@1: 75.0000 (75.7500)  Acc@5: 87.5000 (95.3300)
Test (EMA): [Whole Val]  Time: 9.505  Loss: 1.0556  Acc@1: 75.7500 Pruned: 50.54% 
Train: 139 [   0/390 (  0%)]  Loss: 3.535 (3.54)  Time: 0.845s,  151.45/s  (0.845s,  151.45/s)  LR: 7.992e-05  Data: 0.545 (0.545)
Train: 139 [ 100/390 ( 26%)]  Loss: 3.634 (3.29)  Time: 0.314s,  408.11/s  (0.317s,  403.88/s)  LR: 7.992e-05  Data: 0.014 (0.017)
Train: 139 [ 200/390 ( 51%)]  Loss: 2.539 (3.26)  Time: 0.322s,  397.53/s  (0.315s,  406.12/s)  LR: 7.992e-05  Data: 0.015 (0.014)
Train: 139 [ 300/390 ( 77%)]  Loss: 3.615 (3.23)  Time: 0.312s,  410.32/s  (0.316s,  405.69/s)  LR: 7.992e-05  Data: 0.012 (0.014)
Train: 139 [ 389/390 (100%)]  Loss: 3.554 (3.23)  Time: 0.300s,  427.33/s  (0.315s,  406.89/s)  LR: 7.992e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.346 (0.346)  Loss:  1.0176 (1.0176)  Acc@1: 72.6562 (72.6562)  Acc@5: 96.0938 (96.0938)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.9165 (1.0429)  Acc@1: 75.0000 (75.9500)  Acc@5: 93.7500 (95.2700)
Test: [Whole Val]  Time: 9.523  Loss: 1.0429  Acc@1: 75.9500 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.312 (0.312)  Loss:  1.0117 (1.0117)  Acc@1: 73.4375 (73.4375)  Acc@5: 96.0938 (96.0938)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.9131 (1.0363)  Acc@1: 75.0000 (75.9600)  Acc@5: 93.7500 (95.3500)
Test (EMA): [Whole Val]  Time: 9.519  Loss: 1.0363  Acc@1: 75.9600 Pruned: 50.54% 
Train: 140 [   0/390 (  0%)]  Loss: 3.247 (3.25)  Time: 0.889s,  144.06/s  (0.889s,  144.06/s)  LR: 7.498e-05  Data: 0.588 (0.588)
Train: 140 [ 100/390 ( 26%)]  Loss: 3.630 (3.21)  Time: 0.313s,  409.53/s  (0.318s,  402.94/s)  LR: 7.498e-05  Data: 0.013 (0.018)
Train: 140 [ 200/390 ( 51%)]  Loss: 3.150 (3.23)  Time: 0.313s,  409.44/s  (0.315s,  406.07/s)  LR: 7.498e-05  Data: 0.012 (0.015)
Train: 140 [ 300/390 ( 77%)]  Loss: 3.373 (3.22)  Time: 0.311s,  411.11/s  (0.315s,  406.26/s)  LR: 7.498e-05  Data: 0.012 (0.014)
Train: 140 [ 389/390 (100%)]  Loss: 2.884 (3.25)  Time: 0.303s,  421.78/s  (0.315s,  406.52/s)  LR: 7.498e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.342 (0.342)  Loss:  1.0449 (1.0449)  Acc@1: 73.4375 (73.4375)  Acc@5: 96.8750 (96.8750)
Test: [  78/78]  Time: 0.021 (0.121)  Loss:  0.9863 (1.0773)  Acc@1: 75.0000 (75.7100)  Acc@5: 93.7500 (95.1600)
Test: [Whole Val]  Time: 9.545  Loss: 1.0773  Acc@1: 75.7100 Pruned: 50.53% 
Test (EMA): [   0/78]  Time: 0.377 (0.377)  Loss:  1.0439 (1.0439)  Acc@1: 74.2188 (74.2188)  Acc@5: 96.0938 (96.0938)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9819 (1.0741)  Acc@1: 75.0000 (75.7200)  Acc@5: 93.7500 (95.2200)
Test (EMA): [Whole Val]  Time: 9.554  Loss: 1.0741  Acc@1: 75.7200 Pruned: 50.53% 
Train: 141 [   0/390 (  0%)]  Loss: 3.588 (3.59)  Time: 0.723s,  177.07/s  (0.723s,  177.07/s)  LR: 7.019e-05  Data: 0.421 (0.421)
Train: 141 [ 100/390 ( 26%)]  Loss: 3.110 (3.27)  Time: 0.312s,  410.90/s  (0.320s,  400.05/s)  LR: 7.019e-05  Data: 0.012 (0.016)
Train: 141 [ 200/390 ( 51%)]  Loss: 2.622 (3.24)  Time: 0.314s,  407.44/s  (0.316s,  405.26/s)  LR: 7.019e-05  Data: 0.012 (0.014)
Train: 141 [ 300/390 ( 77%)]  Loss: 2.797 (3.19)  Time: 0.313s,  409.13/s  (0.315s,  406.96/s)  LR: 7.019e-05  Data: 0.012 (0.013)
Train: 141 [ 389/390 (100%)]  Loss: 2.832 (3.21)  Time: 0.301s,  424.92/s  (0.315s,  406.82/s)  LR: 7.019e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.400 (0.400)  Loss:  1.0225 (1.0225)  Acc@1: 72.6562 (72.6562)  Acc@5: 96.0938 (96.0938)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.9380 (1.0558)  Acc@1: 75.0000 (75.6700)  Acc@5: 93.7500 (95.1600)
Test: [Whole Val]  Time: 9.588  Loss: 1.0558  Acc@1: 75.6700 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.312 (0.312)  Loss:  1.0176 (1.0176)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.9316 (1.0507)  Acc@1: 75.0000 (75.5900)  Acc@5: 93.7500 (95.1200)
Test (EMA): [Whole Val]  Time: 9.479  Loss: 1.0507  Acc@1: 75.5900 Pruned: 50.54% 
Train: 142 [   0/390 (  0%)]  Loss: 2.444 (2.44)  Time: 0.890s,  143.87/s  (0.890s,  143.87/s)  LR: 6.555e-05  Data: 0.588 (0.588)
Train: 142 [ 100/390 ( 26%)]  Loss: 3.163 (3.19)  Time: 0.311s,  411.54/s  (0.319s,  401.76/s)  LR: 6.555e-05  Data: 0.011 (0.018)
Train: 142 [ 200/390 ( 51%)]  Loss: 3.307 (3.21)  Time: 0.311s,  410.97/s  (0.315s,  405.72/s)  LR: 6.555e-05  Data: 0.012 (0.015)
Train: 142 [ 300/390 ( 77%)]  Loss: 3.613 (3.20)  Time: 0.312s,  410.51/s  (0.315s,  406.84/s)  LR: 6.555e-05  Data: 0.012 (0.014)
Train: 142 [ 389/390 (100%)]  Loss: 2.980 (3.21)  Time: 0.300s,  426.58/s  (0.314s,  407.60/s)  LR: 6.555e-05  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.314 (0.314)  Loss:  1.0146 (1.0146)  Acc@1: 72.6562 (72.6562)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  0.9521 (1.0470)  Acc@1: 75.0000 (75.8400)  Acc@5: 93.7500 (95.2700)
Test: [Whole Val]  Time: 9.517  Loss: 1.0470  Acc@1: 75.8400 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.357 (0.357)  Loss:  1.0137 (1.0137)  Acc@1: 72.6562 (72.6562)  Acc@5: 96.0938 (96.0938)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9448 (1.0431)  Acc@1: 75.0000 (75.9300)  Acc@5: 93.7500 (95.2500)
Test (EMA): [Whole Val]  Time: 9.578  Loss: 1.0431  Acc@1: 75.9300 Pruned: 50.54% 
Train: 143 [   0/390 (  0%)]  Loss: 2.295 (2.30)  Time: 0.755s,  169.55/s  (0.755s,  169.55/s)  LR: 6.105e-05  Data: 0.453 (0.453)
Train: 143 [ 100/390 ( 26%)]  Loss: 3.331 (3.19)  Time: 0.311s,  411.11/s  (0.317s,  403.52/s)  LR: 6.105e-05  Data: 0.011 (0.017)
Train: 143 [ 200/390 ( 51%)]  Loss: 3.619 (3.20)  Time: 0.312s,  410.21/s  (0.315s,  406.55/s)  LR: 6.105e-05  Data: 0.012 (0.014)
Train: 143 [ 300/390 ( 77%)]  Loss: 2.615 (3.21)  Time: 0.312s,  409.75/s  (0.314s,  407.01/s)  LR: 6.105e-05  Data: 0.012 (0.014)
Train: 143 [ 389/390 (100%)]  Loss: 3.662 (3.24)  Time: 0.301s,  425.27/s  (0.314s,  407.68/s)  LR: 6.105e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.377 (0.377)  Loss:  1.0342 (1.0342)  Acc@1: 74.2188 (74.2188)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.9175 (1.0532)  Acc@1: 75.0000 (75.9400)  Acc@5: 93.7500 (95.1300)
Test: [Whole Val]  Time: 9.572  Loss: 1.0532  Acc@1: 75.9400 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.319 (0.319)  Loss:  1.0303 (1.0303)  Acc@1: 74.2188 (74.2188)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9136 (1.0499)  Acc@1: 75.0000 (75.9500)  Acc@5: 93.7500 (95.1300)
Test (EMA): [Whole Val]  Time: 9.548  Loss: 1.0499  Acc@1: 75.9500 Pruned: 50.54% 
Train: 144 [   0/390 (  0%)]  Loss: 3.029 (3.03)  Time: 0.844s,  151.57/s  (0.844s,  151.57/s)  LR: 5.671e-05  Data: 0.543 (0.543)
Train: 144 [ 100/390 ( 26%)]  Loss: 3.245 (3.21)  Time: 0.312s,  410.48/s  (0.317s,  403.26/s)  LR: 5.671e-05  Data: 0.011 (0.017)
Train: 144 [ 200/390 ( 51%)]  Loss: 3.313 (3.20)  Time: 0.311s,  411.80/s  (0.315s,  405.97/s)  LR: 5.671e-05  Data: 0.012 (0.015)
Train: 144 [ 300/390 ( 77%)]  Loss: 2.951 (3.23)  Time: 0.313s,  409.46/s  (0.315s,  406.25/s)  LR: 5.671e-05  Data: 0.012 (0.014)
Train: 144 [ 389/390 (100%)]  Loss: 3.542 (3.21)  Time: 0.300s,  426.68/s  (0.314s,  407.16/s)  LR: 5.671e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.400 (0.400)  Loss:  1.0117 (1.0117)  Acc@1: 73.4375 (73.4375)  Acc@5: 96.0938 (96.0938)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.9209 (1.0289)  Acc@1: 75.0000 (75.9700)  Acc@5: 93.7500 (95.1700)
Test: [Whole Val]  Time: 9.630  Loss: 1.0289  Acc@1: 75.9700 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.371 (0.371)  Loss:  1.0068 (1.0068)  Acc@1: 72.6562 (72.6562)  Acc@5: 96.0938 (96.0938)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9067 (1.0222)  Acc@1: 75.0000 (76.0100)  Acc@5: 93.7500 (95.2300)
Test (EMA): [Whole Val]  Time: 9.587  Loss: 1.0222  Acc@1: 76.0100 Pruned: 50.54% 
Train: 145 [   0/390 (  0%)]  Loss: 3.354 (3.35)  Time: 0.724s,  176.81/s  (0.724s,  176.81/s)  LR: 5.251e-05  Data: 0.424 (0.424)
Train: 145 [ 100/390 ( 26%)]  Loss: 3.013 (3.18)  Time: 0.313s,  408.64/s  (0.317s,  404.07/s)  LR: 5.251e-05  Data: 0.013 (0.016)
Train: 145 [ 200/390 ( 51%)]  Loss: 2.426 (3.19)  Time: 0.312s,  410.66/s  (0.314s,  407.09/s)  LR: 5.251e-05  Data: 0.012 (0.014)
Train: 145 [ 300/390 ( 77%)]  Loss: 2.973 (3.17)  Time: 0.325s,  393.70/s  (0.314s,  407.96/s)  LR: 5.251e-05  Data: 0.013 (0.013)
Train: 145 [ 389/390 (100%)]  Loss: 2.602 (3.16)  Time: 0.300s,  426.36/s  (0.314s,  407.42/s)  LR: 5.251e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.314 (0.314)  Loss:  1.0068 (1.0068)  Acc@1: 71.0938 (71.0938)  Acc@5: 96.0938 (96.0938)
Test: [  78/78]  Time: 0.018 (0.120)  Loss:  0.8848 (1.0279)  Acc@1: 75.0000 (76.0000)  Acc@5: 93.7500 (95.1900)
Test: [Whole Val]  Time: 9.519  Loss: 1.0279  Acc@1: 76.0000 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.315 (0.315)  Loss:  1.0039 (1.0039)  Acc@1: 70.3125 (70.3125)  Acc@5: 96.0938 (96.0938)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.8833 (1.0223)  Acc@1: 75.0000 (75.9300)  Acc@5: 93.7500 (95.2000)
Test (EMA): [Whole Val]  Time: 9.534  Loss: 1.0223  Acc@1: 75.9300 Pruned: 50.54% 
Train: 146 [   0/390 (  0%)]  Loss: 3.491 (3.49)  Time: 0.736s,  173.95/s  (0.736s,  173.95/s)  LR: 4.847e-05  Data: 0.435 (0.435)
Train: 146 [ 100/390 ( 26%)]  Loss: 3.467 (3.22)  Time: 0.311s,  412.19/s  (0.316s,  404.58/s)  LR: 4.847e-05  Data: 0.011 (0.016)
Train: 146 [ 200/390 ( 51%)]  Loss: 3.177 (3.21)  Time: 0.312s,  409.64/s  (0.314s,  407.27/s)  LR: 4.847e-05  Data: 0.013 (0.014)
Train: 146 [ 300/390 ( 77%)]  Loss: 3.628 (3.24)  Time: 0.312s,  410.82/s  (0.314s,  407.73/s)  LR: 4.847e-05  Data: 0.012 (0.013)
Train: 146 [ 389/390 (100%)]  Loss: 3.199 (3.25)  Time: 0.301s,  424.99/s  (0.314s,  407.87/s)  LR: 4.847e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.306 (0.306)  Loss:  1.0312 (1.0312)  Acc@1: 71.8750 (71.8750)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.021 (0.121)  Loss:  0.8843 (1.0410)  Acc@1: 75.0000 (75.9900)  Acc@5: 93.7500 (95.1300)
Test: [Whole Val]  Time: 9.541  Loss: 1.0410  Acc@1: 75.9900 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.312 (0.312)  Loss:  1.0303 (1.0303)  Acc@1: 72.6562 (72.6562)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.8770 (1.0391)  Acc@1: 75.0000 (76.1000)  Acc@5: 93.7500 (95.1600)
Test (EMA): [Whole Val]  Time: 9.534  Loss: 1.0391  Acc@1: 76.1000 Pruned: 50.54% 
Train: 147 [   0/390 (  0%)]  Loss: 2.343 (2.34)  Time: 0.737s,  173.72/s  (0.737s,  173.72/s)  LR: 4.458e-05  Data: 0.434 (0.434)
Train: 147 [ 100/390 ( 26%)]  Loss: 2.436 (3.14)  Time: 0.312s,  410.77/s  (0.317s,  404.30/s)  LR: 4.458e-05  Data: 0.012 (0.016)
Train: 147 [ 200/390 ( 51%)]  Loss: 3.352 (3.18)  Time: 0.314s,  407.65/s  (0.315s,  406.91/s)  LR: 4.458e-05  Data: 0.015 (0.014)
Train: 147 [ 300/390 ( 77%)]  Loss: 3.080 (3.20)  Time: 0.311s,  411.84/s  (0.314s,  407.91/s)  LR: 4.458e-05  Data: 0.011 (0.014)
Train: 147 [ 389/390 (100%)]  Loss: 2.936 (3.20)  Time: 0.301s,  425.29/s  (0.313s,  408.46/s)  LR: 4.458e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.323 (0.323)  Loss:  1.0137 (1.0137)  Acc@1: 71.0938 (71.0938)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.9204 (1.0361)  Acc@1: 75.0000 (75.7400)  Acc@5: 93.7500 (95.1400)
Test: [Whole Val]  Time: 9.543  Loss: 1.0361  Acc@1: 75.7400 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.410 (0.410)  Loss:  1.0146 (1.0146)  Acc@1: 71.0938 (71.0938)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.9116 (1.0347)  Acc@1: 75.0000 (75.7700)  Acc@5: 93.7500 (95.2100)
Test (EMA): [Whole Val]  Time: 9.629  Loss: 1.0347  Acc@1: 75.7700 Pruned: 50.54% 
Train: 148 [   0/390 (  0%)]  Loss: 3.577 (3.58)  Time: 0.791s,  161.88/s  (0.791s,  161.88/s)  LR: 4.085e-05  Data: 0.490 (0.490)
Train: 148 [ 100/390 ( 26%)]  Loss: 3.734 (3.29)  Time: 0.312s,  409.67/s  (0.317s,  403.95/s)  LR: 4.085e-05  Data: 0.012 (0.017)
Train: 148 [ 200/390 ( 51%)]  Loss: 3.646 (3.22)  Time: 0.311s,  412.09/s  (0.315s,  406.92/s)  LR: 4.085e-05  Data: 0.011 (0.014)
Train: 148 [ 300/390 ( 77%)]  Loss: 2.889 (3.20)  Time: 0.311s,  411.18/s  (0.314s,  408.01/s)  LR: 4.085e-05  Data: 0.012 (0.014)
Train: 148 [ 389/390 (100%)]  Loss: 2.522 (3.21)  Time: 0.300s,  426.30/s  (0.313s,  408.42/s)  LR: 4.085e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.309 (0.309)  Loss:  1.0225 (1.0225)  Acc@1: 71.0938 (71.0938)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.8979 (1.0462)  Acc@1: 75.0000 (75.9500)  Acc@5: 93.7500 (95.1700)
Test: [Whole Val]  Time: 9.542  Loss: 1.0462  Acc@1: 75.9500 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.319 (0.319)  Loss:  1.0234 (1.0234)  Acc@1: 71.0938 (71.0938)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.8994 (1.0457)  Acc@1: 75.0000 (75.9500)  Acc@5: 93.7500 (95.1900)
Test (EMA): [Whole Val]  Time: 9.537  Loss: 1.0457  Acc@1: 75.9500 Pruned: 50.54% 
Train: 149 [   0/390 (  0%)]  Loss: 3.168 (3.17)  Time: 0.806s,  158.80/s  (0.806s,  158.80/s)  LR: 3.728e-05  Data: 0.503 (0.503)
Train: 149 [ 100/390 ( 26%)]  Loss: 3.561 (3.07)  Time: 0.312s,  410.43/s  (0.317s,  403.35/s)  LR: 3.728e-05  Data: 0.012 (0.017)
Train: 149 [ 200/390 ( 51%)]  Loss: 3.569 (3.12)  Time: 0.314s,  407.07/s  (0.316s,  404.63/s)  LR: 3.728e-05  Data: 0.013 (0.015)
Train: 149 [ 300/390 ( 77%)]  Loss: 3.391 (3.16)  Time: 0.320s,  399.41/s  (0.316s,  405.24/s)  LR: 3.728e-05  Data: 0.020 (0.014)
Train: 149 [ 389/390 (100%)]  Loss: 2.893 (3.17)  Time: 0.300s,  427.16/s  (0.315s,  406.15/s)  LR: 3.728e-05  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.319 (0.319)  Loss:  1.0205 (1.0205)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.9170 (1.0410)  Acc@1: 75.0000 (76.0400)  Acc@5: 93.7500 (95.2800)
Test: [Whole Val]  Time: 9.545  Loss: 1.0410  Acc@1: 76.0400 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.394 (0.394)  Loss:  1.0225 (1.0225)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.9165 (1.0406)  Acc@1: 75.0000 (76.0600)  Acc@5: 93.7500 (95.2800)
Test (EMA): [Whole Val]  Time: 9.600  Loss: 1.0406  Acc@1: 76.0600 Pruned: 50.54% 
Train: 150 [   0/390 (  0%)]  Loss: 3.588 (3.59)  Time: 0.783s,  163.41/s  (0.783s,  163.41/s)  LR: 3.386e-05  Data: 0.483 (0.483)
Train: 150 [ 100/390 ( 26%)]  Loss: 2.260 (3.30)  Time: 0.310s,  412.58/s  (0.319s,  401.52/s)  LR: 3.386e-05  Data: 0.011 (0.017)
Train: 150 [ 200/390 ( 51%)]  Loss: 3.456 (3.25)  Time: 0.311s,  411.04/s  (0.318s,  402.40/s)  LR: 3.386e-05  Data: 0.012 (0.015)
Train: 150 [ 300/390 ( 77%)]  Loss: 2.485 (3.24)  Time: 0.310s,  412.77/s  (0.316s,  404.62/s)  LR: 3.386e-05  Data: 0.012 (0.014)
Train: 150 [ 389/390 (100%)]  Loss: 2.762 (3.25)  Time: 0.301s,  424.92/s  (0.315s,  405.96/s)  LR: 3.386e-05  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.316 (0.316)  Loss:  1.0254 (1.0254)  Acc@1: 71.0938 (71.0938)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.9175 (1.0428)  Acc@1: 75.0000 (75.9000)  Acc@5: 93.7500 (95.2800)
Test: [Whole Val]  Time: 9.528  Loss: 1.0428  Acc@1: 75.9000 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.325 (0.325)  Loss:  1.0254 (1.0254)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9150 (1.0413)  Acc@1: 75.0000 (75.9700)  Acc@5: 93.7500 (95.2400)
Test (EMA): [Whole Val]  Time: 9.528  Loss: 1.0413  Acc@1: 75.9700 Pruned: 50.54% 
Train: 151 [   0/390 (  0%)]  Loss: 2.245 (2.24)  Time: 0.816s,  156.83/s  (0.816s,  156.83/s)  LR: 3.060e-05  Data: 0.515 (0.515)
Train: 151 [ 100/390 ( 26%)]  Loss: 2.742 (3.17)  Time: 0.313s,  408.41/s  (0.317s,  403.26/s)  LR: 3.060e-05  Data: 0.012 (0.017)
Train: 151 [ 200/390 ( 51%)]  Loss: 3.557 (3.19)  Time: 0.310s,  412.51/s  (0.315s,  406.61/s)  LR: 3.060e-05  Data: 0.011 (0.015)
Train: 151 [ 300/390 ( 77%)]  Loss: 3.599 (3.20)  Time: 0.312s,  410.76/s  (0.314s,  407.96/s)  LR: 3.060e-05  Data: 0.012 (0.014)
Train: 151 [ 389/390 (100%)]  Loss: 2.885 (3.20)  Time: 0.301s,  425.41/s  (0.313s,  408.77/s)  LR: 3.060e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.316 (0.316)  Loss:  1.0098 (1.0098)  Acc@1: 73.4375 (73.4375)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.8647 (1.0225)  Acc@1: 75.0000 (76.1100)  Acc@5: 93.7500 (95.1400)
Test: [Whole Val]  Time: 9.530  Loss: 1.0225  Acc@1: 76.1100 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.314 (0.314)  Loss:  1.0127 (1.0127)  Acc@1: 73.4375 (73.4375)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.8755 (1.0247)  Acc@1: 75.0000 (76.1000)  Acc@5: 93.7500 (95.2200)
Test (EMA): [Whole Val]  Time: 9.504  Loss: 1.0247  Acc@1: 76.1000 Pruned: 50.54% 
Train: 152 [   0/390 (  0%)]  Loss: 3.852 (3.85)  Time: 0.780s,  164.14/s  (0.780s,  164.14/s)  LR: 2.751e-05  Data: 0.466 (0.466)
Train: 152 [ 100/390 ( 26%)]  Loss: 3.443 (3.26)  Time: 0.313s,  408.30/s  (0.316s,  404.87/s)  LR: 2.751e-05  Data: 0.012 (0.016)
Train: 152 [ 200/390 ( 51%)]  Loss: 3.669 (3.27)  Time: 0.310s,  412.31/s  (0.314s,  407.55/s)  LR: 2.751e-05  Data: 0.011 (0.014)
Train: 152 [ 300/390 ( 77%)]  Loss: 2.545 (3.26)  Time: 0.312s,  410.62/s  (0.313s,  408.70/s)  LR: 2.751e-05  Data: 0.011 (0.013)
Train: 152 [ 389/390 (100%)]  Loss: 3.626 (3.24)  Time: 0.300s,  426.35/s  (0.313s,  409.22/s)  LR: 2.751e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.395 (0.395)  Loss:  1.0117 (1.0117)  Acc@1: 72.6562 (72.6562)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.8774 (1.0284)  Acc@1: 75.0000 (76.1200)  Acc@5: 93.7500 (95.2000)
Test: [Whole Val]  Time: 9.574  Loss: 1.0284  Acc@1: 76.1200 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.360 (0.360)  Loss:  1.0137 (1.0137)  Acc@1: 72.6562 (72.6562)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.8730 (1.0272)  Acc@1: 75.0000 (76.1400)  Acc@5: 93.7500 (95.2300)
Test (EMA): [Whole Val]  Time: 9.544  Loss: 1.0272  Acc@1: 76.1400 Pruned: 50.54% 
Train: 153 [   0/390 (  0%)]  Loss: 2.555 (2.55)  Time: 0.770s,  166.28/s  (0.770s,  166.28/s)  LR: 2.457e-05  Data: 0.437 (0.437)
Train: 153 [ 100/390 ( 26%)]  Loss: 3.448 (3.26)  Time: 0.310s,  413.15/s  (0.320s,  400.41/s)  LR: 2.457e-05  Data: 0.011 (0.016)
Train: 153 [ 200/390 ( 51%)]  Loss: 3.604 (3.22)  Time: 0.311s,  412.15/s  (0.316s,  404.91/s)  LR: 2.457e-05  Data: 0.011 (0.014)
Train: 153 [ 300/390 ( 77%)]  Loss: 2.547 (3.19)  Time: 0.312s,  410.38/s  (0.316s,  405.70/s)  LR: 2.457e-05  Data: 0.012 (0.013)
Train: 153 [ 389/390 (100%)]  Loss: 3.474 (3.20)  Time: 0.301s,  425.51/s  (0.315s,  406.82/s)  LR: 2.457e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.294 (0.294)  Loss:  1.0117 (1.0117)  Acc@1: 72.6562 (72.6562)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  0.8872 (1.0283)  Acc@1: 75.0000 (75.9000)  Acc@5: 93.7500 (95.2600)
Test: [Whole Val]  Time: 9.491  Loss: 1.0283  Acc@1: 75.9000 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.370 (0.370)  Loss:  1.0127 (1.0127)  Acc@1: 72.6562 (72.6562)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.8887 (1.0293)  Acc@1: 75.0000 (75.9000)  Acc@5: 93.7500 (95.2100)
Test (EMA): [Whole Val]  Time: 9.562  Loss: 1.0293  Acc@1: 75.9000 Pruned: 50.54% 
Train: 154 [   0/390 (  0%)]  Loss: 3.753 (3.75)  Time: 0.829s,  154.47/s  (0.829s,  154.47/s)  LR: 2.180e-05  Data: 0.528 (0.528)
Train: 154 [ 100/390 ( 26%)]  Loss: 2.426 (3.16)  Time: 0.311s,  411.29/s  (0.317s,  403.90/s)  LR: 2.180e-05  Data: 0.012 (0.017)
Train: 154 [ 200/390 ( 51%)]  Loss: 3.265 (3.19)  Time: 0.313s,  408.35/s  (0.315s,  406.47/s)  LR: 2.180e-05  Data: 0.014 (0.015)
Train: 154 [ 300/390 ( 77%)]  Loss: 2.992 (3.22)  Time: 0.314s,  407.29/s  (0.315s,  406.89/s)  LR: 2.180e-05  Data: 0.012 (0.014)
Train: 154 [ 389/390 (100%)]  Loss: 2.858 (3.21)  Time: 0.300s,  426.80/s  (0.314s,  407.49/s)  LR: 2.180e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.313 (0.313)  Loss:  1.0146 (1.0146)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.020 (0.121)  Loss:  0.8726 (1.0303)  Acc@1: 75.0000 (76.1300)  Acc@5: 93.7500 (95.3400)
Test: [Whole Val]  Time: 9.535  Loss: 1.0303  Acc@1: 76.1300 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.385 (0.385)  Loss:  1.0137 (1.0137)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.8711 (1.0304)  Acc@1: 75.0000 (76.0800)  Acc@5: 93.7500 (95.3200)
Test (EMA): [Whole Val]  Time: 9.577  Loss: 1.0304  Acc@1: 76.0800 Pruned: 50.54% 
Train: 155 [   0/390 (  0%)]  Loss: 3.539 (3.54)  Time: 0.709s,  180.51/s  (0.709s,  180.51/s)  LR: 1.919e-05  Data: 0.408 (0.408)
Train: 155 [ 100/390 ( 26%)]  Loss: 3.723 (3.21)  Time: 0.326s,  393.12/s  (0.321s,  398.73/s)  LR: 1.919e-05  Data: 0.013 (0.016)
Train: 155 [ 200/390 ( 51%)]  Loss: 3.751 (3.24)  Time: 0.311s,  411.13/s  (0.320s,  399.91/s)  LR: 1.919e-05  Data: 0.012 (0.014)
Train: 155 [ 300/390 ( 77%)]  Loss: 3.315 (3.21)  Time: 0.315s,  406.95/s  (0.318s,  402.77/s)  LR: 1.919e-05  Data: 0.011 (0.014)
Train: 155 [ 389/390 (100%)]  Loss: 3.640 (3.19)  Time: 0.299s,  427.64/s  (0.316s,  404.50/s)  LR: 1.919e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.404 (0.404)  Loss:  1.0068 (1.0068)  Acc@1: 71.0938 (71.0938)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.8774 (1.0257)  Acc@1: 75.0000 (75.9000)  Acc@5: 93.7500 (95.2300)
Test: [Whole Val]  Time: 9.593  Loss: 1.0257  Acc@1: 75.9000 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.350 (0.350)  Loss:  1.0068 (1.0068)  Acc@1: 71.0938 (71.0938)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.8755 (1.0230)  Acc@1: 75.0000 (75.9100)  Acc@5: 93.7500 (95.2600)
Test (EMA): [Whole Val]  Time: 9.534  Loss: 1.0230  Acc@1: 75.9100 Pruned: 50.54% 
Train: 156 [   0/390 (  0%)]  Loss: 2.341 (2.34)  Time: 0.811s,  157.84/s  (0.811s,  157.84/s)  LR: 1.674e-05  Data: 0.510 (0.510)
Train: 156 [ 100/390 ( 26%)]  Loss: 3.204 (3.16)  Time: 0.312s,  410.76/s  (0.317s,  404.00/s)  LR: 1.674e-05  Data: 0.011 (0.017)
Train: 156 [ 200/390 ( 51%)]  Loss: 3.490 (3.15)  Time: 0.312s,  410.64/s  (0.314s,  407.07/s)  LR: 1.674e-05  Data: 0.012 (0.014)
Train: 156 [ 300/390 ( 77%)]  Loss: 3.640 (3.18)  Time: 0.313s,  408.37/s  (0.315s,  406.57/s)  LR: 1.674e-05  Data: 0.012 (0.014)
Train: 156 [ 389/390 (100%)]  Loss: 2.914 (3.19)  Time: 0.301s,  425.62/s  (0.314s,  407.53/s)  LR: 1.674e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.415 (0.415)  Loss:  1.0078 (1.0078)  Acc@1: 72.6562 (72.6562)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.8867 (1.0241)  Acc@1: 75.0000 (76.1100)  Acc@5: 93.7500 (95.2500)
Test: [Whole Val]  Time: 9.607  Loss: 1.0241  Acc@1: 76.1100 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.377 (0.377)  Loss:  1.0088 (1.0088)  Acc@1: 72.6562 (72.6562)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.8848 (1.0254)  Acc@1: 75.0000 (76.1500)  Acc@5: 93.7500 (95.2500)
Test (EMA): [Whole Val]  Time: 9.561  Loss: 1.0254  Acc@1: 76.1500 Pruned: 50.54% 
Train: 157 [   0/390 (  0%)]  Loss: 2.519 (2.52)  Time: 0.792s,  161.68/s  (0.792s,  161.68/s)  LR: 1.446e-05  Data: 0.492 (0.492)
Train: 157 [ 100/390 ( 26%)]  Loss: 3.347 (3.20)  Time: 0.324s,  395.27/s  (0.321s,  398.92/s)  LR: 1.446e-05  Data: 0.012 (0.017)
Train: 157 [ 200/390 ( 51%)]  Loss: 3.293 (3.20)  Time: 0.311s,  411.38/s  (0.317s,  403.77/s)  LR: 1.446e-05  Data: 0.011 (0.014)
Train: 157 [ 300/390 ( 77%)]  Loss: 3.492 (3.20)  Time: 0.311s,  411.42/s  (0.315s,  405.73/s)  LR: 1.446e-05  Data: 0.012 (0.014)
Train: 157 [ 389/390 (100%)]  Loss: 3.924 (3.19)  Time: 0.302s,  423.89/s  (0.315s,  405.89/s)  LR: 1.446e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.365 (0.365)  Loss:  1.0068 (1.0068)  Acc@1: 73.4375 (73.4375)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.8848 (1.0223)  Acc@1: 75.0000 (76.1300)  Acc@5: 93.7500 (95.2000)
Test: [Whole Val]  Time: 9.547  Loss: 1.0223  Acc@1: 76.1300 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.314 (0.314)  Loss:  1.0078 (1.0078)  Acc@1: 73.4375 (73.4375)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.8877 (1.0229)  Acc@1: 75.0000 (76.1300)  Acc@5: 93.7500 (95.2300)
Test (EMA): [Whole Val]  Time: 9.510  Loss: 1.0229  Acc@1: 76.1300 Pruned: 50.54% 
Train: 158 [   0/390 (  0%)]  Loss: 2.945 (2.95)  Time: 0.760s,  168.46/s  (0.760s,  168.46/s)  LR: 1.234e-05  Data: 0.458 (0.458)
Train: 158 [ 100/390 ( 26%)]  Loss: 3.146 (3.25)  Time: 0.315s,  406.13/s  (0.317s,  404.14/s)  LR: 1.234e-05  Data: 0.012 (0.016)
Train: 158 [ 200/390 ( 51%)]  Loss: 3.227 (3.23)  Time: 0.311s,  412.00/s  (0.314s,  407.15/s)  LR: 1.234e-05  Data: 0.012 (0.014)
Train: 158 [ 300/390 ( 77%)]  Loss: 3.555 (3.24)  Time: 0.312s,  410.50/s  (0.314s,  408.02/s)  LR: 1.234e-05  Data: 0.011 (0.013)
Train: 158 [ 389/390 (100%)]  Loss: 3.353 (3.23)  Time: 0.300s,  426.61/s  (0.313s,  408.68/s)  LR: 1.234e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.359 (0.359)  Loss:  1.0176 (1.0176)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.8979 (1.0323)  Acc@1: 75.0000 (75.9900)  Acc@5: 93.7500 (95.2600)
Test: [Whole Val]  Time: 9.569  Loss: 1.0323  Acc@1: 75.9900 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.306 (0.306)  Loss:  1.0166 (1.0166)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.8975 (1.0332)  Acc@1: 75.0000 (75.9900)  Acc@5: 93.7500 (95.2200)
Test (EMA): [Whole Val]  Time: 9.525  Loss: 1.0332  Acc@1: 75.9900 Pruned: 50.54% 
Train: 159 [   0/390 (  0%)]  Loss: 2.803 (2.80)  Time: 0.827s,  154.84/s  (0.827s,  154.84/s)  LR: 1.039e-05  Data: 0.526 (0.526)
Train: 159 [ 100/390 ( 26%)]  Loss: 3.022 (3.27)  Time: 0.326s,  392.83/s  (0.321s,  398.18/s)  LR: 1.039e-05  Data: 0.012 (0.017)
Train: 159 [ 200/390 ( 51%)]  Loss: 3.208 (3.24)  Time: 0.321s,  399.37/s  (0.317s,  403.75/s)  LR: 1.039e-05  Data: 0.012 (0.015)
Train: 159 [ 300/390 ( 77%)]  Loss: 3.082 (3.23)  Time: 0.311s,  411.59/s  (0.315s,  405.92/s)  LR: 1.039e-05  Data: 0.011 (0.014)
Train: 159 [ 389/390 (100%)]  Loss: 3.800 (3.22)  Time: 0.300s,  426.54/s  (0.315s,  406.73/s)  LR: 1.039e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.368 (0.368)  Loss:  1.0146 (1.0146)  Acc@1: 72.6562 (72.6562)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.8896 (1.0282)  Acc@1: 75.0000 (76.1300)  Acc@5: 93.7500 (95.2000)
Test: [Whole Val]  Time: 9.586  Loss: 1.0282  Acc@1: 76.1300 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.299 (0.299)  Loss:  1.0137 (1.0137)  Acc@1: 72.6562 (72.6562)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.8901 (1.0279)  Acc@1: 75.0000 (76.1600)  Acc@5: 93.7500 (95.2100)
Test (EMA): [Whole Val]  Time: 9.493  Loss: 1.0279  Acc@1: 76.1600 Pruned: 50.54% 
Train: 160 [   0/390 (  0%)]  Loss: 3.131 (3.13)  Time: 0.752s,  170.21/s  (0.752s,  170.21/s)  LR: 8.613e-06  Data: 0.451 (0.451)
Train: 160 [ 100/390 ( 26%)]  Loss: 2.760 (3.23)  Time: 0.313s,  409.25/s  (0.316s,  405.05/s)  LR: 8.613e-06  Data: 0.013 (0.016)
Train: 160 [ 200/390 ( 51%)]  Loss: 2.679 (3.19)  Time: 0.311s,  411.73/s  (0.314s,  407.23/s)  LR: 8.613e-06  Data: 0.012 (0.014)
Train: 160 [ 300/390 ( 77%)]  Loss: 3.477 (3.21)  Time: 0.311s,  412.07/s  (0.315s,  406.96/s)  LR: 8.613e-06  Data: 0.012 (0.014)
Train: 160 [ 389/390 (100%)]  Loss: 2.495 (3.21)  Time: 0.302s,  424.51/s  (0.314s,  407.60/s)  LR: 8.613e-06  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.311 (0.311)  Loss:  1.0127 (1.0127)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  0.8940 (1.0292)  Acc@1: 75.0000 (76.1200)  Acc@5: 93.7500 (95.2000)
Test: [Whole Val]  Time: 9.506  Loss: 1.0292  Acc@1: 76.1200 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.309 (0.309)  Loss:  1.0137 (1.0137)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.8955 (1.0299)  Acc@1: 75.0000 (76.1400)  Acc@5: 93.7500 (95.1800)
Test (EMA): [Whole Val]  Time: 9.477  Loss: 1.0299  Acc@1: 76.1400 Pruned: 50.54% 
Train: 161 [   0/390 (  0%)]  Loss: 3.747 (3.75)  Time: 0.752s,  170.32/s  (0.752s,  170.32/s)  LR: 6.999e-06  Data: 0.450 (0.450)
Train: 161 [ 100/390 ( 26%)]  Loss: 2.860 (3.28)  Time: 0.311s,  410.96/s  (0.317s,  404.24/s)  LR: 6.999e-06  Data: 0.012 (0.016)
Train: 161 [ 200/390 ( 51%)]  Loss: 2.402 (3.29)  Time: 0.311s,  411.23/s  (0.314s,  407.06/s)  LR: 6.999e-06  Data: 0.012 (0.014)
Train: 161 [ 300/390 ( 77%)]  Loss: 2.299 (3.26)  Time: 0.310s,  412.43/s  (0.314s,  408.13/s)  LR: 6.999e-06  Data: 0.011 (0.014)
Train: 161 [ 389/390 (100%)]  Loss: 2.969 (3.24)  Time: 0.300s,  426.99/s  (0.313s,  408.65/s)  LR: 6.999e-06  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.309 (0.309)  Loss:  1.0117 (1.0117)  Acc@1: 71.0938 (71.0938)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  0.8911 (1.0279)  Acc@1: 75.0000 (76.0500)  Acc@5: 93.7500 (95.2100)
Test: [Whole Val]  Time: 9.504  Loss: 1.0279  Acc@1: 76.0500 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.308 (0.308)  Loss:  1.0107 (1.0107)  Acc@1: 71.0938 (71.0938)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.8916 (1.0277)  Acc@1: 75.0000 (76.0300)  Acc@5: 93.7500 (95.2200)
Test (EMA): [Whole Val]  Time: 9.521  Loss: 1.0277  Acc@1: 76.0300 Pruned: 50.54% 
Train: 162 [   0/390 (  0%)]  Loss: 3.723 (3.72)  Time: 0.834s,  153.52/s  (0.834s,  153.52/s)  LR: 5.554e-06  Data: 0.533 (0.533)
Train: 162 [ 100/390 ( 26%)]  Loss: 3.303 (3.22)  Time: 0.312s,  409.62/s  (0.318s,  403.11/s)  LR: 5.554e-06  Data: 0.012 (0.017)
Train: 162 [ 200/390 ( 51%)]  Loss: 3.149 (3.24)  Time: 0.312s,  410.48/s  (0.315s,  406.71/s)  LR: 5.554e-06  Data: 0.012 (0.015)
Train: 162 [ 300/390 ( 77%)]  Loss: 3.716 (3.26)  Time: 0.310s,  412.25/s  (0.314s,  407.93/s)  LR: 5.554e-06  Data: 0.011 (0.014)
Train: 162 [ 389/390 (100%)]  Loss: 3.841 (3.25)  Time: 0.300s,  427.19/s  (0.313s,  408.35/s)  LR: 5.554e-06  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.330 (0.330)  Loss:  1.0195 (1.0195)  Acc@1: 71.0938 (71.0938)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.9004 (1.0366)  Acc@1: 75.0000 (75.9700)  Acc@5: 93.7500 (95.2400)
Test: [Whole Val]  Time: 9.543  Loss: 1.0366  Acc@1: 75.9700 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.375 (0.375)  Loss:  1.0186 (1.0186)  Acc@1: 71.0938 (71.0938)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.8999 (1.0362)  Acc@1: 75.0000 (75.9400)  Acc@5: 93.7500 (95.2300)
Test (EMA): [Whole Val]  Time: 9.568  Loss: 1.0362  Acc@1: 75.9400 Pruned: 50.54% 
Train: 163 [   0/390 (  0%)]  Loss: 2.817 (2.82)  Time: 0.747s,  171.32/s  (0.747s,  171.32/s)  LR: 4.277e-06  Data: 0.444 (0.444)
Train: 163 [ 100/390 ( 26%)]  Loss: 3.496 (3.15)  Time: 0.311s,  411.00/s  (0.319s,  401.34/s)  LR: 4.277e-06  Data: 0.011 (0.016)
Train: 163 [ 200/390 ( 51%)]  Loss: 3.153 (3.18)  Time: 0.311s,  412.01/s  (0.317s,  403.23/s)  LR: 4.277e-06  Data: 0.012 (0.014)
Train: 163 [ 300/390 ( 77%)]  Loss: 3.654 (3.21)  Time: 0.312s,  410.41/s  (0.316s,  405.62/s)  LR: 4.277e-06  Data: 0.012 (0.013)
Train: 163 [ 389/390 (100%)]  Loss: 3.037 (3.22)  Time: 0.300s,  427.02/s  (0.315s,  406.76/s)  LR: 4.277e-06  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.316 (0.316)  Loss:  1.0146 (1.0146)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  0.8979 (1.0343)  Acc@1: 75.0000 (75.9100)  Acc@5: 93.7500 (95.2200)
Test: [Whole Val]  Time: 9.506  Loss: 1.0343  Acc@1: 75.9100 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.337 (0.337)  Loss:  1.0137 (1.0137)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.8984 (1.0339)  Acc@1: 75.0000 (75.9000)  Acc@5: 93.7500 (95.2200)
Test (EMA): [Whole Val]  Time: 9.540  Loss: 1.0339  Acc@1: 75.9000 Pruned: 50.54% 
Train: 164 [   0/390 (  0%)]  Loss: 3.780 (3.78)  Time: 0.825s,  155.09/s  (0.825s,  155.09/s)  LR: 3.170e-06  Data: 0.522 (0.522)
Train: 164 [ 100/390 ( 26%)]  Loss: 3.550 (3.22)  Time: 0.314s,  407.45/s  (0.317s,  403.36/s)  LR: 3.170e-06  Data: 0.015 (0.017)
Train: 164 [ 200/390 ( 51%)]  Loss: 2.667 (3.22)  Time: 0.325s,  393.59/s  (0.317s,  403.79/s)  LR: 3.170e-06  Data: 0.012 (0.015)
Train: 164 [ 300/390 ( 77%)]  Loss: 2.648 (3.22)  Time: 0.314s,  407.65/s  (0.316s,  405.40/s)  LR: 3.170e-06  Data: 0.014 (0.014)
Train: 164 [ 389/390 (100%)]  Loss: 3.462 (3.23)  Time: 0.300s,  427.37/s  (0.315s,  406.55/s)  LR: 3.170e-06  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.363 (0.363)  Loss:  1.0156 (1.0156)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.024 (0.121)  Loss:  0.8945 (1.0340)  Acc@1: 75.0000 (76.0400)  Acc@5: 93.7500 (95.1500)
Test: [Whole Val]  Time: 9.566  Loss: 1.0340  Acc@1: 76.0400 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.380 (0.380)  Loss:  1.0146 (1.0146)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.8950 (1.0339)  Acc@1: 75.0000 (76.0400)  Acc@5: 93.7500 (95.1600)
Test (EMA): [Whole Val]  Time: 9.578  Loss: 1.0339  Acc@1: 76.0400 Pruned: 50.54% 
Train: 165 [   0/390 (  0%)]  Loss: 3.415 (3.42)  Time: 0.835s,  153.28/s  (0.835s,  153.28/s)  LR: 2.233e-06  Data: 0.527 (0.527)
Train: 165 [ 100/390 ( 26%)]  Loss: 3.654 (3.21)  Time: 0.312s,  409.65/s  (0.317s,  403.41/s)  LR: 2.233e-06  Data: 0.012 (0.017)
Train: 165 [ 200/390 ( 51%)]  Loss: 3.276 (3.19)  Time: 0.312s,  409.82/s  (0.315s,  406.00/s)  LR: 2.233e-06  Data: 0.012 (0.015)
Train: 165 [ 300/390 ( 77%)]  Loss: 2.983 (3.19)  Time: 0.310s,  412.44/s  (0.314s,  407.36/s)  LR: 2.233e-06  Data: 0.012 (0.014)
Train: 165 [ 389/390 (100%)]  Loss: 3.493 (3.21)  Time: 0.301s,  425.00/s  (0.314s,  408.06/s)  LR: 2.233e-06  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.396 (0.396)  Loss:  1.0117 (1.0117)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.8950 (1.0295)  Acc@1: 75.0000 (76.0600)  Acc@5: 93.7500 (95.1700)
Test: [Whole Val]  Time: 9.572  Loss: 1.0295  Acc@1: 76.0600 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.417 (0.417)  Loss:  1.0117 (1.0117)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.8955 (1.0294)  Acc@1: 75.0000 (76.0400)  Acc@5: 93.7500 (95.1900)
Test (EMA): [Whole Val]  Time: 9.594  Loss: 1.0294  Acc@1: 76.0400 Pruned: 50.54% 
Train: 166 [   0/390 (  0%)]  Loss: 2.463 (2.46)  Time: 0.774s,  165.30/s  (0.774s,  165.30/s)  LR: 1.465e-06  Data: 0.474 (0.474)
Train: 166 [ 100/390 ( 26%)]  Loss: 2.554 (3.23)  Time: 0.312s,  410.89/s  (0.319s,  401.59/s)  LR: 1.465e-06  Data: 0.012 (0.016)
Train: 166 [ 200/390 ( 51%)]  Loss: 3.786 (3.18)  Time: 0.311s,  411.05/s  (0.316s,  405.09/s)  LR: 1.465e-06  Data: 0.012 (0.014)
Train: 166 [ 300/390 ( 77%)]  Loss: 3.742 (3.19)  Time: 0.313s,  408.80/s  (0.315s,  406.79/s)  LR: 1.465e-06  Data: 0.014 (0.014)
Train: 166 [ 389/390 (100%)]  Loss: 3.137 (3.20)  Time: 0.300s,  427.14/s  (0.314s,  407.68/s)  LR: 1.465e-06  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.339 (0.339)  Loss:  1.0107 (1.0107)  Acc@1: 72.6562 (72.6562)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  0.8945 (1.0292)  Acc@1: 75.0000 (76.0400)  Acc@5: 93.7500 (95.2100)
Test: [Whole Val]  Time: 9.516  Loss: 1.0292  Acc@1: 76.0400 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.313 (0.313)  Loss:  1.0098 (1.0098)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.8940 (1.0290)  Acc@1: 75.0000 (76.0300)  Acc@5: 93.7500 (95.2000)
Test (EMA): [Whole Val]  Time: 9.524  Loss: 1.0290  Acc@1: 76.0300 Pruned: 50.54% 
Train: 167 [   0/390 (  0%)]  Loss: 2.532 (2.53)  Time: 0.772s,  165.77/s  (0.772s,  165.77/s)  LR: 8.681e-07  Data: 0.466 (0.466)
Train: 167 [ 100/390 ( 26%)]  Loss: 2.190 (3.16)  Time: 0.310s,  412.98/s  (0.322s,  397.22/s)  LR: 8.681e-07  Data: 0.011 (0.017)
Train: 167 [ 200/390 ( 51%)]  Loss: 3.515 (3.19)  Time: 0.313s,  409.59/s  (0.317s,  403.29/s)  LR: 8.681e-07  Data: 0.013 (0.014)
Train: 167 [ 300/390 ( 77%)]  Loss: 3.784 (3.18)  Time: 0.311s,  411.96/s  (0.316s,  405.41/s)  LR: 8.681e-07  Data: 0.011 (0.014)
Train: 167 [ 389/390 (100%)]  Loss: 3.402 (3.15)  Time: 0.301s,  425.72/s  (0.315s,  406.34/s)  LR: 8.681e-07  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.317 (0.317)  Loss:  1.0088 (1.0088)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.8926 (1.0268)  Acc@1: 75.0000 (76.0300)  Acc@5: 93.7500 (95.2100)
Test: [Whole Val]  Time: 9.524  Loss: 1.0268  Acc@1: 76.0300 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.364 (0.364)  Loss:  1.0088 (1.0088)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.8921 (1.0269)  Acc@1: 75.0000 (76.0400)  Acc@5: 93.7500 (95.2000)
Test (EMA): [Whole Val]  Time: 9.575  Loss: 1.0269  Acc@1: 76.0400 Pruned: 50.54% 
Train: 168 [   0/390 (  0%)]  Loss: 3.386 (3.39)  Time: 0.736s,  173.90/s  (0.736s,  173.90/s)  LR: 4.414e-07  Data: 0.435 (0.435)
Train: 168 [ 100/390 ( 26%)]  Loss: 2.459 (3.17)  Time: 0.328s,  389.91/s  (0.322s,  398.07/s)  LR: 4.414e-07  Data: 0.013 (0.017)
Train: 168 [ 200/390 ( 51%)]  Loss: 3.282 (3.17)  Time: 0.316s,  405.10/s  (0.318s,  401.93/s)  LR: 4.414e-07  Data: 0.016 (0.014)
Train: 168 [ 300/390 ( 77%)]  Loss: 2.310 (3.19)  Time: 0.312s,  410.43/s  (0.318s,  402.63/s)  LR: 4.414e-07  Data: 0.012 (0.014)
Train: 168 [ 389/390 (100%)]  Loss: 2.357 (3.18)  Time: 0.301s,  425.66/s  (0.317s,  404.33/s)  LR: 4.414e-07  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.402 (0.402)  Loss:  1.0098 (1.0098)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.020 (0.122)  Loss:  0.8916 (1.0269)  Acc@1: 75.0000 (75.9900)  Acc@5: 93.7500 (95.2000)
Test: [Whole Val]  Time: 9.619  Loss: 1.0269  Acc@1: 75.9900 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.369 (0.369)  Loss:  1.0098 (1.0098)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.8921 (1.0269)  Acc@1: 75.0000 (76.0100)  Acc@5: 93.7500 (95.2000)
Test (EMA): [Whole Val]  Time: 9.518  Loss: 1.0269  Acc@1: 76.0100 Pruned: 50.54% 
Train: 169 [   0/390 (  0%)]  Loss: 3.612 (3.61)  Time: 0.773s,  165.66/s  (0.773s,  165.66/s)  LR: 1.854e-07  Data: 0.472 (0.472)
Train: 169 [ 100/390 ( 26%)]  Loss: 3.154 (3.19)  Time: 0.309s,  413.75/s  (0.315s,  406.76/s)  LR: 1.854e-07  Data: 0.011 (0.016)
Train: 169 [ 200/390 ( 51%)]  Loss: 2.184 (3.16)  Time: 0.310s,  412.89/s  (0.313s,  408.37/s)  LR: 1.854e-07  Data: 0.012 (0.014)
Train: 169 [ 300/390 ( 77%)]  Loss: 3.646 (3.19)  Time: 0.313s,  409.08/s  (0.312s,  409.62/s)  LR: 1.854e-07  Data: 0.012 (0.013)
Train: 169 [ 389/390 (100%)]  Loss: 3.684 (3.20)  Time: 0.297s,  431.28/s  (0.312s,  410.55/s)  LR: 1.854e-07  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.309 (0.309)  Loss:  1.0098 (1.0098)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  0.8926 (1.0270)  Acc@1: 75.0000 (76.0000)  Acc@5: 93.7500 (95.1900)
Test: [Whole Val]  Time: 9.445  Loss: 1.0270  Acc@1: 76.0000 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.306 (0.306)  Loss:  1.0098 (1.0098)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.119)  Loss:  0.8926 (1.0269)  Acc@1: 75.0000 (76.0000)  Acc@5: 93.7500 (95.2100)
Test (EMA): [Whole Val]  Time: 9.433  Loss: 1.0269  Acc@1: 76.0000 Pruned: 50.54% 
Train: 170 [   0/390 (  0%)]  Loss: 3.650 (3.65)  Time: 0.816s,  156.84/s  (0.816s,  156.84/s)  LR: 1.000e-07  Data: 0.517 (0.517)
Train: 170 [ 100/390 ( 26%)]  Loss: 3.525 (3.24)  Time: 0.310s,  412.75/s  (0.315s,  406.00/s)  LR: 1.000e-07  Data: 0.012 (0.016)
Train: 170 [ 200/390 ( 51%)]  Loss: 2.891 (3.25)  Time: 0.327s,  391.95/s  (0.313s,  409.25/s)  LR: 1.000e-07  Data: 0.015 (0.014)
Train: 170 [ 300/390 ( 77%)]  Loss: 3.078 (3.23)  Time: 0.310s,  413.32/s  (0.314s,  408.29/s)  LR: 1.000e-07  Data: 0.011 (0.013)
Train: 170 [ 389/390 (100%)]  Loss: 3.761 (3.24)  Time: 0.297s,  430.48/s  (0.313s,  409.54/s)  LR: 1.000e-07  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.306 (0.306)  Loss:  1.0098 (1.0098)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  0.8926 (1.0270)  Acc@1: 75.0000 (75.9900)  Acc@5: 93.7500 (95.2200)
Test: [Whole Val]  Time: 9.442  Loss: 1.0270  Acc@1: 75.9900 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.366 (0.366)  Loss:  1.0098 (1.0098)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.8931 (1.0271)  Acc@1: 75.0000 (76.0300)  Acc@5: 93.7500 (95.2200)
Test (EMA): [Whole Val]  Time: 9.504  Loss: 1.0271  Acc@1: 76.0300 Pruned: 50.54% 
Train: 171 [   0/390 (  0%)]  Loss: 3.725 (3.73)  Time: 0.716s,  178.73/s  (0.716s,  178.73/s)  LR: 1.000e-07  Data: 0.416 (0.416)
Train: 171 [ 100/390 ( 26%)]  Loss: 2.716 (3.18)  Time: 0.310s,  412.90/s  (0.317s,  403.31/s)  LR: 1.000e-07  Data: 0.011 (0.015)
Train: 171 [ 200/390 ( 51%)]  Loss: 2.703 (3.19)  Time: 0.310s,  413.24/s  (0.314s,  407.75/s)  LR: 1.000e-07  Data: 0.011 (0.013)
Train: 171 [ 300/390 ( 77%)]  Loss: 3.860 (3.19)  Time: 0.310s,  413.05/s  (0.313s,  409.04/s)  LR: 1.000e-07  Data: 0.011 (0.013)
Train: 171 [ 389/390 (100%)]  Loss: 4.016 (3.20)  Time: 0.310s,  412.87/s  (0.313s,  409.51/s)  LR: 1.000e-07  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.372 (0.372)  Loss:  1.0098 (1.0098)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  0.8926 (1.0271)  Acc@1: 75.0000 (76.0200)  Acc@5: 93.7500 (95.2100)
Test: [Whole Val]  Time: 9.502  Loss: 1.0271  Acc@1: 76.0200 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.306 (0.306)  Loss:  1.0098 (1.0098)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.8926 (1.0270)  Acc@1: 75.0000 (76.0300)  Acc@5: 93.7500 (95.2100)
Test (EMA): [Whole Val]  Time: 9.444  Loss: 1.0270  Acc@1: 76.0300 Pruned: 50.54% 
Train: 172 [   0/390 (  0%)]  Loss: 3.588 (3.59)  Time: 0.732s,  174.84/s  (0.732s,  174.84/s)  LR: 1.000e-07  Data: 0.432 (0.432)
Train: 172 [ 100/390 ( 26%)]  Loss: 3.461 (3.22)  Time: 0.312s,  410.20/s  (0.314s,  407.72/s)  LR: 1.000e-07  Data: 0.011 (0.015)
Train: 172 [ 200/390 ( 51%)]  Loss: 3.774 (3.22)  Time: 0.310s,  412.68/s  (0.312s,  410.44/s)  LR: 1.000e-07  Data: 0.011 (0.013)
Train: 172 [ 300/390 ( 77%)]  Loss: 3.782 (3.21)  Time: 0.309s,  413.93/s  (0.311s,  411.21/s)  LR: 1.000e-07  Data: 0.011 (0.013)
Train: 172 [ 389/390 (100%)]  Loss: 2.549 (3.20)  Time: 0.297s,  431.09/s  (0.311s,  411.47/s)  LR: 1.000e-07  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.305 (0.305)  Loss:  1.0098 (1.0098)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.119)  Loss:  0.8931 (1.0271)  Acc@1: 75.0000 (76.0300)  Acc@5: 93.7500 (95.2100)
Test: [Whole Val]  Time: 9.440  Loss: 1.0271  Acc@1: 76.0300 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.367 (0.367)  Loss:  1.0098 (1.0098)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.8926 (1.0270)  Acc@1: 75.0000 (76.0400)  Acc@5: 93.7500 (95.2000)
Test (EMA): [Whole Val]  Time: 9.509  Loss: 1.0270  Acc@1: 76.0400 Pruned: 50.54% 
Train: 173 [   0/390 (  0%)]  Loss: 2.732 (2.73)  Time: 0.809s,  158.19/s  (0.809s,  158.19/s)  LR: 1.000e-07  Data: 0.510 (0.510)
Train: 173 [ 100/390 ( 26%)]  Loss: 3.664 (3.25)  Time: 0.310s,  413.51/s  (0.316s,  405.50/s)  LR: 1.000e-07  Data: 0.011 (0.016)
Train: 173 [ 200/390 ( 51%)]  Loss: 3.277 (3.22)  Time: 0.311s,  412.18/s  (0.313s,  409.12/s)  LR: 1.000e-07  Data: 0.011 (0.014)
Train: 173 [ 300/390 ( 77%)]  Loss: 3.207 (3.22)  Time: 0.310s,  413.31/s  (0.312s,  410.16/s)  LR: 1.000e-07  Data: 0.011 (0.013)
Train: 173 [ 389/390 (100%)]  Loss: 3.562 (3.21)  Time: 0.297s,  430.66/s  (0.311s,  410.95/s)  LR: 1.000e-07  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.361 (0.361)  Loss:  1.0098 (1.0098)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  0.8921 (1.0270)  Acc@1: 75.0000 (76.0100)  Acc@5: 93.7500 (95.2100)
Test: [Whole Val]  Time: 9.494  Loss: 1.0270  Acc@1: 76.0100 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.315 (0.315)  Loss:  1.0098 (1.0098)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.019 (0.120)  Loss:  0.8926 (1.0270)  Acc@1: 75.0000 (76.0100)  Acc@5: 93.7500 (95.2100)
Test (EMA): [Whole Val]  Time: 9.459  Loss: 1.0270  Acc@1: 76.0100 Pruned: 50.54% 
Train: 174 [   0/390 (  0%)]  Loss: 2.570 (2.57)  Time: 0.810s,  158.10/s  (0.810s,  158.10/s)  LR: 1.000e-07  Data: 0.510 (0.510)
Train: 174 [ 100/390 ( 26%)]  Loss: 2.318 (3.10)  Time: 0.310s,  413.35/s  (0.315s,  406.52/s)  LR: 1.000e-07  Data: 0.011 (0.016)
Train: 174 [ 200/390 ( 51%)]  Loss: 3.621 (3.14)  Time: 0.315s,  406.69/s  (0.313s,  408.86/s)  LR: 1.000e-07  Data: 0.016 (0.014)
Train: 174 [ 300/390 ( 77%)]  Loss: 2.738 (3.13)  Time: 0.310s,  412.47/s  (0.312s,  410.21/s)  LR: 1.000e-07  Data: 0.011 (0.013)
Train: 174 [ 389/390 (100%)]  Loss: 3.841 (3.17)  Time: 0.311s,  411.77/s  (0.313s,  408.42/s)  LR: 1.000e-07  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.307 (0.307)  Loss:  1.0098 (1.0098)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  0.8921 (1.0268)  Acc@1: 75.0000 (76.0100)  Acc@5: 93.7500 (95.2100)
Test: [Whole Val]  Time: 9.446  Loss: 1.0268  Acc@1: 76.0100 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.340 (0.340)  Loss:  1.0098 (1.0098)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.8926 (1.0268)  Acc@1: 75.0000 (76.0100)  Acc@5: 93.7500 (95.2100)
Test (EMA): [Whole Val]  Time: 9.458  Loss: 1.0268  Acc@1: 76.0100 Pruned: 50.54% 
Train: 175 [   0/390 (  0%)]  Loss: 2.240 (2.24)  Time: 0.724s,  176.74/s  (0.724s,  176.74/s)  LR: 1.000e-07  Data: 0.425 (0.425)
Train: 175 [ 100/390 ( 26%)]  Loss: 3.529 (3.14)  Time: 0.310s,  413.01/s  (0.314s,  407.49/s)  LR: 1.000e-07  Data: 0.011 (0.016)
Train: 175 [ 200/390 ( 51%)]  Loss: 3.466 (3.12)  Time: 0.310s,  413.44/s  (0.312s,  410.34/s)  LR: 1.000e-07  Data: 0.011 (0.013)
Train: 175 [ 300/390 ( 77%)]  Loss: 3.176 (3.14)  Time: 0.311s,  411.52/s  (0.311s,  411.19/s)  LR: 1.000e-07  Data: 0.012 (0.013)
Train: 175 [ 389/390 (100%)]  Loss: 3.207 (3.16)  Time: 0.297s,  431.10/s  (0.311s,  411.69/s)  LR: 1.000e-07  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.354 (0.354)  Loss:  1.0098 (1.0098)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  0.8921 (1.0266)  Acc@1: 75.0000 (76.0100)  Acc@5: 93.7500 (95.2000)
Test: [Whole Val]  Time: 9.477  Loss: 1.0266  Acc@1: 76.0100 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.334 (0.334)  Loss:  1.0098 (1.0098)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.8916 (1.0266)  Acc@1: 75.0000 (76.0100)  Acc@5: 93.7500 (95.2100)
Test (EMA): [Whole Val]  Time: 9.472  Loss: 1.0266  Acc@1: 76.0100 Pruned: 50.54% 
Train: 176 [   0/390 (  0%)]  Loss: 3.557 (3.56)  Time: 0.707s,  181.11/s  (0.707s,  181.11/s)  LR: 1.000e-07  Data: 0.407 (0.407)
Train: 176 [ 100/390 ( 26%)]  Loss: 3.025 (3.26)  Time: 0.309s,  413.92/s  (0.315s,  406.60/s)  LR: 1.000e-07  Data: 0.011 (0.015)
Train: 176 [ 200/390 ( 51%)]  Loss: 3.423 (3.22)  Time: 0.313s,  409.11/s  (0.312s,  409.74/s)  LR: 1.000e-07  Data: 0.014 (0.013)
Train: 176 [ 300/390 ( 77%)]  Loss: 2.207 (3.21)  Time: 0.310s,  413.07/s  (0.312s,  410.34/s)  LR: 1.000e-07  Data: 0.011 (0.013)
Train: 176 [ 389/390 (100%)]  Loss: 3.172 (3.22)  Time: 0.298s,  430.18/s  (0.311s,  411.03/s)  LR: 1.000e-07  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.349 (0.349)  Loss:  1.0098 (1.0098)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.019 (0.120)  Loss:  0.8921 (1.0267)  Acc@1: 75.0000 (76.0600)  Acc@5: 93.7500 (95.2300)
Test: [Whole Val]  Time: 9.507  Loss: 1.0267  Acc@1: 76.0600 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.312 (0.312)  Loss:  1.0088 (1.0088)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.8921 (1.0267)  Acc@1: 75.0000 (76.0500)  Acc@5: 93.7500 (95.2100)
Test (EMA): [Whole Val]  Time: 9.446  Loss: 1.0267  Acc@1: 76.0500 Pruned: 50.54% 
Train: 177 [   0/390 (  0%)]  Loss: 3.800 (3.80)  Time: 0.748s,  171.05/s  (0.748s,  171.05/s)  LR: 1.000e-07  Data: 0.448 (0.448)
Train: 177 [ 100/390 ( 26%)]  Loss: 3.326 (3.30)  Time: 0.324s,  395.31/s  (0.325s,  393.57/s)  LR: 1.000e-07  Data: 0.012 (0.016)
Train: 177 [ 200/390 ( 51%)]  Loss: 3.132 (3.27)  Time: 0.309s,  414.01/s  (0.319s,  401.19/s)  LR: 1.000e-07  Data: 0.011 (0.014)
Train: 177 [ 300/390 ( 77%)]  Loss: 3.401 (3.27)  Time: 0.309s,  414.05/s  (0.316s,  405.01/s)  LR: 1.000e-07  Data: 0.011 (0.013)
Train: 177 [ 389/390 (100%)]  Loss: 2.871 (3.25)  Time: 0.298s,  430.00/s  (0.315s,  405.92/s)  LR: 1.000e-07  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.368 (0.368)  Loss:  1.0098 (1.0098)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  0.8926 (1.0269)  Acc@1: 75.0000 (76.0600)  Acc@5: 93.7500 (95.2100)
Test: [Whole Val]  Time: 9.516  Loss: 1.0269  Acc@1: 76.0600 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.308 (0.308)  Loss:  1.0098 (1.0098)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.8921 (1.0269)  Acc@1: 75.0000 (76.0400)  Acc@5: 93.7500 (95.2000)
Test (EMA): [Whole Val]  Time: 9.454  Loss: 1.0269  Acc@1: 76.0400 Pruned: 50.54% 
Train: 178 [   0/390 (  0%)]  Loss: 2.611 (2.61)  Time: 0.787s,  162.59/s  (0.787s,  162.59/s)  LR: 1.000e-07  Data: 0.488 (0.488)
Train: 178 [ 100/390 ( 26%)]  Loss: 2.761 (3.26)  Time: 0.309s,  414.22/s  (0.315s,  406.86/s)  LR: 1.000e-07  Data: 0.011 (0.016)
Train: 178 [ 200/390 ( 51%)]  Loss: 2.393 (3.22)  Time: 0.310s,  412.96/s  (0.312s,  409.91/s)  LR: 1.000e-07  Data: 0.011 (0.014)
Train: 178 [ 300/390 ( 77%)]  Loss: 2.595 (3.20)  Time: 0.310s,  412.98/s  (0.313s,  409.33/s)  LR: 1.000e-07  Data: 0.011 (0.013)
Train: 178 [ 389/390 (100%)]  Loss: 2.622 (3.19)  Time: 0.298s,  429.70/s  (0.312s,  410.22/s)  LR: 1.000e-07  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.355 (0.355)  Loss:  1.0098 (1.0098)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  0.8916 (1.0269)  Acc@1: 75.0000 (76.0200)  Acc@5: 93.7500 (95.2000)
Test: [Whole Val]  Time: 9.509  Loss: 1.0269  Acc@1: 76.0200 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.342 (0.342)  Loss:  1.0098 (1.0098)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.8926 (1.0269)  Acc@1: 75.0000 (76.0400)  Acc@5: 93.7500 (95.2100)
Test (EMA): [Whole Val]  Time: 9.517  Loss: 1.0269  Acc@1: 76.0400 Pruned: 50.54% 
Train: 179 [   0/390 (  0%)]  Loss: 3.319 (3.32)  Time: 0.866s,  147.87/s  (0.866s,  147.87/s)  LR: 1.000e-07  Data: 0.566 (0.566)
Train: 179 [ 100/390 ( 26%)]  Loss: 3.661 (3.24)  Time: 0.313s,  408.60/s  (0.318s,  403.00/s)  LR: 1.000e-07  Data: 0.012 (0.017)
Train: 179 [ 200/390 ( 51%)]  Loss: 2.722 (3.23)  Time: 0.315s,  406.73/s  (0.316s,  404.73/s)  LR: 1.000e-07  Data: 0.012 (0.014)
Train: 179 [ 300/390 ( 77%)]  Loss: 3.870 (3.24)  Time: 0.314s,  408.13/s  (0.316s,  405.68/s)  LR: 1.000e-07  Data: 0.012 (0.013)
Train: 179 [ 389/390 (100%)]  Loss: 3.295 (3.24)  Time: 0.301s,  425.17/s  (0.315s,  406.44/s)  LR: 1.000e-07  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.323 (0.323)  Loss:  1.0098 (1.0098)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.8926 (1.0270)  Acc@1: 75.0000 (76.0700)  Acc@5: 93.7500 (95.2100)
Test: [Whole Val]  Time: 9.591  Loss: 1.0270  Acc@1: 76.0700 Pruned: 50.54% 
Test (EMA): [   0/78]  Time: 0.362 (0.362)  Loss:  1.0098 (1.0098)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.8926 (1.0271)  Acc@1: 75.0000 (76.0700)  Acc@5: 93.7500 (95.2100)
Test (EMA): [Whole Val]  Time: 9.615  Loss: 1.0271  Acc@1: 76.0700 Pruned: 50.54% 
*** Best metric: OrderedDict([('loss', 1.027065625), ('top1', 76.07), ('top5', 95.21), ('pruned', 0.5053638059701493)]) (epoch 179)
