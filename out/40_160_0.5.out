/home/zxy21/miniconda3/envs/ssfn/lib/python3.10/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Training with a single process on 1 GPUs.
Data processing configuration for current model + dataset:
	input_size: (3, 224, 224)
	interpolation: bicubic
	mean: (0.5, 0.5, 0.5)
	std: (0.5, 0.5, 0.5)
	crop_pct: 0.9
/home/zxy21/miniconda3/envs/ssfn/lib/python3.10/site-packages/torch_pruning/dependency.py:360: UserWarning: Unwrapped parameters detected: ['blocks.2.attn.ssf_shift_2', 'blocks.3.mlp.ssf_shift_1', 'blocks.6.ssf_shift_1', 'blocks.10.ssf_shift_1', 'blocks.2.ssf_scale_2', 'blocks.4.attn.ssf_scale_1', 'blocks.8.mlp.ssf_scale_2', 'blocks.0.mlp.ssf_shift_2', 'blocks.4.mlp.ssf_shift_2', 'blocks.7.ssf_shift_2', 'blocks.9.attn.ssf_shift_1', 'blocks.11.ssf_shift_2', 'blocks.1.attn.ssf_scale_2', 'blocks.2.mlp.ssf_scale_1', 'blocks.5.attn.ssf_scale_2', 'blocks.9.ssf_scale_1', 'blocks.0.attn.ssf_shift_2', 'blocks.1.ssf_shift_1', 'blocks.5.ssf_shift_1', 'blocks.6.attn.ssf_shift_2', 'blocks.7.mlp.ssf_shift_1', 'blocks.10.attn.ssf_shift_2', 'blocks.11.mlp.ssf_shift_1', 'blocks.3.mlp.ssf_scale_2', 'blocks.6.ssf_scale_2', 'blocks.8.attn.ssf_scale_1', 'blocks.10.ssf_scale_2', 'ssf_shift_1', 'blocks.2.ssf_shift_2', 'blocks.4.attn.ssf_shift_1', 'blocks.8.mlp.ssf_shift_2', 'blocks.0.ssf_scale_1', 'blocks.4.ssf_scale_1', 'blocks.6.mlp.ssf_scale_1', 'blocks.9.attn.ssf_scale_2', 'blocks.10.mlp.ssf_scale_1', 'blocks.1.attn.ssf_shift_2', 'blocks.2.mlp.ssf_shift_1', 'blocks.5.attn.ssf_shift_2', 'blocks.9.ssf_shift_1', 'blocks.1.ssf_scale_2', 'blocks.3.attn.ssf_scale_1', 'blocks.5.ssf_scale_2', 'blocks.7.mlp.ssf_scale_2', 'blocks.11.mlp.ssf_scale_2', 'blocks.3.mlp.ssf_shift_2', 'blocks.6.ssf_shift_2', 'blocks.8.attn.ssf_shift_1', 'blocks.10.ssf_shift_2', 'blocks.1.mlp.ssf_scale_1', 'blocks.4.attn.ssf_scale_2', 'blocks.5.mlp.ssf_scale_1', 'blocks.8.ssf_scale_1', 'blocks.0.ssf_shift_1', 'blocks.4.ssf_shift_1', 'blocks.6.mlp.ssf_shift_1', 'blocks.9.attn.ssf_shift_2', 'blocks.10.mlp.ssf_shift_1', 'blocks.2.mlp.ssf_scale_2', 'blocks.7.attn.ssf_scale_1', 'blocks.9.ssf_scale_2', 'blocks.11.attn.ssf_scale_1', 'blocks.5.ssf_shift_2', 'blocks.1.ssf_shift_2', 'blocks.3.attn.ssf_shift_1', 'blocks.7.mlp.ssf_shift_2', 'blocks.11.mlp.ssf_shift_2', 'blocks.3.ssf_scale_1', 'blocks.8.attn.ssf_scale_2', 'blocks.9.mlp.ssf_scale_1', 'blocks.1.mlp.ssf_shift_1', 'blocks.4.attn.ssf_shift_2', 'blocks.5.mlp.ssf_shift_1', 'blocks.8.ssf_shift_1', 'blocks.0.ssf_scale_2', 'blocks.2.attn.ssf_scale_1', 'blocks.4.ssf_scale_2', 'blocks.6.attn.ssf_scale_1', 'blocks.6.mlp.ssf_scale_2', 'blocks.10.mlp.ssf_scale_2', 'patch_embed.ssf_scale_1', 'blocks.2.mlp.ssf_shift_2', 'blocks.7.attn.ssf_shift_1', 'blocks.9.ssf_shift_2', 'blocks.11.attn.ssf_shift_1', 'blocks.0.mlp.ssf_scale_1', 'blocks.3.attn.ssf_scale_2', 'blocks.4.mlp.ssf_scale_1', 'blocks.7.ssf_scale_1', 'blocks.11.ssf_scale_1', 'blocks.3.ssf_shift_1', 'blocks.8.attn.ssf_shift_2', 'blocks.9.mlp.ssf_shift_1', 'blocks.0.attn.ssf_scale_1', 'blocks.1.mlp.ssf_scale_2', 'blocks.5.mlp.ssf_scale_2', 'blocks.8.ssf_scale_2', 'blocks.10.attn.ssf_scale_1', 'blocks.0.ssf_shift_2', 'blocks.2.attn.ssf_shift_1', 'blocks.4.ssf_shift_2', 'blocks.6.attn.ssf_shift_1', 'blocks.6.mlp.ssf_shift_2', 'blocks.10.mlp.ssf_shift_2', 'blocks.2.ssf_scale_1', 'blocks.7.attn.ssf_scale_2', 'blocks.8.mlp.ssf_scale_1', 'blocks.11.attn.ssf_scale_2', 'blocks.0.mlp.ssf_shift_1', 'blocks.3.attn.ssf_shift_2', 'blocks.4.mlp.ssf_shift_1', 'blocks.7.ssf_shift_1', 'blocks.11.ssf_shift_1', 'blocks.5.attn.ssf_scale_1', 'blocks.1.attn.ssf_scale_1', 'blocks.3.ssf_scale_2', 'blocks.9.mlp.ssf_scale_2', 'blocks.0.attn.ssf_shift_1', 'blocks.1.mlp.ssf_shift_2', 'blocks.5.mlp.ssf_shift_2', 'blocks.8.ssf_shift_2', 'blocks.10.attn.ssf_shift_1', 'blocks.2.attn.ssf_scale_2', 'blocks.3.mlp.ssf_scale_1', 'blocks.6.ssf_scale_1', 'blocks.6.attn.ssf_scale_2', 'blocks.10.ssf_scale_1', 'patch_embed.ssf_shift_1', 'blocks.2.ssf_shift_1', 'blocks.7.attn.ssf_shift_2', 'blocks.8.mlp.ssf_shift_1', 'blocks.11.attn.ssf_shift_2', 'ssf_scale_1', 'blocks.0.mlp.ssf_scale_2', 'blocks.4.mlp.ssf_scale_2', 'blocks.7.ssf_scale_2', 'blocks.9.attn.ssf_scale_1', 'blocks.11.ssf_scale_2', 'blocks.5.attn.ssf_shift_1', 'blocks.1.attn.ssf_shift_1', 'blocks.3.ssf_shift_2', 'blocks.9.mlp.ssf_shift_2', 'blocks.0.attn.ssf_scale_2', 'blocks.1.ssf_scale_1', 'blocks.5.ssf_scale_1', 'blocks.7.mlp.ssf_scale_1', 'blocks.10.attn.ssf_scale_2', 'blocks.11.mlp.ssf_scale_1'].
 Torch-Pruning will prune the last non-singleton dimension of a parameter. If you wish to customize this behavior, please provide an unwrapped_parameters argument.
  warnings.warn("Unwrapped parameters detected: {}.\n Torch-Pruning will prune the last non-singleton dimension of a parameter. If you wish to customize this behavior, please provide an unwrapped_parameters argument.".format([_param_to_name[p] for p in unwrapped_detected]))
Params: 86.0814 M
ops: 16.8553 G
ssf_scale_1
ssf_shift_1
patch_embed.ssf_scale_1
patch_embed.ssf_shift_1
blocks.0.ssf_scale_1
blocks.0.ssf_shift_1
blocks.0.ssf_scale_2
blocks.0.ssf_shift_2
blocks.0.attn.ssf_scale_1
blocks.0.attn.ssf_shift_1
blocks.0.attn.ssf_scale_2
blocks.0.attn.ssf_shift_2
blocks.0.mlp.ssf_scale_1
blocks.0.mlp.ssf_shift_1
blocks.0.mlp.ssf_scale_2
blocks.0.mlp.ssf_shift_2
blocks.1.ssf_scale_1
blocks.1.ssf_shift_1
blocks.1.ssf_scale_2
blocks.1.ssf_shift_2
blocks.1.attn.ssf_scale_1
blocks.1.attn.ssf_shift_1
blocks.1.attn.ssf_scale_2
blocks.1.attn.ssf_shift_2
blocks.1.mlp.ssf_scale_1
blocks.1.mlp.ssf_shift_1
blocks.1.mlp.ssf_scale_2
blocks.1.mlp.ssf_shift_2
blocks.2.ssf_scale_1
blocks.2.ssf_shift_1
blocks.2.ssf_scale_2
blocks.2.ssf_shift_2
blocks.2.attn.ssf_scale_1
blocks.2.attn.ssf_shift_1
blocks.2.attn.ssf_scale_2
blocks.2.attn.ssf_shift_2
blocks.2.mlp.ssf_scale_1
blocks.2.mlp.ssf_shift_1
blocks.2.mlp.ssf_scale_2
blocks.2.mlp.ssf_shift_2
blocks.3.ssf_scale_1
blocks.3.ssf_shift_1
blocks.3.ssf_scale_2
blocks.3.ssf_shift_2
blocks.3.attn.ssf_scale_1
blocks.3.attn.ssf_shift_1
blocks.3.attn.ssf_scale_2
blocks.3.attn.ssf_shift_2
blocks.3.mlp.ssf_scale_1
blocks.3.mlp.ssf_shift_1
blocks.3.mlp.ssf_scale_2
blocks.3.mlp.ssf_shift_2
blocks.4.ssf_scale_1
blocks.4.ssf_shift_1
blocks.4.ssf_scale_2
blocks.4.ssf_shift_2
blocks.4.attn.ssf_scale_1
blocks.4.attn.ssf_shift_1
blocks.4.attn.ssf_scale_2
blocks.4.attn.ssf_shift_2
blocks.4.mlp.ssf_scale_1
blocks.4.mlp.ssf_shift_1
blocks.4.mlp.ssf_scale_2
blocks.4.mlp.ssf_shift_2
blocks.5.ssf_scale_1
blocks.5.ssf_shift_1
blocks.5.ssf_scale_2
blocks.5.ssf_shift_2
blocks.5.attn.ssf_scale_1
blocks.5.attn.ssf_shift_1
blocks.5.attn.ssf_scale_2
blocks.5.attn.ssf_shift_2
blocks.5.mlp.ssf_scale_1
blocks.5.mlp.ssf_shift_1
blocks.5.mlp.ssf_scale_2
blocks.5.mlp.ssf_shift_2
blocks.6.ssf_scale_1
blocks.6.ssf_shift_1
blocks.6.ssf_scale_2
blocks.6.ssf_shift_2
blocks.6.attn.ssf_scale_1
blocks.6.attn.ssf_shift_1
blocks.6.attn.ssf_scale_2
blocks.6.attn.ssf_shift_2
blocks.6.mlp.ssf_scale_1
blocks.6.mlp.ssf_shift_1
blocks.6.mlp.ssf_scale_2
blocks.6.mlp.ssf_shift_2
blocks.7.ssf_scale_1
blocks.7.ssf_shift_1
blocks.7.ssf_scale_2
blocks.7.ssf_shift_2
blocks.7.attn.ssf_scale_1
blocks.7.attn.ssf_shift_1
blocks.7.attn.ssf_scale_2
blocks.7.attn.ssf_shift_2
blocks.7.mlp.ssf_scale_1
blocks.7.mlp.ssf_shift_1
blocks.7.mlp.ssf_scale_2
blocks.7.mlp.ssf_shift_2
blocks.8.ssf_scale_1
blocks.8.ssf_shift_1
blocks.8.ssf_scale_2
blocks.8.ssf_shift_2
blocks.8.attn.ssf_scale_1
blocks.8.attn.ssf_shift_1
blocks.8.attn.ssf_scale_2
blocks.8.attn.ssf_shift_2
blocks.8.mlp.ssf_scale_1
blocks.8.mlp.ssf_shift_1
blocks.8.mlp.ssf_scale_2
blocks.8.mlp.ssf_shift_2
blocks.9.ssf_scale_1
blocks.9.ssf_shift_1
blocks.9.ssf_scale_2
blocks.9.ssf_shift_2
blocks.9.attn.ssf_scale_1
blocks.9.attn.ssf_shift_1
blocks.9.attn.ssf_scale_2
blocks.9.attn.ssf_shift_2
blocks.9.mlp.ssf_scale_1
blocks.9.mlp.ssf_shift_1
blocks.9.mlp.ssf_scale_2
blocks.9.mlp.ssf_shift_2
blocks.10.ssf_scale_1
blocks.10.ssf_shift_1
blocks.10.ssf_scale_2
blocks.10.ssf_shift_2
blocks.10.attn.ssf_scale_1
blocks.10.attn.ssf_shift_1
blocks.10.attn.ssf_scale_2
blocks.10.attn.ssf_shift_2
blocks.10.mlp.ssf_scale_1
blocks.10.mlp.ssf_shift_1
blocks.10.mlp.ssf_scale_2
blocks.10.mlp.ssf_shift_2
blocks.11.ssf_scale_1
blocks.11.ssf_shift_1
blocks.11.ssf_scale_2
blocks.11.ssf_shift_2
blocks.11.attn.ssf_scale_1
blocks.11.attn.ssf_shift_1
blocks.11.attn.ssf_scale_2
blocks.11.attn.ssf_shift_2
blocks.11.mlp.ssf_scale_1
blocks.11.mlp.ssf_shift_1
blocks.11.mlp.ssf_scale_2
blocks.11.mlp.ssf_shift_2
head.weight
head.bias
freezing parameters finished!
Model vit_base_patch16_224_in21k created, param count:86081380
number of params for requires grad: 282724
Using native Torch AMP. Training in mixed precision.
Scheduled epochs: 170
Train: 0 [   0/390 (  0%)]  Loss: 5.723 (5.72)  Time: 3.649s,   35.08/s  (3.649s,   35.08/s)  LR: 1.000e-03  Data: 0.904 (0.904)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.498 (3.71)  Time: 0.314s,  407.49/s  (0.350s,  366.19/s)  LR: 1.000e-03  Data: 0.011 (0.021)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.159 (3.36)  Time: 0.320s,  399.77/s  (0.338s,  378.75/s)  LR: 1.000e-03  Data: 0.014 (0.017)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.063 (3.18)  Time: 0.316s,  405.40/s  (0.332s,  386.06/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 389/390 (100%)]  Loss: 3.413 (3.10)  Time: 0.306s,  417.81/s  (0.328s,  389.87/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 2.019 (2.02)  Time: 0.836s,  153.08/s  (0.836s,  153.08/s)  LR: 1.000e-03  Data: 0.528 (0.528)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.835 (2.79)  Time: 0.324s,  395.42/s  (0.330s,  387.87/s)  LR: 1.000e-03  Data: 0.018 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.461 (2.76)  Time: 0.342s,  374.75/s  (0.328s,  390.46/s)  LR: 1.000e-03  Data: 0.018 (0.016)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.191 (2.79)  Time: 0.321s,  398.89/s  (0.328s,  390.59/s)  LR: 1.000e-03  Data: 0.013 (0.015)
Train: 0 [ 389/390 (100%)]  Loss: 2.223 (2.79)  Time: 0.320s,  399.46/s  (0.326s,  392.56/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 2.995 (2.99)  Time: 0.767s,  166.92/s  (0.767s,  166.92/s)  LR: 1.000e-03  Data: 0.461 (0.461)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.177 (2.76)  Time: 0.319s,  401.43/s  (0.326s,  392.95/s)  LR: 1.000e-03  Data: 0.012 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.077 (2.73)  Time: 0.318s,  402.81/s  (0.324s,  394.72/s)  LR: 1.000e-03  Data: 0.010 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.471 (2.74)  Time: 0.340s,  376.23/s  (0.323s,  395.69/s)  LR: 1.000e-03  Data: 0.015 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 2.704 (2.74)  Time: 0.308s,  415.75/s  (0.323s,  396.41/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.374 (3.37)  Time: 0.778s,  164.45/s  (0.778s,  164.45/s)  LR: 1.000e-03  Data: 0.473 (0.473)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.151 (2.68)  Time: 0.319s,  401.72/s  (0.324s,  395.05/s)  LR: 1.000e-03  Data: 0.012 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.519 (2.71)  Time: 0.317s,  403.70/s  (0.322s,  397.69/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.246 (2.71)  Time: 0.318s,  402.15/s  (0.321s,  399.14/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 2.637 (2.72)  Time: 0.305s,  419.13/s  (0.320s,  399.87/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.136 (3.14)  Time: 0.746s,  171.53/s  (0.746s,  171.53/s)  LR: 1.000e-03  Data: 0.440 (0.440)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.969 (2.75)  Time: 0.318s,  402.35/s  (0.323s,  396.71/s)  LR: 1.000e-03  Data: 0.012 (0.016)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.421 (2.76)  Time: 0.318s,  402.92/s  (0.320s,  399.64/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.323 (2.78)  Time: 0.320s,  399.80/s  (0.320s,  400.28/s)  LR: 1.000e-03  Data: 0.015 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 3.196 (2.78)  Time: 0.307s,  417.55/s  (0.319s,  400.87/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 2.996 (3.00)  Time: 0.806s,  158.80/s  (0.806s,  158.80/s)  LR: 1.000e-03  Data: 0.493 (0.493)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.031 (2.83)  Time: 0.316s,  404.47/s  (0.323s,  396.89/s)  LR: 1.000e-03  Data: 0.012 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.446 (2.80)  Time: 0.318s,  402.48/s  (0.320s,  399.75/s)  LR: 1.000e-03  Data: 0.013 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.279 (2.78)  Time: 0.317s,  404.16/s  (0.319s,  400.72/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.012 (2.79)  Time: 0.305s,  419.95/s  (0.319s,  401.07/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 2.244 (2.24)  Time: 0.761s,  168.30/s  (0.761s,  168.30/s)  LR: 1.000e-03  Data: 0.455 (0.455)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.126 (2.86)  Time: 0.318s,  402.06/s  (0.325s,  393.77/s)  LR: 1.000e-03  Data: 0.011 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.177 (2.87)  Time: 0.318s,  401.98/s  (0.322s,  396.93/s)  LR: 1.000e-03  Data: 0.013 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.445 (2.84)  Time: 0.320s,  400.33/s  (0.322s,  397.69/s)  LR: 1.000e-03  Data: 0.015 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 2.406 (2.84)  Time: 0.308s,  415.08/s  (0.321s,  398.60/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 2.966 (2.97)  Time: 0.732s,  174.77/s  (0.732s,  174.77/s)  LR: 1.000e-03  Data: 0.427 (0.427)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.293 (2.82)  Time: 0.319s,  401.39/s  (0.323s,  396.60/s)  LR: 1.000e-03  Data: 0.011 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 1.866 (2.82)  Time: 0.316s,  405.23/s  (0.322s,  397.05/s)  LR: 1.000e-03  Data: 0.010 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.936 (2.83)  Time: 0.317s,  403.76/s  (0.321s,  399.07/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.286 (2.86)  Time: 0.318s,  402.80/s  (0.321s,  398.38/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 1.870 (1.87)  Time: 0.841s,  152.12/s  (0.841s,  152.12/s)  LR: 1.000e-03  Data: 0.537 (0.537)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.454 (2.86)  Time: 0.318s,  403.08/s  (0.324s,  394.72/s)  LR: 1.000e-03  Data: 0.013 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.265 (2.86)  Time: 0.321s,  398.34/s  (0.323s,  396.13/s)  LR: 1.000e-03  Data: 0.015 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.580 (2.89)  Time: 0.318s,  402.66/s  (0.321s,  398.33/s)  LR: 1.000e-03  Data: 0.013 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 2.044 (2.89)  Time: 0.305s,  419.85/s  (0.322s,  397.22/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.453 (3.45)  Time: 0.910s,  140.70/s  (0.910s,  140.70/s)  LR: 1.000e-03  Data: 0.604 (0.604)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.282 (2.85)  Time: 0.318s,  402.75/s  (0.325s,  394.16/s)  LR: 1.000e-03  Data: 0.012 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.031 (2.87)  Time: 0.322s,  397.28/s  (0.321s,  398.15/s)  LR: 1.000e-03  Data: 0.017 (0.016)
Train: 0 [ 300/390 ( 77%)]  Loss: 1.905 (2.88)  Time: 0.331s,  386.70/s  (0.323s,  396.33/s)  LR: 1.000e-03  Data: 0.013 (0.015)
Train: 0 [ 389/390 (100%)]  Loss: 2.089 (2.88)  Time: 0.312s,  410.50/s  (0.322s,  397.05/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 2.747 (2.75)  Time: 0.787s,  162.65/s  (0.787s,  162.65/s)  LR: 1.000e-03  Data: 0.484 (0.484)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.395 (2.92)  Time: 0.318s,  402.18/s  (0.327s,  391.51/s)  LR: 1.000e-03  Data: 0.014 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.521 (2.92)  Time: 0.317s,  403.86/s  (0.327s,  391.59/s)  LR: 1.000e-03  Data: 0.012 (0.016)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.835 (2.93)  Time: 0.323s,  395.86/s  (0.326s,  393.16/s)  LR: 1.000e-03  Data: 0.018 (0.015)
Train: 0 [ 389/390 (100%)]  Loss: 3.195 (2.94)  Time: 0.322s,  396.92/s  (0.325s,  393.84/s)  LR: 1.000e-03  Data: 0.000 (0.015)
Train: 0 [   0/390 (  0%)]  Loss: 2.997 (3.00)  Time: 0.744s,  172.01/s  (0.744s,  172.01/s)  LR: 1.000e-03  Data: 0.438 (0.438)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.940 (2.92)  Time: 0.317s,  404.02/s  (0.328s,  390.42/s)  LR: 1.000e-03  Data: 0.012 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.668 (2.90)  Time: 0.334s,  383.11/s  (0.325s,  393.85/s)  LR: 1.000e-03  Data: 0.015 (0.016)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.686 (2.90)  Time: 0.318s,  402.21/s  (0.324s,  395.16/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 389/390 (100%)]  Loss: 1.886 (2.89)  Time: 0.305s,  418.99/s  (0.323s,  396.24/s)  LR: 1.000e-03  Data: 0.000 (0.015)
Train: 0 [   0/390 (  0%)]  Loss: 3.589 (3.59)  Time: 0.909s,  140.78/s  (0.909s,  140.78/s)  LR: 1.000e-03  Data: 0.603 (0.603)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.434 (3.03)  Time: 0.332s,  385.92/s  (0.330s,  388.32/s)  LR: 1.000e-03  Data: 0.013 (0.019)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.476 (2.99)  Time: 0.336s,  380.61/s  (0.328s,  390.25/s)  LR: 1.000e-03  Data: 0.014 (0.017)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.472 (2.98)  Time: 0.332s,  386.12/s  (0.327s,  391.27/s)  LR: 1.000e-03  Data: 0.013 (0.016)
Train: 0 [ 389/390 (100%)]  Loss: 3.471 (2.96)  Time: 0.306s,  417.62/s  (0.327s,  391.93/s)  LR: 1.000e-03  Data: 0.000 (0.015)
Train: 0 [   0/390 (  0%)]  Loss: 2.108 (2.11)  Time: 0.770s,  166.30/s  (0.770s,  166.30/s)  LR: 1.000e-03  Data: 0.451 (0.451)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.859 (3.00)  Time: 0.331s,  386.93/s  (0.332s,  385.83/s)  LR: 1.000e-03  Data: 0.013 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.350 (2.99)  Time: 0.317s,  403.72/s  (0.327s,  391.00/s)  LR: 1.000e-03  Data: 0.012 (0.016)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.857 (2.98)  Time: 0.322s,  398.12/s  (0.326s,  392.51/s)  LR: 1.000e-03  Data: 0.015 (0.016)
Train: 0 [ 389/390 (100%)]  Loss: 3.481 (2.98)  Time: 0.308s,  415.67/s  (0.326s,  392.47/s)  LR: 1.000e-03  Data: 0.000 (0.016)
Train: 0 [   0/390 (  0%)]  Loss: 3.182 (3.18)  Time: 0.777s,  164.83/s  (0.777s,  164.83/s)  LR: 1.000e-03  Data: 0.468 (0.468)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.944 (2.87)  Time: 0.334s,  383.42/s  (0.332s,  386.01/s)  LR: 1.000e-03  Data: 0.029 (0.019)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.157 (2.94)  Time: 0.319s,  401.84/s  (0.328s,  390.54/s)  LR: 1.000e-03  Data: 0.013 (0.017)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.515 (2.95)  Time: 0.319s,  401.27/s  (0.326s,  392.83/s)  LR: 1.000e-03  Data: 0.013 (0.016)
Train: 0 [ 389/390 (100%)]  Loss: 2.683 (2.95)  Time: 0.307s,  416.98/s  (0.326s,  392.84/s)  LR: 1.000e-03  Data: 0.000 (0.016)
Train: 0 [   0/390 (  0%)]  Loss: 3.351 (3.35)  Time: 0.799s,  160.15/s  (0.799s,  160.15/s)  LR: 1.000e-03  Data: 0.494 (0.494)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.303 (3.06)  Time: 0.333s,  383.99/s  (0.333s,  384.95/s)  LR: 1.000e-03  Data: 0.014 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.287 (3.02)  Time: 0.331s,  386.28/s  (0.329s,  389.45/s)  LR: 1.000e-03  Data: 0.013 (0.016)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.213 (3.02)  Time: 0.333s,  384.46/s  (0.330s,  388.39/s)  LR: 1.000e-03  Data: 0.014 (0.016)
Train: 0 [ 389/390 (100%)]  Loss: 3.085 (3.02)  Time: 0.319s,  401.30/s  (0.329s,  389.26/s)  LR: 1.000e-03  Data: 0.000 (0.015)
Train: 0 [   0/390 (  0%)]  Loss: 3.557 (3.56)  Time: 0.788s,  162.44/s  (0.788s,  162.44/s)  LR: 1.000e-03  Data: 0.483 (0.483)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.150 (3.00)  Time: 0.318s,  402.27/s  (0.327s,  391.42/s)  LR: 1.000e-03  Data: 0.012 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.031 (3.02)  Time: 0.319s,  401.44/s  (0.324s,  395.48/s)  LR: 1.000e-03  Data: 0.013 (0.016)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.386 (3.03)  Time: 0.318s,  402.46/s  (0.324s,  395.66/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 389/390 (100%)]  Loss: 2.912 (3.04)  Time: 0.306s,  418.87/s  (0.323s,  396.11/s)  LR: 1.000e-03  Data: 0.000 (0.015)
Train: 0 [   0/390 (  0%)]  Loss: 3.135 (3.14)  Time: 0.808s,  158.40/s  (0.808s,  158.40/s)  LR: 1.000e-03  Data: 0.502 (0.502)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.451 (3.09)  Time: 0.337s,  379.85/s  (0.332s,  385.11/s)  LR: 1.000e-03  Data: 0.015 (0.020)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.319 (3.07)  Time: 0.318s,  402.63/s  (0.328s,  390.45/s)  LR: 1.000e-03  Data: 0.012 (0.017)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.871 (3.02)  Time: 0.333s,  384.74/s  (0.328s,  390.27/s)  LR: 1.000e-03  Data: 0.013 (0.017)
Train: 0 [ 389/390 (100%)]  Loss: 3.339 (3.01)  Time: 0.308s,  415.29/s  (0.327s,  392.03/s)  LR: 1.000e-03  Data: 0.000 (0.016)
Train: 0 [   0/390 (  0%)]  Loss: 3.296 (3.30)  Time: 0.809s,  158.16/s  (0.809s,  158.16/s)  LR: 1.000e-03  Data: 0.496 (0.496)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.699 (3.13)  Time: 0.327s,  391.76/s  (0.329s,  389.00/s)  LR: 1.000e-03  Data: 0.013 (0.019)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.080 (3.13)  Time: 0.318s,  402.40/s  (0.326s,  392.21/s)  LR: 1.000e-03  Data: 0.012 (0.017)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.352 (3.11)  Time: 0.320s,  399.39/s  (0.325s,  393.45/s)  LR: 1.000e-03  Data: 0.014 (0.016)
Train: 0 [ 389/390 (100%)]  Loss: 3.319 (3.11)  Time: 0.306s,  418.38/s  (0.326s,  393.20/s)  LR: 1.000e-03  Data: 0.000 (0.016)
Train: 0 [   0/390 (  0%)]  Loss: 2.458 (2.46)  Time: 0.838s,  152.78/s  (0.838s,  152.78/s)  LR: 1.000e-03  Data: 0.527 (0.527)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.480 (3.09)  Time: 0.322s,  397.41/s  (0.328s,  390.38/s)  LR: 1.000e-03  Data: 0.014 (0.019)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.762 (3.06)  Time: 0.319s,  401.11/s  (0.326s,  392.85/s)  LR: 1.000e-03  Data: 0.012 (0.017)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.782 (3.06)  Time: 0.325s,  394.05/s  (0.325s,  393.82/s)  LR: 1.000e-03  Data: 0.014 (0.016)
Train: 0 [ 389/390 (100%)]  Loss: 2.695 (3.07)  Time: 0.306s,  418.07/s  (0.325s,  394.35/s)  LR: 1.000e-03  Data: 0.000 (0.016)
Train: 0 [   0/390 (  0%)]  Loss: 3.942 (3.94)  Time: 0.766s,  167.12/s  (0.766s,  167.12/s)  LR: 1.000e-03  Data: 0.457 (0.457)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.094 (3.09)  Time: 0.320s,  399.89/s  (0.328s,  389.67/s)  LR: 1.000e-03  Data: 0.013 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.424 (3.06)  Time: 0.322s,  397.12/s  (0.325s,  393.69/s)  LR: 1.000e-03  Data: 0.015 (0.016)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.519 (3.07)  Time: 0.323s,  396.40/s  (0.324s,  394.67/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 389/390 (100%)]  Loss: 3.435 (3.07)  Time: 0.308s,  416.24/s  (0.325s,  393.96/s)  LR: 1.000e-03  Data: 0.000 (0.015)
Train: 0 [   0/390 (  0%)]  Loss: 3.078 (3.08)  Time: 0.760s,  168.38/s  (0.760s,  168.38/s)  LR: 1.000e-03  Data: 0.451 (0.451)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.736 (3.11)  Time: 0.332s,  385.86/s  (0.328s,  390.02/s)  LR: 1.000e-03  Data: 0.019 (0.019)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.856 (3.07)  Time: 0.321s,  399.16/s  (0.325s,  393.25/s)  LR: 1.000e-03  Data: 0.013 (0.017)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.809 (3.10)  Time: 0.322s,  397.98/s  (0.326s,  393.04/s)  LR: 1.000e-03  Data: 0.014 (0.016)
Train: 0 [ 389/390 (100%)]  Loss: 3.485 (3.12)  Time: 0.308s,  415.84/s  (0.325s,  393.96/s)  LR: 1.000e-03  Data: 0.000 (0.015)
Train: 0 [   0/390 (  0%)]  Loss: 2.335 (2.34)  Time: 0.827s,  154.85/s  (0.827s,  154.85/s)  LR: 1.000e-03  Data: 0.517 (0.517)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.452 (3.13)  Time: 0.332s,  385.56/s  (0.328s,  390.06/s)  LR: 1.000e-03  Data: 0.015 (0.019)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.749 (3.14)  Time: 0.322s,  396.95/s  (0.326s,  392.63/s)  LR: 1.000e-03  Data: 0.016 (0.017)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.811 (3.16)  Time: 0.336s,  381.47/s  (0.327s,  391.97/s)  LR: 1.000e-03  Data: 0.014 (0.016)
Train: 0 [ 389/390 (100%)]  Loss: 2.917 (3.16)  Time: 0.313s,  408.93/s  (0.326s,  392.16/s)  LR: 1.000e-03  Data: 0.000 (0.016)
Train: 0 [   0/390 (  0%)]  Loss: 3.577 (3.58)  Time: 0.785s,  162.99/s  (0.785s,  162.99/s)  LR: 1.000e-03  Data: 0.477 (0.477)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.588 (3.10)  Time: 0.326s,  392.53/s  (0.327s,  391.15/s)  LR: 1.000e-03  Data: 0.013 (0.019)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.448 (3.15)  Time: 0.320s,  400.44/s  (0.324s,  395.50/s)  LR: 1.000e-03  Data: 0.013 (0.016)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.058 (3.17)  Time: 0.320s,  400.46/s  (0.323s,  396.66/s)  LR: 1.000e-03  Data: 0.015 (0.015)
Train: 0 [ 389/390 (100%)]  Loss: 3.745 (3.17)  Time: 0.305s,  419.72/s  (0.322s,  397.86/s)  LR: 1.000e-03  Data: 0.000 (0.015)
Train: 0 [   0/390 (  0%)]  Loss: 3.563 (3.56)  Time: 0.789s,  162.24/s  (0.789s,  162.24/s)  LR: 1.000e-03  Data: 0.483 (0.483)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.741 (3.21)  Time: 0.320s,  399.57/s  (0.326s,  392.66/s)  LR: 1.000e-03  Data: 0.014 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.601 (3.17)  Time: 0.322s,  397.22/s  (0.322s,  396.97/s)  LR: 1.000e-03  Data: 0.013 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.756 (3.18)  Time: 0.317s,  403.54/s  (0.322s,  397.71/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 389/390 (100%)]  Loss: 2.394 (3.17)  Time: 0.305s,  419.96/s  (0.321s,  398.14/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.496 (3.50)  Time: 0.807s,  158.64/s  (0.807s,  158.64/s)  LR: 1.000e-03  Data: 0.502 (0.502)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.653 (3.16)  Time: 0.318s,  402.57/s  (0.325s,  393.87/s)  LR: 1.000e-03  Data: 0.013 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.373 (3.16)  Time: 0.317s,  403.54/s  (0.322s,  397.80/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.526 (3.17)  Time: 0.318s,  402.32/s  (0.321s,  399.07/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 389/390 (100%)]  Loss: 3.749 (3.16)  Time: 0.305s,  419.91/s  (0.320s,  399.76/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.851 (3.85)  Time: 0.951s,  134.63/s  (0.951s,  134.63/s)  LR: 1.000e-03  Data: 0.635 (0.635)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.091 (3.20)  Time: 0.317s,  403.45/s  (0.325s,  393.74/s)  LR: 1.000e-03  Data: 0.013 (0.019)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.580 (3.21)  Time: 0.316s,  404.61/s  (0.322s,  397.95/s)  LR: 1.000e-03  Data: 0.012 (0.016)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.451 (3.22)  Time: 0.318s,  403.13/s  (0.321s,  398.88/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 389/390 (100%)]  Loss: 3.103 (3.23)  Time: 0.306s,  418.07/s  (0.320s,  399.71/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.648 (3.65)  Time: 0.885s,  144.56/s  (0.885s,  144.56/s)  LR: 1.000e-03  Data: 0.580 (0.580)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.437 (3.24)  Time: 0.315s,  405.79/s  (0.325s,  394.03/s)  LR: 1.000e-03  Data: 0.012 (0.019)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.536 (3.21)  Time: 0.317s,  403.68/s  (0.323s,  396.87/s)  LR: 1.000e-03  Data: 0.013 (0.016)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.433 (3.21)  Time: 0.316s,  405.21/s  (0.321s,  398.46/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 389/390 (100%)]  Loss: 3.721 (3.22)  Time: 0.306s,  417.73/s  (0.321s,  399.15/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.514 (3.51)  Time: 0.914s,  140.00/s  (0.914s,  140.00/s)  LR: 1.000e-03  Data: 0.591 (0.591)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.467 (3.21)  Time: 0.317s,  403.55/s  (0.326s,  393.01/s)  LR: 1.000e-03  Data: 0.012 (0.019)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.754 (3.21)  Time: 0.316s,  404.79/s  (0.322s,  397.49/s)  LR: 1.000e-03  Data: 0.012 (0.016)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.738 (3.22)  Time: 0.318s,  402.47/s  (0.321s,  399.07/s)  LR: 1.000e-03  Data: 0.014 (0.015)
Train: 0 [ 389/390 (100%)]  Loss: 3.610 (3.22)  Time: 0.306s,  418.21/s  (0.320s,  399.86/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.644 (3.64)  Time: 0.827s,  154.85/s  (0.827s,  154.85/s)  LR: 1.000e-03  Data: 0.514 (0.514)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.556 (3.29)  Time: 0.318s,  402.47/s  (0.324s,  394.83/s)  LR: 1.000e-03  Data: 0.012 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.870 (3.30)  Time: 0.320s,  399.39/s  (0.321s,  398.64/s)  LR: 1.000e-03  Data: 0.014 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.162 (3.29)  Time: 0.317s,  403.63/s  (0.320s,  399.73/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 389/390 (100%)]  Loss: 3.683 (3.27)  Time: 0.306s,  418.24/s  (0.320s,  400.13/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 2.967 (2.97)  Time: 0.825s,  155.22/s  (0.825s,  155.22/s)  LR: 1.000e-03  Data: 0.502 (0.502)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.735 (3.36)  Time: 0.320s,  400.38/s  (0.325s,  394.36/s)  LR: 1.000e-03  Data: 0.014 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.078 (3.32)  Time: 0.318s,  402.60/s  (0.321s,  398.15/s)  LR: 1.000e-03  Data: 0.012 (0.016)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.406 (3.32)  Time: 0.319s,  400.70/s  (0.321s,  398.97/s)  LR: 1.000e-03  Data: 0.015 (0.015)
Train: 0 [ 389/390 (100%)]  Loss: 3.705 (3.31)  Time: 0.306s,  417.88/s  (0.320s,  399.83/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.670 (3.67)  Time: 0.815s,  157.07/s  (0.815s,  157.07/s)  LR: 1.000e-03  Data: 0.492 (0.492)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.514 (3.21)  Time: 0.320s,  400.19/s  (0.323s,  396.27/s)  LR: 1.000e-03  Data: 0.014 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.662 (3.24)  Time: 0.318s,  402.27/s  (0.321s,  399.06/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.898 (3.26)  Time: 0.318s,  402.22/s  (0.320s,  400.05/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.071 (3.27)  Time: 0.305s,  419.03/s  (0.320s,  400.49/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 2.381 (2.38)  Time: 0.710s,  180.16/s  (0.710s,  180.16/s)  LR: 1.000e-03  Data: 0.402 (0.402)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.982 (3.30)  Time: 0.317s,  404.15/s  (0.322s,  397.21/s)  LR: 1.000e-03  Data: 0.013 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.898 (3.34)  Time: 0.317s,  403.51/s  (0.320s,  399.74/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.561 (3.33)  Time: 0.317s,  403.73/s  (0.320s,  400.49/s)  LR: 1.000e-03  Data: 0.013 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.756 (3.34)  Time: 0.305s,  419.12/s  (0.319s,  401.00/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.816 (3.82)  Time: 0.841s,  152.11/s  (0.841s,  152.11/s)  LR: 1.000e-03  Data: 0.537 (0.537)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.629 (3.36)  Time: 0.319s,  400.76/s  (0.324s,  395.50/s)  LR: 1.000e-03  Data: 0.015 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.628 (3.36)  Time: 0.321s,  398.15/s  (0.321s,  398.80/s)  LR: 1.000e-03  Data: 0.013 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.062 (3.35)  Time: 0.319s,  400.84/s  (0.320s,  399.95/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.613 (3.34)  Time: 0.308s,  416.07/s  (0.319s,  400.94/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 2.447 (2.45)  Time: 0.878s,  145.83/s  (0.878s,  145.83/s)  LR: 1.000e-03  Data: 0.565 (0.565)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.661 (3.32)  Time: 0.320s,  399.58/s  (0.326s,  392.14/s)  LR: 1.000e-03  Data: 0.014 (0.019)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.807 (3.34)  Time: 0.317s,  403.66/s  (0.323s,  396.77/s)  LR: 1.000e-03  Data: 0.011 (0.016)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.616 (3.35)  Time: 0.317s,  403.93/s  (0.321s,  398.32/s)  LR: 1.000e-03  Data: 0.013 (0.015)
Train: 0 [ 389/390 (100%)]  Loss: 2.858 (3.36)  Time: 0.305s,  419.84/s  (0.321s,  399.21/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.495 (3.50)  Time: 0.828s,  154.62/s  (0.828s,  154.62/s)  LR: 1.000e-03  Data: 0.523 (0.523)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.308 (3.33)  Time: 0.318s,  402.79/s  (0.324s,  395.30/s)  LR: 1.000e-03  Data: 0.013 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.920 (3.37)  Time: 0.317s,  403.63/s  (0.322s,  397.69/s)  LR: 1.000e-03  Data: 0.014 (0.016)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.679 (3.38)  Time: 0.317s,  403.99/s  (0.321s,  399.07/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 389/390 (100%)]  Loss: 3.638 (3.37)  Time: 0.305s,  419.13/s  (0.320s,  400.01/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.774 (3.77)  Time: 0.767s,  166.80/s  (0.767s,  166.80/s)  LR: 1.000e-03  Data: 0.461 (0.461)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.893 (3.40)  Time: 0.315s,  405.75/s  (0.323s,  396.59/s)  LR: 1.000e-03  Data: 0.011 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.393 (3.38)  Time: 0.317s,  404.08/s  (0.321s,  399.16/s)  LR: 1.000e-03  Data: 0.013 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.571 (3.39)  Time: 0.317s,  403.33/s  (0.320s,  400.07/s)  LR: 1.000e-03  Data: 0.013 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.921 (3.39)  Time: 0.306s,  417.97/s  (0.319s,  400.77/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.471 (3.47)  Time: 0.886s,  144.39/s  (0.886s,  144.39/s)  LR: 1.000e-03  Data: 0.570 (0.570)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.167 (3.32)  Time: 0.316s,  405.54/s  (0.324s,  395.15/s)  LR: 1.000e-03  Data: 0.011 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.154 (3.33)  Time: 0.319s,  401.73/s  (0.322s,  397.87/s)  LR: 1.000e-03  Data: 0.013 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.759 (3.34)  Time: 0.322s,  397.63/s  (0.320s,  399.42/s)  LR: 1.000e-03  Data: 0.014 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 2.511 (3.34)  Time: 0.305s,  419.48/s  (0.320s,  400.11/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 2.683 (2.68)  Time: 0.842s,  151.98/s  (0.842s,  151.98/s)  LR: 1.000e-03  Data: 0.537 (0.537)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.793 (3.37)  Time: 0.317s,  404.19/s  (0.324s,  395.24/s)  LR: 1.000e-03  Data: 0.012 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.558 (3.35)  Time: 0.323s,  396.81/s  (0.321s,  398.78/s)  LR: 1.000e-03  Data: 0.018 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.096 (3.39)  Time: 0.319s,  401.63/s  (0.320s,  399.97/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.765 (3.41)  Time: 0.305s,  419.43/s  (0.320s,  400.43/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.794 (3.79)  Time: 0.738s,  173.41/s  (0.738s,  173.41/s)  LR: 1.000e-03  Data: 0.419 (0.419)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.362 (3.43)  Time: 0.318s,  402.79/s  (0.323s,  396.51/s)  LR: 1.000e-03  Data: 0.011 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.857 (3.40)  Time: 0.319s,  401.43/s  (0.321s,  399.26/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.857 (3.41)  Time: 0.316s,  404.80/s  (0.320s,  400.39/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 2.721 (3.45)  Time: 0.305s,  419.03/s  (0.319s,  400.92/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Test: [   0/78]  Time: 1.132 (1.132)  Loss:  4.6406 (4.6406)  Acc@1:  4.6875 ( 4.6875)  Acc@5:  7.0312 ( 7.0312)
Test: [  78/78]  Time: 0.074 (0.134)  Loss:  4.6406 (4.6993)  Acc@1:  6.2500 ( 1.6800)  Acc@5: 18.7500 ( 7.7200)
Test: [Whole Val]  Time: 10.548  Loss: 4.6993  Acc@1:  1.6800 Pruned: 55.18% 
*** Pruned results: OrderedDict([('loss', 4.699325), ('top1', 1.68), ('top5', 7.72), ('pruned', 0.5518112562189055)])
Pruned: 50.00%
Train: 0 [   0/390 (  0%)]  Loss: 4.722 (4.72)  Time: 0.924s,  138.58/s  (0.924s,  138.58/s)  LR: 1.000e-07  Data: 0.618 (0.618)
Train: 0 [ 100/390 ( 26%)]  Loss: 4.753 (4.72)  Time: 0.314s,  407.40/s  (0.321s,  398.77/s)  LR: 1.000e-07  Data: 0.013 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 4.708 (4.72)  Time: 0.325s,  394.26/s  (0.319s,  401.59/s)  LR: 1.000e-07  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 4.692 (4.72)  Time: 0.313s,  409.58/s  (0.318s,  403.05/s)  LR: 1.000e-07  Data: 0.012 (0.015)
Train: 0 [ 389/390 (100%)]  Loss: 4.714 (4.72)  Time: 0.302s,  424.23/s  (0.317s,  403.87/s)  LR: 1.000e-07  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.311 (0.311)  Loss:  4.6406 (4.6406)  Acc@1:  4.6875 ( 4.6875)  Acc@5:  7.0312 ( 7.0312)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  4.6406 (4.6969)  Acc@1:  6.2500 ( 1.6700)  Acc@5: 18.7500 ( 7.7400)
Test: [Whole Val]  Time: 9.671  Loss: 4.6969  Acc@1:  1.6700 Pruned: 55.18% 
Test (EMA): [   0/78]  Time: 0.399 (0.399)  Loss:  4.6406 (4.6406)  Acc@1:  4.6875 ( 4.6875)  Acc@5:  7.0312 ( 7.0312)
Test (EMA): [  78/78]  Time: 0.018 (0.124)  Loss:  4.6406 (4.6969)  Acc@1:  6.2500 ( 1.6700)  Acc@5: 18.7500 ( 7.7400)
Test (EMA): [Whole Val]  Time: 9.782  Loss: 4.6969  Acc@1:  1.6700 Pruned: 55.18% 
Train: 1 [   0/390 (  0%)]  Loss: 4.713 (4.71)  Time: 0.771s,  165.99/s  (0.771s,  165.99/s)  LR: 1.001e-04  Data: 0.470 (0.470)
Train: 1 [ 100/390 ( 26%)]  Loss: 4.593 (4.62)  Time: 0.317s,  404.32/s  (0.320s,  399.86/s)  LR: 1.001e-04  Data: 0.012 (0.017)
Train: 1 [ 200/390 ( 51%)]  Loss: 4.597 (4.61)  Time: 0.315s,  406.41/s  (0.318s,  403.11/s)  LR: 1.001e-04  Data: 0.012 (0.015)
Train: 1 [ 300/390 ( 77%)]  Loss: 4.606 (4.60)  Time: 0.318s,  402.22/s  (0.317s,  404.07/s)  LR: 1.001e-04  Data: 0.014 (0.014)
Train: 1 [ 389/390 (100%)]  Loss: 4.605 (4.60)  Time: 0.301s,  424.81/s  (0.316s,  404.57/s)  LR: 1.001e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.344 (0.344)  Loss:  4.5625 (4.5625)  Acc@1:  2.3438 ( 2.3438)  Acc@5:  7.8125 ( 7.8125)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  4.5391 (4.5550)  Acc@1:  0.0000 ( 3.6400)  Acc@5:  6.2500 (11.9900)
Test: [Whole Val]  Time: 9.694  Loss: 4.5550  Acc@1:  3.6400 Pruned: 55.18% 
Test (EMA): [   0/78]  Time: 0.323 (0.323)  Loss:  4.5625 (4.5625)  Acc@1:  1.5625 ( 1.5625)  Acc@5:  8.5938 ( 8.5938)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  4.5469 (4.5549)  Acc@1:  0.0000 ( 3.8600)  Acc@5:  6.2500 (12.8100)
Test (EMA): [Whole Val]  Time: 9.699  Loss: 4.5549  Acc@1:  3.8600 Pruned: 55.18% 
Train: 2 [   0/390 (  0%)]  Loss: 4.597 (4.60)  Time: 0.759s,  168.56/s  (0.759s,  168.56/s)  LR: 2.001e-04  Data: 0.457 (0.457)
Train: 2 [ 100/390 ( 26%)]  Loss: 4.596 (4.59)  Time: 0.316s,  404.49/s  (0.320s,  399.48/s)  LR: 2.001e-04  Data: 0.013 (0.017)
Train: 2 [ 200/390 ( 51%)]  Loss: 4.570 (4.59)  Time: 0.315s,  405.94/s  (0.318s,  402.57/s)  LR: 2.001e-04  Data: 0.011 (0.015)
Train: 2 [ 300/390 ( 77%)]  Loss: 4.523 (4.58)  Time: 0.314s,  407.08/s  (0.317s,  403.97/s)  LR: 2.001e-04  Data: 0.012 (0.014)
Train: 2 [ 389/390 (100%)]  Loss: 4.429 (4.57)  Time: 0.302s,  423.25/s  (0.317s,  404.40/s)  LR: 2.001e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.332 (0.332)  Loss:  4.1953 (4.1953)  Acc@1: 12.5000 (12.5000)  Acc@5: 30.4688 (30.4688)
Test: [  78/78]  Time: 0.020 (0.122)  Loss:  4.2148 (4.2108)  Acc@1: 12.5000 (10.4900)  Acc@5: 25.0000 (29.3800)
Test: [Whole Val]  Time: 9.676  Loss: 4.2108  Acc@1: 10.4900 Pruned: 54.94% 
Test (EMA): [   0/78]  Time: 0.332 (0.332)  Loss:  4.2031 (4.2031)  Acc@1: 12.5000 (12.5000)  Acc@5: 30.4688 (30.4688)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  4.2188 (4.2223)  Acc@1: 12.5000 (10.3400)  Acc@5: 31.2500 (29.4000)
Test (EMA): [Whole Val]  Time: 9.696  Loss: 4.2223  Acc@1: 10.3400 Pruned: 54.96% 
Train: 3 [   0/390 (  0%)]  Loss: 4.466 (4.47)  Time: 0.820s,  156.17/s  (0.820s,  156.17/s)  LR: 3.001e-04  Data: 0.482 (0.482)
Train: 3 [ 100/390 ( 26%)]  Loss: 4.446 (4.42)  Time: 0.315s,  406.66/s  (0.321s,  399.18/s)  LR: 3.001e-04  Data: 0.012 (0.018)
Train: 3 [ 200/390 ( 51%)]  Loss: 3.976 (4.34)  Time: 0.317s,  404.35/s  (0.318s,  402.87/s)  LR: 3.001e-04  Data: 0.012 (0.015)
Train: 3 [ 300/390 ( 77%)]  Loss: 4.338 (4.25)  Time: 0.317s,  403.58/s  (0.317s,  403.48/s)  LR: 3.001e-04  Data: 0.012 (0.014)
Train: 3 [ 389/390 (100%)]  Loss: 4.027 (4.19)  Time: 0.303s,  422.17/s  (0.317s,  404.15/s)  LR: 3.001e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.324 (0.324)  Loss:  2.2715 (2.2715)  Acc@1: 53.9062 (53.9062)  Acc@5: 82.0312 (82.0312)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  2.0156 (2.3425)  Acc@1: 56.2500 (51.2900)  Acc@5: 93.7500 (80.8700)
Test: [Whole Val]  Time: 9.671  Loss: 2.3425  Acc@1: 51.2900 Pruned: 53.46% 
Test (EMA): [   0/78]  Time: 0.410 (0.410)  Loss:  2.2168 (2.2168)  Acc@1: 57.0312 (57.0312)  Acc@5: 82.8125 (82.8125)
Test (EMA): [  78/78]  Time: 0.017 (0.124)  Loss:  2.0508 (2.2986)  Acc@1: 50.0000 (52.3400)  Acc@5: 93.7500 (81.7200)
Test (EMA): [Whole Val]  Time: 9.767  Loss: 2.2986  Acc@1: 52.3400 Pruned: 53.48% 
Train: 4 [   0/390 (  0%)]  Loss: 3.562 (3.56)  Time: 0.775s,  165.07/s  (0.775s,  165.07/s)  LR: 4.001e-04  Data: 0.471 (0.471)
Train: 4 [ 100/390 ( 26%)]  Loss: 4.150 (3.93)  Time: 0.316s,  405.63/s  (0.320s,  400.15/s)  LR: 4.001e-04  Data: 0.011 (0.017)
Train: 4 [ 200/390 ( 51%)]  Loss: 3.887 (3.89)  Time: 0.314s,  408.25/s  (0.318s,  402.82/s)  LR: 4.001e-04  Data: 0.012 (0.015)
Train: 4 [ 300/390 ( 77%)]  Loss: 3.744 (3.86)  Time: 0.313s,  408.94/s  (0.317s,  403.89/s)  LR: 4.001e-04  Data: 0.011 (0.014)
Train: 4 [ 389/390 (100%)]  Loss: 3.821 (3.84)  Time: 0.303s,  422.95/s  (0.317s,  404.15/s)  LR: 4.001e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.383 (0.383)  Loss:  1.7227 (1.7227)  Acc@1: 61.7188 (61.7188)  Acc@5: 86.7188 (86.7188)
Test: [  78/78]  Time: 0.018 (0.124)  Loss:  1.5361 (1.8557)  Acc@1: 56.2500 (58.1400)  Acc@5: 87.5000 (85.5900)
Test: [Whole Val]  Time: 9.758  Loss: 1.8557  Acc@1: 58.1400 Pruned: 52.95% 
Test (EMA): [   0/78]  Time: 0.422 (0.422)  Loss:  1.7285 (1.7285)  Acc@1: 61.7188 (61.7188)  Acc@5: 85.9375 (85.9375)
Test (EMA): [  78/78]  Time: 0.017 (0.124)  Loss:  1.4033 (1.8240)  Acc@1: 75.0000 (58.8700)  Acc@5: 93.7500 (86.9000)
Test (EMA): [Whole Val]  Time: 9.769  Loss: 1.8240  Acc@1: 58.8700 Pruned: 52.97% 
Train: 5 [   0/390 (  0%)]  Loss: 3.245 (3.24)  Time: 0.910s,  140.71/s  (0.910s,  140.71/s)  LR: 5.000e-04  Data: 0.604 (0.604)
Train: 5 [ 100/390 ( 26%)]  Loss: 3.373 (3.75)  Time: 0.314s,  408.24/s  (0.322s,  397.62/s)  LR: 5.000e-04  Data: 0.011 (0.019)
Train: 5 [ 200/390 ( 51%)]  Loss: 4.072 (3.75)  Time: 0.315s,  406.31/s  (0.319s,  401.39/s)  LR: 5.000e-04  Data: 0.013 (0.016)
Train: 5 [ 300/390 ( 77%)]  Loss: 3.501 (3.72)  Time: 0.313s,  408.42/s  (0.318s,  402.87/s)  LR: 5.000e-04  Data: 0.012 (0.015)
Train: 5 [ 389/390 (100%)]  Loss: 3.923 (3.72)  Time: 0.303s,  422.32/s  (0.317s,  403.49/s)  LR: 5.000e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.424 (0.424)  Loss:  1.6904 (1.6904)  Acc@1: 61.7188 (61.7188)  Acc@5: 88.2812 (88.2812)
Test: [  78/78]  Time: 0.018 (0.124)  Loss:  1.6016 (1.8076)  Acc@1: 62.5000 (59.4600)  Acc@5: 81.2500 (87.2500)
Test: [Whole Val]  Time: 9.772  Loss: 1.8076  Acc@1: 59.4600 Pruned: 52.78% 
Test (EMA): [   0/78]  Time: 0.430 (0.430)  Loss:  1.6221 (1.6221)  Acc@1: 61.7188 (61.7188)  Acc@5: 88.2812 (88.2812)
Test (EMA): [  78/78]  Time: 0.018 (0.124)  Loss:  1.3770 (1.6937)  Acc@1: 68.7500 (61.7900)  Acc@5: 93.7500 (88.7100)
Test (EMA): [Whole Val]  Time: 9.766  Loss: 1.6937  Acc@1: 61.7900 Pruned: 52.79% 
Train: 6 [   0/390 (  0%)]  Loss: 3.942 (3.94)  Time: 0.912s,  140.40/s  (0.912s,  140.40/s)  LR: 6.000e-04  Data: 0.601 (0.601)
Train: 6 [ 100/390 ( 26%)]  Loss: 3.911 (3.70)  Time: 0.313s,  409.34/s  (0.322s,  397.99/s)  LR: 6.000e-04  Data: 0.012 (0.019)
Train: 6 [ 200/390 ( 51%)]  Loss: 4.038 (3.68)  Time: 0.314s,  407.96/s  (0.319s,  401.58/s)  LR: 6.000e-04  Data: 0.012 (0.016)
Train: 6 [ 300/390 ( 77%)]  Loss: 4.107 (3.69)  Time: 0.314s,  407.47/s  (0.318s,  402.82/s)  LR: 6.000e-04  Data: 0.012 (0.015)
Train: 6 [ 389/390 (100%)]  Loss: 2.977 (3.69)  Time: 0.301s,  425.09/s  (0.318s,  403.01/s)  LR: 6.000e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.326 (0.326)  Loss:  1.6094 (1.6094)  Acc@1: 60.9375 (60.9375)  Acc@5: 88.2812 (88.2812)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  1.2891 (1.7100)  Acc@1: 68.7500 (59.7300)  Acc@5: 93.7500 (88.0500)
Test: [Whole Val]  Time: 9.738  Loss: 1.7100  Acc@1: 59.7300 Pruned: 52.62% 
Test (EMA): [   0/78]  Time: 0.338 (0.338)  Loss:  1.5771 (1.5771)  Acc@1: 64.0625 (64.0625)  Acc@5: 87.5000 (87.5000)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  1.1250 (1.6297)  Acc@1: 81.2500 (62.4400)  Acc@5: 100.0000 (89.0000)
Test (EMA): [Whole Val]  Time: 9.692  Loss: 1.6297  Acc@1: 62.4400 Pruned: 52.61% 
Train: 7 [   0/390 (  0%)]  Loss: 4.095 (4.10)  Time: 0.830s,  154.26/s  (0.830s,  154.26/s)  LR: 7.000e-04  Data: 0.521 (0.521)
Train: 7 [ 100/390 ( 26%)]  Loss: 3.643 (3.70)  Time: 0.317s,  404.23/s  (0.321s,  398.17/s)  LR: 7.000e-04  Data: 0.013 (0.018)
Train: 7 [ 200/390 ( 51%)]  Loss: 3.518 (3.68)  Time: 0.315s,  406.92/s  (0.319s,  401.37/s)  LR: 7.000e-04  Data: 0.013 (0.016)
Train: 7 [ 300/390 ( 77%)]  Loss: 2.988 (3.66)  Time: 0.313s,  408.41/s  (0.317s,  403.24/s)  LR: 7.000e-04  Data: 0.011 (0.015)
Train: 7 [ 389/390 (100%)]  Loss: 3.800 (3.65)  Time: 0.303s,  422.88/s  (0.317s,  403.81/s)  LR: 7.000e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.422 (0.422)  Loss:  1.5332 (1.5332)  Acc@1: 60.9375 (60.9375)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.018 (0.124)  Loss:  1.2275 (1.5925)  Acc@1: 81.2500 (62.0900)  Acc@5: 93.7500 (88.8900)
Test: [Whole Val]  Time: 9.781  Loss: 1.5925  Acc@1: 62.0900 Pruned: 52.49% 
Test (EMA): [   0/78]  Time: 0.406 (0.406)  Loss:  1.4580 (1.4580)  Acc@1: 65.6250 (65.6250)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  1.1748 (1.5379)  Acc@1: 75.0000 (63.6000)  Acc@5: 93.7500 (89.7800)
Test (EMA): [Whole Val]  Time: 9.741  Loss: 1.5379  Acc@1: 63.6000 Pruned: 52.49% 
Train: 8 [   0/390 (  0%)]  Loss: 3.360 (3.36)  Time: 0.764s,  167.50/s  (0.764s,  167.50/s)  LR: 8.000e-04  Data: 0.457 (0.457)
Train: 8 [ 100/390 ( 26%)]  Loss: 3.782 (3.65)  Time: 0.313s,  409.06/s  (0.321s,  399.22/s)  LR: 8.000e-04  Data: 0.012 (0.017)
Train: 8 [ 200/390 ( 51%)]  Loss: 3.964 (3.64)  Time: 0.315s,  405.99/s  (0.318s,  402.35/s)  LR: 8.000e-04  Data: 0.013 (0.015)
Train: 8 [ 300/390 ( 77%)]  Loss: 3.884 (3.65)  Time: 0.318s,  402.98/s  (0.317s,  403.37/s)  LR: 8.000e-04  Data: 0.014 (0.014)
Train: 8 [ 389/390 (100%)]  Loss: 3.886 (3.64)  Time: 0.301s,  424.95/s  (0.317s,  403.97/s)  LR: 8.000e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.360 (0.360)  Loss:  1.5029 (1.5029)  Acc@1: 64.0625 (64.0625)  Acc@5: 89.8438 (89.8438)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  1.1260 (1.5502)  Acc@1: 81.2500 (63.3700)  Acc@5: 93.7500 (89.6000)
Test: [Whole Val]  Time: 9.676  Loss: 1.5502  Acc@1: 63.3700 Pruned: 52.43% 
Test (EMA): [   0/78]  Time: 0.373 (0.373)  Loss:  1.4814 (1.4814)  Acc@1: 62.5000 (62.5000)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  1.1094 (1.4998)  Acc@1: 75.0000 (64.4500)  Acc@5: 87.5000 (90.1900)
Test (EMA): [Whole Val]  Time: 9.721  Loss: 1.4998  Acc@1: 64.4500 Pruned: 52.43% 
Train: 9 [   0/390 (  0%)]  Loss: 3.784 (3.78)  Time: 0.794s,  161.21/s  (0.794s,  161.21/s)  LR: 9.000e-04  Data: 0.490 (0.490)
Train: 9 [ 100/390 ( 26%)]  Loss: 3.586 (3.64)  Time: 0.314s,  407.76/s  (0.321s,  398.80/s)  LR: 9.000e-04  Data: 0.012 (0.018)
Train: 9 [ 200/390 ( 51%)]  Loss: 3.363 (3.64)  Time: 0.314s,  407.37/s  (0.318s,  402.00/s)  LR: 9.000e-04  Data: 0.012 (0.015)
Train: 9 [ 300/390 ( 77%)]  Loss: 4.005 (3.64)  Time: 0.321s,  398.49/s  (0.317s,  403.17/s)  LR: 9.000e-04  Data: 0.013 (0.015)
Train: 9 [ 389/390 (100%)]  Loss: 4.036 (3.63)  Time: 0.302s,  423.76/s  (0.317s,  403.64/s)  LR: 9.000e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.380 (0.380)  Loss:  1.6064 (1.6064)  Acc@1: 61.7188 (61.7188)  Acc@5: 89.0625 (89.0625)
Test: [  78/78]  Time: 0.018 (0.124)  Loss:  1.3271 (1.6408)  Acc@1: 81.2500 (61.7400)  Acc@5: 93.7500 (88.7300)
Test: [Whole Val]  Time: 9.757  Loss: 1.6408  Acc@1: 61.7400 Pruned: 52.38% 
Test (EMA): [   0/78]  Time: 0.412 (0.412)  Loss:  1.4990 (1.4990)  Acc@1: 62.5000 (62.5000)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.017 (0.124)  Loss:  1.1895 (1.5283)  Acc@1: 81.2500 (63.8200)  Acc@5: 93.7500 (89.9900)
Test (EMA): [Whole Val]  Time: 9.757  Loss: 1.5283  Acc@1: 63.8200 Pruned: 52.39% 
Train: 10 [   0/390 (  0%)]  Loss: 3.894 (3.89)  Time: 0.840s,  152.30/s  (0.840s,  152.30/s)  LR: 9.904e-04  Data: 0.538 (0.538)
Train: 10 [ 100/390 ( 26%)]  Loss: 2.914 (3.62)  Time: 0.320s,  400.47/s  (0.323s,  396.81/s)  LR: 9.904e-04  Data: 0.013 (0.018)
Train: 10 [ 200/390 ( 51%)]  Loss: 3.868 (3.56)  Time: 0.313s,  408.84/s  (0.319s,  400.93/s)  LR: 9.904e-04  Data: 0.012 (0.016)
Train: 10 [ 300/390 ( 77%)]  Loss: 3.197 (3.58)  Time: 0.317s,  403.76/s  (0.318s,  402.30/s)  LR: 9.904e-04  Data: 0.013 (0.015)
Train: 10 [ 389/390 (100%)]  Loss: 2.985 (3.59)  Time: 0.302s,  423.93/s  (0.317s,  403.22/s)  LR: 9.904e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.388 (0.388)  Loss:  1.5049 (1.5049)  Acc@1: 60.9375 (60.9375)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.025 (0.123)  Loss:  1.1221 (1.4891)  Acc@1: 68.7500 (63.9500)  Acc@5: 93.7500 (90.1900)
Test: [Whole Val]  Time: 9.720  Loss: 1.4891  Acc@1: 63.9500 Pruned: 52.32% 
Test (EMA): [   0/78]  Time: 0.422 (0.422)  Loss:  1.4453 (1.4453)  Acc@1: 61.7188 (61.7188)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  1.0801 (1.4584)  Acc@1: 75.0000 (65.4000)  Acc@5: 93.7500 (90.7400)
Test (EMA): [Whole Val]  Time: 9.745  Loss: 1.4584  Acc@1: 65.4000 Pruned: 52.33% 
Train: 11 [   0/390 (  0%)]  Loss: 3.743 (3.74)  Time: 0.756s,  169.22/s  (0.756s,  169.22/s)  LR: 9.884e-04  Data: 0.443 (0.443)
Train: 11 [ 100/390 ( 26%)]  Loss: 3.776 (3.58)  Time: 0.315s,  406.78/s  (0.320s,  399.93/s)  LR: 9.884e-04  Data: 0.012 (0.017)
Train: 11 [ 200/390 ( 51%)]  Loss: 3.711 (3.58)  Time: 0.312s,  409.72/s  (0.317s,  403.26/s)  LR: 9.884e-04  Data: 0.011 (0.015)
Train: 11 [ 300/390 ( 77%)]  Loss: 3.827 (3.56)  Time: 0.313s,  408.65/s  (0.317s,  404.16/s)  LR: 9.884e-04  Data: 0.011 (0.014)
Train: 11 [ 389/390 (100%)]  Loss: 3.762 (3.56)  Time: 0.301s,  425.33/s  (0.316s,  404.73/s)  LR: 9.884e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.378 (0.378)  Loss:  1.4326 (1.4326)  Acc@1: 61.7188 (61.7188)  Acc@5: 89.8438 (89.8438)
Test: [  78/78]  Time: 0.017 (0.123)  Loss:  1.1523 (1.4681)  Acc@1: 75.0000 (64.2400)  Acc@5: 87.5000 (89.9600)
Test: [Whole Val]  Time: 9.716  Loss: 1.4681  Acc@1: 64.2400 Pruned: 52.25% 
Test (EMA): [   0/78]  Time: 0.327 (0.327)  Loss:  1.3887 (1.3887)  Acc@1: 65.6250 (65.6250)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  1.0342 (1.4233)  Acc@1: 81.2500 (66.9100)  Acc@5: 93.7500 (91.2900)
Test (EMA): [Whole Val]  Time: 9.691  Loss: 1.4233  Acc@1: 66.9100 Pruned: 52.25% 
Train: 12 [   0/390 (  0%)]  Loss: 3.087 (3.09)  Time: 0.819s,  156.32/s  (0.819s,  156.32/s)  LR: 9.862e-04  Data: 0.505 (0.505)
Train: 12 [ 100/390 ( 26%)]  Loss: 3.633 (3.56)  Time: 0.316s,  405.13/s  (0.321s,  399.08/s)  LR: 9.862e-04  Data: 0.012 (0.018)
Train: 12 [ 200/390 ( 51%)]  Loss: 3.663 (3.52)  Time: 0.315s,  405.96/s  (0.318s,  402.55/s)  LR: 9.862e-04  Data: 0.013 (0.015)
Train: 12 [ 300/390 ( 77%)]  Loss: 3.806 (3.54)  Time: 0.319s,  400.67/s  (0.317s,  403.73/s)  LR: 9.862e-04  Data: 0.016 (0.014)
Train: 12 [ 389/390 (100%)]  Loss: 3.240 (3.54)  Time: 0.302s,  424.17/s  (0.316s,  404.71/s)  LR: 9.862e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.361 (0.361)  Loss:  1.4043 (1.4043)  Acc@1: 64.8438 (64.8438)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  1.1748 (1.4859)  Acc@1: 75.0000 (64.4400)  Acc@5: 87.5000 (90.2000)
Test: [Whole Val]  Time: 9.685  Loss: 1.4859  Acc@1: 64.4400 Pruned: 52.20% 
Test (EMA): [   0/78]  Time: 0.345 (0.345)  Loss:  1.3711 (1.3711)  Acc@1: 67.1875 (67.1875)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  1.0068 (1.4104)  Acc@1: 81.2500 (66.1300)  Acc@5: 93.7500 (91.0900)
Test (EMA): [Whole Val]  Time: 9.686  Loss: 1.4104  Acc@1: 66.1300 Pruned: 52.20% 
Train: 13 [   0/390 (  0%)]  Loss: 4.008 (4.01)  Time: 0.821s,  155.96/s  (0.821s,  155.96/s)  LR: 9.838e-04  Data: 0.515 (0.515)
Train: 13 [ 100/390 ( 26%)]  Loss: 3.965 (3.58)  Time: 0.318s,  403.11/s  (0.321s,  398.67/s)  LR: 9.838e-04  Data: 0.012 (0.018)
Train: 13 [ 200/390 ( 51%)]  Loss: 3.563 (3.58)  Time: 0.316s,  404.91/s  (0.319s,  401.16/s)  LR: 9.838e-04  Data: 0.013 (0.015)
Train: 13 [ 300/390 ( 77%)]  Loss: 3.440 (3.55)  Time: 0.315s,  406.01/s  (0.318s,  401.92/s)  LR: 9.838e-04  Data: 0.013 (0.015)
Train: 13 [ 389/390 (100%)]  Loss: 4.030 (3.54)  Time: 0.304s,  421.70/s  (0.318s,  402.54/s)  LR: 9.838e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.348 (0.348)  Loss:  1.4121 (1.4121)  Acc@1: 63.2812 (63.2812)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.018 (0.124)  Loss:  1.0381 (1.4079)  Acc@1: 75.0000 (65.9300)  Acc@5: 93.7500 (91.0600)
Test: [Whole Val]  Time: 9.758  Loss: 1.4079  Acc@1: 65.9300 Pruned: 52.14% 
Test (EMA): [   0/78]  Time: 0.432 (0.432)  Loss:  1.3750 (1.3750)  Acc@1: 64.8438 (64.8438)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.018 (0.124)  Loss:  1.0391 (1.3582)  Acc@1: 81.2500 (67.5000)  Acc@5: 87.5000 (91.4300)
Test (EMA): [Whole Val]  Time: 9.825  Loss: 1.3582  Acc@1: 67.5000 Pruned: 52.14% 
Train: 14 [   0/390 (  0%)]  Loss: 3.723 (3.72)  Time: 0.788s,  162.40/s  (0.788s,  162.40/s)  LR: 9.812e-04  Data: 0.488 (0.488)
Train: 14 [ 100/390 ( 26%)]  Loss: 3.220 (3.49)  Time: 0.313s,  409.52/s  (0.321s,  399.07/s)  LR: 9.812e-04  Data: 0.012 (0.018)
Train: 14 [ 200/390 ( 51%)]  Loss: 2.792 (3.48)  Time: 0.317s,  403.81/s  (0.319s,  401.24/s)  LR: 9.812e-04  Data: 0.015 (0.016)
Train: 14 [ 300/390 ( 77%)]  Loss: 3.458 (3.48)  Time: 0.312s,  409.91/s  (0.318s,  402.68/s)  LR: 9.812e-04  Data: 0.012 (0.015)
Train: 14 [ 389/390 (100%)]  Loss: 3.914 (3.49)  Time: 0.307s,  416.45/s  (0.317s,  403.40/s)  LR: 9.812e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.427 (0.427)  Loss:  1.4648 (1.4648)  Acc@1: 62.5000 (62.5000)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  1.2764 (1.5209)  Acc@1: 62.5000 (65.6200)  Acc@5: 100.0000 (89.8100)
Test: [Whole Val]  Time: 9.755  Loss: 1.5209  Acc@1: 65.6200 Pruned: 52.11% 
Test (EMA): [   0/78]  Time: 0.399 (0.399)  Loss:  1.3359 (1.3359)  Acc@1: 64.8438 (64.8438)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  0.9697 (1.3575)  Acc@1: 87.5000 (67.7600)  Acc@5: 93.7500 (91.4700)
Test (EMA): [Whole Val]  Time: 9.715  Loss: 1.3575  Acc@1: 67.7600 Pruned: 52.10% 
Train: 15 [   0/390 (  0%)]  Loss: 3.519 (3.52)  Time: 0.761s,  168.30/s  (0.761s,  168.30/s)  LR: 9.785e-04  Data: 0.456 (0.456)
Train: 15 [ 100/390 ( 26%)]  Loss: 3.219 (3.50)  Time: 0.317s,  404.31/s  (0.321s,  399.00/s)  LR: 9.785e-04  Data: 0.012 (0.017)
Train: 15 [ 200/390 ( 51%)]  Loss: 3.962 (3.51)  Time: 0.315s,  406.76/s  (0.318s,  402.28/s)  LR: 9.785e-04  Data: 0.012 (0.015)
Train: 15 [ 300/390 ( 77%)]  Loss: 3.917 (3.50)  Time: 0.317s,  403.33/s  (0.317s,  403.40/s)  LR: 9.785e-04  Data: 0.014 (0.014)
Train: 15 [ 389/390 (100%)]  Loss: 3.625 (3.51)  Time: 0.302s,  423.32/s  (0.317s,  404.32/s)  LR: 9.785e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.302 (0.302)  Loss:  1.3281 (1.3281)  Acc@1: 67.1875 (67.1875)  Acc@5: 89.8438 (89.8438)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.9863 (1.3455)  Acc@1: 68.7500 (66.5700)  Acc@5: 87.5000 (90.9900)
Test: [Whole Val]  Time: 9.631  Loss: 1.3455  Acc@1: 66.5700 Pruned: 52.05% 
Test (EMA): [   0/78]  Time: 0.317 (0.317)  Loss:  1.3525 (1.3525)  Acc@1: 67.9688 (67.9688)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  1.0859 (1.3579)  Acc@1: 62.5000 (67.4000)  Acc@5: 87.5000 (91.5700)
Test (EMA): [Whole Val]  Time: 9.644  Loss: 1.3579  Acc@1: 67.4000 Pruned: 52.04% 
Train: 16 [   0/390 (  0%)]  Loss: 3.116 (3.12)  Time: 0.882s,  145.19/s  (0.882s,  145.19/s)  LR: 9.755e-04  Data: 0.578 (0.578)
Train: 16 [ 100/390 ( 26%)]  Loss: 3.658 (3.44)  Time: 0.314s,  407.96/s  (0.322s,  397.93/s)  LR: 9.755e-04  Data: 0.011 (0.018)
Train: 16 [ 200/390 ( 51%)]  Loss: 2.890 (3.46)  Time: 0.312s,  409.84/s  (0.319s,  401.83/s)  LR: 9.755e-04  Data: 0.012 (0.015)
Train: 16 [ 300/390 ( 77%)]  Loss: 3.827 (3.48)  Time: 0.314s,  407.76/s  (0.318s,  402.79/s)  LR: 9.755e-04  Data: 0.012 (0.014)
Train: 16 [ 389/390 (100%)]  Loss: 3.966 (3.47)  Time: 0.305s,  419.43/s  (0.317s,  403.53/s)  LR: 9.755e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.350 (0.350)  Loss:  1.4746 (1.4746)  Acc@1: 63.2812 (63.2812)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.017 (0.123)  Loss:  1.1035 (1.4614)  Acc@1: 75.0000 (65.8000)  Acc@5: 93.7500 (90.9900)
Test: [Whole Val]  Time: 9.709  Loss: 1.4614  Acc@1: 65.8000 Pruned: 52.01% 
Test (EMA): [   0/78]  Time: 0.417 (0.417)  Loss:  1.3555 (1.3555)  Acc@1: 64.8438 (64.8438)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.018 (0.124)  Loss:  0.9868 (1.3343)  Acc@1: 75.0000 (67.3200)  Acc@5: 93.7500 (91.7800)
Test (EMA): [Whole Val]  Time: 9.761  Loss: 1.3343  Acc@1: 67.3200 Pruned: 52.01% 
Train: 17 [   0/390 (  0%)]  Loss: 2.688 (2.69)  Time: 0.764s,  167.59/s  (0.764s,  167.59/s)  LR: 9.724e-04  Data: 0.461 (0.461)
Train: 17 [ 100/390 ( 26%)]  Loss: 2.594 (3.49)  Time: 0.315s,  406.75/s  (0.320s,  400.57/s)  LR: 9.724e-04  Data: 0.012 (0.017)
Train: 17 [ 200/390 ( 51%)]  Loss: 3.706 (3.50)  Time: 0.316s,  404.71/s  (0.318s,  403.08/s)  LR: 9.724e-04  Data: 0.013 (0.015)
Train: 17 [ 300/390 ( 77%)]  Loss: 3.433 (3.51)  Time: 0.320s,  399.73/s  (0.317s,  403.86/s)  LR: 9.724e-04  Data: 0.015 (0.014)
Train: 17 [ 389/390 (100%)]  Loss: 3.935 (3.52)  Time: 0.302s,  423.49/s  (0.317s,  404.38/s)  LR: 9.724e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.318 (0.318)  Loss:  1.3867 (1.3867)  Acc@1: 65.6250 (65.6250)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  1.1836 (1.4074)  Acc@1: 81.2500 (67.8400)  Acc@5: 87.5000 (91.9600)
Test: [Whole Val]  Time: 9.633  Loss: 1.4074  Acc@1: 67.8400 Pruned: 51.96% 
Test (EMA): [   0/78]  Time: 0.421 (0.421)  Loss:  1.3799 (1.3799)  Acc@1: 66.4062 (66.4062)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  1.1143 (1.3813)  Acc@1: 75.0000 (68.8900)  Acc@5: 93.7500 (92.2800)
Test (EMA): [Whole Val]  Time: 9.707  Loss: 1.3813  Acc@1: 68.8900 Pruned: 51.97% 
Train: 18 [   0/390 (  0%)]  Loss: 3.037 (3.04)  Time: 0.854s,  149.83/s  (0.854s,  149.83/s)  LR: 9.691e-04  Data: 0.551 (0.551)
Train: 18 [ 100/390 ( 26%)]  Loss: 3.969 (3.48)  Time: 0.313s,  408.41/s  (0.321s,  399.14/s)  LR: 9.691e-04  Data: 0.013 (0.018)
Train: 18 [ 200/390 ( 51%)]  Loss: 3.869 (3.50)  Time: 0.314s,  407.69/s  (0.318s,  402.69/s)  LR: 9.691e-04  Data: 0.012 (0.015)
Train: 18 [ 300/390 ( 77%)]  Loss: 3.446 (3.49)  Time: 0.314s,  407.44/s  (0.317s,  403.81/s)  LR: 9.691e-04  Data: 0.012 (0.014)
Train: 18 [ 389/390 (100%)]  Loss: 3.457 (3.49)  Time: 0.303s,  422.21/s  (0.316s,  404.49/s)  LR: 9.691e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.305 (0.305)  Loss:  1.3916 (1.3916)  Acc@1: 68.7500 (68.7500)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  1.1641 (1.4067)  Acc@1: 68.7500 (66.8200)  Acc@5: 87.5000 (91.2400)
Test: [Whole Val]  Time: 9.611  Loss: 1.4067  Acc@1: 66.8200 Pruned: 51.90% 
Test (EMA): [   0/78]  Time: 0.362 (0.362)  Loss:  1.3242 (1.3242)  Acc@1: 69.5312 (69.5312)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  1.0762 (1.3518)  Acc@1: 75.0000 (68.6600)  Acc@5: 87.5000 (92.4400)
Test (EMA): [Whole Val]  Time: 9.695  Loss: 1.3518  Acc@1: 68.6600 Pruned: 51.90% 
Train: 19 [   0/390 (  0%)]  Loss: 3.498 (3.50)  Time: 0.952s,  134.50/s  (0.952s,  134.50/s)  LR: 9.656e-04  Data: 0.646 (0.646)
Train: 19 [ 100/390 ( 26%)]  Loss: 3.710 (3.45)  Time: 0.316s,  405.21/s  (0.321s,  398.50/s)  LR: 9.656e-04  Data: 0.012 (0.019)
Train: 19 [ 200/390 ( 51%)]  Loss: 3.872 (3.44)  Time: 0.315s,  406.07/s  (0.318s,  402.44/s)  LR: 9.656e-04  Data: 0.011 (0.015)
Train: 19 [ 300/390 ( 77%)]  Loss: 3.798 (3.46)  Time: 0.315s,  405.84/s  (0.317s,  403.72/s)  LR: 9.656e-04  Data: 0.012 (0.014)
Train: 19 [ 389/390 (100%)]  Loss: 4.002 (3.47)  Time: 0.304s,  421.02/s  (0.317s,  403.91/s)  LR: 9.656e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.404 (0.404)  Loss:  1.3096 (1.3096)  Acc@1: 67.9688 (67.9688)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  1.0088 (1.3419)  Acc@1: 75.0000 (68.4000)  Acc@5: 100.0000 (92.0800)
Test: [Whole Val]  Time: 9.743  Loss: 1.3419  Acc@1: 68.4000 Pruned: 51.89% 
Test (EMA): [   0/78]  Time: 0.320 (0.320)  Loss:  1.2900 (1.2900)  Acc@1: 69.5312 (69.5312)  Acc@5: 89.0625 (89.0625)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  1.0186 (1.3267)  Acc@1: 75.0000 (69.0500)  Acc@5: 100.0000 (92.2600)
Test (EMA): [Whole Val]  Time: 9.659  Loss: 1.3267  Acc@1: 69.0500 Pruned: 51.87% 
Train: 20 [   0/390 (  0%)]  Loss: 3.702 (3.70)  Time: 0.744s,  172.06/s  (0.744s,  172.06/s)  LR: 9.619e-04  Data: 0.423 (0.423)
Train: 20 [ 100/390 ( 26%)]  Loss: 3.130 (3.49)  Time: 0.320s,  399.84/s  (0.320s,  400.49/s)  LR: 9.619e-04  Data: 0.012 (0.016)
Train: 20 [ 200/390 ( 51%)]  Loss: 4.031 (3.48)  Time: 0.317s,  403.84/s  (0.317s,  403.18/s)  LR: 9.619e-04  Data: 0.012 (0.014)
Train: 20 [ 300/390 ( 77%)]  Loss: 3.580 (3.49)  Time: 0.316s,  404.67/s  (0.317s,  404.12/s)  LR: 9.619e-04  Data: 0.013 (0.014)
Train: 20 [ 389/390 (100%)]  Loss: 3.859 (3.49)  Time: 0.304s,  420.94/s  (0.316s,  404.65/s)  LR: 9.619e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.379 (0.379)  Loss:  1.3330 (1.3330)  Acc@1: 69.5312 (69.5312)  Acc@5: 88.2812 (88.2812)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  1.1377 (1.3447)  Acc@1: 75.0000 (68.4400)  Acc@5: 81.2500 (91.8100)
Test: [Whole Val]  Time: 9.681  Loss: 1.3447  Acc@1: 68.4400 Pruned: 51.83% 
Test (EMA): [   0/78]  Time: 0.443 (0.443)  Loss:  1.2705 (1.2705)  Acc@1: 67.9688 (67.9688)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.124)  Loss:  1.0078 (1.2818)  Acc@1: 75.0000 (69.2400)  Acc@5: 93.7500 (92.3500)
Test (EMA): [Whole Val]  Time: 9.766  Loss: 1.2818  Acc@1: 69.2400 Pruned: 51.85% 
Train: 21 [   0/390 (  0%)]  Loss: 2.955 (2.96)  Time: 0.763s,  167.85/s  (0.763s,  167.85/s)  LR: 9.581e-04  Data: 0.452 (0.452)
Train: 21 [ 100/390 ( 26%)]  Loss: 3.299 (3.45)  Time: 0.313s,  408.62/s  (0.320s,  399.71/s)  LR: 9.581e-04  Data: 0.012 (0.017)
Train: 21 [ 200/390 ( 51%)]  Loss: 4.080 (3.44)  Time: 0.317s,  403.34/s  (0.318s,  402.72/s)  LR: 9.581e-04  Data: 0.013 (0.015)
Train: 21 [ 300/390 ( 77%)]  Loss: 3.953 (3.46)  Time: 0.316s,  404.59/s  (0.317s,  403.81/s)  LR: 9.581e-04  Data: 0.013 (0.014)
Train: 21 [ 389/390 (100%)]  Loss: 3.206 (3.43)  Time: 0.303s,  423.03/s  (0.317s,  404.29/s)  LR: 9.581e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.333 (0.333)  Loss:  1.2529 (1.2529)  Acc@1: 71.8750 (71.8750)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.0293 (1.3191)  Acc@1: 75.0000 (67.9200)  Acc@5: 87.5000 (91.7300)
Test: [Whole Val]  Time: 9.673  Loss: 1.3191  Acc@1: 67.9200 Pruned: 51.79% 
Test (EMA): [   0/78]  Time: 0.322 (0.322)  Loss:  1.2246 (1.2246)  Acc@1: 71.8750 (71.8750)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.9419 (1.2723)  Acc@1: 75.0000 (69.1400)  Acc@5: 93.7500 (92.5200)
Test (EMA): [Whole Val]  Time: 9.665  Loss: 1.2723  Acc@1: 69.1400 Pruned: 51.80% 
Train: 22 [   0/390 (  0%)]  Loss: 3.662 (3.66)  Time: 0.845s,  151.53/s  (0.845s,  151.53/s)  LR: 9.541e-04  Data: 0.537 (0.537)
Train: 22 [ 100/390 ( 26%)]  Loss: 2.754 (3.40)  Time: 0.322s,  397.76/s  (0.323s,  396.70/s)  LR: 9.541e-04  Data: 0.013 (0.019)
Train: 22 [ 200/390 ( 51%)]  Loss: 3.726 (3.42)  Time: 0.315s,  406.58/s  (0.319s,  401.09/s)  LR: 9.541e-04  Data: 0.013 (0.016)
Train: 22 [ 300/390 ( 77%)]  Loss: 2.780 (3.45)  Time: 0.315s,  406.12/s  (0.318s,  402.74/s)  LR: 9.541e-04  Data: 0.013 (0.015)
Train: 22 [ 389/390 (100%)]  Loss: 3.650 (3.44)  Time: 0.303s,  422.30/s  (0.317s,  403.54/s)  LR: 9.541e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.392 (0.392)  Loss:  1.2842 (1.2842)  Acc@1: 70.3125 (70.3125)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  1.1338 (1.3113)  Acc@1: 75.0000 (68.2400)  Acc@5: 93.7500 (92.0400)
Test: [Whole Val]  Time: 9.701  Loss: 1.3113  Acc@1: 68.2400 Pruned: 51.75% 
Test (EMA): [   0/78]  Time: 0.385 (0.385)  Loss:  1.2383 (1.2383)  Acc@1: 71.0938 (71.0938)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  1.0781 (1.2679)  Acc@1: 75.0000 (70.1000)  Acc@5: 81.2500 (92.7700)
Test (EMA): [Whole Val]  Time: 9.708  Loss: 1.2679  Acc@1: 70.1000 Pruned: 51.76% 
Train: 23 [   0/390 (  0%)]  Loss: 3.832 (3.83)  Time: 0.876s,  146.11/s  (0.876s,  146.11/s)  LR: 9.499e-04  Data: 0.574 (0.574)
Train: 23 [ 100/390 ( 26%)]  Loss: 2.713 (3.47)  Time: 0.316s,  405.30/s  (0.322s,  397.62/s)  LR: 9.499e-04  Data: 0.011 (0.018)
Train: 23 [ 200/390 ( 51%)]  Loss: 3.348 (3.44)  Time: 0.317s,  403.42/s  (0.318s,  401.97/s)  LR: 9.499e-04  Data: 0.013 (0.015)
Train: 23 [ 300/390 ( 77%)]  Loss: 3.539 (3.45)  Time: 0.316s,  404.55/s  (0.317s,  403.20/s)  LR: 9.499e-04  Data: 0.012 (0.014)
Train: 23 [ 389/390 (100%)]  Loss: 3.613 (3.45)  Time: 0.304s,  421.54/s  (0.317s,  403.54/s)  LR: 9.499e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.318 (0.318)  Loss:  1.3252 (1.3252)  Acc@1: 67.9688 (67.9688)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  1.0576 (1.3077)  Acc@1: 75.0000 (68.7200)  Acc@5: 93.7500 (92.3800)
Test: [Whole Val]  Time: 9.640  Loss: 1.3077  Acc@1: 68.7200 Pruned: 51.75% 
Test (EMA): [   0/78]  Time: 0.346 (0.346)  Loss:  1.2783 (1.2783)  Acc@1: 68.7500 (68.7500)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  1.0303 (1.2744)  Acc@1: 75.0000 (69.4000)  Acc@5: 93.7500 (92.8700)
Test (EMA): [Whole Val]  Time: 9.670  Loss: 1.2744  Acc@1: 69.4000 Pruned: 51.74% 
Train: 24 [   0/390 (  0%)]  Loss: 3.621 (3.62)  Time: 0.915s,  139.86/s  (0.915s,  139.86/s)  LR: 9.455e-04  Data: 0.611 (0.611)
Train: 24 [ 100/390 ( 26%)]  Loss: 2.555 (3.41)  Time: 0.315s,  406.61/s  (0.321s,  399.00/s)  LR: 9.455e-04  Data: 0.012 (0.018)
Train: 24 [ 200/390 ( 51%)]  Loss: 3.856 (3.47)  Time: 0.314s,  407.49/s  (0.318s,  402.44/s)  LR: 9.455e-04  Data: 0.011 (0.015)
Train: 24 [ 300/390 ( 77%)]  Loss: 3.561 (3.45)  Time: 0.315s,  405.98/s  (0.317s,  403.38/s)  LR: 9.455e-04  Data: 0.013 (0.014)
Train: 24 [ 389/390 (100%)]  Loss: 3.985 (3.45)  Time: 0.303s,  423.00/s  (0.317s,  403.96/s)  LR: 9.455e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.384 (0.384)  Loss:  1.3008 (1.3008)  Acc@1: 67.1875 (67.1875)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.123)  Loss:  0.9609 (1.3136)  Acc@1: 81.2500 (68.1300)  Acc@5: 93.7500 (91.7200)
Test: [Whole Val]  Time: 9.705  Loss: 1.3136  Acc@1: 68.1300 Pruned: 51.70% 
Test (EMA): [   0/78]  Time: 0.434 (0.434)  Loss:  1.2725 (1.2725)  Acc@1: 66.4062 (66.4062)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.124)  Loss:  0.9165 (1.2565)  Acc@1: 75.0000 (70.0800)  Acc@5: 100.0000 (92.7900)
Test (EMA): [Whole Val]  Time: 9.765  Loss: 1.2565  Acc@1: 70.0800 Pruned: 51.71% 
Train: 25 [   0/390 (  0%)]  Loss: 3.315 (3.32)  Time: 0.902s,  141.89/s  (0.902s,  141.89/s)  LR: 9.410e-04  Data: 0.579 (0.579)
Train: 25 [ 100/390 ( 26%)]  Loss: 3.099 (3.38)  Time: 0.317s,  403.54/s  (0.322s,  397.41/s)  LR: 9.410e-04  Data: 0.013 (0.018)
Train: 25 [ 200/390 ( 51%)]  Loss: 3.222 (3.39)  Time: 0.316s,  405.34/s  (0.319s,  401.80/s)  LR: 9.410e-04  Data: 0.013 (0.015)
Train: 25 [ 300/390 ( 77%)]  Loss: 3.503 (3.41)  Time: 0.319s,  401.52/s  (0.318s,  403.09/s)  LR: 9.410e-04  Data: 0.015 (0.014)
Train: 25 [ 389/390 (100%)]  Loss: 3.694 (3.44)  Time: 0.305s,  419.53/s  (0.317s,  403.74/s)  LR: 9.410e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.333 (0.333)  Loss:  1.2734 (1.2734)  Acc@1: 69.5312 (69.5312)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  1.2305 (1.3157)  Acc@1: 62.5000 (69.8000)  Acc@5: 81.2500 (92.5200)
Test: [Whole Val]  Time: 9.691  Loss: 1.3157  Acc@1: 69.8000 Pruned: 51.67% 
Test (EMA): [   0/78]  Time: 0.357 (0.357)  Loss:  1.2617 (1.2617)  Acc@1: 69.5312 (69.5312)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  1.1953 (1.2994)  Acc@1: 68.7500 (70.4700)  Acc@5: 87.5000 (92.7100)
Test (EMA): [Whole Val]  Time: 9.692  Loss: 1.2994  Acc@1: 70.4700 Pruned: 51.66% 
Train: 26 [   0/390 (  0%)]  Loss: 3.649 (3.65)  Time: 0.835s,  153.28/s  (0.835s,  153.28/s)  LR: 9.363e-04  Data: 0.530 (0.530)
Train: 26 [ 100/390 ( 26%)]  Loss: 3.949 (3.48)  Time: 0.314s,  407.97/s  (0.321s,  398.63/s)  LR: 9.363e-04  Data: 0.011 (0.018)
Train: 26 [ 200/390 ( 51%)]  Loss: 3.950 (3.46)  Time: 0.314s,  408.10/s  (0.319s,  401.72/s)  LR: 9.363e-04  Data: 0.012 (0.015)
Train: 26 [ 300/390 ( 77%)]  Loss: 2.654 (3.46)  Time: 0.314s,  407.14/s  (0.318s,  403.00/s)  LR: 9.363e-04  Data: 0.012 (0.014)
Train: 26 [ 389/390 (100%)]  Loss: 3.839 (3.48)  Time: 0.302s,  423.96/s  (0.317s,  403.71/s)  LR: 9.363e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.316 (0.316)  Loss:  1.2695 (1.2695)  Acc@1: 71.8750 (71.8750)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.0332 (1.3140)  Acc@1: 68.7500 (69.4400)  Acc@5: 87.5000 (92.9200)
Test: [Whole Val]  Time: 9.635  Loss: 1.3140  Acc@1: 69.4400 Pruned: 51.62% 
Test (EMA): [   0/78]  Time: 0.316 (0.316)  Loss:  1.2539 (1.2539)  Acc@1: 72.6562 (72.6562)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  1.0098 (1.2814)  Acc@1: 81.2500 (70.3600)  Acc@5: 87.5000 (93.3200)
Test (EMA): [Whole Val]  Time: 9.667  Loss: 1.2814  Acc@1: 70.3600 Pruned: 51.63% 
Train: 27 [   0/390 (  0%)]  Loss: 3.757 (3.76)  Time: 0.904s,  141.64/s  (0.904s,  141.64/s)  LR: 9.314e-04  Data: 0.602 (0.602)
Train: 27 [ 100/390 ( 26%)]  Loss: 2.693 (3.38)  Time: 0.317s,  403.37/s  (0.322s,  397.97/s)  LR: 9.314e-04  Data: 0.013 (0.019)
Train: 27 [ 200/390 ( 51%)]  Loss: 3.671 (3.39)  Time: 0.314s,  408.16/s  (0.319s,  401.65/s)  LR: 9.314e-04  Data: 0.012 (0.016)
Train: 27 [ 300/390 ( 77%)]  Loss: 3.533 (3.38)  Time: 0.315s,  406.57/s  (0.317s,  403.24/s)  LR: 9.314e-04  Data: 0.012 (0.015)
Train: 27 [ 389/390 (100%)]  Loss: 2.852 (3.40)  Time: 0.302s,  424.11/s  (0.317s,  403.63/s)  LR: 9.314e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.427 (0.427)  Loss:  1.3135 (1.3135)  Acc@1: 67.1875 (67.1875)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  1.0938 (1.3125)  Acc@1: 75.0000 (69.3400)  Acc@5: 87.5000 (92.5300)
Test: [Whole Val]  Time: 9.738  Loss: 1.3125  Acc@1: 69.3400 Pruned: 51.60% 
Test (EMA): [   0/78]  Time: 0.318 (0.318)  Loss:  1.2852 (1.2852)  Acc@1: 70.3125 (70.3125)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  1.0791 (1.2836)  Acc@1: 68.7500 (69.9400)  Acc@5: 93.7500 (93.0300)
Test (EMA): [Whole Val]  Time: 9.660  Loss: 1.2836  Acc@1: 69.9400 Pruned: 51.61% 
Train: 28 [   0/390 (  0%)]  Loss: 3.583 (3.58)  Time: 0.753s,  170.00/s  (0.753s,  170.00/s)  LR: 9.263e-04  Data: 0.447 (0.447)
Train: 28 [ 100/390 ( 26%)]  Loss: 3.314 (3.42)  Time: 0.315s,  406.09/s  (0.319s,  400.75/s)  LR: 9.263e-04  Data: 0.012 (0.017)
Train: 28 [ 200/390 ( 51%)]  Loss: 3.099 (3.41)  Time: 0.315s,  406.88/s  (0.318s,  402.95/s)  LR: 9.263e-04  Data: 0.013 (0.015)
Train: 28 [ 300/390 ( 77%)]  Loss: 3.727 (3.42)  Time: 0.315s,  406.12/s  (0.317s,  403.66/s)  LR: 9.263e-04  Data: 0.013 (0.014)
Train: 28 [ 389/390 (100%)]  Loss: 2.700 (3.42)  Time: 0.302s,  423.36/s  (0.317s,  404.13/s)  LR: 9.263e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.362 (0.362)  Loss:  1.3213 (1.3213)  Acc@1: 69.5312 (69.5312)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  1.0166 (1.3321)  Acc@1: 75.0000 (69.1800)  Acc@5: 93.7500 (92.7200)
Test: [Whole Val]  Time: 9.707  Loss: 1.3321  Acc@1: 69.1800 Pruned: 51.52% 
Test (EMA): [   0/78]  Time: 0.317 (0.317)  Loss:  1.2666 (1.2666)  Acc@1: 69.5312 (69.5312)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.9512 (1.2758)  Acc@1: 81.2500 (71.0000)  Acc@5: 87.5000 (93.1300)
Test (EMA): [Whole Val]  Time: 9.661  Loss: 1.2758  Acc@1: 71.0000 Pruned: 51.53% 
Train: 29 [   0/390 (  0%)]  Loss: 2.735 (2.73)  Time: 0.722s,  177.31/s  (0.722s,  177.31/s)  LR: 9.211e-04  Data: 0.411 (0.411)
Train: 29 [ 100/390 ( 26%)]  Loss: 2.867 (3.31)  Time: 0.315s,  405.97/s  (0.320s,  400.40/s)  LR: 9.211e-04  Data: 0.011 (0.017)
Train: 29 [ 200/390 ( 51%)]  Loss: 3.380 (3.34)  Time: 0.314s,  408.08/s  (0.318s,  402.90/s)  LR: 9.211e-04  Data: 0.012 (0.015)
Train: 29 [ 300/390 ( 77%)]  Loss: 2.899 (3.33)  Time: 0.312s,  410.38/s  (0.317s,  403.51/s)  LR: 9.211e-04  Data: 0.012 (0.014)
Train: 29 [ 389/390 (100%)]  Loss: 3.137 (3.37)  Time: 0.302s,  424.07/s  (0.317s,  404.13/s)  LR: 9.211e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.402 (0.402)  Loss:  1.1641 (1.1641)  Acc@1: 72.6562 (72.6562)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.017 (0.123)  Loss:  0.9058 (1.2095)  Acc@1: 75.0000 (70.5200)  Acc@5: 93.7500 (92.8700)
Test: [Whole Val]  Time: 9.734  Loss: 1.2095  Acc@1: 70.5200 Pruned: 51.48% 
Test (EMA): [   0/78]  Time: 0.350 (0.350)  Loss:  1.2266 (1.2266)  Acc@1: 71.8750 (71.8750)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.9556 (1.2486)  Acc@1: 75.0000 (70.6700)  Acc@5: 93.7500 (93.2300)
Test (EMA): [Whole Val]  Time: 9.675  Loss: 1.2486  Acc@1: 70.6700 Pruned: 51.48% 
Train: 30 [   0/390 (  0%)]  Loss: 3.814 (3.81)  Time: 0.855s,  149.71/s  (0.855s,  149.71/s)  LR: 9.157e-04  Data: 0.539 (0.539)
Train: 30 [ 100/390 ( 26%)]  Loss: 3.684 (3.46)  Time: 0.312s,  409.95/s  (0.320s,  399.70/s)  LR: 9.157e-04  Data: 0.011 (0.018)
Train: 30 [ 200/390 ( 51%)]  Loss: 3.919 (3.45)  Time: 0.314s,  407.60/s  (0.318s,  402.70/s)  LR: 9.157e-04  Data: 0.012 (0.015)
Train: 30 [ 300/390 ( 77%)]  Loss: 3.761 (3.46)  Time: 0.314s,  407.85/s  (0.317s,  403.76/s)  LR: 9.157e-04  Data: 0.012 (0.014)
Train: 30 [ 389/390 (100%)]  Loss: 3.620 (3.43)  Time: 0.299s,  427.58/s  (0.316s,  404.58/s)  LR: 9.157e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.313 (0.313)  Loss:  1.2217 (1.2217)  Acc@1: 70.3125 (70.3125)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.121)  Loss:  0.9932 (1.2821)  Acc@1: 81.2500 (69.3800)  Acc@5: 93.7500 (92.6700)
Test: [Whole Val]  Time: 9.589  Loss: 1.2821  Acc@1: 69.3800 Pruned: 51.45% 
Test (EMA): [   0/78]  Time: 0.431 (0.431)  Loss:  1.1611 (1.1611)  Acc@1: 72.6562 (72.6562)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.017 (0.124)  Loss:  0.8955 (1.1985)  Acc@1: 81.2500 (70.8100)  Acc@5: 93.7500 (93.3700)
Test (EMA): [Whole Val]  Time: 9.798  Loss: 1.1985  Acc@1: 70.8100 Pruned: 51.44% 
Train: 31 [   0/390 (  0%)]  Loss: 2.833 (2.83)  Time: 0.829s,  154.38/s  (0.829s,  154.38/s)  LR: 9.102e-04  Data: 0.526 (0.526)
Train: 31 [ 100/390 ( 26%)]  Loss: 2.971 (3.41)  Time: 0.315s,  405.74/s  (0.321s,  398.93/s)  LR: 9.102e-04  Data: 0.012 (0.018)
Train: 31 [ 200/390 ( 51%)]  Loss: 3.564 (3.44)  Time: 0.315s,  406.84/s  (0.318s,  402.23/s)  LR: 9.102e-04  Data: 0.012 (0.015)
Train: 31 [ 300/390 ( 77%)]  Loss: 3.060 (3.42)  Time: 0.314s,  407.38/s  (0.317s,  403.17/s)  LR: 9.102e-04  Data: 0.012 (0.014)
Train: 31 [ 389/390 (100%)]  Loss: 3.768 (3.40)  Time: 0.320s,  399.99/s  (0.317s,  403.40/s)  LR: 9.102e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.445 (0.445)  Loss:  1.1729 (1.1729)  Acc@1: 70.3125 (70.3125)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.018 (0.124)  Loss:  0.7886 (1.2031)  Acc@1: 87.5000 (70.1400)  Acc@5: 100.0000 (92.9800)
Test: [Whole Val]  Time: 9.801  Loss: 1.2031  Acc@1: 70.1400 Pruned: 51.42% 
Test (EMA): [   0/78]  Time: 0.417 (0.417)  Loss:  1.1641 (1.1641)  Acc@1: 72.6562 (72.6562)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.018 (0.124)  Loss:  0.7681 (1.1757)  Acc@1: 75.0000 (70.9200)  Acc@5: 100.0000 (93.3400)
Test (EMA): [Whole Val]  Time: 9.763  Loss: 1.1757  Acc@1: 70.9200 Pruned: 51.42% 
Train: 32 [   0/390 (  0%)]  Loss: 2.536 (2.54)  Time: 0.760s,  168.41/s  (0.760s,  168.41/s)  LR: 9.045e-04  Data: 0.453 (0.453)
Train: 32 [ 100/390 ( 26%)]  Loss: 3.707 (3.45)  Time: 0.322s,  397.08/s  (0.320s,  399.56/s)  LR: 9.045e-04  Data: 0.012 (0.017)
Train: 32 [ 200/390 ( 51%)]  Loss: 3.994 (3.43)  Time: 0.317s,  403.15/s  (0.318s,  402.45/s)  LR: 9.045e-04  Data: 0.013 (0.015)
Train: 32 [ 300/390 ( 77%)]  Loss: 3.013 (3.42)  Time: 0.314s,  407.88/s  (0.317s,  403.68/s)  LR: 9.045e-04  Data: 0.012 (0.014)
Train: 32 [ 389/390 (100%)]  Loss: 3.161 (3.40)  Time: 0.303s,  422.68/s  (0.317s,  403.83/s)  LR: 9.045e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.412 (0.412)  Loss:  1.1895 (1.1895)  Acc@1: 72.6562 (72.6562)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  0.9038 (1.2241)  Acc@1: 81.2500 (70.7300)  Acc@5: 87.5000 (93.0100)
Test: [Whole Val]  Time: 9.720  Loss: 1.2241  Acc@1: 70.7300 Pruned: 51.40% 
Test (EMA): [   0/78]  Time: 0.412 (0.412)  Loss:  1.1611 (1.1611)  Acc@1: 68.7500 (68.7500)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  0.8350 (1.1810)  Acc@1: 75.0000 (71.8200)  Acc@5: 93.7500 (93.4800)
Test (EMA): [Whole Val]  Time: 9.747  Loss: 1.1810  Acc@1: 71.8200 Pruned: 51.40% 
Train: 33 [   0/390 (  0%)]  Loss: 3.726 (3.73)  Time: 0.872s,  146.82/s  (0.872s,  146.82/s)  LR: 8.987e-04  Data: 0.567 (0.567)
Train: 33 [ 100/390 ( 26%)]  Loss: 2.995 (3.30)  Time: 0.315s,  406.54/s  (0.321s,  399.08/s)  LR: 8.987e-04  Data: 0.012 (0.018)
Train: 33 [ 200/390 ( 51%)]  Loss: 3.223 (3.35)  Time: 0.317s,  403.78/s  (0.318s,  402.65/s)  LR: 8.987e-04  Data: 0.014 (0.015)
Train: 33 [ 300/390 ( 77%)]  Loss: 3.537 (3.37)  Time: 0.316s,  405.12/s  (0.317s,  403.61/s)  LR: 8.987e-04  Data: 0.012 (0.014)
Train: 33 [ 389/390 (100%)]  Loss: 3.420 (3.38)  Time: 0.302s,  424.09/s  (0.317s,  404.01/s)  LR: 8.987e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.377 (0.377)  Loss:  1.1758 (1.1758)  Acc@1: 70.3125 (70.3125)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  1.0254 (1.2363)  Acc@1: 75.0000 (70.9900)  Acc@5: 87.5000 (93.1700)
Test: [Whole Val]  Time: 9.701  Loss: 1.2363  Acc@1: 70.9900 Pruned: 51.36% 
Test (EMA): [   0/78]  Time: 0.425 (0.425)  Loss:  1.1865 (1.1865)  Acc@1: 71.0938 (71.0938)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  0.9888 (1.2126)  Acc@1: 75.0000 (71.4900)  Acc@5: 87.5000 (93.5100)
Test (EMA): [Whole Val]  Time: 9.734  Loss: 1.2126  Acc@1: 71.4900 Pruned: 51.37% 
Train: 34 [   0/390 (  0%)]  Loss: 3.603 (3.60)  Time: 0.869s,  147.25/s  (0.869s,  147.25/s)  LR: 8.927e-04  Data: 0.567 (0.567)
Train: 34 [ 100/390 ( 26%)]  Loss: 2.524 (3.26)  Time: 0.314s,  408.16/s  (0.321s,  399.35/s)  LR: 8.927e-04  Data: 0.013 (0.018)
Train: 34 [ 200/390 ( 51%)]  Loss: 3.542 (3.37)  Time: 0.313s,  408.52/s  (0.318s,  402.56/s)  LR: 8.927e-04  Data: 0.012 (0.015)
Train: 34 [ 300/390 ( 77%)]  Loss: 3.824 (3.36)  Time: 0.318s,  402.10/s  (0.317s,  403.63/s)  LR: 8.927e-04  Data: 0.014 (0.014)
Train: 34 [ 389/390 (100%)]  Loss: 3.942 (3.37)  Time: 0.302s,  423.32/s  (0.317s,  404.05/s)  LR: 8.927e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.319 (0.319)  Loss:  1.1982 (1.1982)  Acc@1: 75.0000 (75.0000)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  1.0410 (1.2459)  Acc@1: 75.0000 (70.4100)  Acc@5: 93.7500 (92.9900)
Test: [Whole Val]  Time: 9.627  Loss: 1.2459  Acc@1: 70.4100 Pruned: 51.34% 
Test (EMA): [   0/78]  Time: 0.430 (0.430)  Loss:  1.1797 (1.1797)  Acc@1: 74.2188 (74.2188)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.017 (0.124)  Loss:  1.0039 (1.2171)  Acc@1: 75.0000 (71.6700)  Acc@5: 87.5000 (93.5800)
Test (EMA): [Whole Val]  Time: 9.779  Loss: 1.2171  Acc@1: 71.6700 Pruned: 51.34% 
Train: 35 [   0/390 (  0%)]  Loss: 3.874 (3.87)  Time: 0.882s,  145.15/s  (0.882s,  145.15/s)  LR: 8.865e-04  Data: 0.577 (0.577)
Train: 35 [ 100/390 ( 26%)]  Loss: 3.801 (3.39)  Time: 0.315s,  406.82/s  (0.322s,  398.02/s)  LR: 8.865e-04  Data: 0.012 (0.018)
Train: 35 [ 200/390 ( 51%)]  Loss: 3.611 (3.37)  Time: 0.315s,  406.22/s  (0.318s,  401.90/s)  LR: 8.865e-04  Data: 0.012 (0.015)
Train: 35 [ 300/390 ( 77%)]  Loss: 3.718 (3.37)  Time: 0.318s,  402.49/s  (0.318s,  403.06/s)  LR: 8.865e-04  Data: 0.013 (0.014)
Train: 35 [ 389/390 (100%)]  Loss: 3.563 (3.38)  Time: 0.301s,  424.66/s  (0.317s,  403.81/s)  LR: 8.865e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.409 (0.409)  Loss:  1.2646 (1.2646)  Acc@1: 74.2188 (74.2188)  Acc@5: 89.8438 (89.8438)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  1.0527 (1.3084)  Acc@1: 75.0000 (70.0100)  Acc@5: 87.5000 (93.0000)
Test: [Whole Val]  Time: 9.703  Loss: 1.3084  Acc@1: 70.0100 Pruned: 51.29% 
Test (EMA): [   0/78]  Time: 0.350 (0.350)  Loss:  1.2139 (1.2139)  Acc@1: 75.0000 (75.0000)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  1.0078 (1.2455)  Acc@1: 75.0000 (72.0600)  Acc@5: 93.7500 (93.7000)
Test (EMA): [Whole Val]  Time: 9.682  Loss: 1.2455  Acc@1: 72.0600 Pruned: 51.30% 
Train: 36 [   0/390 (  0%)]  Loss: 3.640 (3.64)  Time: 0.940s,  136.18/s  (0.940s,  136.18/s)  LR: 8.802e-04  Data: 0.622 (0.622)
Train: 36 [ 100/390 ( 26%)]  Loss: 2.728 (3.38)  Time: 0.313s,  408.68/s  (0.323s,  396.10/s)  LR: 8.802e-04  Data: 0.011 (0.019)
Train: 36 [ 200/390 ( 51%)]  Loss: 3.493 (3.38)  Time: 0.317s,  404.29/s  (0.319s,  400.82/s)  LR: 8.802e-04  Data: 0.013 (0.016)
Train: 36 [ 300/390 ( 77%)]  Loss: 3.730 (3.38)  Time: 0.313s,  408.39/s  (0.318s,  402.17/s)  LR: 8.802e-04  Data: 0.012 (0.015)
Train: 36 [ 389/390 (100%)]  Loss: 3.605 (3.38)  Time: 0.303s,  422.36/s  (0.318s,  402.98/s)  LR: 8.802e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.418 (0.418)  Loss:  1.1797 (1.1797)  Acc@1: 72.6562 (72.6562)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  1.0020 (1.2363)  Acc@1: 68.7500 (70.8600)  Acc@5: 93.7500 (92.9300)
Test: [Whole Val]  Time: 9.726  Loss: 1.2363  Acc@1: 70.8600 Pruned: 51.29% 
Test (EMA): [   0/78]  Time: 0.306 (0.306)  Loss:  1.1748 (1.1748)  Acc@1: 72.6562 (72.6562)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.9531 (1.2153)  Acc@1: 75.0000 (71.5900)  Acc@5: 93.7500 (93.4200)
Test (EMA): [Whole Val]  Time: 9.622  Loss: 1.2153  Acc@1: 71.5900 Pruned: 51.30% 
Train: 37 [   0/390 (  0%)]  Loss: 3.714 (3.71)  Time: 0.759s,  168.72/s  (0.759s,  168.72/s)  LR: 8.738e-04  Data: 0.453 (0.453)
Train: 37 [ 100/390 ( 26%)]  Loss: 3.087 (3.40)  Time: 0.314s,  407.96/s  (0.320s,  399.82/s)  LR: 8.738e-04  Data: 0.012 (0.017)
Train: 37 [ 200/390 ( 51%)]  Loss: 2.637 (3.42)  Time: 0.316s,  405.68/s  (0.318s,  402.89/s)  LR: 8.738e-04  Data: 0.014 (0.015)
Train: 37 [ 300/390 ( 77%)]  Loss: 3.078 (3.41)  Time: 0.318s,  402.29/s  (0.317s,  403.84/s)  LR: 8.738e-04  Data: 0.014 (0.014)
Train: 37 [ 389/390 (100%)]  Loss: 3.308 (3.40)  Time: 0.303s,  422.92/s  (0.317s,  404.10/s)  LR: 8.738e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.343 (0.343)  Loss:  1.1934 (1.1934)  Acc@1: 71.8750 (71.8750)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.9038 (1.2414)  Acc@1: 81.2500 (71.0400)  Acc@5: 93.7500 (93.5600)
Test: [Whole Val]  Time: 9.671  Loss: 1.2414  Acc@1: 71.0400 Pruned: 51.25% 
Test (EMA): [   0/78]  Time: 0.315 (0.315)  Loss:  1.1631 (1.1631)  Acc@1: 71.8750 (71.8750)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.8965 (1.2164)  Acc@1: 81.2500 (71.8300)  Acc@5: 100.0000 (93.7900)
Test (EMA): [Whole Val]  Time: 9.653  Loss: 1.2164  Acc@1: 71.8300 Pruned: 51.25% 
Train: 38 [   0/390 (  0%)]  Loss: 3.332 (3.33)  Time: 0.819s,  156.38/s  (0.819s,  156.38/s)  LR: 8.672e-04  Data: 0.512 (0.512)
Train: 38 [ 100/390 ( 26%)]  Loss: 3.838 (3.42)  Time: 0.318s,  402.48/s  (0.321s,  399.09/s)  LR: 8.672e-04  Data: 0.014 (0.018)
Train: 38 [ 200/390 ( 51%)]  Loss: 3.394 (3.41)  Time: 0.313s,  408.31/s  (0.318s,  402.88/s)  LR: 8.672e-04  Data: 0.012 (0.015)
Train: 38 [ 300/390 ( 77%)]  Loss: 3.155 (3.40)  Time: 0.314s,  407.92/s  (0.317s,  404.04/s)  LR: 8.672e-04  Data: 0.012 (0.014)
Train: 38 [ 389/390 (100%)]  Loss: 2.772 (3.38)  Time: 0.302s,  423.67/s  (0.316s,  404.66/s)  LR: 8.672e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.298 (0.298)  Loss:  1.1992 (1.1992)  Acc@1: 70.3125 (70.3125)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.8877 (1.2087)  Acc@1: 75.0000 (71.1200)  Acc@5: 87.5000 (93.0100)
Test: [Whole Val]  Time: 9.630  Loss: 1.2087  Acc@1: 71.1200 Pruned: 51.23% 
Test (EMA): [   0/78]  Time: 0.349 (0.349)  Loss:  1.1602 (1.1602)  Acc@1: 72.6562 (72.6562)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.9048 (1.1778)  Acc@1: 75.0000 (71.8700)  Acc@5: 93.7500 (93.6500)
Test (EMA): [Whole Val]  Time: 9.677  Loss: 1.1778  Acc@1: 71.8700 Pruned: 51.24% 
Train: 39 [   0/390 (  0%)]  Loss: 3.594 (3.59)  Time: 0.857s,  149.27/s  (0.857s,  149.27/s)  LR: 8.604e-04  Data: 0.555 (0.555)
Train: 39 [ 100/390 ( 26%)]  Loss: 3.707 (3.35)  Time: 0.313s,  408.82/s  (0.321s,  399.29/s)  LR: 8.604e-04  Data: 0.013 (0.018)
Train: 39 [ 200/390 ( 51%)]  Loss: 2.648 (3.38)  Time: 0.317s,  404.18/s  (0.319s,  401.68/s)  LR: 8.604e-04  Data: 0.016 (0.015)
Train: 39 [ 300/390 ( 77%)]  Loss: 3.594 (3.36)  Time: 0.315s,  406.82/s  (0.317s,  403.18/s)  LR: 8.604e-04  Data: 0.012 (0.014)
Train: 39 [ 389/390 (100%)]  Loss: 3.892 (3.36)  Time: 0.302s,  423.49/s  (0.317s,  403.92/s)  LR: 8.604e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.384 (0.384)  Loss:  1.1123 (1.1123)  Acc@1: 71.8750 (71.8750)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.026 (0.123)  Loss:  0.8667 (1.1483)  Acc@1: 81.2500 (71.9800)  Acc@5: 93.7500 (93.6700)
Test: [Whole Val]  Time: 9.699  Loss: 1.1483  Acc@1: 71.9800 Pruned: 51.21% 
Test (EMA): [   0/78]  Time: 0.309 (0.309)  Loss:  1.1318 (1.1318)  Acc@1: 72.6562 (72.6562)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.7974 (1.1520)  Acc@1: 75.0000 (72.4200)  Acc@5: 100.0000 (93.8900)
Test (EMA): [Whole Val]  Time: 9.605  Loss: 1.1520  Acc@1: 72.4200 Pruned: 51.20% 
Train: 40 [   0/390 (  0%)]  Loss: 3.271 (3.27)  Time: 0.984s,  130.07/s  (0.984s,  130.07/s)  LR: 8.536e-04  Data: 0.681 (0.681)
Train: 40 [ 100/390 ( 26%)]  Loss: 3.705 (3.37)  Time: 0.314s,  407.02/s  (0.322s,  397.23/s)  LR: 8.536e-04  Data: 0.013 (0.019)
Train: 40 [ 200/390 ( 51%)]  Loss: 3.862 (3.35)  Time: 0.315s,  405.94/s  (0.319s,  401.43/s)  LR: 8.536e-04  Data: 0.013 (0.016)
Train: 40 [ 300/390 ( 77%)]  Loss: 3.362 (3.36)  Time: 0.317s,  403.58/s  (0.318s,  402.69/s)  LR: 8.536e-04  Data: 0.013 (0.015)
Train: 40 [ 389/390 (100%)]  Loss: 3.799 (3.37)  Time: 0.303s,  422.23/s  (0.317s,  403.24/s)  LR: 8.536e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.400 (0.400)  Loss:  1.0928 (1.0928)  Acc@1: 72.6562 (72.6562)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  0.8618 (1.1514)  Acc@1: 81.2500 (71.2200)  Acc@5: 100.0000 (93.6800)
Test: [Whole Val]  Time: 9.735  Loss: 1.1514  Acc@1: 71.2200 Pruned: 51.21% 
Test (EMA): [   0/78]  Time: 0.427 (0.427)  Loss:  1.1396 (1.1396)  Acc@1: 71.8750 (71.8750)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.018 (0.125)  Loss:  0.8862 (1.1668)  Acc@1: 81.2500 (71.6500)  Acc@5: 100.0000 (93.9100)
Test (EMA): [Whole Val]  Time: 9.838  Loss: 1.1668  Acc@1: 71.6500 Pruned: 51.20% 
Train: 41 [   0/390 (  0%)]  Loss: 2.551 (2.55)  Time: 0.832s,  153.90/s  (0.832s,  153.90/s)  LR: 8.466e-04  Data: 0.527 (0.527)
Train: 41 [ 100/390 ( 26%)]  Loss: 3.808 (3.36)  Time: 0.315s,  406.65/s  (0.321s,  398.92/s)  LR: 8.466e-04  Data: 0.013 (0.018)
Train: 41 [ 200/390 ( 51%)]  Loss: 3.385 (3.36)  Time: 0.313s,  408.51/s  (0.318s,  402.01/s)  LR: 8.466e-04  Data: 0.011 (0.015)
Train: 41 [ 300/390 ( 77%)]  Loss: 3.687 (3.37)  Time: 0.314s,  408.08/s  (0.317s,  403.22/s)  LR: 8.466e-04  Data: 0.012 (0.014)
Train: 41 [ 389/390 (100%)]  Loss: 3.737 (3.36)  Time: 0.304s,  421.68/s  (0.317s,  403.89/s)  LR: 8.466e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.422 (0.422)  Loss:  1.1514 (1.1514)  Acc@1: 72.6562 (72.6562)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.123)  Loss:  0.9126 (1.1634)  Acc@1: 81.2500 (71.6600)  Acc@5: 93.7500 (93.8600)
Test: [Whole Val]  Time: 9.730  Loss: 1.1634  Acc@1: 71.6600 Pruned: 51.19% 
Test (EMA): [   0/78]  Time: 0.428 (0.428)  Loss:  1.1299 (1.1299)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.124)  Loss:  0.9067 (1.1658)  Acc@1: 81.2500 (72.3900)  Acc@5: 87.5000 (93.8800)
Test (EMA): [Whole Val]  Time: 9.784  Loss: 1.1658  Acc@1: 72.3900 Pruned: 51.19% 
Train: 42 [   0/390 (  0%)]  Loss: 3.538 (3.54)  Time: 0.800s,  159.99/s  (0.800s,  159.99/s)  LR: 8.394e-04  Data: 0.483 (0.483)
Train: 42 [ 100/390 ( 26%)]  Loss: 3.267 (3.30)  Time: 0.317s,  404.09/s  (0.320s,  399.80/s)  LR: 8.394e-04  Data: 0.012 (0.017)
Train: 42 [ 200/390 ( 51%)]  Loss: 3.785 (3.35)  Time: 0.312s,  409.64/s  (0.318s,  402.93/s)  LR: 8.394e-04  Data: 0.012 (0.015)
Train: 42 [ 300/390 ( 77%)]  Loss: 3.653 (3.34)  Time: 0.316s,  405.50/s  (0.317s,  403.68/s)  LR: 8.394e-04  Data: 0.015 (0.014)
Train: 42 [ 389/390 (100%)]  Loss: 3.697 (3.35)  Time: 0.302s,  423.81/s  (0.317s,  404.07/s)  LR: 8.394e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.309 (0.309)  Loss:  1.1875 (1.1875)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  1.0098 (1.2169)  Acc@1: 68.7500 (71.7000)  Acc@5: 87.5000 (93.9200)
Test: [Whole Val]  Time: 9.622  Loss: 1.2169  Acc@1: 71.7000 Pruned: 51.16% 
Test (EMA): [   0/78]  Time: 0.408 (0.408)  Loss:  1.1514 (1.1514)  Acc@1: 71.8750 (71.8750)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  0.9946 (1.1819)  Acc@1: 68.7500 (72.3100)  Acc@5: 87.5000 (93.7400)
Test (EMA): [Whole Val]  Time: 9.732  Loss: 1.1819  Acc@1: 72.3100 Pruned: 51.16% 
Train: 43 [   0/390 (  0%)]  Loss: 2.985 (2.99)  Time: 0.767s,  166.83/s  (0.767s,  166.83/s)  LR: 8.321e-04  Data: 0.456 (0.456)
Train: 43 [ 100/390 ( 26%)]  Loss: 3.666 (3.34)  Time: 0.313s,  408.65/s  (0.320s,  400.05/s)  LR: 8.321e-04  Data: 0.012 (0.017)
Train: 43 [ 200/390 ( 51%)]  Loss: 3.485 (3.33)  Time: 0.314s,  407.21/s  (0.318s,  402.94/s)  LR: 8.321e-04  Data: 0.013 (0.015)
Train: 43 [ 300/390 ( 77%)]  Loss: 3.689 (3.35)  Time: 0.316s,  405.22/s  (0.317s,  403.81/s)  LR: 8.321e-04  Data: 0.013 (0.014)
Train: 43 [ 389/390 (100%)]  Loss: 3.880 (3.34)  Time: 0.303s,  422.59/s  (0.317s,  404.22/s)  LR: 8.321e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.308 (0.308)  Loss:  1.1768 (1.1768)  Acc@1: 71.8750 (71.8750)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  1.0449 (1.2021)  Acc@1: 75.0000 (71.8200)  Acc@5: 87.5000 (93.5700)
Test: [Whole Val]  Time: 9.608  Loss: 1.2021  Acc@1: 71.8200 Pruned: 51.15% 
Test (EMA): [   0/78]  Time: 0.322 (0.322)  Loss:  1.1465 (1.1465)  Acc@1: 71.8750 (71.8750)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.9673 (1.1818)  Acc@1: 75.0000 (72.6200)  Acc@5: 93.7500 (93.9400)
Test (EMA): [Whole Val]  Time: 9.668  Loss: 1.1818  Acc@1: 72.6200 Pruned: 51.15% 
Train: 44 [   0/390 (  0%)]  Loss: 3.124 (3.12)  Time: 0.859s,  149.06/s  (0.859s,  149.06/s)  LR: 8.247e-04  Data: 0.552 (0.552)
Train: 44 [ 100/390 ( 26%)]  Loss: 3.317 (3.41)  Time: 0.315s,  406.20/s  (0.321s,  398.92/s)  LR: 8.247e-04  Data: 0.012 (0.018)
Train: 44 [ 200/390 ( 51%)]  Loss: 2.471 (3.39)  Time: 0.318s,  402.67/s  (0.318s,  402.35/s)  LR: 8.247e-04  Data: 0.013 (0.015)
Train: 44 [ 300/390 ( 77%)]  Loss: 4.045 (3.40)  Time: 0.315s,  405.80/s  (0.317s,  403.23/s)  LR: 8.247e-04  Data: 0.013 (0.014)
Train: 44 [ 389/390 (100%)]  Loss: 3.956 (3.40)  Time: 0.303s,  422.73/s  (0.317s,  403.85/s)  LR: 8.247e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.347 (0.347)  Loss:  1.2090 (1.2090)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  0.9780 (1.2753)  Acc@1: 81.2500 (71.2500)  Acc@5: 100.0000 (93.3500)
Test: [Whole Val]  Time: 9.703  Loss: 1.2753  Acc@1: 71.2500 Pruned: 51.15% 
Test (EMA): [   0/78]  Time: 0.408 (0.408)  Loss:  1.1865 (1.1865)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  0.9790 (1.2438)  Acc@1: 87.5000 (72.2300)  Acc@5: 93.7500 (93.9200)
Test (EMA): [Whole Val]  Time: 9.725  Loss: 1.2438  Acc@1: 72.2300 Pruned: 51.14% 
Train: 45 [   0/390 (  0%)]  Loss: 3.222 (3.22)  Time: 1.004s,  127.43/s  (1.004s,  127.43/s)  LR: 8.172e-04  Data: 0.703 (0.703)
Train: 45 [ 100/390 ( 26%)]  Loss: 3.946 (3.39)  Time: 0.317s,  403.73/s  (0.322s,  397.86/s)  LR: 8.172e-04  Data: 0.014 (0.019)
Train: 45 [ 200/390 ( 51%)]  Loss: 2.281 (3.37)  Time: 0.313s,  409.24/s  (0.319s,  401.84/s)  LR: 8.172e-04  Data: 0.012 (0.016)
Train: 45 [ 300/390 ( 77%)]  Loss: 3.701 (3.34)  Time: 0.319s,  400.99/s  (0.318s,  403.05/s)  LR: 8.172e-04  Data: 0.016 (0.015)
Train: 45 [ 389/390 (100%)]  Loss: 3.699 (3.34)  Time: 0.304s,  420.75/s  (0.317s,  403.25/s)  LR: 8.172e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.420 (0.420)  Loss:  1.2158 (1.2158)  Acc@1: 73.4375 (73.4375)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.018 (0.124)  Loss:  0.9561 (1.2429)  Acc@1: 75.0000 (72.0100)  Acc@5: 93.7500 (93.8700)
Test: [Whole Val]  Time: 9.762  Loss: 1.2429  Acc@1: 72.0100 Pruned: 51.12% 
Test (EMA): [   0/78]  Time: 0.423 (0.423)  Loss:  1.1797 (1.1797)  Acc@1: 72.6562 (72.6562)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.018 (0.124)  Loss:  0.9033 (1.1867)  Acc@1: 81.2500 (72.3400)  Acc@5: 93.7500 (94.0400)
Test (EMA): [Whole Val]  Time: 9.803  Loss: 1.1867  Acc@1: 72.3400 Pruned: 51.11% 
Train: 46 [   0/390 (  0%)]  Loss: 3.089 (3.09)  Time: 0.794s,  161.12/s  (0.794s,  161.12/s)  LR: 8.096e-04  Data: 0.490 (0.490)
Train: 46 [ 100/390 ( 26%)]  Loss: 3.553 (3.39)  Time: 0.316s,  404.90/s  (0.322s,  397.74/s)  LR: 8.096e-04  Data: 0.014 (0.018)
Train: 46 [ 200/390 ( 51%)]  Loss: 2.797 (3.36)  Time: 0.321s,  398.30/s  (0.319s,  401.17/s)  LR: 8.096e-04  Data: 0.016 (0.015)
Train: 46 [ 300/390 ( 77%)]  Loss: 2.807 (3.34)  Time: 0.315s,  405.88/s  (0.318s,  402.52/s)  LR: 8.096e-04  Data: 0.012 (0.015)
Train: 46 [ 389/390 (100%)]  Loss: 2.839 (3.36)  Time: 0.301s,  424.83/s  (0.318s,  402.95/s)  LR: 8.096e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.394 (0.394)  Loss:  1.1543 (1.1543)  Acc@1: 72.6562 (72.6562)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  0.9839 (1.1744)  Acc@1: 68.7500 (72.0200)  Acc@5: 87.5000 (93.7100)
Test: [Whole Val]  Time: 9.716  Loss: 1.1744  Acc@1: 72.0200 Pruned: 51.10% 
Test (EMA): [   0/78]  Time: 0.314 (0.314)  Loss:  1.1826 (1.1826)  Acc@1: 72.6562 (72.6562)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  1.0068 (1.1932)  Acc@1: 68.7500 (72.3700)  Acc@5: 93.7500 (93.9400)
Test (EMA): [Whole Val]  Time: 9.681  Loss: 1.1932  Acc@1: 72.3700 Pruned: 51.10% 
Train: 47 [   0/390 (  0%)]  Loss: 3.673 (3.67)  Time: 0.737s,  173.67/s  (0.737s,  173.67/s)  LR: 8.018e-04  Data: 0.433 (0.433)
Train: 47 [ 100/390 ( 26%)]  Loss: 2.626 (3.37)  Time: 0.313s,  408.35/s  (0.319s,  400.93/s)  LR: 8.018e-04  Data: 0.012 (0.017)
Train: 47 [ 200/390 ( 51%)]  Loss: 3.550 (3.37)  Time: 0.313s,  408.33/s  (0.318s,  403.04/s)  LR: 8.018e-04  Data: 0.012 (0.015)
Train: 47 [ 300/390 ( 77%)]  Loss: 2.732 (3.37)  Time: 0.317s,  403.66/s  (0.317s,  404.10/s)  LR: 8.018e-04  Data: 0.015 (0.014)
Train: 47 [ 389/390 (100%)]  Loss: 3.107 (3.37)  Time: 0.303s,  423.06/s  (0.316s,  404.51/s)  LR: 8.018e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.305 (0.305)  Loss:  1.1123 (1.1123)  Acc@1: 72.6562 (72.6562)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.9688 (1.1365)  Acc@1: 75.0000 (71.3100)  Acc@5: 100.0000 (93.3700)
Test: [Whole Val]  Time: 9.612  Loss: 1.1365  Acc@1: 71.3100 Pruned: 51.09% 
Test (EMA): [   0/78]  Time: 0.367 (0.367)  Loss:  1.1123 (1.1123)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  0.9243 (1.1405)  Acc@1: 75.0000 (72.6300)  Acc@5: 93.7500 (94.0100)
Test (EMA): [Whole Val]  Time: 9.698  Loss: 1.1405  Acc@1: 72.6300 Pruned: 51.09% 
Train: 48 [   0/390 (  0%)]  Loss: 2.828 (2.83)  Time: 0.815s,  156.97/s  (0.815s,  156.97/s)  LR: 7.939e-04  Data: 0.501 (0.501)
Train: 48 [ 100/390 ( 26%)]  Loss: 2.914 (3.34)  Time: 0.314s,  408.28/s  (0.320s,  400.52/s)  LR: 7.939e-04  Data: 0.012 (0.017)
Train: 48 [ 200/390 ( 51%)]  Loss: 3.347 (3.30)  Time: 0.313s,  408.77/s  (0.317s,  403.44/s)  LR: 7.939e-04  Data: 0.012 (0.015)
Train: 48 [ 300/390 ( 77%)]  Loss: 3.565 (3.29)  Time: 0.315s,  406.14/s  (0.317s,  404.32/s)  LR: 7.939e-04  Data: 0.012 (0.014)
Train: 48 [ 389/390 (100%)]  Loss: 3.719 (3.30)  Time: 0.302s,  424.13/s  (0.316s,  404.65/s)  LR: 7.939e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.383 (0.383)  Loss:  1.1367 (1.1367)  Acc@1: 69.5312 (69.5312)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.017 (0.123)  Loss:  0.8716 (1.1796)  Acc@1: 75.0000 (71.8700)  Acc@5: 93.7500 (93.7400)
Test: [Whole Val]  Time: 9.713  Loss: 1.1796  Acc@1: 71.8700 Pruned: 51.07% 
Test (EMA): [   0/78]  Time: 0.363 (0.363)  Loss:  1.0996 (1.0996)  Acc@1: 74.2188 (74.2188)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.8281 (1.1384)  Acc@1: 87.5000 (72.9000)  Acc@5: 93.7500 (94.2300)
Test (EMA): [Whole Val]  Time: 9.609  Loss: 1.1384  Acc@1: 72.9000 Pruned: 51.07% 
Train: 49 [   0/390 (  0%)]  Loss: 2.904 (2.90)  Time: 0.748s,  171.05/s  (0.748s,  171.05/s)  LR: 7.859e-04  Data: 0.448 (0.448)
Train: 49 [ 100/390 ( 26%)]  Loss: 3.595 (3.32)  Time: 0.317s,  403.84/s  (0.324s,  394.49/s)  LR: 7.859e-04  Data: 0.012 (0.018)
Train: 49 [ 200/390 ( 51%)]  Loss: 3.413 (3.35)  Time: 0.321s,  398.22/s  (0.323s,  396.50/s)  LR: 7.859e-04  Data: 0.014 (0.016)
Train: 49 [ 300/390 ( 77%)]  Loss: 3.921 (3.37)  Time: 0.319s,  401.82/s  (0.322s,  397.73/s)  LR: 7.859e-04  Data: 0.014 (0.015)
Train: 49 [ 389/390 (100%)]  Loss: 3.659 (3.37)  Time: 0.312s,  410.41/s  (0.322s,  398.11/s)  LR: 7.859e-04  Data: 0.000 (0.015)
Test: [   0/78]  Time: 0.408 (0.408)  Loss:  1.0645 (1.0645)  Acc@1: 73.4375 (73.4375)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.018 (0.124)  Loss:  0.8730 (1.1247)  Acc@1: 75.0000 (72.3100)  Acc@5: 93.7500 (93.9200)
Test: [Whole Val]  Time: 9.810  Loss: 1.1247  Acc@1: 72.3100 Pruned: 51.05% 
Test (EMA): [   0/78]  Time: 0.358 (0.358)  Loss:  1.0977 (1.0977)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  0.9165 (1.1289)  Acc@1: 75.0000 (72.9300)  Acc@5: 93.7500 (93.9400)
Test (EMA): [Whole Val]  Time: 9.743  Loss: 1.1289  Acc@1: 72.9300 Pruned: 51.05% 
Train: 50 [   0/390 (  0%)]  Loss: 3.398 (3.40)  Time: 0.853s,  150.09/s  (0.853s,  150.09/s)  LR: 7.778e-04  Data: 0.546 (0.546)
Train: 50 [ 100/390 ( 26%)]  Loss: 3.871 (3.42)  Time: 0.318s,  402.06/s  (0.325s,  393.75/s)  LR: 7.778e-04  Data: 0.013 (0.019)
Train: 50 [ 200/390 ( 51%)]  Loss: 3.266 (3.39)  Time: 0.339s,  377.54/s  (0.322s,  397.57/s)  LR: 7.778e-04  Data: 0.028 (0.017)
Train: 50 [ 300/390 ( 77%)]  Loss: 3.760 (3.37)  Time: 0.317s,  403.70/s  (0.321s,  398.86/s)  LR: 7.778e-04  Data: 0.013 (0.016)
Train: 50 [ 389/390 (100%)]  Loss: 3.788 (3.38)  Time: 0.303s,  423.05/s  (0.320s,  399.38/s)  LR: 7.778e-04  Data: 0.000 (0.015)
Test: [   0/78]  Time: 0.325 (0.325)  Loss:  1.1592 (1.1592)  Acc@1: 71.8750 (71.8750)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.017 (0.123)  Loss:  0.9058 (1.2084)  Acc@1: 81.2500 (72.4900)  Acc@5: 93.7500 (93.7400)
Test: [Whole Val]  Time: 9.712  Loss: 1.2084  Acc@1: 72.4900 Pruned: 51.03% 
Test (EMA): [   0/78]  Time: 0.358 (0.358)  Loss:  1.1338 (1.1338)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  0.8564 (1.1702)  Acc@1: 81.2500 (73.0200)  Acc@5: 87.5000 (94.0400)
Test (EMA): [Whole Val]  Time: 9.708  Loss: 1.1702  Acc@1: 73.0200 Pruned: 51.03% 
Train: 51 [   0/390 (  0%)]  Loss: 3.085 (3.08)  Time: 0.974s,  131.43/s  (0.974s,  131.43/s)  LR: 7.696e-04  Data: 0.671 (0.671)
Train: 51 [ 100/390 ( 26%)]  Loss: 3.019 (3.34)  Time: 0.314s,  407.28/s  (0.323s,  396.49/s)  LR: 7.696e-04  Data: 0.012 (0.019)
Train: 51 [ 200/390 ( 51%)]  Loss: 3.291 (3.36)  Time: 0.314s,  407.63/s  (0.320s,  400.54/s)  LR: 7.696e-04  Data: 0.012 (0.016)
Train: 51 [ 300/390 ( 77%)]  Loss: 2.453 (3.35)  Time: 0.316s,  405.58/s  (0.318s,  401.91/s)  LR: 7.696e-04  Data: 0.012 (0.015)
Train: 51 [ 389/390 (100%)]  Loss: 3.784 (3.35)  Time: 0.303s,  422.53/s  (0.318s,  402.75/s)  LR: 7.696e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.366 (0.366)  Loss:  1.1484 (1.1484)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  0.8921 (1.1592)  Acc@1: 87.5000 (72.1400)  Acc@5: 93.7500 (93.8000)
Test: [Whole Val]  Time: 9.688  Loss: 1.1592  Acc@1: 72.1400 Pruned: 51.04% 
Test (EMA): [   0/78]  Time: 0.312 (0.312)  Loss:  1.1240 (1.1240)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.8159 (1.1345)  Acc@1: 81.2500 (72.8100)  Acc@5: 100.0000 (94.0400)
Test (EMA): [Whole Val]  Time: 9.664  Loss: 1.1345  Acc@1: 72.8100 Pruned: 51.04% 
Train: 52 [   0/390 (  0%)]  Loss: 3.503 (3.50)  Time: 0.875s,  146.35/s  (0.875s,  146.35/s)  LR: 7.613e-04  Data: 0.571 (0.571)
Train: 52 [ 100/390 ( 26%)]  Loss: 3.803 (3.40)  Time: 0.317s,  403.37/s  (0.322s,  397.92/s)  LR: 7.613e-04  Data: 0.013 (0.018)
Train: 52 [ 200/390 ( 51%)]  Loss: 3.718 (3.40)  Time: 0.314s,  408.10/s  (0.319s,  400.97/s)  LR: 7.613e-04  Data: 0.012 (0.015)
Train: 52 [ 300/390 ( 77%)]  Loss: 3.249 (3.37)  Time: 0.317s,  403.68/s  (0.318s,  402.27/s)  LR: 7.613e-04  Data: 0.012 (0.015)
Train: 52 [ 389/390 (100%)]  Loss: 3.677 (3.37)  Time: 0.303s,  422.60/s  (0.318s,  402.87/s)  LR: 7.613e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.378 (0.378)  Loss:  1.0986 (1.0986)  Acc@1: 73.4375 (73.4375)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  0.8696 (1.1434)  Acc@1: 81.2500 (72.3500)  Acc@5: 93.7500 (93.8600)
Test: [Whole Val]  Time: 9.700  Loss: 1.1434  Acc@1: 72.3500 Pruned: 51.03% 
Test (EMA): [   0/78]  Time: 0.420 (0.420)  Loss:  1.0889 (1.0889)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.018 (0.124)  Loss:  0.8955 (1.1209)  Acc@1: 81.2500 (73.1800)  Acc@5: 93.7500 (94.2300)
Test (EMA): [Whole Val]  Time: 9.772  Loss: 1.1209  Acc@1: 73.1800 Pruned: 51.02% 
Train: 53 [   0/390 (  0%)]  Loss: 3.630 (3.63)  Time: 0.781s,  163.80/s  (0.781s,  163.80/s)  LR: 7.529e-04  Data: 0.478 (0.478)
Train: 53 [ 100/390 ( 26%)]  Loss: 3.415 (3.36)  Time: 0.317s,  403.75/s  (0.320s,  399.64/s)  LR: 7.529e-04  Data: 0.012 (0.017)
Train: 53 [ 200/390 ( 51%)]  Loss: 3.240 (3.38)  Time: 0.312s,  409.77/s  (0.318s,  402.71/s)  LR: 7.529e-04  Data: 0.011 (0.015)
Train: 53 [ 300/390 ( 77%)]  Loss: 3.553 (3.35)  Time: 0.315s,  406.99/s  (0.317s,  403.74/s)  LR: 7.529e-04  Data: 0.013 (0.014)
Train: 53 [ 389/390 (100%)]  Loss: 3.331 (3.34)  Time: 0.302s,  423.32/s  (0.317s,  404.28/s)  LR: 7.529e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.413 (0.413)  Loss:  1.1064 (1.1064)  Acc@1: 75.0000 (75.0000)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.017 (0.123)  Loss:  0.7988 (1.1519)  Acc@1: 87.5000 (72.2400)  Acc@5: 93.7500 (93.7200)
Test: [Whole Val]  Time: 9.742  Loss: 1.1519  Acc@1: 72.2400 Pruned: 51.03% 
Test (EMA): [   0/78]  Time: 0.321 (0.321)  Loss:  1.1016 (1.1016)  Acc@1: 74.2188 (74.2188)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.7793 (1.1095)  Acc@1: 81.2500 (73.5000)  Acc@5: 93.7500 (94.1800)
Test (EMA): [Whole Val]  Time: 9.672  Loss: 1.1095  Acc@1: 73.5000 Pruned: 51.02% 
Train: 54 [   0/390 (  0%)]  Loss: 2.972 (2.97)  Time: 0.847s,  151.07/s  (0.847s,  151.07/s)  LR: 7.443e-04  Data: 0.544 (0.544)
Train: 54 [ 100/390 ( 26%)]  Loss: 3.727 (3.27)  Time: 0.314s,  407.59/s  (0.321s,  398.86/s)  LR: 7.443e-04  Data: 0.011 (0.018)
Train: 54 [ 200/390 ( 51%)]  Loss: 3.802 (3.30)  Time: 0.314s,  407.92/s  (0.318s,  401.99/s)  LR: 7.443e-04  Data: 0.012 (0.015)
Train: 54 [ 300/390 ( 77%)]  Loss: 2.623 (3.33)  Time: 0.317s,  403.86/s  (0.318s,  403.04/s)  LR: 7.443e-04  Data: 0.013 (0.014)
Train: 54 [ 389/390 (100%)]  Loss: 3.845 (3.32)  Time: 0.303s,  422.57/s  (0.317s,  403.62/s)  LR: 7.443e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.407 (0.407)  Loss:  1.1934 (1.1934)  Acc@1: 71.8750 (71.8750)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  0.9414 (1.2063)  Acc@1: 81.2500 (71.8100)  Acc@5: 93.7500 (93.6900)
Test: [Whole Val]  Time: 9.728  Loss: 1.2063  Acc@1: 71.8100 Pruned: 51.00% 
Test (EMA): [   0/78]  Time: 0.413 (0.413)  Loss:  1.1572 (1.1572)  Acc@1: 72.6562 (72.6562)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  0.9043 (1.1572)  Acc@1: 68.7500 (73.0400)  Acc@5: 93.7500 (94.4100)
Test (EMA): [Whole Val]  Time: 9.745  Loss: 1.1572  Acc@1: 73.0400 Pruned: 51.00% 
Train: 55 [   0/390 (  0%)]  Loss: 3.746 (3.75)  Time: 0.841s,  152.15/s  (0.841s,  152.15/s)  LR: 7.357e-04  Data: 0.527 (0.527)
Train: 55 [ 100/390 ( 26%)]  Loss: 2.688 (3.35)  Time: 0.313s,  409.17/s  (0.320s,  399.44/s)  LR: 7.357e-04  Data: 0.011 (0.018)
Train: 55 [ 200/390 ( 51%)]  Loss: 3.063 (3.35)  Time: 0.314s,  408.25/s  (0.318s,  402.64/s)  LR: 7.357e-04  Data: 0.012 (0.015)
Train: 55 [ 300/390 ( 77%)]  Loss: 2.900 (3.35)  Time: 0.316s,  405.06/s  (0.318s,  402.98/s)  LR: 7.357e-04  Data: 0.013 (0.014)
Train: 55 [ 389/390 (100%)]  Loss: 2.837 (3.33)  Time: 0.303s,  422.06/s  (0.318s,  403.03/s)  LR: 7.357e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.419 (0.419)  Loss:  1.1611 (1.1611)  Acc@1: 71.8750 (71.8750)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  0.8047 (1.1749)  Acc@1: 81.2500 (72.0000)  Acc@5: 93.7500 (93.8200)
Test: [Whole Val]  Time: 9.735  Loss: 1.1749  Acc@1: 72.0000 Pruned: 50.99% 
Test (EMA): [   0/78]  Time: 0.321 (0.321)  Loss:  1.1455 (1.1455)  Acc@1: 72.6562 (72.6562)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.7920 (1.1551)  Acc@1: 87.5000 (72.7500)  Acc@5: 100.0000 (94.1700)
Test (EMA): [Whole Val]  Time: 9.674  Loss: 1.1551  Acc@1: 72.7500 Pruned: 51.01% 
Train: 56 [   0/390 (  0%)]  Loss: 3.358 (3.36)  Time: 0.761s,  168.22/s  (0.761s,  168.22/s)  LR: 7.270e-04  Data: 0.455 (0.455)
Train: 56 [ 100/390 ( 26%)]  Loss: 3.101 (3.36)  Time: 0.314s,  407.76/s  (0.321s,  399.03/s)  LR: 7.270e-04  Data: 0.012 (0.017)
Train: 56 [ 200/390 ( 51%)]  Loss: 2.618 (3.34)  Time: 0.315s,  406.78/s  (0.318s,  402.13/s)  LR: 7.270e-04  Data: 0.012 (0.015)
Train: 56 [ 300/390 ( 77%)]  Loss: 2.598 (3.33)  Time: 0.317s,  403.73/s  (0.318s,  402.96/s)  LR: 7.270e-04  Data: 0.014 (0.014)
Train: 56 [ 389/390 (100%)]  Loss: 2.491 (3.33)  Time: 0.302s,  423.48/s  (0.317s,  403.60/s)  LR: 7.270e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.400 (0.400)  Loss:  1.1631 (1.1631)  Acc@1: 76.5625 (76.5625)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  0.8037 (1.1597)  Acc@1: 81.2500 (72.7700)  Acc@5: 93.7500 (94.1100)
Test: [Whole Val]  Time: 9.728  Loss: 1.1597  Acc@1: 72.7700 Pruned: 50.99% 
Test (EMA): [   0/78]  Time: 0.348 (0.348)  Loss:  1.1426 (1.1426)  Acc@1: 75.7812 (75.7812)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  0.8047 (1.1544)  Acc@1: 87.5000 (73.1700)  Acc@5: 93.7500 (94.1900)
Test (EMA): [Whole Val]  Time: 9.698  Loss: 1.1544  Acc@1: 73.1700 Pruned: 50.99% 
Train: 57 [   0/390 (  0%)]  Loss: 3.576 (3.58)  Time: 0.811s,  157.86/s  (0.811s,  157.86/s)  LR: 7.182e-04  Data: 0.506 (0.506)
Train: 57 [ 100/390 ( 26%)]  Loss: 2.888 (3.41)  Time: 0.316s,  405.09/s  (0.320s,  400.07/s)  LR: 7.182e-04  Data: 0.013 (0.017)
Train: 57 [ 200/390 ( 51%)]  Loss: 3.332 (3.33)  Time: 0.317s,  404.11/s  (0.318s,  402.73/s)  LR: 7.182e-04  Data: 0.014 (0.015)
Train: 57 [ 300/390 ( 77%)]  Loss: 2.413 (3.30)  Time: 0.317s,  403.48/s  (0.317s,  403.77/s)  LR: 7.182e-04  Data: 0.014 (0.014)
Train: 57 [ 389/390 (100%)]  Loss: 3.691 (3.31)  Time: 0.305s,  419.90/s  (0.317s,  404.23/s)  LR: 7.182e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.394 (0.394)  Loss:  1.2207 (1.2207)  Acc@1: 75.7812 (75.7812)  Acc@5: 88.2812 (88.2812)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  0.8979 (1.2196)  Acc@1: 75.0000 (71.3000)  Acc@5: 100.0000 (93.2400)
Test: [Whole Val]  Time: 9.703  Loss: 1.2196  Acc@1: 71.3000 Pruned: 50.97% 
Test (EMA): [   0/78]  Time: 0.314 (0.314)  Loss:  1.1191 (1.1191)  Acc@1: 74.2188 (74.2188)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.8228 (1.1218)  Acc@1: 68.7500 (73.2900)  Acc@5: 100.0000 (94.1600)
Test (EMA): [Whole Val]  Time: 9.655  Loss: 1.1218  Acc@1: 73.2900 Pruned: 50.97% 
Train: 58 [   0/390 (  0%)]  Loss: 3.695 (3.69)  Time: 0.924s,  138.51/s  (0.924s,  138.51/s)  LR: 7.094e-04  Data: 0.621 (0.621)
Train: 58 [ 100/390 ( 26%)]  Loss: 3.378 (3.33)  Time: 0.314s,  408.26/s  (0.322s,  397.06/s)  LR: 7.094e-04  Data: 0.012 (0.019)
Train: 58 [ 200/390 ( 51%)]  Loss: 3.393 (3.32)  Time: 0.314s,  407.69/s  (0.319s,  401.72/s)  LR: 7.094e-04  Data: 0.012 (0.015)
Train: 58 [ 300/390 ( 77%)]  Loss: 3.708 (3.32)  Time: 0.317s,  404.36/s  (0.318s,  403.11/s)  LR: 7.094e-04  Data: 0.012 (0.014)
Train: 58 [ 389/390 (100%)]  Loss: 2.796 (3.32)  Time: 0.304s,  421.54/s  (0.317s,  403.42/s)  LR: 7.094e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.329 (0.329)  Loss:  1.2266 (1.2266)  Acc@1: 71.0938 (71.0938)  Acc@5: 89.8438 (89.8438)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.9238 (1.2294)  Acc@1: 81.2500 (72.1300)  Acc@5: 93.7500 (93.6500)
Test: [Whole Val]  Time: 9.658  Loss: 1.2294  Acc@1: 72.1300 Pruned: 50.97% 
Test (EMA): [   0/78]  Time: 0.433 (0.433)  Loss:  1.1582 (1.1582)  Acc@1: 73.4375 (73.4375)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  0.7876 (1.1536)  Acc@1: 87.5000 (73.3600)  Acc@5: 93.7500 (94.1400)
Test (EMA): [Whole Val]  Time: 9.748  Loss: 1.1536  Acc@1: 73.3600 Pruned: 50.97% 
Train: 59 [   0/390 (  0%)]  Loss: 2.669 (2.67)  Time: 0.893s,  143.38/s  (0.893s,  143.38/s)  LR: 7.004e-04  Data: 0.590 (0.590)
Train: 59 [ 100/390 ( 26%)]  Loss: 3.729 (3.30)  Time: 0.314s,  408.16/s  (0.320s,  399.39/s)  LR: 7.004e-04  Data: 0.012 (0.018)
Train: 59 [ 200/390 ( 51%)]  Loss: 2.836 (3.32)  Time: 0.312s,  409.76/s  (0.318s,  402.89/s)  LR: 7.004e-04  Data: 0.011 (0.015)
Train: 59 [ 300/390 ( 77%)]  Loss: 3.914 (3.34)  Time: 0.317s,  403.75/s  (0.317s,  404.03/s)  LR: 7.004e-04  Data: 0.015 (0.014)
Train: 59 [ 389/390 (100%)]  Loss: 3.851 (3.33)  Time: 0.305s,  419.06/s  (0.317s,  404.33/s)  LR: 7.004e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.324 (0.324)  Loss:  1.1289 (1.1289)  Acc@1: 75.0000 (75.0000)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.7578 (1.1441)  Acc@1: 81.2500 (72.4700)  Acc@5: 100.0000 (93.8700)
Test: [Whole Val]  Time: 9.657  Loss: 1.1441  Acc@1: 72.4700 Pruned: 50.97% 
Test (EMA): [   0/78]  Time: 0.393 (0.393)  Loss:  1.1436 (1.1436)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  0.8193 (1.1420)  Acc@1: 75.0000 (73.4900)  Acc@5: 100.0000 (94.2900)
Test (EMA): [Whole Val]  Time: 9.724  Loss: 1.1420  Acc@1: 73.4900 Pruned: 50.96% 
Train: 60 [   0/390 (  0%)]  Loss: 3.134 (3.13)  Time: 0.726s,  176.31/s  (0.726s,  176.31/s)  LR: 6.914e-04  Data: 0.419 (0.419)
Train: 60 [ 100/390 ( 26%)]  Loss: 3.482 (3.29)  Time: 0.313s,  408.34/s  (0.320s,  399.89/s)  LR: 6.914e-04  Data: 0.012 (0.017)
Train: 60 [ 200/390 ( 51%)]  Loss: 3.977 (3.28)  Time: 0.316s,  405.46/s  (0.317s,  403.17/s)  LR: 6.914e-04  Data: 0.014 (0.015)
Train: 60 [ 300/390 ( 77%)]  Loss: 3.575 (3.29)  Time: 0.317s,  403.76/s  (0.317s,  404.10/s)  LR: 6.914e-04  Data: 0.015 (0.014)
Train: 60 [ 389/390 (100%)]  Loss: 3.618 (3.30)  Time: 0.303s,  422.63/s  (0.316s,  404.52/s)  LR: 6.914e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.430 (0.430)  Loss:  1.1455 (1.1455)  Acc@1: 72.6562 (72.6562)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.124)  Loss:  0.7998 (1.1568)  Acc@1: 87.5000 (72.9700)  Acc@5: 93.7500 (94.2900)
Test: [Whole Val]  Time: 9.767  Loss: 1.1568  Acc@1: 72.9700 Pruned: 50.96% 
Test (EMA): [   0/78]  Time: 0.320 (0.320)  Loss:  1.1436 (1.1436)  Acc@1: 72.6562 (72.6562)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.8042 (1.1551)  Acc@1: 87.5000 (73.3700)  Acc@5: 93.7500 (94.4000)
Test (EMA): [Whole Val]  Time: 9.648  Loss: 1.1551  Acc@1: 73.3700 Pruned: 50.96% 
Train: 61 [   0/390 (  0%)]  Loss: 3.385 (3.39)  Time: 0.817s,  156.63/s  (0.817s,  156.63/s)  LR: 6.823e-04  Data: 0.490 (0.490)
Train: 61 [ 100/390 ( 26%)]  Loss: 3.016 (3.29)  Time: 0.315s,  406.87/s  (0.320s,  399.97/s)  LR: 6.823e-04  Data: 0.012 (0.017)
Train: 61 [ 200/390 ( 51%)]  Loss: 3.728 (3.30)  Time: 0.315s,  406.81/s  (0.318s,  402.91/s)  LR: 6.823e-04  Data: 0.012 (0.015)
Train: 61 [ 300/390 ( 77%)]  Loss: 3.498 (3.32)  Time: 0.313s,  408.78/s  (0.317s,  403.79/s)  LR: 6.823e-04  Data: 0.012 (0.014)
Train: 61 [ 389/390 (100%)]  Loss: 3.648 (3.31)  Time: 0.303s,  422.80/s  (0.317s,  404.18/s)  LR: 6.823e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.354 (0.354)  Loss:  1.0957 (1.0957)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.7422 (1.0788)  Acc@1: 81.2500 (73.0600)  Acc@5: 100.0000 (93.9200)
Test: [Whole Val]  Time: 9.667  Loss: 1.0788  Acc@1: 73.0600 Pruned: 50.96% 
Test (EMA): [   0/78]  Time: 0.400 (0.400)  Loss:  1.0830 (1.0830)  Acc@1: 75.0000 (75.0000)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  0.7559 (1.0844)  Acc@1: 81.2500 (74.1100)  Acc@5: 100.0000 (94.3100)
Test (EMA): [Whole Val]  Time: 9.751  Loss: 1.0844  Acc@1: 74.1100 Pruned: 50.96% 
Train: 62 [   0/390 (  0%)]  Loss: 3.667 (3.67)  Time: 0.799s,  160.16/s  (0.799s,  160.16/s)  LR: 6.731e-04  Data: 0.495 (0.495)
Train: 62 [ 100/390 ( 26%)]  Loss: 3.822 (3.35)  Time: 0.313s,  408.30/s  (0.322s,  397.90/s)  LR: 6.731e-04  Data: 0.011 (0.018)
Train: 62 [ 200/390 ( 51%)]  Loss: 3.507 (3.36)  Time: 0.313s,  408.96/s  (0.319s,  401.73/s)  LR: 6.731e-04  Data: 0.011 (0.015)
Train: 62 [ 300/390 ( 77%)]  Loss: 2.954 (3.33)  Time: 0.314s,  408.27/s  (0.317s,  403.21/s)  LR: 6.731e-04  Data: 0.012 (0.014)
Train: 62 [ 389/390 (100%)]  Loss: 2.770 (3.31)  Time: 0.302s,  424.02/s  (0.317s,  403.96/s)  LR: 6.731e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.350 (0.350)  Loss:  1.0596 (1.0596)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  0.7339 (1.0637)  Acc@1: 93.7500 (74.2500)  Acc@5: 100.0000 (94.5700)
Test: [Whole Val]  Time: 9.721  Loss: 1.0637  Acc@1: 74.2500 Pruned: 50.96% 
Test (EMA): [   0/78]  Time: 0.450 (0.450)  Loss:  1.0693 (1.0693)  Acc@1: 75.7812 (75.7812)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.124)  Loss:  0.7266 (1.0633)  Acc@1: 81.2500 (74.4400)  Acc@5: 100.0000 (94.7900)
Test (EMA): [Whole Val]  Time: 9.798  Loss: 1.0633  Acc@1: 74.4400 Pruned: 50.96% 
Train: 63 [   0/390 (  0%)]  Loss: 2.832 (2.83)  Time: 0.909s,  140.86/s  (0.909s,  140.86/s)  LR: 6.638e-04  Data: 0.606 (0.606)
Train: 63 [ 100/390 ( 26%)]  Loss: 2.619 (3.27)  Time: 0.312s,  409.97/s  (0.321s,  398.68/s)  LR: 6.638e-04  Data: 0.012 (0.018)
Train: 63 [ 200/390 ( 51%)]  Loss: 3.483 (3.25)  Time: 0.313s,  408.40/s  (0.318s,  402.61/s)  LR: 6.638e-04  Data: 0.012 (0.015)
Train: 63 [ 300/390 ( 77%)]  Loss: 3.801 (3.28)  Time: 0.313s,  408.67/s  (0.317s,  403.87/s)  LR: 6.638e-04  Data: 0.012 (0.014)
Train: 63 [ 389/390 (100%)]  Loss: 3.365 (3.28)  Time: 0.303s,  422.42/s  (0.317s,  404.30/s)  LR: 6.638e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.332 (0.332)  Loss:  1.1260 (1.1260)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.8262 (1.1634)  Acc@1: 87.5000 (73.0300)  Acc@5: 93.7500 (94.1300)
Test: [Whole Val]  Time: 9.672  Loss: 1.1634  Acc@1: 73.0300 Pruned: 50.93% 
Test (EMA): [   0/78]  Time: 0.412 (0.412)  Loss:  1.0801 (1.0801)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  0.7988 (1.1090)  Acc@1: 81.2500 (73.8800)  Acc@5: 93.7500 (94.6000)
Test (EMA): [Whole Val]  Time: 9.739  Loss: 1.1090  Acc@1: 73.8800 Pruned: 50.93% 
Train: 64 [   0/390 (  0%)]  Loss: 3.487 (3.49)  Time: 0.909s,  140.74/s  (0.909s,  140.74/s)  LR: 6.545e-04  Data: 0.608 (0.608)
Train: 64 [ 100/390 ( 26%)]  Loss: 3.451 (3.33)  Time: 0.313s,  408.36/s  (0.321s,  398.69/s)  LR: 6.545e-04  Data: 0.012 (0.018)
Train: 64 [ 200/390 ( 51%)]  Loss: 3.733 (3.31)  Time: 0.313s,  408.51/s  (0.318s,  402.20/s)  LR: 6.545e-04  Data: 0.011 (0.016)
Train: 64 [ 300/390 ( 77%)]  Loss: 2.762 (3.31)  Time: 0.315s,  406.21/s  (0.317s,  403.56/s)  LR: 6.545e-04  Data: 0.012 (0.015)
Train: 64 [ 389/390 (100%)]  Loss: 3.900 (3.32)  Time: 0.304s,  421.72/s  (0.317s,  404.01/s)  LR: 6.545e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.373 (0.373)  Loss:  1.1621 (1.1621)  Acc@1: 71.8750 (71.8750)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.8569 (1.1565)  Acc@1: 81.2500 (72.8700)  Acc@5: 93.7500 (94.1700)
Test: [Whole Val]  Time: 9.672  Loss: 1.1565  Acc@1: 72.8700 Pruned: 50.94% 
Test (EMA): [   0/78]  Time: 0.437 (0.437)  Loss:  1.0947 (1.0947)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.124)  Loss:  0.8438 (1.1074)  Acc@1: 75.0000 (74.0800)  Acc@5: 100.0000 (94.6000)
Test (EMA): [Whole Val]  Time: 9.772  Loss: 1.1074  Acc@1: 74.0800 Pruned: 50.93% 
Train: 65 [   0/390 (  0%)]  Loss: 2.762 (2.76)  Time: 0.829s,  154.47/s  (0.829s,  154.47/s)  LR: 6.452e-04  Data: 0.526 (0.526)
Train: 65 [ 100/390 ( 26%)]  Loss: 3.511 (3.22)  Time: 0.317s,  404.13/s  (0.320s,  399.61/s)  LR: 6.452e-04  Data: 0.012 (0.018)
Train: 65 [ 200/390 ( 51%)]  Loss: 2.503 (3.25)  Time: 0.314s,  407.36/s  (0.318s,  401.97/s)  LR: 6.452e-04  Data: 0.011 (0.015)
Train: 65 [ 300/390 ( 77%)]  Loss: 3.789 (3.28)  Time: 0.314s,  407.67/s  (0.318s,  403.00/s)  LR: 6.452e-04  Data: 0.012 (0.014)
Train: 65 [ 389/390 (100%)]  Loss: 3.711 (3.27)  Time: 0.302s,  423.52/s  (0.317s,  403.76/s)  LR: 6.452e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.309 (0.309)  Loss:  1.1504 (1.1504)  Acc@1: 74.2188 (74.2188)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.9316 (1.1481)  Acc@1: 81.2500 (73.1600)  Acc@5: 93.7500 (94.4400)
Test: [Whole Val]  Time: 9.636  Loss: 1.1481  Acc@1: 73.1600 Pruned: 50.93% 
Test (EMA): [   0/78]  Time: 0.341 (0.341)  Loss:  1.1094 (1.1094)  Acc@1: 75.7812 (75.7812)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.8535 (1.1014)  Acc@1: 75.0000 (74.1500)  Acc@5: 93.7500 (94.6200)
Test (EMA): [Whole Val]  Time: 9.662  Loss: 1.1014  Acc@1: 74.1500 Pruned: 50.94% 
Train: 66 [   0/390 (  0%)]  Loss: 3.706 (3.71)  Time: 0.821s,  155.87/s  (0.821s,  155.87/s)  LR: 6.358e-04  Data: 0.517 (0.517)
Train: 66 [ 100/390 ( 26%)]  Loss: 2.825 (3.26)  Time: 0.318s,  401.97/s  (0.320s,  399.77/s)  LR: 6.358e-04  Data: 0.016 (0.017)
Train: 66 [ 200/390 ( 51%)]  Loss: 2.909 (3.32)  Time: 0.314s,  407.55/s  (0.318s,  402.72/s)  LR: 6.358e-04  Data: 0.012 (0.015)
Train: 66 [ 300/390 ( 77%)]  Loss: 3.015 (3.30)  Time: 0.316s,  405.22/s  (0.317s,  403.66/s)  LR: 6.358e-04  Data: 0.014 (0.014)
Train: 66 [ 389/390 (100%)]  Loss: 3.501 (3.31)  Time: 0.302s,  423.54/s  (0.317s,  404.11/s)  LR: 6.358e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.416 (0.416)  Loss:  1.1201 (1.1201)  Acc@1: 71.8750 (71.8750)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.124)  Loss:  0.8403 (1.1554)  Acc@1: 93.7500 (73.3900)  Acc@5: 93.7500 (94.4600)
Test: [Whole Val]  Time: 9.767  Loss: 1.1554  Acc@1: 73.3900 Pruned: 50.94% 
Test (EMA): [   0/78]  Time: 0.347 (0.347)  Loss:  1.0713 (1.0713)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.8154 (1.0956)  Acc@1: 87.5000 (74.1400)  Acc@5: 93.7500 (94.6100)
Test (EMA): [Whole Val]  Time: 9.635  Loss: 1.0956  Acc@1: 74.1400 Pruned: 50.94% 
Train: 67 [   0/390 (  0%)]  Loss: 3.523 (3.52)  Time: 0.726s,  176.33/s  (0.726s,  176.33/s)  LR: 6.263e-04  Data: 0.424 (0.424)
Train: 67 [ 100/390 ( 26%)]  Loss: 3.193 (3.22)  Time: 0.315s,  406.49/s  (0.321s,  399.18/s)  LR: 6.263e-04  Data: 0.012 (0.017)
Train: 67 [ 200/390 ( 51%)]  Loss: 3.684 (3.28)  Time: 0.315s,  406.45/s  (0.318s,  402.16/s)  LR: 6.263e-04  Data: 0.012 (0.015)
Train: 67 [ 300/390 ( 77%)]  Loss: 3.059 (3.27)  Time: 0.315s,  406.36/s  (0.318s,  402.94/s)  LR: 6.263e-04  Data: 0.012 (0.014)
Train: 67 [ 389/390 (100%)]  Loss: 3.297 (3.28)  Time: 0.304s,  421.26/s  (0.317s,  403.34/s)  LR: 6.263e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.396 (0.396)  Loss:  1.1084 (1.1084)  Acc@1: 72.6562 (72.6562)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.017 (0.124)  Loss:  0.8530 (1.1182)  Acc@1: 75.0000 (73.9200)  Acc@5: 93.7500 (94.1500)
Test: [Whole Val]  Time: 9.764  Loss: 1.1182  Acc@1: 73.9200 Pruned: 50.92% 
Test (EMA): [   0/78]  Time: 0.405 (0.405)  Loss:  1.1006 (1.1006)  Acc@1: 72.6562 (72.6562)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.018 (0.124)  Loss:  0.7988 (1.0993)  Acc@1: 81.2500 (74.2700)  Acc@5: 93.7500 (94.4800)
Test (EMA): [Whole Val]  Time: 9.766  Loss: 1.0993  Acc@1: 74.2700 Pruned: 50.92% 
Train: 68 [   0/390 (  0%)]  Loss: 3.492 (3.49)  Time: 0.852s,  150.28/s  (0.852s,  150.28/s)  LR: 6.168e-04  Data: 0.527 (0.527)
Train: 68 [ 100/390 ( 26%)]  Loss: 3.826 (3.32)  Time: 0.318s,  402.16/s  (0.322s,  396.99/s)  LR: 6.168e-04  Data: 0.014 (0.018)
Train: 68 [ 200/390 ( 51%)]  Loss: 3.323 (3.31)  Time: 0.311s,  411.13/s  (0.319s,  401.80/s)  LR: 6.168e-04  Data: 0.011 (0.015)
Train: 68 [ 300/390 ( 77%)]  Loss: 3.466 (3.29)  Time: 0.313s,  409.41/s  (0.318s,  402.42/s)  LR: 6.168e-04  Data: 0.011 (0.014)
Train: 68 [ 389/390 (100%)]  Loss: 2.599 (3.29)  Time: 0.304s,  421.49/s  (0.318s,  403.01/s)  LR: 6.168e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.310 (0.310)  Loss:  1.1523 (1.1523)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.9141 (1.1576)  Acc@1: 68.7500 (73.8000)  Acc@5: 100.0000 (94.3300)
Test: [Whole Val]  Time: 9.673  Loss: 1.1576  Acc@1: 73.8000 Pruned: 50.91% 
Test (EMA): [   0/78]  Time: 0.312 (0.312)  Loss:  1.1191 (1.1191)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.8623 (1.1147)  Acc@1: 68.7500 (74.1500)  Acc@5: 100.0000 (94.6400)
Test (EMA): [Whole Val]  Time: 9.660  Loss: 1.1147  Acc@1: 74.1500 Pruned: 50.92% 
Train: 69 [   0/390 (  0%)]  Loss: 3.558 (3.56)  Time: 0.979s,  130.73/s  (0.979s,  130.73/s)  LR: 6.072e-04  Data: 0.673 (0.673)
Train: 69 [ 100/390 ( 26%)]  Loss: 3.110 (3.35)  Time: 0.314s,  407.66/s  (0.323s,  396.26/s)  LR: 6.072e-04  Data: 0.012 (0.019)
Train: 69 [ 200/390 ( 51%)]  Loss: 3.405 (3.34)  Time: 0.327s,  391.62/s  (0.320s,  400.61/s)  LR: 6.072e-04  Data: 0.013 (0.016)
Train: 69 [ 300/390 ( 77%)]  Loss: 3.601 (3.33)  Time: 0.320s,  399.62/s  (0.318s,  401.97/s)  LR: 6.072e-04  Data: 0.017 (0.015)
Train: 69 [ 389/390 (100%)]  Loss: 3.639 (3.29)  Time: 0.302s,  424.46/s  (0.318s,  402.69/s)  LR: 6.072e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.425 (0.425)  Loss:  1.0557 (1.0557)  Acc@1: 76.5625 (76.5625)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  0.9043 (1.0909)  Acc@1: 68.7500 (74.1200)  Acc@5: 93.7500 (94.5200)
Test: [Whole Val]  Time: 9.746  Loss: 1.0909  Acc@1: 74.1200 Pruned: 50.91% 
Test (EMA): [   0/78]  Time: 0.394 (0.394)  Loss:  1.0762 (1.0762)  Acc@1: 75.7812 (75.7812)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  0.9126 (1.0975)  Acc@1: 68.7500 (74.4200)  Acc@5: 93.7500 (94.6100)
Test (EMA): [Whole Val]  Time: 9.712  Loss: 1.0975  Acc@1: 74.4200 Pruned: 50.92% 
Train: 70 [   0/390 (  0%)]  Loss: 2.996 (3.00)  Time: 0.817s,  156.77/s  (0.817s,  156.77/s)  LR: 5.976e-04  Data: 0.510 (0.510)
Train: 70 [ 100/390 ( 26%)]  Loss: 3.214 (3.20)  Time: 0.316s,  405.49/s  (0.321s,  398.73/s)  LR: 5.976e-04  Data: 0.014 (0.018)
Train: 70 [ 200/390 ( 51%)]  Loss: 3.708 (3.26)  Time: 0.317s,  403.58/s  (0.318s,  402.08/s)  LR: 5.976e-04  Data: 0.015 (0.015)
Train: 70 [ 300/390 ( 77%)]  Loss: 2.546 (3.30)  Time: 0.315s,  406.05/s  (0.318s,  403.13/s)  LR: 5.976e-04  Data: 0.012 (0.014)
Train: 70 [ 389/390 (100%)]  Loss: 3.469 (3.30)  Time: 0.304s,  420.74/s  (0.317s,  403.80/s)  LR: 5.976e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.410 (0.410)  Loss:  1.0605 (1.0605)  Acc@1: 75.7812 (75.7812)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.017 (0.123)  Loss:  0.8013 (1.1077)  Acc@1: 87.5000 (73.4700)  Acc@5: 93.7500 (94.4600)
Test: [Whole Val]  Time: 9.726  Loss: 1.1077  Acc@1: 73.4700 Pruned: 50.92% 
Test (EMA): [   0/78]  Time: 0.410 (0.410)  Loss:  1.0605 (1.0605)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.018 (0.124)  Loss:  0.7949 (1.0882)  Acc@1: 81.2500 (74.2600)  Acc@5: 100.0000 (94.4800)
Test (EMA): [Whole Val]  Time: 9.765  Loss: 1.0882  Acc@1: 74.2600 Pruned: 50.92% 
Train: 71 [   0/390 (  0%)]  Loss: 3.649 (3.65)  Time: 0.858s,  149.13/s  (0.858s,  149.13/s)  LR: 5.879e-04  Data: 0.556 (0.556)
Train: 71 [ 100/390 ( 26%)]  Loss: 2.880 (3.21)  Time: 0.314s,  407.01/s  (0.321s,  398.96/s)  LR: 5.879e-04  Data: 0.012 (0.018)
Train: 71 [ 200/390 ( 51%)]  Loss: 3.240 (3.27)  Time: 0.314s,  407.73/s  (0.318s,  402.44/s)  LR: 5.879e-04  Data: 0.011 (0.015)
Train: 71 [ 300/390 ( 77%)]  Loss: 3.091 (3.28)  Time: 0.325s,  394.16/s  (0.317s,  403.51/s)  LR: 5.879e-04  Data: 0.022 (0.014)
Train: 71 [ 389/390 (100%)]  Loss: 2.963 (3.30)  Time: 0.302s,  424.23/s  (0.317s,  403.94/s)  LR: 5.879e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.380 (0.380)  Loss:  1.1602 (1.1602)  Acc@1: 73.4375 (73.4375)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  0.9688 (1.1775)  Acc@1: 81.2500 (73.5300)  Acc@5: 93.7500 (94.0700)
Test: [Whole Val]  Time: 9.729  Loss: 1.1775  Acc@1: 73.5300 Pruned: 50.91% 
Test (EMA): [   0/78]  Time: 0.320 (0.320)  Loss:  1.0938 (1.0938)  Acc@1: 75.7812 (75.7812)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.8330 (1.1134)  Acc@1: 75.0000 (74.4100)  Acc@5: 100.0000 (94.7200)
Test (EMA): [Whole Val]  Time: 9.660  Loss: 1.1134  Acc@1: 74.4100 Pruned: 50.90% 
Train: 72 [   0/390 (  0%)]  Loss: 3.552 (3.55)  Time: 0.909s,  140.83/s  (0.909s,  140.83/s)  LR: 5.783e-04  Data: 0.592 (0.592)
Train: 72 [ 100/390 ( 26%)]  Loss: 3.821 (3.32)  Time: 0.321s,  398.28/s  (0.323s,  395.85/s)  LR: 5.783e-04  Data: 0.012 (0.019)
Train: 72 [ 200/390 ( 51%)]  Loss: 3.716 (3.27)  Time: 0.316s,  404.62/s  (0.320s,  400.26/s)  LR: 5.783e-04  Data: 0.013 (0.016)
Train: 72 [ 300/390 ( 77%)]  Loss: 3.360 (3.29)  Time: 0.315s,  406.86/s  (0.319s,  401.51/s)  LR: 5.783e-04  Data: 0.012 (0.015)
Train: 72 [ 389/390 (100%)]  Loss: 3.557 (3.29)  Time: 0.304s,  421.65/s  (0.318s,  402.31/s)  LR: 5.783e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.315 (0.315)  Loss:  1.0879 (1.0879)  Acc@1: 74.2188 (74.2188)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.7939 (1.1245)  Acc@1: 87.5000 (73.6800)  Acc@5: 100.0000 (94.4400)
Test: [Whole Val]  Time: 9.653  Loss: 1.1245  Acc@1: 73.6800 Pruned: 50.89% 
Test (EMA): [   0/78]  Time: 0.334 (0.334)  Loss:  1.0537 (1.0537)  Acc@1: 75.0000 (75.0000)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.7949 (1.0932)  Acc@1: 87.5000 (74.1200)  Acc@5: 100.0000 (94.7300)
Test (EMA): [Whole Val]  Time: 9.652  Loss: 1.0932  Acc@1: 74.1200 Pruned: 50.89% 
Train: 73 [   0/390 (  0%)]  Loss: 3.217 (3.22)  Time: 0.778s,  164.56/s  (0.778s,  164.56/s)  LR: 5.685e-04  Data: 0.469 (0.469)
Train: 73 [ 100/390 ( 26%)]  Loss: 2.638 (3.25)  Time: 0.315s,  406.32/s  (0.320s,  399.52/s)  LR: 5.685e-04  Data: 0.012 (0.017)
Train: 73 [ 200/390 ( 51%)]  Loss: 3.701 (3.27)  Time: 0.315s,  406.16/s  (0.318s,  402.49/s)  LR: 5.685e-04  Data: 0.013 (0.015)
Train: 73 [ 300/390 ( 77%)]  Loss: 3.112 (3.27)  Time: 0.314s,  407.26/s  (0.317s,  403.57/s)  LR: 5.685e-04  Data: 0.012 (0.014)
Train: 73 [ 389/390 (100%)]  Loss: 3.204 (3.25)  Time: 0.302s,  423.82/s  (0.317s,  404.18/s)  LR: 5.685e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.343 (0.343)  Loss:  1.0781 (1.0781)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.7993 (1.1052)  Acc@1: 75.0000 (73.7000)  Acc@5: 100.0000 (94.4600)
Test: [Whole Val]  Time: 9.646  Loss: 1.1052  Acc@1: 73.7000 Pruned: 50.90% 
Test (EMA): [   0/78]  Time: 0.347 (0.347)  Loss:  1.0605 (1.0605)  Acc@1: 75.7812 (75.7812)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.8091 (1.0663)  Acc@1: 68.7500 (74.4400)  Acc@5: 100.0000 (94.8500)
Test (EMA): [Whole Val]  Time: 9.648  Loss: 1.0663  Acc@1: 74.4400 Pruned: 50.90% 
Train: 74 [   0/390 (  0%)]  Loss: 3.239 (3.24)  Time: 0.784s,  163.24/s  (0.784s,  163.24/s)  LR: 5.588e-04  Data: 0.479 (0.479)
Train: 74 [ 100/390 ( 26%)]  Loss: 2.637 (3.33)  Time: 0.314s,  407.35/s  (0.320s,  400.50/s)  LR: 5.588e-04  Data: 0.012 (0.017)
Train: 74 [ 200/390 ( 51%)]  Loss: 2.524 (3.32)  Time: 0.313s,  408.56/s  (0.318s,  402.83/s)  LR: 5.588e-04  Data: 0.011 (0.015)
Train: 74 [ 300/390 ( 77%)]  Loss: 3.900 (3.31)  Time: 0.316s,  404.98/s  (0.317s,  403.68/s)  LR: 5.588e-04  Data: 0.013 (0.014)
Train: 74 [ 389/390 (100%)]  Loss: 3.623 (3.29)  Time: 0.306s,  418.10/s  (0.317s,  404.23/s)  LR: 5.588e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.398 (0.398)  Loss:  1.0264 (1.0264)  Acc@1: 76.5625 (76.5625)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  0.8896 (1.0686)  Acc@1: 68.7500 (74.0900)  Acc@5: 93.7500 (94.6800)
Test: [Whole Val]  Time: 9.719  Loss: 1.0686  Acc@1: 74.0900 Pruned: 50.90% 
Test (EMA): [   0/78]  Time: 0.427 (0.427)  Loss:  1.0283 (1.0283)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.018 (0.124)  Loss:  0.8213 (1.0768)  Acc@1: 68.7500 (74.5700)  Acc@5: 100.0000 (94.8700)
Test (EMA): [Whole Val]  Time: 9.762  Loss: 1.0768  Acc@1: 74.5700 Pruned: 50.90% 
Train: 75 [   0/390 (  0%)]  Loss: 3.576 (3.58)  Time: 0.832s,  153.85/s  (0.832s,  153.85/s)  LR: 5.491e-04  Data: 0.516 (0.516)
Train: 75 [ 100/390 ( 26%)]  Loss: 2.690 (3.28)  Time: 0.318s,  402.01/s  (0.322s,  397.68/s)  LR: 5.491e-04  Data: 0.016 (0.018)
Train: 75 [ 200/390 ( 51%)]  Loss: 3.045 (3.26)  Time: 0.316s,  405.70/s  (0.319s,  401.42/s)  LR: 5.491e-04  Data: 0.012 (0.015)
Train: 75 [ 300/390 ( 77%)]  Loss: 3.886 (3.24)  Time: 0.318s,  401.93/s  (0.318s,  402.85/s)  LR: 5.491e-04  Data: 0.013 (0.014)
Train: 75 [ 389/390 (100%)]  Loss: 3.550 (3.24)  Time: 0.304s,  421.62/s  (0.317s,  403.41/s)  LR: 5.491e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.338 (0.338)  Loss:  1.1475 (1.1475)  Acc@1: 73.4375 (73.4375)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.8755 (1.1565)  Acc@1: 87.5000 (73.6000)  Acc@5: 93.7500 (94.4700)
Test: [Whole Val]  Time: 9.668  Loss: 1.1565  Acc@1: 73.6000 Pruned: 50.87% 
Test (EMA): [   0/78]  Time: 0.310 (0.310)  Loss:  1.0811 (1.0811)  Acc@1: 75.0000 (75.0000)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.8408 (1.0821)  Acc@1: 87.5000 (74.8000)  Acc@5: 93.7500 (94.8000)
Test (EMA): [Whole Val]  Time: 9.673  Loss: 1.0821  Acc@1: 74.8000 Pruned: 50.87% 
Train: 76 [   0/390 (  0%)]  Loss: 3.652 (3.65)  Time: 0.791s,  161.76/s  (0.791s,  161.76/s)  LR: 5.393e-04  Data: 0.481 (0.481)
Train: 76 [ 100/390 ( 26%)]  Loss: 2.997 (3.28)  Time: 0.315s,  406.62/s  (0.321s,  398.48/s)  LR: 5.393e-04  Data: 0.012 (0.017)
Train: 76 [ 200/390 ( 51%)]  Loss: 3.716 (3.27)  Time: 0.316s,  405.55/s  (0.318s,  401.99/s)  LR: 5.393e-04  Data: 0.012 (0.015)
Train: 76 [ 300/390 ( 77%)]  Loss: 3.371 (3.29)  Time: 0.314s,  407.17/s  (0.318s,  403.06/s)  LR: 5.393e-04  Data: 0.012 (0.014)
Train: 76 [ 389/390 (100%)]  Loss: 3.034 (3.31)  Time: 0.304s,  421.29/s  (0.317s,  403.71/s)  LR: 5.393e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.360 (0.360)  Loss:  1.1289 (1.1289)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.017 (0.123)  Loss:  0.9282 (1.1405)  Acc@1: 75.0000 (74.2600)  Acc@5: 87.5000 (94.8900)
Test: [Whole Val]  Time: 9.683  Loss: 1.1405  Acc@1: 74.2600 Pruned: 50.88% 
Test (EMA): [   0/78]  Time: 0.308 (0.308)  Loss:  1.1064 (1.1064)  Acc@1: 75.7812 (75.7812)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.8652 (1.1154)  Acc@1: 75.0000 (74.3100)  Acc@5: 93.7500 (94.9700)
Test (EMA): [Whole Val]  Time: 9.661  Loss: 1.1154  Acc@1: 74.3100 Pruned: 50.88% 
Train: 77 [   0/390 (  0%)]  Loss: 3.667 (3.67)  Time: 0.996s,  128.57/s  (0.996s,  128.57/s)  LR: 5.295e-04  Data: 0.694 (0.694)
Train: 77 [ 100/390 ( 26%)]  Loss: 3.105 (3.25)  Time: 0.313s,  408.67/s  (0.322s,  397.59/s)  LR: 5.295e-04  Data: 0.012 (0.019)
Train: 77 [ 200/390 ( 51%)]  Loss: 3.733 (3.25)  Time: 0.315s,  405.82/s  (0.319s,  401.44/s)  LR: 5.295e-04  Data: 0.013 (0.016)
Train: 77 [ 300/390 ( 77%)]  Loss: 3.972 (3.27)  Time: 0.316s,  404.87/s  (0.318s,  402.65/s)  LR: 5.295e-04  Data: 0.014 (0.015)
Train: 77 [ 389/390 (100%)]  Loss: 2.905 (3.28)  Time: 0.302s,  423.67/s  (0.317s,  403.26/s)  LR: 5.295e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.300 (0.300)  Loss:  1.1367 (1.1367)  Acc@1: 74.2188 (74.2188)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.8936 (1.1453)  Acc@1: 68.7500 (73.8100)  Acc@5: 100.0000 (94.4500)
Test: [Whole Val]  Time: 9.632  Loss: 1.1453  Acc@1: 73.8100 Pruned: 50.88% 
Test (EMA): [   0/78]  Time: 0.351 (0.351)  Loss:  1.1006 (1.1006)  Acc@1: 76.5625 (76.5625)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  0.8511 (1.1137)  Acc@1: 75.0000 (74.4400)  Acc@5: 93.7500 (94.9200)
Test (EMA): [Whole Val]  Time: 9.705  Loss: 1.1137  Acc@1: 74.4400 Pruned: 50.88% 
Train: 78 [   0/390 (  0%)]  Loss: 3.426 (3.43)  Time: 0.821s,  155.95/s  (0.821s,  155.95/s)  LR: 5.197e-04  Data: 0.508 (0.508)
Train: 78 [ 100/390 ( 26%)]  Loss: 3.350 (3.27)  Time: 0.317s,  404.37/s  (0.320s,  399.54/s)  LR: 5.197e-04  Data: 0.013 (0.017)
Train: 78 [ 200/390 ( 51%)]  Loss: 3.325 (3.27)  Time: 0.313s,  409.39/s  (0.319s,  401.69/s)  LR: 5.197e-04  Data: 0.011 (0.015)
Train: 78 [ 300/390 ( 77%)]  Loss: 3.179 (3.26)  Time: 0.315s,  405.99/s  (0.318s,  402.95/s)  LR: 5.197e-04  Data: 0.013 (0.014)
Train: 78 [ 389/390 (100%)]  Loss: 3.453 (3.26)  Time: 0.304s,  420.85/s  (0.317s,  403.53/s)  LR: 5.197e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.424 (0.424)  Loss:  1.0791 (1.0791)  Acc@1: 76.5625 (76.5625)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  0.8423 (1.0879)  Acc@1: 75.0000 (74.2900)  Acc@5: 93.7500 (94.7400)
Test: [Whole Val]  Time: 9.750  Loss: 1.0879  Acc@1: 74.2900 Pruned: 50.87% 
Test (EMA): [   0/78]  Time: 0.366 (0.366)  Loss:  1.1064 (1.1064)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  0.8755 (1.1111)  Acc@1: 81.2500 (74.5100)  Acc@5: 93.7500 (94.8600)
Test (EMA): [Whole Val]  Time: 9.714  Loss: 1.1111  Acc@1: 74.5100 Pruned: 50.87% 
Train: 79 [   0/390 (  0%)]  Loss: 2.950 (2.95)  Time: 0.930s,  137.58/s  (0.930s,  137.58/s)  LR: 5.099e-04  Data: 0.610 (0.610)
Train: 79 [ 100/390 ( 26%)]  Loss: 2.703 (3.30)  Time: 0.323s,  395.97/s  (0.322s,  397.10/s)  LR: 5.099e-04  Data: 0.012 (0.019)
Train: 79 [ 200/390 ( 51%)]  Loss: 2.918 (3.28)  Time: 0.313s,  408.73/s  (0.319s,  401.15/s)  LR: 5.099e-04  Data: 0.012 (0.016)
Train: 79 [ 300/390 ( 77%)]  Loss: 2.931 (3.30)  Time: 0.315s,  406.14/s  (0.318s,  402.70/s)  LR: 5.099e-04  Data: 0.012 (0.015)
Train: 79 [ 389/390 (100%)]  Loss: 3.582 (3.30)  Time: 0.306s,  418.56/s  (0.317s,  403.54/s)  LR: 5.099e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.423 (0.423)  Loss:  1.1484 (1.1484)  Acc@1: 71.0938 (71.0938)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.018 (0.124)  Loss:  0.9453 (1.1400)  Acc@1: 75.0000 (73.8800)  Acc@5: 87.5000 (94.4600)
Test: [Whole Val]  Time: 9.758  Loss: 1.1400  Acc@1: 73.8800 Pruned: 50.87% 
Test (EMA): [   0/78]  Time: 0.429 (0.429)  Loss:  1.1104 (1.1104)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.020 (0.124)  Loss:  0.8398 (1.0995)  Acc@1: 81.2500 (74.7300)  Acc@5: 100.0000 (94.7400)
Test (EMA): [Whole Val]  Time: 9.760  Loss: 1.0995  Acc@1: 74.7300 Pruned: 50.87% 
Train: 80 [   0/390 (  0%)]  Loss: 3.548 (3.55)  Time: 0.795s,  161.08/s  (0.795s,  161.08/s)  LR: 5.000e-04  Data: 0.492 (0.492)
Train: 80 [ 100/390 ( 26%)]  Loss: 2.557 (3.29)  Time: 0.314s,  407.37/s  (0.320s,  399.48/s)  LR: 5.000e-04  Data: 0.012 (0.017)
Train: 80 [ 200/390 ( 51%)]  Loss: 2.513 (3.30)  Time: 0.316s,  405.37/s  (0.318s,  402.36/s)  LR: 5.000e-04  Data: 0.012 (0.015)
Train: 80 [ 300/390 ( 77%)]  Loss: 2.933 (3.28)  Time: 0.318s,  402.72/s  (0.317s,  403.26/s)  LR: 5.000e-04  Data: 0.014 (0.014)
Train: 80 [ 389/390 (100%)]  Loss: 2.867 (3.27)  Time: 0.303s,  422.56/s  (0.317s,  403.91/s)  LR: 5.000e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.371 (0.371)  Loss:  1.0254 (1.0254)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.6953 (1.0139)  Acc@1: 81.2500 (74.3500)  Acc@5: 100.0000 (94.6600)
Test: [Whole Val]  Time: 9.664  Loss: 1.0139  Acc@1: 74.3500 Pruned: 50.86% 
Test (EMA): [   0/78]  Time: 0.407 (0.407)  Loss:  1.0273 (1.0273)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.018 (0.124)  Loss:  0.7134 (1.0222)  Acc@1: 81.2500 (75.0600)  Acc@5: 100.0000 (94.9900)
Test (EMA): [Whole Val]  Time: 9.763  Loss: 1.0222  Acc@1: 75.0600 Pruned: 50.86% 
Train: 81 [   0/390 (  0%)]  Loss: 3.887 (3.89)  Time: 0.964s,  132.82/s  (0.964s,  132.82/s)  LR: 4.902e-04  Data: 0.657 (0.657)
Train: 81 [ 100/390 ( 26%)]  Loss: 3.999 (3.26)  Time: 0.313s,  408.32/s  (0.322s,  397.65/s)  LR: 4.902e-04  Data: 0.012 (0.019)
Train: 81 [ 200/390 ( 51%)]  Loss: 3.501 (3.25)  Time: 0.316s,  404.75/s  (0.319s,  401.35/s)  LR: 4.902e-04  Data: 0.014 (0.016)
Train: 81 [ 300/390 ( 77%)]  Loss: 3.833 (3.25)  Time: 0.316s,  404.47/s  (0.318s,  402.29/s)  LR: 4.902e-04  Data: 0.015 (0.015)
Train: 81 [ 389/390 (100%)]  Loss: 3.260 (3.25)  Time: 0.305s,  420.09/s  (0.318s,  403.11/s)  LR: 4.902e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.384 (0.384)  Loss:  1.1104 (1.1104)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  0.8716 (1.1352)  Acc@1: 81.2500 (74.1900)  Acc@5: 93.7500 (94.4200)
Test: [Whole Val]  Time: 9.683  Loss: 1.1352  Acc@1: 74.1900 Pruned: 50.85% 
Test (EMA): [   0/78]  Time: 0.310 (0.310)  Loss:  1.0820 (1.0820)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.8296 (1.1055)  Acc@1: 81.2500 (74.9000)  Acc@5: 93.7500 (94.8400)
Test (EMA): [Whole Val]  Time: 9.632  Loss: 1.1055  Acc@1: 74.9000 Pruned: 50.85% 
Train: 82 [   0/390 (  0%)]  Loss: 3.323 (3.32)  Time: 0.819s,  156.26/s  (0.819s,  156.26/s)  LR: 4.804e-04  Data: 0.502 (0.502)
Train: 82 [ 100/390 ( 26%)]  Loss: 2.574 (3.26)  Time: 0.321s,  398.41/s  (0.321s,  398.40/s)  LR: 4.804e-04  Data: 0.012 (0.018)
Train: 82 [ 200/390 ( 51%)]  Loss: 2.206 (3.25)  Time: 0.315s,  406.02/s  (0.318s,  402.08/s)  LR: 4.804e-04  Data: 0.013 (0.015)
Train: 82 [ 300/390 ( 77%)]  Loss: 2.869 (3.26)  Time: 0.314s,  408.11/s  (0.318s,  403.13/s)  LR: 4.804e-04  Data: 0.013 (0.014)
Train: 82 [ 389/390 (100%)]  Loss: 3.599 (3.26)  Time: 0.301s,  424.81/s  (0.317s,  403.77/s)  LR: 4.804e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.306 (0.306)  Loss:  1.1172 (1.1172)  Acc@1: 74.2188 (74.2188)  Acc@5: 89.0625 (89.0625)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.6992 (1.1184)  Acc@1: 87.5000 (73.5400)  Acc@5: 100.0000 (94.4500)
Test: [Whole Val]  Time: 9.618  Loss: 1.1184  Acc@1: 73.5400 Pruned: 50.86% 
Test (EMA): [   0/78]  Time: 0.419 (0.419)  Loss:  1.0918 (1.0918)  Acc@1: 72.6562 (72.6562)  Acc@5: 89.0625 (89.0625)
Test (EMA): [  78/78]  Time: 0.018 (0.124)  Loss:  0.7148 (1.0877)  Acc@1: 93.7500 (74.4400)  Acc@5: 100.0000 (94.7400)
Test (EMA): [Whole Val]  Time: 9.761  Loss: 1.0877  Acc@1: 74.4400 Pruned: 50.87% 
Train: 83 [   0/390 (  0%)]  Loss: 3.785 (3.79)  Time: 0.905s,  141.50/s  (0.905s,  141.50/s)  LR: 4.706e-04  Data: 0.601 (0.601)
Train: 83 [ 100/390 ( 26%)]  Loss: 3.882 (3.22)  Time: 0.314s,  408.28/s  (0.322s,  397.42/s)  LR: 4.706e-04  Data: 0.012 (0.019)
Train: 83 [ 200/390 ( 51%)]  Loss: 3.601 (3.26)  Time: 0.314s,  408.20/s  (0.319s,  401.76/s)  LR: 4.706e-04  Data: 0.012 (0.016)
Train: 83 [ 300/390 ( 77%)]  Loss: 3.367 (3.25)  Time: 0.315s,  406.90/s  (0.318s,  402.87/s)  LR: 4.706e-04  Data: 0.012 (0.015)
Train: 83 [ 389/390 (100%)]  Loss: 2.527 (3.26)  Time: 0.303s,  423.14/s  (0.317s,  403.68/s)  LR: 4.706e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.430 (0.430)  Loss:  1.0811 (1.0811)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.124)  Loss:  0.7661 (1.0863)  Acc@1: 68.7500 (74.0200)  Acc@5: 100.0000 (94.6600)
Test: [Whole Val]  Time: 9.779  Loss: 1.0863  Acc@1: 74.0200 Pruned: 50.87% 
Test (EMA): [   0/78]  Time: 0.320 (0.320)  Loss:  1.0938 (1.0938)  Acc@1: 72.6562 (72.6562)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.7842 (1.0994)  Acc@1: 81.2500 (74.4200)  Acc@5: 100.0000 (94.6200)
Test (EMA): [Whole Val]  Time: 9.665  Loss: 1.0994  Acc@1: 74.4200 Pruned: 50.86% 
Train: 84 [   0/390 (  0%)]  Loss: 2.279 (2.28)  Time: 0.787s,  162.63/s  (0.787s,  162.63/s)  LR: 4.608e-04  Data: 0.472 (0.472)
Train: 84 [ 100/390 ( 26%)]  Loss: 2.923 (3.23)  Time: 0.314s,  408.00/s  (0.320s,  399.56/s)  LR: 4.608e-04  Data: 0.012 (0.017)
Train: 84 [ 200/390 ( 51%)]  Loss: 2.843 (3.25)  Time: 0.316s,  405.29/s  (0.318s,  402.33/s)  LR: 4.608e-04  Data: 0.013 (0.015)
Train: 84 [ 300/390 ( 77%)]  Loss: 3.387 (3.24)  Time: 0.313s,  409.05/s  (0.317s,  403.49/s)  LR: 4.608e-04  Data: 0.012 (0.014)
Train: 84 [ 389/390 (100%)]  Loss: 3.640 (3.25)  Time: 0.303s,  422.44/s  (0.317s,  403.73/s)  LR: 4.608e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.387 (0.387)  Loss:  0.9951 (0.9951)  Acc@1: 77.3438 (77.3438)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.123)  Loss:  0.7773 (1.0569)  Acc@1: 75.0000 (74.5700)  Acc@5: 100.0000 (94.8300)
Test: [Whole Val]  Time: 9.704  Loss: 1.0569  Acc@1: 74.5700 Pruned: 50.85% 
Test (EMA): [   0/78]  Time: 0.297 (0.297)  Loss:  1.0088 (1.0088)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.7456 (1.0505)  Acc@1: 81.2500 (74.8500)  Acc@5: 100.0000 (95.0300)
Test (EMA): [Whole Val]  Time: 9.635  Loss: 1.0505  Acc@1: 74.8500 Pruned: 50.85% 
Train: 85 [   0/390 (  0%)]  Loss: 3.779 (3.78)  Time: 0.812s,  157.73/s  (0.812s,  157.73/s)  LR: 4.510e-04  Data: 0.509 (0.509)
Train: 85 [ 100/390 ( 26%)]  Loss: 3.227 (3.22)  Time: 0.315s,  406.36/s  (0.321s,  399.23/s)  LR: 4.510e-04  Data: 0.014 (0.018)
Train: 85 [ 200/390 ( 51%)]  Loss: 3.732 (3.20)  Time: 0.315s,  406.39/s  (0.319s,  401.86/s)  LR: 4.510e-04  Data: 0.013 (0.015)
Train: 85 [ 300/390 ( 77%)]  Loss: 3.551 (3.24)  Time: 0.315s,  406.29/s  (0.318s,  402.44/s)  LR: 4.510e-04  Data: 0.011 (0.015)
Train: 85 [ 389/390 (100%)]  Loss: 3.597 (3.27)  Time: 0.303s,  422.67/s  (0.318s,  402.85/s)  LR: 4.510e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.387 (0.387)  Loss:  1.0742 (1.0742)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.123)  Loss:  0.6929 (1.0725)  Acc@1: 87.5000 (74.5000)  Acc@5: 100.0000 (94.6600)
Test: [Whole Val]  Time: 9.718  Loss: 1.0725  Acc@1: 74.5000 Pruned: 50.85% 
Test (EMA): [   0/78]  Time: 0.424 (0.424)  Loss:  1.0791 (1.0791)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.124)  Loss:  0.7314 (1.0833)  Acc@1: 87.5000 (74.9900)  Acc@5: 100.0000 (94.9600)
Test (EMA): [Whole Val]  Time: 9.779  Loss: 1.0833  Acc@1: 74.9900 Pruned: 50.84% 
Train: 86 [   0/390 (  0%)]  Loss: 3.782 (3.78)  Time: 0.845s,  151.41/s  (0.845s,  151.41/s)  LR: 4.413e-04  Data: 0.541 (0.541)
Train: 86 [ 100/390 ( 26%)]  Loss: 3.890 (3.31)  Time: 0.324s,  394.71/s  (0.322s,  398.01/s)  LR: 4.413e-04  Data: 0.012 (0.018)
Train: 86 [ 200/390 ( 51%)]  Loss: 3.164 (3.32)  Time: 0.313s,  408.73/s  (0.319s,  401.50/s)  LR: 4.413e-04  Data: 0.012 (0.015)
Train: 86 [ 300/390 ( 77%)]  Loss: 3.577 (3.29)  Time: 0.314s,  408.01/s  (0.318s,  403.03/s)  LR: 4.413e-04  Data: 0.013 (0.015)
Train: 86 [ 389/390 (100%)]  Loss: 2.541 (3.28)  Time: 0.303s,  422.51/s  (0.317s,  403.20/s)  LR: 4.413e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.328 (0.328)  Loss:  1.0146 (1.0146)  Acc@1: 74.2188 (74.2188)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.7490 (1.0602)  Acc@1: 87.5000 (74.4300)  Acc@5: 100.0000 (94.6900)
Test: [Whole Val]  Time: 9.667  Loss: 1.0602  Acc@1: 74.4300 Pruned: 50.85% 
Test (EMA): [   0/78]  Time: 0.310 (0.310)  Loss:  1.0225 (1.0225)  Acc@1: 75.7812 (75.7812)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.7520 (1.0488)  Acc@1: 81.2500 (74.9300)  Acc@5: 100.0000 (94.8700)
Test (EMA): [Whole Val]  Time: 9.627  Loss: 1.0488  Acc@1: 74.9300 Pruned: 50.85% 
Train: 87 [   0/390 (  0%)]  Loss: 3.562 (3.56)  Time: 0.951s,  134.60/s  (0.951s,  134.60/s)  LR: 4.316e-04  Data: 0.647 (0.647)
Train: 87 [ 100/390 ( 26%)]  Loss: 2.952 (3.16)  Time: 0.314s,  407.75/s  (0.322s,  397.72/s)  LR: 4.316e-04  Data: 0.012 (0.019)
Train: 87 [ 200/390 ( 51%)]  Loss: 2.450 (3.24)  Time: 0.315s,  406.91/s  (0.319s,  401.55/s)  LR: 4.316e-04  Data: 0.013 (0.016)
Train: 87 [ 300/390 ( 77%)]  Loss: 3.529 (3.26)  Time: 0.316s,  405.38/s  (0.318s,  402.67/s)  LR: 4.316e-04  Data: 0.012 (0.015)
Train: 87 [ 389/390 (100%)]  Loss: 2.614 (3.27)  Time: 0.303s,  422.75/s  (0.317s,  403.28/s)  LR: 4.316e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.410 (0.410)  Loss:  1.1006 (1.1006)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.017 (0.123)  Loss:  0.8125 (1.1138)  Acc@1: 81.2500 (74.7300)  Acc@5: 100.0000 (94.6900)
Test: [Whole Val]  Time: 9.737  Loss: 1.1138  Acc@1: 74.7300 Pruned: 50.85% 
Test (EMA): [   0/78]  Time: 0.384 (0.384)  Loss:  1.0938 (1.0938)  Acc@1: 75.7812 (75.7812)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  0.8052 (1.1142)  Acc@1: 87.5000 (75.1200)  Acc@5: 100.0000 (94.9300)
Test (EMA): [Whole Val]  Time: 9.725  Loss: 1.1142  Acc@1: 75.1200 Pruned: 50.85% 
Train: 88 [   0/390 (  0%)]  Loss: 3.123 (3.12)  Time: 0.812s,  157.62/s  (0.812s,  157.62/s)  LR: 4.218e-04  Data: 0.506 (0.506)
Train: 88 [ 100/390 ( 26%)]  Loss: 3.846 (3.31)  Time: 0.318s,  402.39/s  (0.322s,  397.27/s)  LR: 4.218e-04  Data: 0.016 (0.018)
Train: 88 [ 200/390 ( 51%)]  Loss: 2.376 (3.26)  Time: 0.315s,  406.32/s  (0.319s,  401.07/s)  LR: 4.218e-04  Data: 0.012 (0.015)
Train: 88 [ 300/390 ( 77%)]  Loss: 3.461 (3.25)  Time: 0.315s,  406.05/s  (0.318s,  402.52/s)  LR: 4.218e-04  Data: 0.011 (0.014)
Train: 88 [ 389/390 (100%)]  Loss: 2.197 (3.27)  Time: 0.302s,  423.20/s  (0.317s,  403.30/s)  LR: 4.218e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.410 (0.410)  Loss:  1.1055 (1.1055)  Acc@1: 75.7812 (75.7812)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  0.8472 (1.1004)  Acc@1: 75.0000 (75.2600)  Acc@5: 100.0000 (94.9600)
Test: [Whole Val]  Time: 9.724  Loss: 1.1004  Acc@1: 75.2600 Pruned: 50.85% 
Test (EMA): [   0/78]  Time: 0.321 (0.321)  Loss:  1.0801 (1.0801)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.7783 (1.0767)  Acc@1: 87.5000 (75.0700)  Acc@5: 100.0000 (94.7800)
Test (EMA): [Whole Val]  Time: 9.658  Loss: 1.0767  Acc@1: 75.0700 Pruned: 50.84% 
Train: 89 [   0/390 (  0%)]  Loss: 3.499 (3.50)  Time: 0.886s,  144.42/s  (0.886s,  144.42/s)  LR: 4.122e-04  Data: 0.584 (0.584)
Train: 89 [ 100/390 ( 26%)]  Loss: 2.273 (3.36)  Time: 0.314s,  407.11/s  (0.321s,  398.98/s)  LR: 4.122e-04  Data: 0.012 (0.018)
Train: 89 [ 200/390 ( 51%)]  Loss: 3.249 (3.32)  Time: 0.313s,  408.51/s  (0.318s,  402.53/s)  LR: 4.122e-04  Data: 0.012 (0.015)
Train: 89 [ 300/390 ( 77%)]  Loss: 2.636 (3.28)  Time: 0.316s,  405.41/s  (0.317s,  403.51/s)  LR: 4.122e-04  Data: 0.012 (0.014)
Train: 89 [ 389/390 (100%)]  Loss: 2.169 (3.27)  Time: 0.302s,  423.44/s  (0.317s,  404.09/s)  LR: 4.122e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.408 (0.408)  Loss:  1.0840 (1.0840)  Acc@1: 73.4375 (73.4375)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  0.8022 (1.0788)  Acc@1: 81.2500 (74.7700)  Acc@5: 100.0000 (94.6800)
Test: [Whole Val]  Time: 9.705  Loss: 1.0788  Acc@1: 74.7700 Pruned: 50.85% 
Test (EMA): [   0/78]  Time: 0.378 (0.378)  Loss:  1.0723 (1.0723)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  0.7666 (1.0769)  Acc@1: 87.5000 (75.0200)  Acc@5: 100.0000 (94.8900)
Test (EMA): [Whole Val]  Time: 9.695  Loss: 1.0769  Acc@1: 75.0200 Pruned: 50.84% 
Train: 90 [   0/390 (  0%)]  Loss: 3.667 (3.67)  Time: 0.715s,  178.99/s  (0.715s,  178.99/s)  LR: 4.025e-04  Data: 0.410 (0.410)
Train: 90 [ 100/390 ( 26%)]  Loss: 3.261 (3.29)  Time: 0.316s,  405.60/s  (0.320s,  400.39/s)  LR: 4.025e-04  Data: 0.012 (0.017)
Train: 90 [ 200/390 ( 51%)]  Loss: 3.763 (3.27)  Time: 0.314s,  407.17/s  (0.318s,  402.73/s)  LR: 4.025e-04  Data: 0.012 (0.015)
Train: 90 [ 300/390 ( 77%)]  Loss: 3.416 (3.28)  Time: 0.317s,  403.36/s  (0.317s,  403.48/s)  LR: 4.025e-04  Data: 0.015 (0.014)
Train: 90 [ 389/390 (100%)]  Loss: 3.519 (3.26)  Time: 0.304s,  421.07/s  (0.317s,  404.30/s)  LR: 4.025e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.372 (0.372)  Loss:  1.0059 (1.0059)  Acc@1: 75.7812 (75.7812)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  0.6445 (1.0173)  Acc@1: 93.7500 (75.0000)  Acc@5: 100.0000 (94.9600)
Test: [Whole Val]  Time: 9.716  Loss: 1.0173  Acc@1: 75.0000 Pruned: 50.85% 
Test (EMA): [   0/78]  Time: 0.313 (0.313)  Loss:  1.0205 (1.0205)  Acc@1: 76.5625 (76.5625)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.6875 (1.0292)  Acc@1: 93.7500 (75.3100)  Acc@5: 100.0000 (95.0700)
Test (EMA): [Whole Val]  Time: 9.638  Loss: 1.0292  Acc@1: 75.3100 Pruned: 50.85% 
Train: 91 [   0/390 (  0%)]  Loss: 2.774 (2.77)  Time: 0.907s,  141.07/s  (0.907s,  141.07/s)  LR: 3.929e-04  Data: 0.576 (0.576)
Train: 91 [ 100/390 ( 26%)]  Loss: 3.451 (3.21)  Time: 0.314s,  408.00/s  (0.322s,  397.43/s)  LR: 3.929e-04  Data: 0.012 (0.019)
Train: 91 [ 200/390 ( 51%)]  Loss: 3.613 (3.21)  Time: 0.319s,  401.62/s  (0.320s,  400.51/s)  LR: 3.929e-04  Data: 0.016 (0.016)
Train: 91 [ 300/390 ( 77%)]  Loss: 2.514 (3.22)  Time: 0.316s,  405.54/s  (0.318s,  402.17/s)  LR: 3.929e-04  Data: 0.012 (0.015)
Train: 91 [ 389/390 (100%)]  Loss: 2.601 (3.23)  Time: 0.305s,  419.65/s  (0.318s,  403.01/s)  LR: 3.929e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.409 (0.409)  Loss:  1.1113 (1.1113)  Acc@1: 72.6562 (72.6562)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  0.9023 (1.1034)  Acc@1: 68.7500 (74.2900)  Acc@5: 93.7500 (94.8200)
Test: [Whole Val]  Time: 9.727  Loss: 1.1034  Acc@1: 74.2900 Pruned: 50.85% 
Test (EMA): [   0/78]  Time: 0.394 (0.394)  Loss:  1.0840 (1.0840)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  0.8398 (1.0845)  Acc@1: 75.0000 (74.9300)  Acc@5: 93.7500 (94.9300)
Test (EMA): [Whole Val]  Time: 9.710  Loss: 1.0845  Acc@1: 74.9300 Pruned: 50.85% 
Train: 92 [   0/390 (  0%)]  Loss: 2.776 (2.78)  Time: 0.773s,  165.55/s  (0.773s,  165.55/s)  LR: 3.833e-04  Data: 0.459 (0.459)
Train: 92 [ 100/390 ( 26%)]  Loss: 2.283 (3.21)  Time: 0.314s,  407.55/s  (0.320s,  399.62/s)  LR: 3.833e-04  Data: 0.012 (0.017)
Train: 92 [ 200/390 ( 51%)]  Loss: 3.487 (3.23)  Time: 0.314s,  407.77/s  (0.318s,  402.67/s)  LR: 3.833e-04  Data: 0.012 (0.015)
Train: 92 [ 300/390 ( 77%)]  Loss: 3.097 (3.23)  Time: 0.318s,  402.07/s  (0.317s,  403.58/s)  LR: 3.833e-04  Data: 0.015 (0.014)
Train: 92 [ 389/390 (100%)]  Loss: 2.988 (3.23)  Time: 0.301s,  424.90/s  (0.317s,  404.27/s)  LR: 3.833e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.364 (0.364)  Loss:  1.0986 (1.0986)  Acc@1: 76.5625 (76.5625)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.017 (0.123)  Loss:  0.8291 (1.1106)  Acc@1: 87.5000 (74.9600)  Acc@5: 100.0000 (94.9300)
Test: [Whole Val]  Time: 9.708  Loss: 1.1106  Acc@1: 74.9600 Pruned: 50.84% 
Test (EMA): [   0/78]  Time: 0.415 (0.415)  Loss:  1.0928 (1.0928)  Acc@1: 76.5625 (76.5625)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  0.8462 (1.1110)  Acc@1: 87.5000 (75.2200)  Acc@5: 100.0000 (94.8200)
Test (EMA): [Whole Val]  Time: 9.739  Loss: 1.1110  Acc@1: 75.2200 Pruned: 50.84% 
Train: 93 [   0/390 (  0%)]  Loss: 2.734 (2.73)  Time: 0.790s,  162.10/s  (0.790s,  162.10/s)  LR: 3.738e-04  Data: 0.485 (0.485)
Train: 93 [ 100/390 ( 26%)]  Loss: 2.417 (3.21)  Time: 0.317s,  403.58/s  (0.320s,  399.41/s)  LR: 3.738e-04  Data: 0.013 (0.018)
Train: 93 [ 200/390 ( 51%)]  Loss: 3.463 (3.20)  Time: 0.316s,  405.10/s  (0.318s,  402.52/s)  LR: 3.738e-04  Data: 0.012 (0.015)
Train: 93 [ 300/390 ( 77%)]  Loss: 3.458 (3.21)  Time: 0.314s,  407.16/s  (0.317s,  403.22/s)  LR: 3.738e-04  Data: 0.012 (0.014)
Train: 93 [ 389/390 (100%)]  Loss: 3.362 (3.22)  Time: 0.303s,  422.05/s  (0.317s,  403.76/s)  LR: 3.738e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.420 (0.420)  Loss:  1.0488 (1.0488)  Acc@1: 73.4375 (73.4375)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.018 (0.124)  Loss:  0.7080 (1.0493)  Acc@1: 93.7500 (74.8400)  Acc@5: 100.0000 (95.2400)
Test: [Whole Val]  Time: 9.795  Loss: 1.0493  Acc@1: 74.8400 Pruned: 50.82% 
Test (EMA): [   0/78]  Time: 0.327 (0.327)  Loss:  1.0791 (1.0791)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.7437 (1.0631)  Acc@1: 93.7500 (75.1700)  Acc@5: 100.0000 (95.0400)
Test (EMA): [Whole Val]  Time: 9.639  Loss: 1.0631  Acc@1: 75.1700 Pruned: 50.82% 
Train: 94 [   0/390 (  0%)]  Loss: 2.262 (2.26)  Time: 0.867s,  147.61/s  (0.867s,  147.61/s)  LR: 3.643e-04  Data: 0.562 (0.562)
Train: 94 [ 100/390 ( 26%)]  Loss: 3.657 (3.22)  Time: 0.314s,  407.65/s  (0.321s,  398.82/s)  LR: 3.643e-04  Data: 0.012 (0.018)
Train: 94 [ 200/390 ( 51%)]  Loss: 3.395 (3.23)  Time: 0.313s,  408.88/s  (0.318s,  402.32/s)  LR: 3.643e-04  Data: 0.011 (0.015)
Train: 94 [ 300/390 ( 77%)]  Loss: 3.736 (3.24)  Time: 0.313s,  408.48/s  (0.318s,  403.00/s)  LR: 3.643e-04  Data: 0.011 (0.014)
Train: 94 [ 389/390 (100%)]  Loss: 3.467 (3.24)  Time: 0.301s,  425.19/s  (0.317s,  403.64/s)  LR: 3.643e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.355 (0.355)  Loss:  1.0518 (1.0518)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  0.8491 (1.0706)  Acc@1: 75.0000 (75.2200)  Acc@5: 93.7500 (95.1300)
Test: [Whole Val]  Time: 9.705  Loss: 1.0706  Acc@1: 75.2200 Pruned: 50.82% 
Test (EMA): [   0/78]  Time: 0.402 (0.402)  Loss:  1.0352 (1.0352)  Acc@1: 75.7812 (75.7812)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.124)  Loss:  0.8105 (1.0517)  Acc@1: 75.0000 (75.4000)  Acc@5: 100.0000 (95.2200)
Test (EMA): [Whole Val]  Time: 9.765  Loss: 1.0517  Acc@1: 75.4000 Pruned: 50.83% 
Train: 95 [   0/390 (  0%)]  Loss: 3.506 (3.51)  Time: 0.748s,  171.16/s  (0.748s,  171.16/s)  LR: 3.549e-04  Data: 0.434 (0.434)
Train: 95 [ 100/390 ( 26%)]  Loss: 3.809 (3.28)  Time: 0.316s,  405.67/s  (0.319s,  400.65/s)  LR: 3.549e-04  Data: 0.012 (0.017)
Train: 95 [ 200/390 ( 51%)]  Loss: 3.571 (3.26)  Time: 0.316s,  405.02/s  (0.318s,  402.98/s)  LR: 3.549e-04  Data: 0.013 (0.015)
Train: 95 [ 300/390 ( 77%)]  Loss: 3.754 (3.24)  Time: 0.317s,  404.10/s  (0.317s,  403.68/s)  LR: 3.549e-04  Data: 0.013 (0.014)
Train: 95 [ 389/390 (100%)]  Loss: 2.691 (3.24)  Time: 0.303s,  422.86/s  (0.317s,  403.96/s)  LR: 3.549e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.425 (0.425)  Loss:  1.0674 (1.0674)  Acc@1: 72.6562 (72.6562)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  0.7871 (1.0876)  Acc@1: 93.7500 (74.4100)  Acc@5: 100.0000 (94.7800)
Test: [Whole Val]  Time: 9.750  Loss: 1.0876  Acc@1: 74.4100 Pruned: 50.82% 
Test (EMA): [   0/78]  Time: 0.418 (0.418)  Loss:  1.0469 (1.0469)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  0.7568 (1.0578)  Acc@1: 87.5000 (74.9600)  Acc@5: 100.0000 (95.0900)
Test (EMA): [Whole Val]  Time: 9.751  Loss: 1.0578  Acc@1: 74.9600 Pruned: 50.83% 
Train: 96 [   0/390 (  0%)]  Loss: 3.777 (3.78)  Time: 0.889s,  144.01/s  (0.889s,  144.01/s)  LR: 3.456e-04  Data: 0.580 (0.580)
Train: 96 [ 100/390 ( 26%)]  Loss: 3.779 (3.22)  Time: 0.315s,  406.08/s  (0.321s,  398.52/s)  LR: 3.456e-04  Data: 0.013 (0.018)
Train: 96 [ 200/390 ( 51%)]  Loss: 3.872 (3.25)  Time: 0.317s,  403.35/s  (0.318s,  402.08/s)  LR: 3.456e-04  Data: 0.013 (0.015)
Train: 96 [ 300/390 ( 77%)]  Loss: 2.286 (3.22)  Time: 0.314s,  407.87/s  (0.317s,  403.25/s)  LR: 3.456e-04  Data: 0.012 (0.014)
Train: 96 [ 389/390 (100%)]  Loss: 3.449 (3.23)  Time: 0.303s,  422.53/s  (0.317s,  403.87/s)  LR: 3.456e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.425 (0.425)  Loss:  1.0420 (1.0420)  Acc@1: 76.5625 (76.5625)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.017 (0.123)  Loss:  0.7744 (1.0573)  Acc@1: 75.0000 (75.0500)  Acc@5: 100.0000 (95.1300)
Test: [Whole Val]  Time: 9.751  Loss: 1.0573  Acc@1: 75.0500 Pruned: 50.83% 
Test (EMA): [   0/78]  Time: 0.318 (0.318)  Loss:  1.0371 (1.0371)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.8037 (1.0592)  Acc@1: 75.0000 (75.2600)  Acc@5: 100.0000 (95.1900)
Test (EMA): [Whole Val]  Time: 9.670  Loss: 1.0592  Acc@1: 75.2600 Pruned: 50.83% 
Train: 97 [   0/390 (  0%)]  Loss: 3.351 (3.35)  Time: 0.741s,  172.66/s  (0.741s,  172.66/s)  LR: 3.363e-04  Data: 0.437 (0.437)
Train: 97 [ 100/390 ( 26%)]  Loss: 3.805 (3.28)  Time: 0.314s,  407.10/s  (0.320s,  400.62/s)  LR: 3.363e-04  Data: 0.012 (0.017)
Train: 97 [ 200/390 ( 51%)]  Loss: 3.382 (3.27)  Time: 0.313s,  408.70/s  (0.317s,  403.24/s)  LR: 3.363e-04  Data: 0.012 (0.015)
Train: 97 [ 300/390 ( 77%)]  Loss: 2.617 (3.27)  Time: 0.314s,  407.89/s  (0.317s,  403.83/s)  LR: 3.363e-04  Data: 0.012 (0.014)
Train: 97 [ 389/390 (100%)]  Loss: 3.858 (3.28)  Time: 0.302s,  423.92/s  (0.317s,  404.02/s)  LR: 3.363e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.350 (0.350)  Loss:  1.0771 (1.0771)  Acc@1: 75.7812 (75.7812)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  0.7256 (1.0732)  Acc@1: 87.5000 (74.8000)  Acc@5: 100.0000 (94.8800)
Test: [Whole Val]  Time: 9.684  Loss: 1.0732  Acc@1: 74.8000 Pruned: 50.82% 
Test (EMA): [   0/78]  Time: 0.325 (0.325)  Loss:  1.0557 (1.0557)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.7432 (1.0505)  Acc@1: 81.2500 (75.3700)  Acc@5: 100.0000 (94.9900)
Test (EMA): [Whole Val]  Time: 9.667  Loss: 1.0505  Acc@1: 75.3700 Pruned: 50.82% 
Train: 98 [   0/390 (  0%)]  Loss: 2.952 (2.95)  Time: 0.831s,  154.04/s  (0.831s,  154.04/s)  LR: 3.270e-04  Data: 0.523 (0.523)
Train: 98 [ 100/390 ( 26%)]  Loss: 3.827 (3.26)  Time: 0.314s,  407.57/s  (0.324s,  395.01/s)  LR: 3.270e-04  Data: 0.011 (0.019)
Train: 98 [ 200/390 ( 51%)]  Loss: 3.310 (3.24)  Time: 0.314s,  407.43/s  (0.320s,  400.09/s)  LR: 3.270e-04  Data: 0.012 (0.016)
Train: 98 [ 300/390 ( 77%)]  Loss: 3.517 (3.22)  Time: 0.319s,  401.61/s  (0.319s,  401.85/s)  LR: 3.270e-04  Data: 0.015 (0.015)
Train: 98 [ 389/390 (100%)]  Loss: 3.474 (3.22)  Time: 0.302s,  423.47/s  (0.318s,  402.71/s)  LR: 3.270e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.423 (0.423)  Loss:  1.0771 (1.0771)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.124)  Loss:  0.7910 (1.0655)  Acc@1: 81.2500 (75.1000)  Acc@5: 93.7500 (94.9200)
Test: [Whole Val]  Time: 9.772  Loss: 1.0655  Acc@1: 75.1000 Pruned: 50.81% 
Test (EMA): [   0/78]  Time: 0.319 (0.319)  Loss:  1.0576 (1.0576)  Acc@1: 75.7812 (75.7812)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.7300 (1.0470)  Acc@1: 87.5000 (75.3200)  Acc@5: 100.0000 (95.0400)
Test (EMA): [Whole Val]  Time: 9.676  Loss: 1.0470  Acc@1: 75.3200 Pruned: 50.82% 
Train: 99 [   0/390 (  0%)]  Loss: 2.653 (2.65)  Time: 0.783s,  163.42/s  (0.783s,  163.42/s)  LR: 3.178e-04  Data: 0.471 (0.471)
Train: 99 [ 100/390 ( 26%)]  Loss: 3.302 (3.21)  Time: 0.313s,  408.39/s  (0.321s,  398.87/s)  LR: 3.178e-04  Data: 0.012 (0.017)
Train: 99 [ 200/390 ( 51%)]  Loss: 2.838 (3.20)  Time: 0.314s,  407.21/s  (0.318s,  402.34/s)  LR: 3.178e-04  Data: 0.012 (0.015)
Train: 99 [ 300/390 ( 77%)]  Loss: 3.454 (3.24)  Time: 0.317s,  403.70/s  (0.317s,  403.41/s)  LR: 3.178e-04  Data: 0.013 (0.014)
Train: 99 [ 389/390 (100%)]  Loss: 3.749 (3.25)  Time: 0.303s,  422.56/s  (0.317s,  404.07/s)  LR: 3.178e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.364 (0.364)  Loss:  1.0479 (1.0479)  Acc@1: 75.0000 (75.0000)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  0.7422 (1.0744)  Acc@1: 87.5000 (74.7900)  Acc@5: 93.7500 (94.8500)
Test: [Whole Val]  Time: 9.689  Loss: 1.0744  Acc@1: 74.7900 Pruned: 50.82% 
Test (EMA): [   0/78]  Time: 0.304 (0.304)  Loss:  1.0420 (1.0420)  Acc@1: 75.7812 (75.7812)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.7568 (1.0712)  Acc@1: 93.7500 (74.9700)  Acc@5: 93.7500 (95.0100)
Test (EMA): [Whole Val]  Time: 9.672  Loss: 1.0712  Acc@1: 74.9700 Pruned: 50.82% 
Train: 100 [   0/390 (  0%)]  Loss: 3.569 (3.57)  Time: 0.924s,  138.49/s  (0.924s,  138.49/s)  LR: 3.087e-04  Data: 0.597 (0.597)
Train: 100 [ 100/390 ( 26%)]  Loss: 3.592 (3.22)  Time: 0.315s,  406.19/s  (0.322s,  397.74/s)  LR: 3.087e-04  Data: 0.012 (0.018)
Train: 100 [ 200/390 ( 51%)]  Loss: 3.734 (3.26)  Time: 0.316s,  405.36/s  (0.318s,  402.06/s)  LR: 3.087e-04  Data: 0.013 (0.015)
Train: 100 [ 300/390 ( 77%)]  Loss: 2.528 (3.25)  Time: 0.314s,  407.52/s  (0.318s,  403.09/s)  LR: 3.087e-04  Data: 0.012 (0.015)
Train: 100 [ 389/390 (100%)]  Loss: 3.308 (3.23)  Time: 0.303s,  421.75/s  (0.317s,  403.69/s)  LR: 3.087e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.403 (0.403)  Loss:  1.0791 (1.0791)  Acc@1: 72.6562 (72.6562)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.124)  Loss:  0.8159 (1.0762)  Acc@1: 87.5000 (75.0300)  Acc@5: 93.7500 (94.9200)
Test: [Whole Val]  Time: 9.763  Loss: 1.0762  Acc@1: 75.0300 Pruned: 50.82% 
Test (EMA): [   0/78]  Time: 0.382 (0.382)  Loss:  1.0537 (1.0537)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  0.7842 (1.0447)  Acc@1: 81.2500 (75.5100)  Acc@5: 93.7500 (95.0700)
Test (EMA): [Whole Val]  Time: 9.711  Loss: 1.0447  Acc@1: 75.5100 Pruned: 50.83% 
Train: 101 [   0/390 (  0%)]  Loss: 3.634 (3.63)  Time: 0.910s,  140.60/s  (0.910s,  140.60/s)  LR: 2.997e-04  Data: 0.607 (0.607)
Train: 101 [ 100/390 ( 26%)]  Loss: 3.433 (3.28)  Time: 0.314s,  407.43/s  (0.323s,  396.02/s)  LR: 2.997e-04  Data: 0.012 (0.019)
Train: 101 [ 200/390 ( 51%)]  Loss: 3.429 (3.25)  Time: 0.317s,  403.30/s  (0.320s,  400.58/s)  LR: 2.997e-04  Data: 0.013 (0.016)
Train: 101 [ 300/390 ( 77%)]  Loss: 3.138 (3.25)  Time: 0.316s,  404.60/s  (0.318s,  402.31/s)  LR: 2.997e-04  Data: 0.012 (0.015)
Train: 101 [ 389/390 (100%)]  Loss: 3.597 (3.24)  Time: 0.302s,  423.93/s  (0.318s,  403.06/s)  LR: 2.997e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.334 (0.334)  Loss:  1.0947 (1.0947)  Acc@1: 72.6562 (72.6562)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.8188 (1.0824)  Acc@1: 81.2500 (75.5100)  Acc@5: 93.7500 (95.0300)
Test: [Whole Val]  Time: 9.646  Loss: 1.0824  Acc@1: 75.5100 Pruned: 50.81% 
Test (EMA): [   0/78]  Time: 0.371 (0.371)  Loss:  1.0898 (1.0898)  Acc@1: 73.4375 (73.4375)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  0.7876 (1.0748)  Acc@1: 87.5000 (75.7500)  Acc@5: 93.7500 (95.0800)
Test (EMA): [Whole Val]  Time: 9.725  Loss: 1.0748  Acc@1: 75.7500 Pruned: 50.81% 
Train: 102 [   0/390 (  0%)]  Loss: 2.882 (2.88)  Time: 0.791s,  161.85/s  (0.791s,  161.85/s)  LR: 2.907e-04  Data: 0.484 (0.484)
Train: 102 [ 100/390 ( 26%)]  Loss: 3.597 (3.26)  Time: 0.313s,  408.86/s  (0.320s,  399.62/s)  LR: 2.907e-04  Data: 0.012 (0.017)
Train: 102 [ 200/390 ( 51%)]  Loss: 3.564 (3.27)  Time: 0.314s,  407.03/s  (0.318s,  402.44/s)  LR: 2.907e-04  Data: 0.012 (0.015)
Train: 102 [ 300/390 ( 77%)]  Loss: 3.586 (3.24)  Time: 0.318s,  402.28/s  (0.317s,  403.38/s)  LR: 2.907e-04  Data: 0.012 (0.014)
Train: 102 [ 389/390 (100%)]  Loss: 2.975 (3.25)  Time: 0.304s,  421.07/s  (0.317s,  404.10/s)  LR: 2.907e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.417 (0.417)  Loss:  1.1133 (1.1133)  Acc@1: 75.7812 (75.7812)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.124)  Loss:  0.8691 (1.0998)  Acc@1: 75.0000 (75.3900)  Acc@5: 100.0000 (94.9900)
Test: [Whole Val]  Time: 9.774  Loss: 1.0998  Acc@1: 75.3900 Pruned: 50.82% 
Test (EMA): [   0/78]  Time: 0.393 (0.393)  Loss:  1.1104 (1.1104)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  0.8335 (1.0960)  Acc@1: 81.2500 (75.5500)  Acc@5: 100.0000 (95.1700)
Test (EMA): [Whole Val]  Time: 9.748  Loss: 1.0960  Acc@1: 75.5500 Pruned: 50.82% 
Train: 103 [   0/390 (  0%)]  Loss: 3.534 (3.53)  Time: 0.786s,  162.95/s  (0.786s,  162.95/s)  LR: 2.819e-04  Data: 0.475 (0.475)
Train: 103 [ 100/390 ( 26%)]  Loss: 2.796 (3.20)  Time: 0.318s,  402.98/s  (0.320s,  400.30/s)  LR: 2.819e-04  Data: 0.013 (0.017)
Train: 103 [ 200/390 ( 51%)]  Loss: 3.336 (3.21)  Time: 0.317s,  403.88/s  (0.319s,  401.42/s)  LR: 2.819e-04  Data: 0.012 (0.015)
Train: 103 [ 300/390 ( 77%)]  Loss: 2.901 (3.21)  Time: 0.316s,  404.98/s  (0.318s,  402.44/s)  LR: 2.819e-04  Data: 0.012 (0.014)
Train: 103 [ 389/390 (100%)]  Loss: 3.472 (3.21)  Time: 0.305s,  419.90/s  (0.318s,  402.86/s)  LR: 2.819e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.387 (0.387)  Loss:  1.0107 (1.0107)  Acc@1: 75.7812 (75.7812)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.124)  Loss:  0.7622 (1.0426)  Acc@1: 87.5000 (75.2500)  Acc@5: 100.0000 (94.9000)
Test: [Whole Val]  Time: 9.783  Loss: 1.0426  Acc@1: 75.2500 Pruned: 50.81% 
Test (EMA): [   0/78]  Time: 0.407 (0.407)  Loss:  1.0098 (1.0098)  Acc@1: 76.5625 (76.5625)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.018 (0.125)  Loss:  0.7563 (1.0331)  Acc@1: 87.5000 (75.4500)  Acc@5: 100.0000 (95.0200)
Test (EMA): [Whole Val]  Time: 9.837  Loss: 1.0331  Acc@1: 75.4500 Pruned: 50.81% 
Train: 104 [   0/390 (  0%)]  Loss: 3.420 (3.42)  Time: 0.864s,  148.14/s  (0.864s,  148.14/s)  LR: 2.731e-04  Data: 0.560 (0.560)
Train: 104 [ 100/390 ( 26%)]  Loss: 3.473 (3.25)  Time: 0.316s,  405.41/s  (0.322s,  397.66/s)  LR: 2.731e-04  Data: 0.012 (0.018)
Train: 104 [ 200/390 ( 51%)]  Loss: 2.926 (3.23)  Time: 0.316s,  405.09/s  (0.320s,  399.73/s)  LR: 2.731e-04  Data: 0.013 (0.016)
Train: 104 [ 300/390 ( 77%)]  Loss: 2.664 (3.23)  Time: 0.319s,  401.43/s  (0.319s,  401.73/s)  LR: 2.731e-04  Data: 0.012 (0.015)
Train: 104 [ 389/390 (100%)]  Loss: 2.352 (3.24)  Time: 0.305s,  420.25/s  (0.318s,  402.55/s)  LR: 2.731e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.392 (0.392)  Loss:  1.0439 (1.0439)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.124)  Loss:  0.7642 (1.0546)  Acc@1: 81.2500 (75.6500)  Acc@5: 100.0000 (95.3400)
Test: [Whole Val]  Time: 9.775  Loss: 1.0546  Acc@1: 75.6500 Pruned: 50.81% 
Test (EMA): [   0/78]  Time: 0.439 (0.439)  Loss:  1.0645 (1.0645)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.018 (0.124)  Loss:  0.8042 (1.0684)  Acc@1: 81.2500 (75.4900)  Acc@5: 100.0000 (95.2000)
Test (EMA): [Whole Val]  Time: 9.799  Loss: 1.0684  Acc@1: 75.4900 Pruned: 50.81% 
Train: 105 [   0/390 (  0%)]  Loss: 3.725 (3.73)  Time: 0.968s,  132.27/s  (0.968s,  132.27/s)  LR: 2.644e-04  Data: 0.653 (0.653)
Train: 105 [ 100/390 ( 26%)]  Loss: 3.460 (3.22)  Time: 0.313s,  409.32/s  (0.322s,  397.00/s)  LR: 2.644e-04  Data: 0.011 (0.019)
Train: 105 [ 200/390 ( 51%)]  Loss: 3.769 (3.21)  Time: 0.317s,  404.40/s  (0.319s,  400.85/s)  LR: 2.644e-04  Data: 0.013 (0.016)
Train: 105 [ 300/390 ( 77%)]  Loss: 2.924 (3.23)  Time: 0.316s,  405.12/s  (0.318s,  402.25/s)  LR: 2.644e-04  Data: 0.014 (0.015)
Train: 105 [ 389/390 (100%)]  Loss: 3.371 (3.23)  Time: 0.302s,  423.85/s  (0.318s,  402.90/s)  LR: 2.644e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.385 (0.385)  Loss:  1.0762 (1.0762)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.020 (0.123)  Loss:  0.8096 (1.0883)  Acc@1: 81.2500 (75.0900)  Acc@5: 100.0000 (94.9600)
Test: [Whole Val]  Time: 9.710  Loss: 1.0883  Acc@1: 75.0900 Pruned: 50.81% 
Test (EMA): [   0/78]  Time: 0.379 (0.379)  Loss:  1.0664 (1.0664)  Acc@1: 75.7812 (75.7812)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  0.7954 (1.0774)  Acc@1: 87.5000 (75.5900)  Acc@5: 100.0000 (95.2100)
Test (EMA): [Whole Val]  Time: 9.719  Loss: 1.0774  Acc@1: 75.5900 Pruned: 50.81% 
Train: 106 [   0/390 (  0%)]  Loss: 2.765 (2.77)  Time: 0.924s,  138.51/s  (0.924s,  138.51/s)  LR: 2.558e-04  Data: 0.621 (0.621)
Train: 106 [ 100/390 ( 26%)]  Loss: 3.853 (3.26)  Time: 0.315s,  406.25/s  (0.322s,  397.70/s)  LR: 2.558e-04  Data: 0.012 (0.019)
Train: 106 [ 200/390 ( 51%)]  Loss: 3.594 (3.24)  Time: 0.317s,  403.42/s  (0.319s,  401.19/s)  LR: 2.558e-04  Data: 0.015 (0.016)
Train: 106 [ 300/390 ( 77%)]  Loss: 3.603 (3.25)  Time: 0.316s,  405.09/s  (0.318s,  402.41/s)  LR: 2.558e-04  Data: 0.013 (0.015)
Train: 106 [ 389/390 (100%)]  Loss: 2.216 (3.23)  Time: 0.303s,  421.98/s  (0.318s,  403.12/s)  LR: 2.558e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.370 (0.370)  Loss:  1.0273 (1.0273)  Acc@1: 76.5625 (76.5625)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  0.7725 (1.0532)  Acc@1: 81.2500 (75.1300)  Acc@5: 100.0000 (95.1200)
Test: [Whole Val]  Time: 9.707  Loss: 1.0532  Acc@1: 75.1300 Pruned: 50.80% 
Test (EMA): [   0/78]  Time: 0.369 (0.369)  Loss:  1.0215 (1.0215)  Acc@1: 78.1250 (78.1250)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  0.7803 (1.0404)  Acc@1: 81.2500 (75.5800)  Acc@5: 100.0000 (95.2300)
Test (EMA): [Whole Val]  Time: 9.686  Loss: 1.0404  Acc@1: 75.5800 Pruned: 50.80% 
Train: 107 [   0/390 (  0%)]  Loss: 3.110 (3.11)  Time: 0.775s,  165.26/s  (0.775s,  165.26/s)  LR: 2.472e-04  Data: 0.471 (0.471)
Train: 107 [ 100/390 ( 26%)]  Loss: 3.554 (3.20)  Time: 0.313s,  408.41/s  (0.320s,  399.49/s)  LR: 2.472e-04  Data: 0.012 (0.017)
Train: 107 [ 200/390 ( 51%)]  Loss: 3.667 (3.20)  Time: 0.315s,  405.96/s  (0.318s,  402.78/s)  LR: 2.472e-04  Data: 0.011 (0.015)
Train: 107 [ 300/390 ( 77%)]  Loss: 2.900 (3.18)  Time: 0.314s,  407.35/s  (0.317s,  403.26/s)  LR: 2.472e-04  Data: 0.012 (0.014)
Train: 107 [ 389/390 (100%)]  Loss: 3.302 (3.18)  Time: 0.303s,  421.93/s  (0.317s,  403.88/s)  LR: 2.472e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.429 (0.429)  Loss:  1.0449 (1.0449)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  0.7393 (1.0408)  Acc@1: 81.2500 (74.5300)  Acc@5: 100.0000 (94.7900)
Test: [Whole Val]  Time: 9.747  Loss: 1.0408  Acc@1: 74.5300 Pruned: 50.81% 
Test (EMA): [   0/78]  Time: 0.432 (0.432)  Loss:  1.0361 (1.0361)  Acc@1: 72.6562 (72.6562)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.018 (0.124)  Loss:  0.7568 (1.0396)  Acc@1: 81.2500 (75.0900)  Acc@5: 100.0000 (95.0300)
Test (EMA): [Whole Val]  Time: 9.765  Loss: 1.0396  Acc@1: 75.0900 Pruned: 50.81% 
Train: 108 [   0/390 (  0%)]  Loss: 3.437 (3.44)  Time: 0.916s,  139.79/s  (0.916s,  139.79/s)  LR: 2.388e-04  Data: 0.615 (0.615)
Train: 108 [ 100/390 ( 26%)]  Loss: 3.812 (3.24)  Time: 0.315s,  405.94/s  (0.321s,  398.23/s)  LR: 2.388e-04  Data: 0.013 (0.018)
Train: 108 [ 200/390 ( 51%)]  Loss: 2.299 (3.19)  Time: 0.317s,  403.54/s  (0.319s,  401.70/s)  LR: 2.388e-04  Data: 0.013 (0.016)
Train: 108 [ 300/390 ( 77%)]  Loss: 2.408 (3.22)  Time: 0.316s,  404.74/s  (0.318s,  402.75/s)  LR: 2.388e-04  Data: 0.012 (0.015)
Train: 108 [ 389/390 (100%)]  Loss: 2.555 (3.23)  Time: 0.302s,  423.85/s  (0.317s,  403.52/s)  LR: 2.388e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.357 (0.357)  Loss:  1.0303 (1.0303)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  0.7378 (1.0622)  Acc@1: 87.5000 (75.5800)  Acc@5: 100.0000 (95.1800)
Test: [Whole Val]  Time: 9.700  Loss: 1.0622  Acc@1: 75.5800 Pruned: 50.80% 
Test (EMA): [   0/78]  Time: 0.363 (0.363)  Loss:  1.0342 (1.0342)  Acc@1: 75.7812 (75.7812)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  0.7734 (1.0596)  Acc@1: 81.2500 (75.9100)  Acc@5: 100.0000 (95.3100)
Test (EMA): [Whole Val]  Time: 9.694  Loss: 1.0596  Acc@1: 75.9100 Pruned: 50.80% 
Train: 109 [   0/390 (  0%)]  Loss: 3.834 (3.83)  Time: 0.847s,  151.16/s  (0.847s,  151.16/s)  LR: 2.305e-04  Data: 0.516 (0.516)
Train: 109 [ 100/390 ( 26%)]  Loss: 2.467 (3.21)  Time: 0.314s,  407.78/s  (0.321s,  399.23/s)  LR: 2.305e-04  Data: 0.012 (0.017)
Train: 109 [ 200/390 ( 51%)]  Loss: 2.892 (3.20)  Time: 0.313s,  409.32/s  (0.318s,  402.31/s)  LR: 2.305e-04  Data: 0.011 (0.015)
Train: 109 [ 300/390 ( 77%)]  Loss: 2.762 (3.19)  Time: 0.314s,  407.53/s  (0.317s,  403.32/s)  LR: 2.305e-04  Data: 0.012 (0.014)
Train: 109 [ 389/390 (100%)]  Loss: 3.128 (3.19)  Time: 0.304s,  421.58/s  (0.317s,  404.07/s)  LR: 2.305e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.418 (0.418)  Loss:  1.0498 (1.0498)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.124)  Loss:  0.7349 (1.0467)  Acc@1: 81.2500 (75.5000)  Acc@5: 100.0000 (95.0400)
Test: [Whole Val]  Time: 9.768  Loss: 1.0467  Acc@1: 75.5000 Pruned: 50.80% 
Test (EMA): [   0/78]  Time: 0.442 (0.442)  Loss:  1.0488 (1.0488)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.124)  Loss:  0.7515 (1.0485)  Acc@1: 75.0000 (75.7600)  Acc@5: 100.0000 (95.0700)
Test (EMA): [Whole Val]  Time: 9.775  Loss: 1.0485  Acc@1: 75.7600 Pruned: 50.80% 
Train: 110 [   0/390 (  0%)]  Loss: 3.512 (3.51)  Time: 0.815s,  157.03/s  (0.815s,  157.03/s)  LR: 2.223e-04  Data: 0.502 (0.502)
Train: 110 [ 100/390 ( 26%)]  Loss: 3.867 (3.18)  Time: 0.316s,  405.61/s  (0.321s,  398.67/s)  LR: 2.223e-04  Data: 0.013 (0.018)
Train: 110 [ 200/390 ( 51%)]  Loss: 3.408 (3.24)  Time: 0.316s,  405.42/s  (0.318s,  402.19/s)  LR: 2.223e-04  Data: 0.013 (0.015)
Train: 110 [ 300/390 ( 77%)]  Loss: 3.547 (3.23)  Time: 0.313s,  408.79/s  (0.317s,  403.31/s)  LR: 2.223e-04  Data: 0.012 (0.014)
Train: 110 [ 389/390 (100%)]  Loss: 3.078 (3.22)  Time: 0.303s,  422.61/s  (0.318s,  403.14/s)  LR: 2.223e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.414 (0.414)  Loss:  1.0859 (1.0859)  Acc@1: 75.7812 (75.7812)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.124)  Loss:  0.7871 (1.0851)  Acc@1: 87.5000 (75.5500)  Acc@5: 100.0000 (95.3300)
Test: [Whole Val]  Time: 9.787  Loss: 1.0851  Acc@1: 75.5500 Pruned: 50.80% 
Test (EMA): [   0/78]  Time: 0.319 (0.319)  Loss:  1.0791 (1.0791)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.7827 (1.0662)  Acc@1: 87.5000 (75.8200)  Acc@5: 100.0000 (95.2600)
Test (EMA): [Whole Val]  Time: 9.659  Loss: 1.0662  Acc@1: 75.8200 Pruned: 50.80% 
Train: 111 [   0/390 (  0%)]  Loss: 3.269 (3.27)  Time: 0.752s,  170.20/s  (0.752s,  170.20/s)  LR: 2.142e-04  Data: 0.447 (0.447)
Train: 111 [ 100/390 ( 26%)]  Loss: 3.578 (3.10)  Time: 0.314s,  407.67/s  (0.320s,  400.33/s)  LR: 2.142e-04  Data: 0.012 (0.017)
Train: 111 [ 200/390 ( 51%)]  Loss: 3.589 (3.14)  Time: 0.320s,  400.34/s  (0.318s,  402.77/s)  LR: 2.142e-04  Data: 0.017 (0.015)
Train: 111 [ 300/390 ( 77%)]  Loss: 2.716 (3.17)  Time: 0.316s,  405.19/s  (0.317s,  403.95/s)  LR: 2.142e-04  Data: 0.013 (0.014)
Train: 111 [ 389/390 (100%)]  Loss: 3.283 (3.19)  Time: 0.308s,  416.02/s  (0.317s,  404.29/s)  LR: 2.142e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.424 (0.424)  Loss:  1.0645 (1.0645)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.124)  Loss:  0.8013 (1.0805)  Acc@1: 81.2500 (75.3200)  Acc@5: 100.0000 (95.0400)
Test: [Whole Val]  Time: 9.782  Loss: 1.0805  Acc@1: 75.3200 Pruned: 50.79% 
Test (EMA): [   0/78]  Time: 0.366 (0.366)  Loss:  1.0488 (1.0488)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  0.8086 (1.0673)  Acc@1: 75.0000 (75.3600)  Acc@5: 100.0000 (95.1900)
Test (EMA): [Whole Val]  Time: 9.692  Loss: 1.0673  Acc@1: 75.3600 Pruned: 50.80% 
Train: 112 [   0/390 (  0%)]  Loss: 3.551 (3.55)  Time: 0.775s,  165.13/s  (0.775s,  165.13/s)  LR: 2.062e-04  Data: 0.465 (0.465)
Train: 112 [ 100/390 ( 26%)]  Loss: 3.078 (3.24)  Time: 0.316s,  405.35/s  (0.320s,  400.23/s)  LR: 2.062e-04  Data: 0.013 (0.017)
Train: 112 [ 200/390 ( 51%)]  Loss: 3.515 (3.22)  Time: 0.317s,  403.57/s  (0.318s,  402.83/s)  LR: 2.062e-04  Data: 0.011 (0.015)
Train: 112 [ 300/390 ( 77%)]  Loss: 2.750 (3.21)  Time: 0.318s,  402.71/s  (0.317s,  403.68/s)  LR: 2.062e-04  Data: 0.013 (0.014)
Train: 112 [ 389/390 (100%)]  Loss: 3.311 (3.20)  Time: 0.304s,  421.72/s  (0.317s,  404.28/s)  LR: 2.062e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.349 (0.349)  Loss:  1.0195 (1.0195)  Acc@1: 74.2188 (74.2188)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  0.7207 (1.0133)  Acc@1: 75.0000 (75.8400)  Acc@5: 100.0000 (95.2400)
Test: [Whole Val]  Time: 9.700  Loss: 1.0133  Acc@1: 75.8400 Pruned: 50.79% 
Test (EMA): [   0/78]  Time: 0.417 (0.417)  Loss:  1.0195 (1.0195)  Acc@1: 75.0000 (75.0000)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.018 (0.124)  Loss:  0.7354 (1.0221)  Acc@1: 81.2500 (75.9200)  Acc@5: 93.7500 (95.2200)
Test (EMA): [Whole Val]  Time: 9.774  Loss: 1.0221  Acc@1: 75.9200 Pruned: 50.79% 
Train: 113 [   0/390 (  0%)]  Loss: 3.869 (3.87)  Time: 0.845s,  151.46/s  (0.845s,  151.46/s)  LR: 1.983e-04  Data: 0.542 (0.542)
Train: 113 [ 100/390 ( 26%)]  Loss: 2.890 (3.21)  Time: 0.313s,  408.58/s  (0.321s,  399.15/s)  LR: 1.983e-04  Data: 0.011 (0.018)
Train: 113 [ 200/390 ( 51%)]  Loss: 3.556 (3.20)  Time: 0.314s,  407.40/s  (0.318s,  402.49/s)  LR: 1.983e-04  Data: 0.012 (0.015)
Train: 113 [ 300/390 ( 77%)]  Loss: 3.711 (3.19)  Time: 0.315s,  406.70/s  (0.317s,  403.79/s)  LR: 1.983e-04  Data: 0.013 (0.014)
Train: 113 [ 389/390 (100%)]  Loss: 2.543 (3.21)  Time: 0.303s,  422.30/s  (0.316s,  404.55/s)  LR: 1.983e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.386 (0.386)  Loss:  1.0342 (1.0342)  Acc@1: 76.5625 (76.5625)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  0.7627 (1.0599)  Acc@1: 81.2500 (75.4700)  Acc@5: 100.0000 (95.1200)
Test: [Whole Val]  Time: 9.726  Loss: 1.0599  Acc@1: 75.4700 Pruned: 50.79% 
Test (EMA): [   0/78]  Time: 0.368 (0.368)  Loss:  1.0303 (1.0303)  Acc@1: 76.5625 (76.5625)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  0.7568 (1.0592)  Acc@1: 87.5000 (75.5100)  Acc@5: 100.0000 (95.0000)
Test (EMA): [Whole Val]  Time: 9.728  Loss: 1.0592  Acc@1: 75.5100 Pruned: 50.79% 
Train: 114 [   0/390 (  0%)]  Loss: 3.560 (3.56)  Time: 0.873s,  146.62/s  (0.873s,  146.62/s)  LR: 1.905e-04  Data: 0.570 (0.570)
Train: 114 [ 100/390 ( 26%)]  Loss: 3.600 (3.27)  Time: 0.313s,  408.37/s  (0.322s,  397.43/s)  LR: 1.905e-04  Data: 0.012 (0.018)
Train: 114 [ 200/390 ( 51%)]  Loss: 2.550 (3.22)  Time: 0.322s,  397.10/s  (0.319s,  401.43/s)  LR: 1.905e-04  Data: 0.013 (0.015)
Train: 114 [ 300/390 ( 77%)]  Loss: 2.629 (3.21)  Time: 0.314s,  407.98/s  (0.318s,  402.59/s)  LR: 1.905e-04  Data: 0.012 (0.015)
Train: 114 [ 389/390 (100%)]  Loss: 3.710 (3.22)  Time: 0.302s,  423.53/s  (0.317s,  403.33/s)  LR: 1.905e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.437 (0.437)  Loss:  1.0732 (1.0732)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.124)  Loss:  0.8037 (1.0616)  Acc@1: 75.0000 (75.6200)  Acc@5: 100.0000 (95.2500)
Test: [Whole Val]  Time: 9.781  Loss: 1.0616  Acc@1: 75.6200 Pruned: 50.79% 
Test (EMA): [   0/78]  Time: 0.322 (0.322)  Loss:  1.0645 (1.0645)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.7837 (1.0607)  Acc@1: 81.2500 (75.7800)  Acc@5: 100.0000 (95.2800)
Test (EMA): [Whole Val]  Time: 9.666  Loss: 1.0607  Acc@1: 75.7800 Pruned: 50.79% 
Train: 115 [   0/390 (  0%)]  Loss: 3.367 (3.37)  Time: 0.843s,  151.77/s  (0.843s,  151.77/s)  LR: 1.829e-04  Data: 0.522 (0.522)
Train: 115 [ 100/390 ( 26%)]  Loss: 3.620 (3.31)  Time: 0.312s,  409.88/s  (0.321s,  398.55/s)  LR: 1.829e-04  Data: 0.011 (0.018)
Train: 115 [ 200/390 ( 51%)]  Loss: 3.577 (3.24)  Time: 0.316s,  404.53/s  (0.318s,  402.28/s)  LR: 1.829e-04  Data: 0.015 (0.015)
Train: 115 [ 300/390 ( 77%)]  Loss: 3.224 (3.25)  Time: 0.313s,  408.42/s  (0.317s,  403.43/s)  LR: 1.829e-04  Data: 0.012 (0.014)
Train: 115 [ 389/390 (100%)]  Loss: 2.397 (3.25)  Time: 0.303s,  422.99/s  (0.317s,  403.91/s)  LR: 1.829e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.301 (0.301)  Loss:  1.0518 (1.0518)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.7812 (1.0345)  Acc@1: 81.2500 (75.8400)  Acc@5: 93.7500 (95.1500)
Test: [Whole Val]  Time: 9.638  Loss: 1.0345  Acc@1: 75.8400 Pruned: 50.79% 
Test (EMA): [   0/78]  Time: 0.317 (0.317)  Loss:  1.0625 (1.0625)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.7754 (1.0556)  Acc@1: 81.2500 (75.7300)  Acc@5: 100.0000 (95.2100)
Test (EMA): [Whole Val]  Time: 9.643  Loss: 1.0556  Acc@1: 75.7300 Pruned: 50.79% 
Train: 116 [   0/390 (  0%)]  Loss: 3.289 (3.29)  Time: 0.870s,  147.20/s  (0.870s,  147.20/s)  LR: 1.754e-04  Data: 0.567 (0.567)
Train: 116 [ 100/390 ( 26%)]  Loss: 2.391 (3.19)  Time: 0.313s,  408.44/s  (0.321s,  398.74/s)  LR: 1.754e-04  Data: 0.012 (0.018)
Train: 116 [ 200/390 ( 51%)]  Loss: 2.959 (3.22)  Time: 0.315s,  405.72/s  (0.319s,  401.72/s)  LR: 1.754e-04  Data: 0.013 (0.015)
Train: 116 [ 300/390 ( 77%)]  Loss: 3.620 (3.20)  Time: 0.317s,  403.34/s  (0.318s,  402.92/s)  LR: 1.754e-04  Data: 0.012 (0.014)
Train: 116 [ 389/390 (100%)]  Loss: 2.734 (3.19)  Time: 0.303s,  422.78/s  (0.317s,  403.47/s)  LR: 1.754e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.340 (0.340)  Loss:  1.0137 (1.0137)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.7539 (1.0182)  Acc@1: 75.0000 (75.7400)  Acc@5: 100.0000 (95.4200)
Test: [Whole Val]  Time: 9.670  Loss: 1.0182  Acc@1: 75.7400 Pruned: 50.79% 
Test (EMA): [   0/78]  Time: 0.407 (0.407)  Loss:  1.0117 (1.0117)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.018 (0.124)  Loss:  0.7368 (1.0175)  Acc@1: 75.0000 (75.9000)  Acc@5: 100.0000 (95.3700)
Test (EMA): [Whole Val]  Time: 9.769  Loss: 1.0175  Acc@1: 75.9000 Pruned: 50.79% 
Train: 117 [   0/390 (  0%)]  Loss: 3.688 (3.69)  Time: 0.808s,  158.36/s  (0.808s,  158.36/s)  LR: 1.680e-04  Data: 0.505 (0.505)
Train: 117 [ 100/390 ( 26%)]  Loss: 3.176 (3.24)  Time: 0.315s,  406.35/s  (0.321s,  398.97/s)  LR: 1.680e-04  Data: 0.012 (0.017)
Train: 117 [ 200/390 ( 51%)]  Loss: 2.855 (3.24)  Time: 0.316s,  404.43/s  (0.319s,  401.83/s)  LR: 1.680e-04  Data: 0.014 (0.015)
Train: 117 [ 300/390 ( 77%)]  Loss: 3.627 (3.25)  Time: 0.317s,  403.68/s  (0.317s,  403.16/s)  LR: 1.680e-04  Data: 0.014 (0.014)
Train: 117 [ 389/390 (100%)]  Loss: 3.040 (3.23)  Time: 0.303s,  422.75/s  (0.317s,  403.82/s)  LR: 1.680e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.412 (0.412)  Loss:  1.0332 (1.0332)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  0.7441 (1.0338)  Acc@1: 81.2500 (75.6500)  Acc@5: 100.0000 (95.1800)
Test: [Whole Val]  Time: 9.720  Loss: 1.0338  Acc@1: 75.6500 Pruned: 50.78% 
Test (EMA): [   0/78]  Time: 0.407 (0.407)  Loss:  1.0391 (1.0391)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  0.7378 (1.0376)  Acc@1: 81.2500 (75.8200)  Acc@5: 100.0000 (95.2100)
Test (EMA): [Whole Val]  Time: 9.729  Loss: 1.0376  Acc@1: 75.8200 Pruned: 50.78% 
Train: 118 [   0/390 (  0%)]  Loss: 3.963 (3.96)  Time: 0.878s,  145.83/s  (0.878s,  145.83/s)  LR: 1.607e-04  Data: 0.574 (0.574)
Train: 118 [ 100/390 ( 26%)]  Loss: 2.462 (3.17)  Time: 0.317s,  403.16/s  (0.322s,  398.02/s)  LR: 1.607e-04  Data: 0.013 (0.018)
Train: 118 [ 200/390 ( 51%)]  Loss: 3.658 (3.21)  Time: 0.316s,  405.64/s  (0.319s,  401.36/s)  LR: 1.607e-04  Data: 0.013 (0.016)
Train: 118 [ 300/390 ( 77%)]  Loss: 3.537 (3.23)  Time: 0.326s,  392.23/s  (0.318s,  402.42/s)  LR: 1.607e-04  Data: 0.022 (0.015)
Train: 118 [ 389/390 (100%)]  Loss: 3.322 (3.21)  Time: 0.301s,  424.60/s  (0.318s,  403.08/s)  LR: 1.607e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.335 (0.335)  Loss:  1.0557 (1.0557)  Acc@1: 72.6562 (72.6562)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.7305 (1.0494)  Acc@1: 87.5000 (75.3800)  Acc@5: 100.0000 (95.1600)
Test: [Whole Val]  Time: 9.653  Loss: 1.0494  Acc@1: 75.3800 Pruned: 50.79% 
Test (EMA): [   0/78]  Time: 0.401 (0.401)  Loss:  1.0469 (1.0469)  Acc@1: 72.6562 (72.6562)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  0.7109 (1.0391)  Acc@1: 87.5000 (75.5600)  Acc@5: 100.0000 (95.1800)
Test (EMA): [Whole Val]  Time: 9.729  Loss: 1.0391  Acc@1: 75.5600 Pruned: 50.79% 
Train: 119 [   0/390 (  0%)]  Loss: 3.483 (3.48)  Time: 0.810s,  157.98/s  (0.810s,  157.98/s)  LR: 1.535e-04  Data: 0.506 (0.506)
Train: 119 [ 100/390 ( 26%)]  Loss: 2.432 (3.18)  Time: 0.315s,  406.29/s  (0.320s,  399.58/s)  LR: 1.535e-04  Data: 0.012 (0.017)
Train: 119 [ 200/390 ( 51%)]  Loss: 3.674 (3.22)  Time: 0.314s,  407.99/s  (0.318s,  402.50/s)  LR: 1.535e-04  Data: 0.012 (0.015)
Train: 119 [ 300/390 ( 77%)]  Loss: 2.594 (3.23)  Time: 0.315s,  405.87/s  (0.317s,  403.52/s)  LR: 1.535e-04  Data: 0.013 (0.014)
Train: 119 [ 389/390 (100%)]  Loss: 3.784 (3.23)  Time: 0.302s,  423.24/s  (0.317s,  403.98/s)  LR: 1.535e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.423 (0.423)  Loss:  1.0098 (1.0098)  Acc@1: 75.7812 (75.7812)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.124)  Loss:  0.7476 (1.0179)  Acc@1: 87.5000 (76.0200)  Acc@5: 100.0000 (95.2800)
Test: [Whole Val]  Time: 9.772  Loss: 1.0179  Acc@1: 76.0200 Pruned: 50.79% 
Test (EMA): [   0/78]  Time: 0.431 (0.431)  Loss:  1.0234 (1.0234)  Acc@1: 76.5625 (76.5625)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.124)  Loss:  0.7539 (1.0281)  Acc@1: 81.2500 (76.0200)  Acc@5: 100.0000 (95.2900)
Test (EMA): [Whole Val]  Time: 9.767  Loss: 1.0281  Acc@1: 76.0200 Pruned: 50.79% 
Train: 120 [   0/390 (  0%)]  Loss: 3.588 (3.59)  Time: 0.897s,  142.64/s  (0.897s,  142.64/s)  LR: 1.465e-04  Data: 0.596 (0.596)
Train: 120 [ 100/390 ( 26%)]  Loss: 3.588 (3.19)  Time: 0.313s,  409.58/s  (0.321s,  398.57/s)  LR: 1.465e-04  Data: 0.011 (0.018)
Train: 120 [ 200/390 ( 51%)]  Loss: 3.537 (3.22)  Time: 0.317s,  403.27/s  (0.318s,  402.03/s)  LR: 1.465e-04  Data: 0.013 (0.016)
Train: 120 [ 300/390 ( 77%)]  Loss: 3.421 (3.23)  Time: 0.315s,  406.31/s  (0.318s,  402.90/s)  LR: 1.465e-04  Data: 0.012 (0.014)
Train: 120 [ 389/390 (100%)]  Loss: 3.561 (3.20)  Time: 0.304s,  421.40/s  (0.317s,  403.48/s)  LR: 1.465e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.416 (0.416)  Loss:  1.0078 (1.0078)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  0.6919 (1.0031)  Acc@1: 81.2500 (75.8200)  Acc@5: 100.0000 (95.2100)
Test: [Whole Val]  Time: 9.751  Loss: 1.0031  Acc@1: 75.8200 Pruned: 50.79% 
Test (EMA): [   0/78]  Time: 0.379 (0.379)  Loss:  1.0098 (1.0098)  Acc@1: 72.6562 (72.6562)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  0.7144 (1.0010)  Acc@1: 81.2500 (75.9400)  Acc@5: 100.0000 (95.3900)
Test (EMA): [Whole Val]  Time: 9.714  Loss: 1.0010  Acc@1: 75.9400 Pruned: 50.78% 
Train: 121 [   0/390 (  0%)]  Loss: 3.588 (3.59)  Time: 0.794s,  161.28/s  (0.794s,  161.28/s)  LR: 1.397e-04  Data: 0.478 (0.478)
Train: 121 [ 100/390 ( 26%)]  Loss: 3.760 (3.20)  Time: 0.311s,  410.93/s  (0.320s,  399.82/s)  LR: 1.397e-04  Data: 0.011 (0.017)
Train: 121 [ 200/390 ( 51%)]  Loss: 3.487 (3.21)  Time: 0.315s,  405.97/s  (0.318s,  402.71/s)  LR: 1.397e-04  Data: 0.012 (0.015)
Train: 121 [ 300/390 ( 77%)]  Loss: 2.572 (3.20)  Time: 0.322s,  397.13/s  (0.317s,  403.19/s)  LR: 1.397e-04  Data: 0.019 (0.014)
Train: 121 [ 389/390 (100%)]  Loss: 3.557 (3.21)  Time: 0.303s,  421.97/s  (0.317s,  403.62/s)  LR: 1.397e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.370 (0.370)  Loss:  1.0400 (1.0400)  Acc@1: 74.2188 (74.2188)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  0.7363 (1.0449)  Acc@1: 87.5000 (75.8500)  Acc@5: 100.0000 (95.2500)
Test: [Whole Val]  Time: 9.706  Loss: 1.0449  Acc@1: 75.8500 Pruned: 50.78% 
Test (EMA): [   0/78]  Time: 0.427 (0.427)  Loss:  1.0381 (1.0381)  Acc@1: 74.2188 (74.2188)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.124)  Loss:  0.7456 (1.0491)  Acc@1: 87.5000 (75.9700)  Acc@5: 100.0000 (95.2700)
Test (EMA): [Whole Val]  Time: 9.780  Loss: 1.0491  Acc@1: 75.9700 Pruned: 50.78% 
Train: 122 [   0/390 (  0%)]  Loss: 2.877 (2.88)  Time: 0.733s,  174.73/s  (0.733s,  174.73/s)  LR: 1.329e-04  Data: 0.423 (0.423)
Train: 122 [ 100/390 ( 26%)]  Loss: 3.498 (3.27)  Time: 0.314s,  407.31/s  (0.320s,  399.48/s)  LR: 1.329e-04  Data: 0.012 (0.017)
Train: 122 [ 200/390 ( 51%)]  Loss: 3.415 (3.24)  Time: 0.316s,  404.48/s  (0.319s,  401.44/s)  LR: 1.329e-04  Data: 0.014 (0.015)
Train: 122 [ 300/390 ( 77%)]  Loss: 3.804 (3.22)  Time: 0.311s,  411.73/s  (0.318s,  402.33/s)  LR: 1.329e-04  Data: 0.011 (0.015)
Train: 122 [ 389/390 (100%)]  Loss: 2.605 (3.21)  Time: 0.301s,  424.99/s  (0.317s,  403.76/s)  LR: 1.329e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.370 (0.370)  Loss:  1.0254 (1.0254)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.7451 (1.0285)  Acc@1: 87.5000 (75.6800)  Acc@5: 93.7500 (95.3200)
Test: [Whole Val]  Time: 9.664  Loss: 1.0285  Acc@1: 75.6800 Pruned: 50.77% 
Test (EMA): [   0/78]  Time: 0.307 (0.307)  Loss:  1.0293 (1.0293)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.121)  Loss:  0.7358 (1.0362)  Acc@1: 87.5000 (75.6800)  Acc@5: 100.0000 (95.3500)
Test (EMA): [Whole Val]  Time: 9.588  Loss: 1.0362  Acc@1: 75.6800 Pruned: 50.78% 
Train: 123 [   0/390 (  0%)]  Loss: 3.443 (3.44)  Time: 0.773s,  165.56/s  (0.773s,  165.56/s)  LR: 1.263e-04  Data: 0.471 (0.471)
Train: 123 [ 100/390 ( 26%)]  Loss: 2.776 (3.20)  Time: 0.312s,  410.06/s  (0.318s,  402.66/s)  LR: 1.263e-04  Data: 0.011 (0.016)
Train: 123 [ 200/390 ( 51%)]  Loss: 2.369 (3.21)  Time: 0.312s,  410.44/s  (0.316s,  405.36/s)  LR: 1.263e-04  Data: 0.011 (0.014)
Train: 123 [ 300/390 ( 77%)]  Loss: 3.126 (3.23)  Time: 0.313s,  409.51/s  (0.315s,  406.40/s)  LR: 1.263e-04  Data: 0.011 (0.013)
Train: 123 [ 389/390 (100%)]  Loss: 2.553 (3.23)  Time: 0.301s,  425.65/s  (0.315s,  406.55/s)  LR: 1.263e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.357 (0.357)  Loss:  1.0293 (1.0293)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.7466 (1.0351)  Acc@1: 81.2500 (75.6800)  Acc@5: 100.0000 (95.2900)
Test: [Whole Val]  Time: 9.655  Loss: 1.0351  Acc@1: 75.6800 Pruned: 50.77% 
Test (EMA): [   0/78]  Time: 0.424 (0.424)  Loss:  1.0420 (1.0420)  Acc@1: 75.7812 (75.7812)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  0.7559 (1.0475)  Acc@1: 87.5000 (75.8800)  Acc@5: 100.0000 (95.3500)
Test (EMA): [Whole Val]  Time: 9.705  Loss: 1.0475  Acc@1: 75.8800 Pruned: 50.77% 
Train: 124 [   0/390 (  0%)]  Loss: 3.752 (3.75)  Time: 0.843s,  151.82/s  (0.843s,  151.82/s)  LR: 1.199e-04  Data: 0.540 (0.540)
Train: 124 [ 100/390 ( 26%)]  Loss: 3.441 (3.21)  Time: 0.314s,  407.19/s  (0.318s,  402.79/s)  LR: 1.199e-04  Data: 0.012 (0.017)
Train: 124 [ 200/390 ( 51%)]  Loss: 3.149 (3.20)  Time: 0.313s,  408.58/s  (0.316s,  405.05/s)  LR: 1.199e-04  Data: 0.012 (0.015)
Train: 124 [ 300/390 ( 77%)]  Loss: 2.749 (3.22)  Time: 0.313s,  409.06/s  (0.315s,  406.23/s)  LR: 1.199e-04  Data: 0.011 (0.014)
Train: 124 [ 389/390 (100%)]  Loss: 2.922 (3.23)  Time: 0.303s,  422.73/s  (0.315s,  406.56/s)  LR: 1.199e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.353 (0.353)  Loss:  1.0488 (1.0488)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.7852 (1.0757)  Acc@1: 81.2500 (75.7600)  Acc@5: 100.0000 (95.1700)
Test: [Whole Val]  Time: 9.616  Loss: 1.0757  Acc@1: 75.7600 Pruned: 50.77% 
Test (EMA): [   0/78]  Time: 0.306 (0.306)  Loss:  1.0381 (1.0381)  Acc@1: 76.5625 (76.5625)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.7720 (1.0624)  Acc@1: 81.2500 (75.8700)  Acc@5: 100.0000 (95.3000)
Test (EMA): [Whole Val]  Time: 9.590  Loss: 1.0624  Acc@1: 75.8700 Pruned: 50.77% 
Train: 125 [   0/390 (  0%)]  Loss: 2.742 (2.74)  Time: 0.782s,  163.68/s  (0.782s,  163.68/s)  LR: 1.136e-04  Data: 0.480 (0.480)
Train: 125 [ 100/390 ( 26%)]  Loss: 2.850 (3.19)  Time: 0.314s,  407.92/s  (0.318s,  402.47/s)  LR: 1.136e-04  Data: 0.012 (0.017)
Train: 125 [ 200/390 ( 51%)]  Loss: 3.671 (3.18)  Time: 0.314s,  407.32/s  (0.316s,  405.26/s)  LR: 1.136e-04  Data: 0.013 (0.014)
Train: 125 [ 300/390 ( 77%)]  Loss: 2.839 (3.19)  Time: 0.314s,  408.18/s  (0.315s,  406.12/s)  LR: 1.136e-04  Data: 0.012 (0.014)
Train: 125 [ 389/390 (100%)]  Loss: 3.698 (3.19)  Time: 0.301s,  424.64/s  (0.315s,  406.65/s)  LR: 1.136e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.361 (0.361)  Loss:  1.0293 (1.0293)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.7480 (1.0430)  Acc@1: 81.2500 (75.9700)  Acc@5: 100.0000 (95.2400)
Test: [Whole Val]  Time: 9.634  Loss: 1.0430  Acc@1: 75.9700 Pruned: 50.77% 
Test (EMA): [   0/78]  Time: 0.308 (0.308)  Loss:  1.0293 (1.0293)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.018 (0.121)  Loss:  0.7573 (1.0354)  Acc@1: 81.2500 (76.1400)  Acc@5: 93.7500 (95.3300)
Test (EMA): [Whole Val]  Time: 9.594  Loss: 1.0354  Acc@1: 76.1400 Pruned: 50.77% 
Train: 126 [   0/390 (  0%)]  Loss: 3.667 (3.67)  Time: 0.914s,  139.99/s  (0.914s,  139.99/s)  LR: 1.074e-04  Data: 0.605 (0.605)
Train: 126 [ 100/390 ( 26%)]  Loss: 3.571 (3.15)  Time: 0.313s,  408.72/s  (0.319s,  400.78/s)  LR: 1.074e-04  Data: 0.012 (0.018)
Train: 126 [ 200/390 ( 51%)]  Loss: 3.497 (3.11)  Time: 0.313s,  408.55/s  (0.316s,  404.59/s)  LR: 1.074e-04  Data: 0.012 (0.015)
Train: 126 [ 300/390 ( 77%)]  Loss: 3.581 (3.14)  Time: 0.311s,  411.02/s  (0.315s,  405.90/s)  LR: 1.074e-04  Data: 0.011 (0.014)
Train: 126 [ 389/390 (100%)]  Loss: 3.315 (3.16)  Time: 0.301s,  425.29/s  (0.315s,  406.44/s)  LR: 1.074e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.310 (0.310)  Loss:  1.0361 (1.0361)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.7686 (1.0448)  Acc@1: 81.2500 (75.9100)  Acc@5: 100.0000 (95.3100)
Test: [Whole Val]  Time: 9.584  Loss: 1.0448  Acc@1: 75.9100 Pruned: 50.77% 
Test (EMA): [   0/78]  Time: 0.372 (0.372)  Loss:  1.0303 (1.0303)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.7539 (1.0431)  Acc@1: 81.2500 (75.9500)  Acc@5: 100.0000 (95.3100)
Test (EMA): [Whole Val]  Time: 9.644  Loss: 1.0431  Acc@1: 75.9500 Pruned: 50.77% 
Train: 127 [   0/390 (  0%)]  Loss: 3.682 (3.68)  Time: 0.788s,  162.39/s  (0.788s,  162.39/s)  LR: 1.014e-04  Data: 0.487 (0.487)
Train: 127 [ 100/390 ( 26%)]  Loss: 3.523 (3.21)  Time: 0.313s,  408.48/s  (0.319s,  401.54/s)  LR: 1.014e-04  Data: 0.012 (0.016)
Train: 127 [ 200/390 ( 51%)]  Loss: 3.592 (3.21)  Time: 0.314s,  407.40/s  (0.316s,  404.63/s)  LR: 1.014e-04  Data: 0.012 (0.014)
Train: 127 [ 300/390 ( 77%)]  Loss: 3.097 (3.19)  Time: 0.312s,  410.66/s  (0.315s,  405.84/s)  LR: 1.014e-04  Data: 0.011 (0.014)
Train: 127 [ 389/390 (100%)]  Loss: 3.482 (3.18)  Time: 0.302s,  424.12/s  (0.315s,  406.51/s)  LR: 1.014e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.332 (0.332)  Loss:  1.0449 (1.0449)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.7314 (1.0361)  Acc@1: 87.5000 (76.0700)  Acc@5: 100.0000 (95.3700)
Test: [Whole Val]  Time: 9.604  Loss: 1.0361  Acc@1: 76.0700 Pruned: 50.76% 
Test (EMA): [   0/78]  Time: 0.332 (0.332)  Loss:  1.0312 (1.0312)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.7075 (1.0260)  Acc@1: 87.5000 (76.1200)  Acc@5: 100.0000 (95.3800)
Test (EMA): [Whole Val]  Time: 9.615  Loss: 1.0260  Acc@1: 76.1200 Pruned: 50.76% 
Train: 128 [   0/390 (  0%)]  Loss: 2.846 (2.85)  Time: 0.774s,  165.34/s  (0.774s,  165.34/s)  LR: 9.558e-05  Data: 0.472 (0.472)
Train: 128 [ 100/390 ( 26%)]  Loss: 3.160 (3.17)  Time: 0.313s,  409.03/s  (0.317s,  403.21/s)  LR: 9.558e-05  Data: 0.012 (0.016)
Train: 128 [ 200/390 ( 51%)]  Loss: 3.048 (3.16)  Time: 0.321s,  398.70/s  (0.315s,  405.97/s)  LR: 9.558e-05  Data: 0.012 (0.014)
Train: 128 [ 300/390 ( 77%)]  Loss: 2.391 (3.19)  Time: 0.314s,  407.55/s  (0.315s,  406.90/s)  LR: 9.558e-05  Data: 0.012 (0.013)
Train: 128 [ 389/390 (100%)]  Loss: 3.809 (3.21)  Time: 0.301s,  425.00/s  (0.314s,  407.28/s)  LR: 9.558e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.311 (0.311)  Loss:  1.0547 (1.0547)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.7583 (1.0527)  Acc@1: 81.2500 (75.9700)  Acc@5: 100.0000 (95.3400)
Test: [Whole Val]  Time: 9.592  Loss: 1.0527  Acc@1: 75.9700 Pruned: 50.77% 
Test (EMA): [   0/78]  Time: 0.320 (0.320)  Loss:  1.0576 (1.0576)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.7681 (1.0568)  Acc@1: 81.2500 (76.1300)  Acc@5: 100.0000 (95.3400)
Test (EMA): [Whole Val]  Time: 9.608  Loss: 1.0568  Acc@1: 76.1300 Pruned: 50.77% 
Train: 129 [   0/390 (  0%)]  Loss: 3.550 (3.55)  Time: 0.743s,  172.36/s  (0.743s,  172.36/s)  LR: 8.989e-05  Data: 0.442 (0.442)
Train: 129 [ 100/390 ( 26%)]  Loss: 3.616 (3.27)  Time: 0.312s,  409.86/s  (0.317s,  403.48/s)  LR: 8.989e-05  Data: 0.011 (0.016)
Train: 129 [ 200/390 ( 51%)]  Loss: 2.536 (3.24)  Time: 0.314s,  408.03/s  (0.315s,  406.23/s)  LR: 8.989e-05  Data: 0.012 (0.014)
Train: 129 [ 300/390 ( 77%)]  Loss: 3.583 (3.21)  Time: 0.313s,  409.24/s  (0.315s,  406.95/s)  LR: 8.989e-05  Data: 0.012 (0.013)
Train: 129 [ 389/390 (100%)]  Loss: 3.570 (3.22)  Time: 0.315s,  406.93/s  (0.314s,  407.22/s)  LR: 8.989e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.373 (0.373)  Loss:  1.0254 (1.0254)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.7461 (1.0397)  Acc@1: 87.5000 (76.1100)  Acc@5: 100.0000 (95.2300)
Test: [Whole Val]  Time: 9.663  Loss: 1.0397  Acc@1: 76.1100 Pruned: 50.77% 
Test (EMA): [   0/78]  Time: 0.341 (0.341)  Loss:  1.0205 (1.0205)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.7285 (1.0321)  Acc@1: 93.7500 (76.2100)  Acc@5: 100.0000 (95.2700)
Test (EMA): [Whole Val]  Time: 9.632  Loss: 1.0321  Acc@1: 76.2100 Pruned: 50.77% 
Train: 130 [   0/390 (  0%)]  Loss: 3.228 (3.23)  Time: 0.789s,  162.30/s  (0.789s,  162.30/s)  LR: 8.436e-05  Data: 0.482 (0.482)
Train: 130 [ 100/390 ( 26%)]  Loss: 3.560 (3.19)  Time: 0.314s,  407.57/s  (0.318s,  402.14/s)  LR: 8.436e-05  Data: 0.012 (0.017)
Train: 130 [ 200/390 ( 51%)]  Loss: 3.160 (3.21)  Time: 0.313s,  409.53/s  (0.317s,  404.31/s)  LR: 8.436e-05  Data: 0.012 (0.014)
Train: 130 [ 300/390 ( 77%)]  Loss: 3.403 (3.21)  Time: 0.315s,  406.81/s  (0.315s,  405.76/s)  LR: 8.436e-05  Data: 0.012 (0.014)
Train: 130 [ 389/390 (100%)]  Loss: 2.843 (3.23)  Time: 0.301s,  425.16/s  (0.315s,  406.42/s)  LR: 8.436e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.380 (0.380)  Loss:  1.0625 (1.0625)  Acc@1: 75.7812 (75.7812)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.7998 (1.0695)  Acc@1: 75.0000 (76.0300)  Acc@5: 93.7500 (95.3900)
Test: [Whole Val]  Time: 9.650  Loss: 1.0695  Acc@1: 76.0300 Pruned: 50.77% 
Test (EMA): [   0/78]  Time: 0.303 (0.303)  Loss:  1.0674 (1.0674)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.8057 (1.0691)  Acc@1: 75.0000 (76.0400)  Acc@5: 93.7500 (95.3700)
Test (EMA): [Whole Val]  Time: 9.566  Loss: 1.0691  Acc@1: 76.0400 Pruned: 50.77% 
Train: 131 [   0/390 (  0%)]  Loss: 3.613 (3.61)  Time: 0.744s,  171.98/s  (0.744s,  171.98/s)  LR: 7.898e-05  Data: 0.440 (0.440)
Train: 131 [ 100/390 ( 26%)]  Loss: 3.133 (3.25)  Time: 0.311s,  411.09/s  (0.317s,  403.53/s)  LR: 7.898e-05  Data: 0.011 (0.016)
Train: 131 [ 200/390 ( 51%)]  Loss: 2.612 (3.22)  Time: 0.314s,  407.96/s  (0.315s,  406.02/s)  LR: 7.898e-05  Data: 0.012 (0.014)
Train: 131 [ 300/390 ( 77%)]  Loss: 2.807 (3.18)  Time: 0.313s,  409.07/s  (0.315s,  406.91/s)  LR: 7.898e-05  Data: 0.012 (0.013)
Train: 131 [ 389/390 (100%)]  Loss: 2.827 (3.19)  Time: 0.301s,  424.88/s  (0.314s,  407.36/s)  LR: 7.898e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.317 (0.317)  Loss:  1.0479 (1.0479)  Acc@1: 76.5625 (76.5625)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.7651 (1.0557)  Acc@1: 81.2500 (76.2300)  Acc@5: 100.0000 (95.3500)
Test: [Whole Val]  Time: 9.600  Loss: 1.0557  Acc@1: 76.2300 Pruned: 50.76% 
Test (EMA): [   0/78]  Time: 0.302 (0.302)  Loss:  1.0430 (1.0430)  Acc@1: 76.5625 (76.5625)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.7642 (1.0514)  Acc@1: 75.0000 (76.1600)  Acc@5: 100.0000 (95.3300)
Test (EMA): [Whole Val]  Time: 9.587  Loss: 1.0514  Acc@1: 76.1600 Pruned: 50.76% 
Train: 132 [   0/390 (  0%)]  Loss: 2.481 (2.48)  Time: 0.830s,  154.21/s  (0.830s,  154.21/s)  LR: 7.377e-05  Data: 0.523 (0.523)
Train: 132 [ 100/390 ( 26%)]  Loss: 3.173 (3.17)  Time: 0.312s,  410.75/s  (0.318s,  402.49/s)  LR: 7.377e-05  Data: 0.011 (0.017)
Train: 132 [ 200/390 ( 51%)]  Loss: 3.321 (3.19)  Time: 0.313s,  409.57/s  (0.316s,  405.60/s)  LR: 7.377e-05  Data: 0.012 (0.014)
Train: 132 [ 300/390 ( 77%)]  Loss: 3.625 (3.19)  Time: 0.313s,  408.66/s  (0.315s,  406.64/s)  LR: 7.377e-05  Data: 0.012 (0.014)
Train: 132 [ 389/390 (100%)]  Loss: 3.038 (3.19)  Time: 0.301s,  424.87/s  (0.314s,  407.17/s)  LR: 7.377e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.374 (0.374)  Loss:  1.0449 (1.0449)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.7910 (1.0521)  Acc@1: 75.0000 (76.2900)  Acc@5: 100.0000 (95.3600)
Test: [Whole Val]  Time: 9.637  Loss: 1.0521  Acc@1: 76.2900 Pruned: 50.76% 
Test (EMA): [   0/78]  Time: 0.311 (0.311)  Loss:  1.0420 (1.0420)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.7788 (1.0448)  Acc@1: 75.0000 (76.3600)  Acc@5: 100.0000 (95.4200)
Test (EMA): [Whole Val]  Time: 9.580  Loss: 1.0448  Acc@1: 76.3600 Pruned: 50.76% 
Train: 133 [   0/390 (  0%)]  Loss: 2.264 (2.26)  Time: 0.760s,  168.43/s  (0.760s,  168.43/s)  LR: 6.873e-05  Data: 0.459 (0.459)
Train: 133 [ 100/390 ( 26%)]  Loss: 3.278 (3.17)  Time: 0.313s,  409.00/s  (0.318s,  402.95/s)  LR: 6.873e-05  Data: 0.011 (0.016)
Train: 133 [ 200/390 ( 51%)]  Loss: 3.629 (3.18)  Time: 0.313s,  408.44/s  (0.315s,  405.99/s)  LR: 6.873e-05  Data: 0.012 (0.014)
Train: 133 [ 300/390 ( 77%)]  Loss: 2.590 (3.20)  Time: 0.312s,  410.72/s  (0.315s,  406.48/s)  LR: 6.873e-05  Data: 0.012 (0.013)
Train: 133 [ 389/390 (100%)]  Loss: 3.678 (3.22)  Time: 0.302s,  424.04/s  (0.314s,  407.15/s)  LR: 6.873e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.429 (0.429)  Loss:  1.0371 (1.0371)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.123)  Loss:  0.7520 (1.0504)  Acc@1: 93.7500 (76.0700)  Acc@5: 100.0000 (95.3400)
Test: [Whole Val]  Time: 9.690  Loss: 1.0504  Acc@1: 76.0700 Pruned: 50.76% 
Test (EMA): [   0/78]  Time: 0.311 (0.311)  Loss:  1.0342 (1.0342)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.121)  Loss:  0.7471 (1.0471)  Acc@1: 93.7500 (76.2200)  Acc@5: 100.0000 (95.3100)
Test (EMA): [Whole Val]  Time: 9.590  Loss: 1.0471  Acc@1: 76.2200 Pruned: 50.76% 
Train: 134 [   0/390 (  0%)]  Loss: 3.026 (3.03)  Time: 0.784s,  163.30/s  (0.784s,  163.30/s)  LR: 6.385e-05  Data: 0.482 (0.482)
Train: 134 [ 100/390 ( 26%)]  Loss: 3.247 (3.20)  Time: 0.313s,  409.44/s  (0.318s,  402.66/s)  LR: 6.385e-05  Data: 0.012 (0.016)
Train: 134 [ 200/390 ( 51%)]  Loss: 3.305 (3.18)  Time: 0.313s,  409.10/s  (0.315s,  405.79/s)  LR: 6.385e-05  Data: 0.012 (0.014)
Train: 134 [ 300/390 ( 77%)]  Loss: 2.968 (3.21)  Time: 0.313s,  408.79/s  (0.315s,  406.80/s)  LR: 6.385e-05  Data: 0.012 (0.013)
Train: 134 [ 389/390 (100%)]  Loss: 3.535 (3.20)  Time: 0.303s,  422.71/s  (0.314s,  407.20/s)  LR: 6.385e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.344 (0.344)  Loss:  1.0234 (1.0234)  Acc@1: 74.2188 (74.2188)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.7446 (1.0223)  Acc@1: 81.2500 (76.2900)  Acc@5: 100.0000 (95.4200)
Test: [Whole Val]  Time: 9.607  Loss: 1.0223  Acc@1: 76.2900 Pruned: 50.76% 
Test (EMA): [   0/78]  Time: 0.313 (0.313)  Loss:  1.0186 (1.0186)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.7290 (1.0149)  Acc@1: 81.2500 (76.3600)  Acc@5: 100.0000 (95.4700)
Test (EMA): [Whole Val]  Time: 9.591  Loss: 1.0149  Acc@1: 76.3600 Pruned: 50.76% 
Train: 135 [   0/390 (  0%)]  Loss: 3.333 (3.33)  Time: 0.722s,  177.29/s  (0.722s,  177.29/s)  LR: 5.913e-05  Data: 0.421 (0.421)
Train: 135 [ 100/390 ( 26%)]  Loss: 2.998 (3.16)  Time: 0.312s,  409.75/s  (0.317s,  403.48/s)  LR: 5.913e-05  Data: 0.012 (0.016)
Train: 135 [ 200/390 ( 51%)]  Loss: 2.370 (3.17)  Time: 0.312s,  410.48/s  (0.315s,  406.07/s)  LR: 5.913e-05  Data: 0.011 (0.014)
Train: 135 [ 300/390 ( 77%)]  Loss: 2.959 (3.15)  Time: 0.315s,  406.46/s  (0.315s,  406.98/s)  LR: 5.913e-05  Data: 0.013 (0.013)
Train: 135 [ 389/390 (100%)]  Loss: 2.585 (3.14)  Time: 0.300s,  426.04/s  (0.314s,  407.41/s)  LR: 5.913e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.310 (0.310)  Loss:  1.0186 (1.0186)  Acc@1: 74.2188 (74.2188)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.7236 (1.0273)  Acc@1: 87.5000 (76.3100)  Acc@5: 100.0000 (95.3200)
Test: [Whole Val]  Time: 9.587  Loss: 1.0273  Acc@1: 76.3100 Pruned: 50.76% 
Test (EMA): [   0/78]  Time: 0.307 (0.307)  Loss:  1.0166 (1.0166)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.018 (0.121)  Loss:  0.7246 (1.0214)  Acc@1: 87.5000 (76.4000)  Acc@5: 100.0000 (95.3400)
Test (EMA): [Whole Val]  Time: 9.588  Loss: 1.0214  Acc@1: 76.4000 Pruned: 50.76% 
Train: 136 [   0/390 (  0%)]  Loss: 3.483 (3.48)  Time: 0.811s,  157.78/s  (0.811s,  157.78/s)  LR: 5.459e-05  Data: 0.495 (0.495)
Train: 136 [ 100/390 ( 26%)]  Loss: 3.479 (3.19)  Time: 0.316s,  404.51/s  (0.318s,  402.22/s)  LR: 5.459e-05  Data: 0.011 (0.017)
Train: 136 [ 200/390 ( 51%)]  Loss: 3.174 (3.20)  Time: 0.315s,  406.71/s  (0.316s,  405.28/s)  LR: 5.459e-05  Data: 0.013 (0.014)
Train: 136 [ 300/390 ( 77%)]  Loss: 3.652 (3.23)  Time: 0.314s,  407.50/s  (0.315s,  406.34/s)  LR: 5.459e-05  Data: 0.012 (0.013)
Train: 136 [ 389/390 (100%)]  Loss: 3.177 (3.23)  Time: 0.302s,  424.00/s  (0.315s,  406.58/s)  LR: 5.459e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.354 (0.354)  Loss:  1.0332 (1.0332)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.7217 (1.0378)  Acc@1: 87.5000 (76.1800)  Acc@5: 100.0000 (95.3600)
Test: [Whole Val]  Time: 9.623  Loss: 1.0378  Acc@1: 76.1800 Pruned: 50.76% 
Test (EMA): [   0/78]  Time: 0.303 (0.303)  Loss:  1.0322 (1.0322)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.018 (0.121)  Loss:  0.7197 (1.0365)  Acc@1: 93.7500 (76.2300)  Acc@5: 100.0000 (95.3800)
Test (EMA): [Whole Val]  Time: 9.575  Loss: 1.0365  Acc@1: 76.2300 Pruned: 50.76% 
Train: 137 [   0/390 (  0%)]  Loss: 2.371 (2.37)  Time: 0.805s,  159.10/s  (0.805s,  159.10/s)  LR: 5.022e-05  Data: 0.504 (0.504)
Train: 137 [ 100/390 ( 26%)]  Loss: 2.449 (3.13)  Time: 0.313s,  409.37/s  (0.318s,  402.14/s)  LR: 5.022e-05  Data: 0.011 (0.017)
Train: 137 [ 200/390 ( 51%)]  Loss: 3.318 (3.17)  Time: 0.313s,  409.17/s  (0.316s,  405.21/s)  LR: 5.022e-05  Data: 0.012 (0.014)
Train: 137 [ 300/390 ( 77%)]  Loss: 3.038 (3.18)  Time: 0.313s,  409.54/s  (0.315s,  406.25/s)  LR: 5.022e-05  Data: 0.011 (0.013)
Train: 137 [ 389/390 (100%)]  Loss: 2.865 (3.18)  Time: 0.302s,  423.83/s  (0.315s,  406.77/s)  LR: 5.022e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.373 (0.373)  Loss:  1.0156 (1.0156)  Acc@1: 75.7812 (75.7812)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.026 (0.123)  Loss:  0.7383 (1.0302)  Acc@1: 81.2500 (76.3100)  Acc@5: 100.0000 (95.4300)
Test: [Whole Val]  Time: 9.678  Loss: 1.0302  Acc@1: 76.3100 Pruned: 50.76% 
Test (EMA): [   0/78]  Time: 0.327 (0.327)  Loss:  1.0156 (1.0156)  Acc@1: 75.7812 (75.7812)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.7310 (1.0284)  Acc@1: 81.2500 (76.3700)  Acc@5: 100.0000 (95.4200)
Test (EMA): [Whole Val]  Time: 9.612  Loss: 1.0284  Acc@1: 76.3700 Pruned: 50.76% 
Train: 138 [   0/390 (  0%)]  Loss: 3.526 (3.53)  Time: 0.804s,  159.29/s  (0.804s,  159.29/s)  LR: 4.602e-05  Data: 0.497 (0.497)
Train: 138 [ 100/390 ( 26%)]  Loss: 3.668 (3.27)  Time: 0.314s,  408.20/s  (0.319s,  400.77/s)  LR: 4.602e-05  Data: 0.012 (0.017)
Train: 138 [ 200/390 ( 51%)]  Loss: 3.669 (3.20)  Time: 0.313s,  408.69/s  (0.317s,  403.49/s)  LR: 4.602e-05  Data: 0.012 (0.015)
Train: 138 [ 300/390 ( 77%)]  Loss: 2.833 (3.18)  Time: 0.312s,  410.70/s  (0.316s,  404.96/s)  LR: 4.602e-05  Data: 0.011 (0.014)
Train: 138 [ 389/390 (100%)]  Loss: 2.562 (3.19)  Time: 0.302s,  424.38/s  (0.315s,  405.75/s)  LR: 4.602e-05  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.402 (0.402)  Loss:  1.0283 (1.0283)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.019 (0.123)  Loss:  0.7329 (1.0406)  Acc@1: 93.7500 (76.2700)  Acc@5: 100.0000 (95.4300)
Test: [Whole Val]  Time: 9.695  Loss: 1.0406  Acc@1: 76.2700 Pruned: 50.76% 
Test (EMA): [   0/78]  Time: 0.315 (0.315)  Loss:  1.0312 (1.0312)  Acc@1: 74.2188 (74.2188)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.7378 (1.0408)  Acc@1: 93.7500 (76.2100)  Acc@5: 100.0000 (95.4800)
Test (EMA): [Whole Val]  Time: 9.600  Loss: 1.0408  Acc@1: 76.2100 Pruned: 50.75% 
Train: 139 [   0/390 (  0%)]  Loss: 3.131 (3.13)  Time: 0.765s,  167.31/s  (0.765s,  167.31/s)  LR: 4.200e-05  Data: 0.463 (0.463)
Train: 139 [ 100/390 ( 26%)]  Loss: 3.550 (3.05)  Time: 0.313s,  408.31/s  (0.318s,  402.34/s)  LR: 4.200e-05  Data: 0.012 (0.016)
Train: 139 [ 200/390 ( 51%)]  Loss: 3.524 (3.10)  Time: 0.315s,  406.69/s  (0.316s,  405.46/s)  LR: 4.200e-05  Data: 0.013 (0.014)
Train: 139 [ 300/390 ( 77%)]  Loss: 3.440 (3.14)  Time: 0.312s,  409.86/s  (0.315s,  406.52/s)  LR: 4.200e-05  Data: 0.012 (0.013)
Train: 139 [ 389/390 (100%)]  Loss: 2.887 (3.15)  Time: 0.302s,  423.85/s  (0.314s,  407.10/s)  LR: 4.200e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.339 (0.339)  Loss:  1.0273 (1.0273)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.7373 (1.0363)  Acc@1: 93.7500 (76.3900)  Acc@5: 100.0000 (95.3200)
Test: [Whole Val]  Time: 9.632  Loss: 1.0363  Acc@1: 76.3900 Pruned: 50.75% 
Test (EMA): [   0/78]  Time: 0.302 (0.302)  Loss:  1.0273 (1.0273)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.7383 (1.0348)  Acc@1: 93.7500 (76.4100)  Acc@5: 100.0000 (95.3100)
Test (EMA): [Whole Val]  Time: 9.582  Loss: 1.0348  Acc@1: 76.4100 Pruned: 50.75% 
Train: 140 [   0/390 (  0%)]  Loss: 3.601 (3.60)  Time: 0.851s,  150.50/s  (0.851s,  150.50/s)  LR: 3.816e-05  Data: 0.548 (0.548)
Train: 140 [ 100/390 ( 26%)]  Loss: 2.262 (3.29)  Time: 0.313s,  409.12/s  (0.320s,  400.33/s)  LR: 3.816e-05  Data: 0.011 (0.017)
Train: 140 [ 200/390 ( 51%)]  Loss: 3.439 (3.23)  Time: 0.315s,  406.45/s  (0.317s,  404.16/s)  LR: 3.816e-05  Data: 0.013 (0.015)
Train: 140 [ 300/390 ( 77%)]  Loss: 2.469 (3.22)  Time: 0.312s,  410.35/s  (0.316s,  405.54/s)  LR: 3.816e-05  Data: 0.011 (0.014)
Train: 140 [ 389/390 (100%)]  Loss: 2.764 (3.23)  Time: 0.302s,  423.98/s  (0.315s,  406.42/s)  LR: 3.816e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.312 (0.312)  Loss:  1.0352 (1.0352)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.021 (0.121)  Loss:  0.7549 (1.0436)  Acc@1: 87.5000 (76.2600)  Acc@5: 100.0000 (95.4000)
Test: [Whole Val]  Time: 9.575  Loss: 1.0436  Acc@1: 76.2600 Pruned: 50.76% 
Test (EMA): [   0/78]  Time: 0.344 (0.344)  Loss:  1.0332 (1.0332)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.7515 (1.0412)  Acc@1: 87.5000 (76.2900)  Acc@5: 100.0000 (95.4300)
Test (EMA): [Whole Val]  Time: 9.640  Loss: 1.0412  Acc@1: 76.2900 Pruned: 50.75% 
Train: 141 [   0/390 (  0%)]  Loss: 2.251 (2.25)  Time: 0.780s,  164.15/s  (0.780s,  164.15/s)  LR: 3.449e-05  Data: 0.477 (0.477)
Train: 141 [ 100/390 ( 26%)]  Loss: 2.719 (3.15)  Time: 0.313s,  408.97/s  (0.319s,  401.86/s)  LR: 3.449e-05  Data: 0.012 (0.017)
Train: 141 [ 200/390 ( 51%)]  Loss: 3.588 (3.18)  Time: 0.313s,  409.55/s  (0.316s,  404.83/s)  LR: 3.449e-05  Data: 0.012 (0.014)
Train: 141 [ 300/390 ( 77%)]  Loss: 3.626 (3.18)  Time: 0.316s,  405.61/s  (0.315s,  405.71/s)  LR: 3.449e-05  Data: 0.014 (0.014)
Train: 141 [ 389/390 (100%)]  Loss: 2.832 (3.18)  Time: 0.302s,  424.33/s  (0.315s,  406.13/s)  LR: 3.449e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.379 (0.379)  Loss:  1.0127 (1.0127)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.7031 (1.0150)  Acc@1: 93.7500 (76.2700)  Acc@5: 100.0000 (95.4000)
Test: [Whole Val]  Time: 9.673  Loss: 1.0150  Acc@1: 76.2700 Pruned: 50.74% 
Test (EMA): [   0/78]  Time: 0.391 (0.391)  Loss:  1.0146 (1.0146)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  0.7119 (1.0172)  Acc@1: 87.5000 (76.2900)  Acc@5: 100.0000 (95.4700)
Test (EMA): [Whole Val]  Time: 9.683  Loss: 1.0172  Acc@1: 76.2900 Pruned: 50.74% 
Train: 142 [   0/390 (  0%)]  Loss: 3.821 (3.82)  Time: 0.834s,  153.48/s  (0.834s,  153.48/s)  LR: 3.100e-05  Data: 0.530 (0.530)
Train: 142 [ 100/390 ( 26%)]  Loss: 3.454 (3.24)  Time: 0.315s,  406.18/s  (0.319s,  401.08/s)  LR: 3.100e-05  Data: 0.013 (0.017)
Train: 142 [ 200/390 ( 51%)]  Loss: 3.677 (3.25)  Time: 0.313s,  408.73/s  (0.316s,  404.52/s)  LR: 3.100e-05  Data: 0.012 (0.015)
Train: 142 [ 300/390 ( 77%)]  Loss: 2.545 (3.24)  Time: 0.314s,  407.48/s  (0.315s,  405.75/s)  LR: 3.100e-05  Data: 0.012 (0.014)
Train: 142 [ 389/390 (100%)]  Loss: 3.652 (3.23)  Time: 0.302s,  423.94/s  (0.315s,  406.43/s)  LR: 3.100e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.313 (0.313)  Loss:  1.0195 (1.0195)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.7080 (1.0263)  Acc@1: 87.5000 (76.2400)  Acc@5: 100.0000 (95.2600)
Test: [Whole Val]  Time: 9.586  Loss: 1.0263  Acc@1: 76.2400 Pruned: 50.75% 
Test (EMA): [   0/78]  Time: 0.309 (0.309)  Loss:  1.0195 (1.0195)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.7036 (1.0238)  Acc@1: 87.5000 (76.2700)  Acc@5: 100.0000 (95.3300)
Test (EMA): [Whole Val]  Time: 9.590  Loss: 1.0238  Acc@1: 76.2700 Pruned: 50.75% 
Train: 143 [   0/390 (  0%)]  Loss: 2.567 (2.57)  Time: 0.841s,  152.19/s  (0.841s,  152.19/s)  LR: 2.769e-05  Data: 0.537 (0.537)
Train: 143 [ 100/390 ( 26%)]  Loss: 3.427 (3.25)  Time: 0.312s,  409.79/s  (0.319s,  401.33/s)  LR: 2.769e-05  Data: 0.011 (0.017)
Train: 143 [ 200/390 ( 51%)]  Loss: 3.583 (3.20)  Time: 0.313s,  408.86/s  (0.317s,  403.82/s)  LR: 2.769e-05  Data: 0.011 (0.015)
Train: 143 [ 300/390 ( 77%)]  Loss: 2.521 (3.17)  Time: 0.314s,  408.23/s  (0.316s,  405.31/s)  LR: 2.769e-05  Data: 0.012 (0.014)
Train: 143 [ 389/390 (100%)]  Loss: 3.480 (3.18)  Time: 0.301s,  424.94/s  (0.315s,  405.95/s)  LR: 2.769e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.312 (0.312)  Loss:  1.0146 (1.0146)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.7065 (1.0218)  Acc@1: 87.5000 (76.4100)  Acc@5: 100.0000 (95.3800)
Test: [Whole Val]  Time: 9.611  Loss: 1.0218  Acc@1: 76.4100 Pruned: 50.75% 
Test (EMA): [   0/78]  Time: 0.348 (0.348)  Loss:  1.0166 (1.0166)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.7085 (1.0236)  Acc@1: 87.5000 (76.4300)  Acc@5: 100.0000 (95.3900)
Test (EMA): [Whole Val]  Time: 9.641  Loss: 1.0236  Acc@1: 76.4300 Pruned: 50.75% 
Train: 144 [   0/390 (  0%)]  Loss: 3.779 (3.78)  Time: 0.925s,  138.42/s  (0.925s,  138.42/s)  LR: 2.457e-05  Data: 0.620 (0.620)
Train: 144 [ 100/390 ( 26%)]  Loss: 2.454 (3.14)  Time: 0.313s,  408.51/s  (0.320s,  400.43/s)  LR: 2.457e-05  Data: 0.012 (0.018)
Train: 144 [ 200/390 ( 51%)]  Loss: 3.194 (3.17)  Time: 0.313s,  409.02/s  (0.317s,  404.34/s)  LR: 2.457e-05  Data: 0.011 (0.015)
Train: 144 [ 300/390 ( 77%)]  Loss: 3.041 (3.20)  Time: 0.313s,  409.44/s  (0.316s,  405.60/s)  LR: 2.457e-05  Data: 0.011 (0.014)
Train: 144 [ 389/390 (100%)]  Loss: 2.802 (3.20)  Time: 0.301s,  424.99/s  (0.315s,  406.22/s)  LR: 2.457e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.296 (0.296)  Loss:  1.0166 (1.0166)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.017 (0.124)  Loss:  0.6997 (1.0247)  Acc@1: 87.5000 (76.4300)  Acc@5: 100.0000 (95.3900)
Test: [Whole Val]  Time: 9.809  Loss: 1.0247  Acc@1: 76.4300 Pruned: 50.75% 
Test (EMA): [   0/78]  Time: 0.309 (0.309)  Loss:  1.0146 (1.0146)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.6997 (1.0247)  Acc@1: 87.5000 (76.4400)  Acc@5: 100.0000 (95.3600)
Test (EMA): [Whole Val]  Time: 9.604  Loss: 1.0247  Acc@1: 76.4400 Pruned: 50.75% 
Train: 145 [   0/390 (  0%)]  Loss: 3.571 (3.57)  Time: 0.784s,  163.31/s  (0.784s,  163.31/s)  LR: 2.163e-05  Data: 0.479 (0.479)
Train: 145 [ 100/390 ( 26%)]  Loss: 3.661 (3.18)  Time: 0.313s,  408.42/s  (0.318s,  402.29/s)  LR: 2.163e-05  Data: 0.012 (0.017)
Train: 145 [ 200/390 ( 51%)]  Loss: 3.758 (3.22)  Time: 0.312s,  409.76/s  (0.316s,  405.29/s)  LR: 2.163e-05  Data: 0.012 (0.014)
Train: 145 [ 300/390 ( 77%)]  Loss: 3.226 (3.19)  Time: 0.314s,  407.86/s  (0.315s,  406.24/s)  LR: 2.163e-05  Data: 0.012 (0.014)
Train: 145 [ 389/390 (100%)]  Loss: 3.559 (3.17)  Time: 0.302s,  424.26/s  (0.315s,  406.86/s)  LR: 2.163e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.316 (0.316)  Loss:  1.0166 (1.0166)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.7051 (1.0185)  Acc@1: 87.5000 (76.3100)  Acc@5: 100.0000 (95.4300)
Test: [Whole Val]  Time: 9.604  Loss: 1.0185  Acc@1: 76.3100 Pruned: 50.75% 
Test (EMA): [   0/78]  Time: 0.371 (0.371)  Loss:  1.0156 (1.0156)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.7017 (1.0157)  Acc@1: 87.5000 (76.4300)  Acc@5: 100.0000 (95.4200)
Test (EMA): [Whole Val]  Time: 9.664  Loss: 1.0157  Acc@1: 76.4300 Pruned: 50.75% 
Train: 146 [   0/390 (  0%)]  Loss: 2.338 (2.34)  Time: 0.768s,  166.70/s  (0.768s,  166.70/s)  LR: 1.887e-05  Data: 0.465 (0.465)
Train: 146 [ 100/390 ( 26%)]  Loss: 3.100 (3.14)  Time: 0.316s,  404.43/s  (0.318s,  402.24/s)  LR: 1.887e-05  Data: 0.016 (0.016)
Train: 146 [ 200/390 ( 51%)]  Loss: 3.423 (3.13)  Time: 0.313s,  408.47/s  (0.316s,  405.25/s)  LR: 1.887e-05  Data: 0.013 (0.014)
Train: 146 [ 300/390 ( 77%)]  Loss: 3.666 (3.16)  Time: 0.313s,  409.13/s  (0.315s,  405.99/s)  LR: 1.887e-05  Data: 0.012 (0.013)
Train: 146 [ 389/390 (100%)]  Loss: 2.865 (3.17)  Time: 0.301s,  425.44/s  (0.315s,  406.56/s)  LR: 1.887e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.418 (0.418)  Loss:  1.0137 (1.0137)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.019 (0.123)  Loss:  0.7144 (1.0206)  Acc@1: 81.2500 (76.3200)  Acc@5: 100.0000 (95.4300)
Test: [Whole Val]  Time: 9.708  Loss: 1.0206  Acc@1: 76.3200 Pruned: 50.75% 
Test (EMA): [   0/78]  Time: 0.309 (0.309)  Loss:  1.0156 (1.0156)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.7109 (1.0221)  Acc@1: 87.5000 (76.2300)  Acc@5: 100.0000 (95.3600)
Test (EMA): [Whole Val]  Time: 9.608  Loss: 1.0221  Acc@1: 76.2300 Pruned: 50.75% 
Train: 147 [   0/390 (  0%)]  Loss: 2.532 (2.53)  Time: 0.746s,  171.62/s  (0.746s,  171.62/s)  LR: 1.630e-05  Data: 0.441 (0.441)
Train: 147 [ 100/390 ( 26%)]  Loss: 3.353 (3.18)  Time: 0.312s,  409.91/s  (0.318s,  402.54/s)  LR: 1.630e-05  Data: 0.011 (0.016)
Train: 147 [ 200/390 ( 51%)]  Loss: 3.261 (3.18)  Time: 0.315s,  406.66/s  (0.316s,  404.99/s)  LR: 1.630e-05  Data: 0.012 (0.014)
Train: 147 [ 300/390 ( 77%)]  Loss: 3.471 (3.18)  Time: 0.313s,  409.48/s  (0.315s,  405.92/s)  LR: 1.630e-05  Data: 0.011 (0.013)
Train: 147 [ 389/390 (100%)]  Loss: 3.923 (3.18)  Time: 0.302s,  424.26/s  (0.315s,  406.38/s)  LR: 1.630e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.425 (0.425)  Loss:  1.0107 (1.0107)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  0.7080 (1.0180)  Acc@1: 81.2500 (76.4200)  Acc@5: 100.0000 (95.3800)
Test: [Whole Val]  Time: 9.713  Loss: 1.0180  Acc@1: 76.4200 Pruned: 50.75% 
Test (EMA): [   0/78]  Time: 0.309 (0.309)  Loss:  1.0117 (1.0117)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.7090 (1.0187)  Acc@1: 87.5000 (76.4200)  Acc@5: 100.0000 (95.3800)
Test (EMA): [Whole Val]  Time: 9.615  Loss: 1.0187  Acc@1: 76.4200 Pruned: 50.75% 
Train: 148 [   0/390 (  0%)]  Loss: 2.894 (2.89)  Time: 0.725s,  176.64/s  (0.725s,  176.64/s)  LR: 1.391e-05  Data: 0.410 (0.410)
Train: 148 [ 100/390 ( 26%)]  Loss: 3.171 (3.22)  Time: 0.313s,  408.31/s  (0.318s,  402.36/s)  LR: 1.391e-05  Data: 0.012 (0.016)
Train: 148 [ 200/390 ( 51%)]  Loss: 3.239 (3.21)  Time: 0.313s,  408.50/s  (0.316s,  405.18/s)  LR: 1.391e-05  Data: 0.013 (0.014)
Train: 148 [ 300/390 ( 77%)]  Loss: 3.557 (3.23)  Time: 0.315s,  406.91/s  (0.315s,  406.12/s)  LR: 1.391e-05  Data: 0.012 (0.013)
Train: 148 [ 389/390 (100%)]  Loss: 3.263 (3.21)  Time: 0.301s,  424.64/s  (0.315s,  406.78/s)  LR: 1.391e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.396 (0.396)  Loss:  1.0195 (1.0195)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.123)  Loss:  0.7188 (1.0227)  Acc@1: 81.2500 (76.3800)  Acc@5: 100.0000 (95.4400)
Test: [Whole Val]  Time: 9.678  Loss: 1.0227  Acc@1: 76.3800 Pruned: 50.75% 
Test (EMA): [   0/78]  Time: 0.313 (0.313)  Loss:  1.0195 (1.0195)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.7202 (1.0235)  Acc@1: 81.2500 (76.4300)  Acc@5: 100.0000 (95.4700)
Test (EMA): [Whole Val]  Time: 9.581  Loss: 1.0235  Acc@1: 76.4300 Pruned: 50.75% 
Train: 149 [   0/390 (  0%)]  Loss: 2.808 (2.81)  Time: 0.772s,  165.71/s  (0.772s,  165.71/s)  LR: 1.172e-05  Data: 0.469 (0.469)
Train: 149 [ 100/390 ( 26%)]  Loss: 2.964 (3.25)  Time: 0.313s,  409.16/s  (0.318s,  403.07/s)  LR: 1.172e-05  Data: 0.011 (0.016)
Train: 149 [ 200/390 ( 51%)]  Loss: 3.239 (3.22)  Time: 0.314s,  407.39/s  (0.316s,  405.65/s)  LR: 1.172e-05  Data: 0.012 (0.014)
Train: 149 [ 300/390 ( 77%)]  Loss: 3.104 (3.21)  Time: 0.312s,  409.69/s  (0.315s,  406.22/s)  LR: 1.172e-05  Data: 0.012 (0.013)
Train: 149 [ 389/390 (100%)]  Loss: 3.844 (3.20)  Time: 0.301s,  425.90/s  (0.315s,  406.71/s)  LR: 1.172e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.306 (0.306)  Loss:  1.0195 (1.0195)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.121)  Loss:  0.7222 (1.0242)  Acc@1: 87.5000 (76.4700)  Acc@5: 100.0000 (95.3500)
Test: [Whole Val]  Time: 9.591  Loss: 1.0242  Acc@1: 76.4700 Pruned: 50.75% 
Test (EMA): [   0/78]  Time: 0.323 (0.323)  Loss:  1.0195 (1.0195)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.7236 (1.0236)  Acc@1: 81.2500 (76.4100)  Acc@5: 100.0000 (95.3700)
Test (EMA): [Whole Val]  Time: 9.614  Loss: 1.0236  Acc@1: 76.4100 Pruned: 50.75% 
Train: 150 [   0/390 (  0%)]  Loss: 3.098 (3.10)  Time: 0.867s,  147.65/s  (0.867s,  147.65/s)  LR: 9.706e-06  Data: 0.565 (0.565)
Train: 150 [ 100/390 ( 26%)]  Loss: 2.700 (3.20)  Time: 0.313s,  409.36/s  (0.319s,  401.32/s)  LR: 9.706e-06  Data: 0.012 (0.017)
Train: 150 [ 200/390 ( 51%)]  Loss: 2.630 (3.17)  Time: 0.313s,  408.54/s  (0.316s,  404.68/s)  LR: 9.706e-06  Data: 0.012 (0.015)
Train: 150 [ 300/390 ( 77%)]  Loss: 3.491 (3.19)  Time: 0.313s,  409.21/s  (0.315s,  405.88/s)  LR: 9.706e-06  Data: 0.012 (0.014)
Train: 150 [ 389/390 (100%)]  Loss: 2.482 (3.19)  Time: 0.303s,  422.63/s  (0.315s,  406.39/s)  LR: 9.706e-06  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.388 (0.388)  Loss:  1.0225 (1.0225)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.7231 (1.0275)  Acc@1: 87.5000 (76.4300)  Acc@5: 100.0000 (95.3700)
Test: [Whole Val]  Time: 9.677  Loss: 1.0275  Acc@1: 76.4300 Pruned: 50.75% 
Test (EMA): [   0/78]  Time: 0.355 (0.355)  Loss:  1.0234 (1.0234)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.019 (0.122)  Loss:  0.7241 (1.0281)  Acc@1: 87.5000 (76.4500)  Acc@5: 100.0000 (95.3800)
Test (EMA): [Whole Val]  Time: 9.672  Loss: 1.0281  Acc@1: 76.4500 Pruned: 50.75% 
Train: 151 [   0/390 (  0%)]  Loss: 3.699 (3.70)  Time: 0.775s,  165.21/s  (0.775s,  165.21/s)  LR: 7.886e-06  Data: 0.466 (0.466)
Train: 151 [ 100/390 ( 26%)]  Loss: 2.867 (3.27)  Time: 0.312s,  409.78/s  (0.320s,  400.39/s)  LR: 7.886e-06  Data: 0.012 (0.017)
Train: 151 [ 200/390 ( 51%)]  Loss: 2.382 (3.28)  Time: 0.312s,  409.78/s  (0.317s,  404.17/s)  LR: 7.886e-06  Data: 0.011 (0.015)
Train: 151 [ 300/390 ( 77%)]  Loss: 2.310 (3.24)  Time: 0.313s,  408.65/s  (0.316s,  405.42/s)  LR: 7.886e-06  Data: 0.011 (0.014)
Train: 151 [ 389/390 (100%)]  Loss: 2.936 (3.22)  Time: 0.301s,  425.21/s  (0.315s,  406.12/s)  LR: 7.886e-06  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.323 (0.323)  Loss:  1.0205 (1.0205)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.7119 (1.0257)  Acc@1: 87.5000 (76.3000)  Acc@5: 100.0000 (95.4400)
Test: [Whole Val]  Time: 9.625  Loss: 1.0257  Acc@1: 76.3000 Pruned: 50.75% 
Test (EMA): [   0/78]  Time: 0.390 (0.390)  Loss:  1.0195 (1.0195)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.7129 (1.0258)  Acc@1: 87.5000 (76.3200)  Acc@5: 100.0000 (95.4100)
Test (EMA): [Whole Val]  Time: 9.665  Loss: 1.0258  Acc@1: 76.3200 Pruned: 50.75% 
Train: 152 [   0/390 (  0%)]  Loss: 3.705 (3.71)  Time: 0.915s,  139.86/s  (0.915s,  139.86/s)  LR: 6.255e-06  Data: 0.612 (0.612)
Train: 152 [ 100/390 ( 26%)]  Loss: 3.206 (3.20)  Time: 0.314s,  407.58/s  (0.320s,  400.40/s)  LR: 6.255e-06  Data: 0.012 (0.018)
Train: 152 [ 200/390 ( 51%)]  Loss: 3.127 (3.22)  Time: 0.314s,  407.53/s  (0.317s,  404.02/s)  LR: 6.255e-06  Data: 0.011 (0.015)
Train: 152 [ 300/390 ( 77%)]  Loss: 3.745 (3.24)  Time: 0.313s,  409.53/s  (0.316s,  405.53/s)  LR: 6.255e-06  Data: 0.012 (0.014)
Train: 152 [ 389/390 (100%)]  Loss: 3.865 (3.23)  Time: 0.303s,  423.08/s  (0.315s,  406.19/s)  LR: 6.255e-06  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.322 (0.322)  Loss:  1.0254 (1.0254)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.7280 (1.0326)  Acc@1: 87.5000 (76.3200)  Acc@5: 100.0000 (95.3700)
Test: [Whole Val]  Time: 9.629  Loss: 1.0326  Acc@1: 76.3200 Pruned: 50.75% 
Test (EMA): [   0/78]  Time: 0.395 (0.395)  Loss:  1.0254 (1.0254)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.7275 (1.0322)  Acc@1: 87.5000 (76.3200)  Acc@5: 100.0000 (95.3600)
Test (EMA): [Whole Val]  Time: 9.652  Loss: 1.0322  Acc@1: 76.3200 Pruned: 50.75% 
Train: 153 [   0/390 (  0%)]  Loss: 2.818 (2.82)  Time: 0.737s,  173.62/s  (0.737s,  173.62/s)  LR: 4.815e-06  Data: 0.436 (0.436)
Train: 153 [ 100/390 ( 26%)]  Loss: 3.488 (3.14)  Time: 0.312s,  409.68/s  (0.319s,  401.68/s)  LR: 4.815e-06  Data: 0.011 (0.016)
Train: 153 [ 200/390 ( 51%)]  Loss: 3.092 (3.16)  Time: 0.312s,  410.16/s  (0.316s,  405.10/s)  LR: 4.815e-06  Data: 0.011 (0.014)
Train: 153 [ 300/390 ( 77%)]  Loss: 3.642 (3.19)  Time: 0.313s,  409.15/s  (0.315s,  406.08/s)  LR: 4.815e-06  Data: 0.012 (0.013)
Train: 153 [ 389/390 (100%)]  Loss: 2.942 (3.20)  Time: 0.302s,  424.43/s  (0.315s,  406.57/s)  LR: 4.815e-06  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.405 (0.405)  Loss:  1.0225 (1.0225)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.7266 (1.0307)  Acc@1: 87.5000 (76.3100)  Acc@5: 100.0000 (95.3600)
Test: [Whole Val]  Time: 9.671  Loss: 1.0307  Acc@1: 76.3100 Pruned: 50.75% 
Test (EMA): [   0/78]  Time: 0.321 (0.321)  Loss:  1.0225 (1.0225)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.7266 (1.0303)  Acc@1: 87.5000 (76.3000)  Acc@5: 100.0000 (95.3800)
Test (EMA): [Whole Val]  Time: 9.600  Loss: 1.0303  Acc@1: 76.3000 Pruned: 50.75% 
Train: 154 [   0/390 (  0%)]  Loss: 3.707 (3.71)  Time: 0.755s,  169.50/s  (0.755s,  169.50/s)  LR: 3.565e-06  Data: 0.453 (0.453)
Train: 154 [ 100/390 ( 26%)]  Loss: 3.493 (3.20)  Time: 0.313s,  408.65/s  (0.318s,  402.76/s)  LR: 3.565e-06  Data: 0.012 (0.016)
Train: 154 [ 200/390 ( 51%)]  Loss: 2.595 (3.21)  Time: 0.312s,  409.89/s  (0.316s,  405.37/s)  LR: 3.565e-06  Data: 0.011 (0.014)
Train: 154 [ 300/390 ( 77%)]  Loss: 2.643 (3.21)  Time: 0.314s,  408.14/s  (0.315s,  406.40/s)  LR: 3.565e-06  Data: 0.012 (0.013)
Train: 154 [ 389/390 (100%)]  Loss: 3.475 (3.22)  Time: 0.302s,  423.93/s  (0.315s,  406.79/s)  LR: 3.565e-06  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.404 (0.404)  Loss:  1.0225 (1.0225)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  0.7246 (1.0295)  Acc@1: 87.5000 (76.4000)  Acc@5: 100.0000 (95.4100)
Test: [Whole Val]  Time: 9.680  Loss: 1.0295  Acc@1: 76.4000 Pruned: 50.75% 
Test (EMA): [   0/78]  Time: 0.314 (0.314)  Loss:  1.0225 (1.0225)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.121)  Loss:  0.7256 (1.0295)  Acc@1: 87.5000 (76.4200)  Acc@5: 100.0000 (95.4200)
Test (EMA): [Whole Val]  Time: 9.585  Loss: 1.0295  Acc@1: 76.4200 Pruned: 50.75% 
Train: 155 [   0/390 (  0%)]  Loss: 3.337 (3.34)  Time: 0.829s,  154.43/s  (0.829s,  154.43/s)  LR: 2.507e-06  Data: 0.528 (0.528)
Train: 155 [ 100/390 ( 26%)]  Loss: 3.588 (3.18)  Time: 0.312s,  409.75/s  (0.318s,  401.96/s)  LR: 2.507e-06  Data: 0.011 (0.017)
Train: 155 [ 200/390 ( 51%)]  Loss: 3.257 (3.17)  Time: 0.313s,  408.68/s  (0.316s,  405.15/s)  LR: 2.507e-06  Data: 0.012 (0.014)
Train: 155 [ 300/390 ( 77%)]  Loss: 2.943 (3.17)  Time: 0.312s,  409.91/s  (0.315s,  406.12/s)  LR: 2.507e-06  Data: 0.011 (0.014)
Train: 155 [ 389/390 (100%)]  Loss: 3.447 (3.19)  Time: 0.301s,  424.90/s  (0.315s,  406.72/s)  LR: 2.507e-06  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.311 (0.311)  Loss:  1.0195 (1.0195)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.121)  Loss:  0.7207 (1.0264)  Acc@1: 87.5000 (76.4000)  Acc@5: 100.0000 (95.3800)
Test: [Whole Val]  Time: 9.586  Loss: 1.0264  Acc@1: 76.4000 Pruned: 50.75% 
Test (EMA): [   0/78]  Time: 0.318 (0.318)  Loss:  1.0195 (1.0195)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.7202 (1.0262)  Acc@1: 87.5000 (76.3900)  Acc@5: 100.0000 (95.3900)
Test (EMA): [Whole Val]  Time: 9.607  Loss: 1.0262  Acc@1: 76.3900 Pruned: 50.75% 
Train: 156 [   0/390 (  0%)]  Loss: 2.430 (2.43)  Time: 0.796s,  160.79/s  (0.796s,  160.79/s)  LR: 1.641e-06  Data: 0.487 (0.487)
Train: 156 [ 100/390 ( 26%)]  Loss: 2.514 (3.22)  Time: 0.313s,  408.86/s  (0.318s,  401.96/s)  LR: 1.641e-06  Data: 0.012 (0.017)
Train: 156 [ 200/390 ( 51%)]  Loss: 3.679 (3.16)  Time: 0.312s,  410.25/s  (0.317s,  404.40/s)  LR: 1.641e-06  Data: 0.011 (0.014)
Train: 156 [ 300/390 ( 77%)]  Loss: 3.696 (3.17)  Time: 0.313s,  409.05/s  (0.316s,  405.53/s)  LR: 1.641e-06  Data: 0.012 (0.014)
Train: 156 [ 389/390 (100%)]  Loss: 3.170 (3.18)  Time: 0.301s,  425.36/s  (0.315s,  406.22/s)  LR: 1.641e-06  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.369 (0.369)  Loss:  1.0176 (1.0176)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.7217 (1.0256)  Acc@1: 87.5000 (76.3900)  Acc@5: 100.0000 (95.4000)
Test: [Whole Val]  Time: 9.650  Loss: 1.0256  Acc@1: 76.3900 Pruned: 50.75% 
Test (EMA): [   0/78]  Time: 0.355 (0.355)  Loss:  1.0176 (1.0176)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.020 (0.122)  Loss:  0.7217 (1.0254)  Acc@1: 87.5000 (76.4000)  Acc@5: 100.0000 (95.4100)
Test (EMA): [Whole Val]  Time: 9.624  Loss: 1.0254  Acc@1: 76.4000 Pruned: 50.75% 
Train: 157 [   0/390 (  0%)]  Loss: 2.557 (2.56)  Time: 0.701s,  182.55/s  (0.701s,  182.55/s)  LR: 9.671e-07  Data: 0.396 (0.396)
Train: 157 [ 100/390 ( 26%)]  Loss: 2.173 (3.14)  Time: 0.313s,  409.54/s  (0.317s,  403.79/s)  LR: 9.671e-07  Data: 0.011 (0.016)
Train: 157 [ 200/390 ( 51%)]  Loss: 3.471 (3.17)  Time: 0.312s,  409.70/s  (0.315s,  406.07/s)  LR: 9.671e-07  Data: 0.012 (0.014)
Train: 157 [ 300/390 ( 77%)]  Loss: 3.729 (3.16)  Time: 0.313s,  409.47/s  (0.315s,  406.84/s)  LR: 9.671e-07  Data: 0.011 (0.013)
Train: 157 [ 389/390 (100%)]  Loss: 3.376 (3.14)  Time: 0.301s,  425.53/s  (0.314s,  407.17/s)  LR: 9.671e-07  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.372 (0.372)  Loss:  1.0156 (1.0156)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.7197 (1.0232)  Acc@1: 87.5000 (76.4000)  Acc@5: 100.0000 (95.4200)
Test: [Whole Val]  Time: 9.633  Loss: 1.0232  Acc@1: 76.4000 Pruned: 50.75% 
Test (EMA): [   0/78]  Time: 0.314 (0.314)  Loss:  1.0156 (1.0156)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.7202 (1.0232)  Acc@1: 87.5000 (76.4200)  Acc@5: 100.0000 (95.4200)
Test (EMA): [Whole Val]  Time: 9.573  Loss: 1.0232  Acc@1: 76.4200 Pruned: 50.75% 
Train: 158 [   0/390 (  0%)]  Loss: 3.372 (3.37)  Time: 0.760s,  168.46/s  (0.760s,  168.46/s)  LR: 4.854e-07  Data: 0.457 (0.457)
Train: 158 [ 100/390 ( 26%)]  Loss: 2.417 (3.15)  Time: 0.312s,  410.04/s  (0.318s,  402.72/s)  LR: 4.854e-07  Data: 0.011 (0.016)
Train: 158 [ 200/390 ( 51%)]  Loss: 3.201 (3.16)  Time: 0.312s,  410.16/s  (0.316s,  405.48/s)  LR: 4.854e-07  Data: 0.012 (0.014)
Train: 158 [ 300/390 ( 77%)]  Loss: 2.329 (3.17)  Time: 0.315s,  406.21/s  (0.315s,  406.57/s)  LR: 4.854e-07  Data: 0.012 (0.013)
Train: 158 [ 389/390 (100%)]  Loss: 2.370 (3.17)  Time: 0.302s,  424.13/s  (0.314s,  407.01/s)  LR: 4.854e-07  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.310 (0.310)  Loss:  1.0156 (1.0156)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.7188 (1.0230)  Acc@1: 87.5000 (76.3900)  Acc@5: 100.0000 (95.4200)
Test: [Whole Val]  Time: 9.576  Loss: 1.0230  Acc@1: 76.3900 Pruned: 50.75% 
Test (EMA): [   0/78]  Time: 0.404 (0.404)  Loss:  1.0156 (1.0156)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.7188 (1.0230)  Acc@1: 87.5000 (76.3800)  Acc@5: 100.0000 (95.4200)
Test (EMA): [Whole Val]  Time: 9.653  Loss: 1.0230  Acc@1: 76.3800 Pruned: 50.75% 
Train: 159 [   0/390 (  0%)]  Loss: 3.619 (3.62)  Time: 0.760s,  168.45/s  (0.760s,  168.45/s)  LR: 1.964e-07  Data: 0.460 (0.460)
Train: 159 [ 100/390 ( 26%)]  Loss: 3.140 (3.17)  Time: 0.314s,  408.09/s  (0.318s,  401.95/s)  LR: 1.964e-07  Data: 0.011 (0.017)
Train: 159 [ 200/390 ( 51%)]  Loss: 2.149 (3.15)  Time: 0.314s,  407.77/s  (0.316s,  404.58/s)  LR: 1.964e-07  Data: 0.013 (0.015)
Train: 159 [ 300/390 ( 77%)]  Loss: 3.580 (3.17)  Time: 0.313s,  409.07/s  (0.316s,  405.26/s)  LR: 1.964e-07  Data: 0.012 (0.014)
Train: 159 [ 389/390 (100%)]  Loss: 3.726 (3.19)  Time: 0.301s,  425.06/s  (0.315s,  405.95/s)  LR: 1.964e-07  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.314 (0.314)  Loss:  1.0156 (1.0156)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.7192 (1.0229)  Acc@1: 87.5000 (76.4200)  Acc@5: 100.0000 (95.4300)
Test: [Whole Val]  Time: 9.593  Loss: 1.0229  Acc@1: 76.4200 Pruned: 50.75% 
Test (EMA): [   0/78]  Time: 0.360 (0.360)  Loss:  1.0156 (1.0156)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.7188 (1.0229)  Acc@1: 87.5000 (76.4100)  Acc@5: 100.0000 (95.4200)
Test (EMA): [Whole Val]  Time: 9.633  Loss: 1.0229  Acc@1: 76.4100 Pruned: 50.75% 
Train: 160 [   0/390 (  0%)]  Loss: 3.577 (3.58)  Time: 0.757s,  169.19/s  (0.757s,  169.19/s)  LR: 1.000e-07  Data: 0.454 (0.454)
Train: 160 [ 100/390 ( 26%)]  Loss: 3.538 (3.23)  Time: 0.313s,  408.33/s  (0.318s,  402.95/s)  LR: 1.000e-07  Data: 0.012 (0.016)
Train: 160 [ 200/390 ( 51%)]  Loss: 2.898 (3.24)  Time: 0.312s,  410.56/s  (0.315s,  405.76/s)  LR: 1.000e-07  Data: 0.011 (0.014)
Train: 160 [ 300/390 ( 77%)]  Loss: 2.959 (3.21)  Time: 0.311s,  410.92/s  (0.314s,  407.27/s)  LR: 1.000e-07  Data: 0.011 (0.013)
Train: 160 [ 389/390 (100%)]  Loss: 3.774 (3.22)  Time: 0.299s,  428.76/s  (0.314s,  408.15/s)  LR: 1.000e-07  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.354 (0.354)  Loss:  1.0156 (1.0156)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.7192 (1.0231)  Acc@1: 87.5000 (76.3800)  Acc@5: 100.0000 (95.4100)
Test: [Whole Val]  Time: 9.569  Loss: 1.0231  Acc@1: 76.3800 Pruned: 50.75% 
Test (EMA): [   0/78]  Time: 0.357 (0.357)  Loss:  1.0156 (1.0156)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.7192 (1.0231)  Acc@1: 87.5000 (76.4000)  Acc@5: 100.0000 (95.4100)
Test (EMA): [Whole Val]  Time: 9.573  Loss: 1.0231  Acc@1: 76.4000 Pruned: 50.75% 
Train: 161 [   0/390 (  0%)]  Loss: 3.709 (3.71)  Time: 0.820s,  156.12/s  (0.820s,  156.12/s)  LR: 1.000e-07  Data: 0.519 (0.519)
Train: 161 [ 100/390 ( 26%)]  Loss: 2.657 (3.17)  Time: 0.311s,  411.01/s  (0.317s,  404.27/s)  LR: 1.000e-07  Data: 0.011 (0.016)
Train: 161 [ 200/390 ( 51%)]  Loss: 2.703 (3.17)  Time: 0.311s,  411.12/s  (0.314s,  407.68/s)  LR: 1.000e-07  Data: 0.011 (0.014)
Train: 161 [ 300/390 ( 77%)]  Loss: 3.868 (3.18)  Time: 0.311s,  411.07/s  (0.313s,  408.73/s)  LR: 1.000e-07  Data: 0.011 (0.013)
Train: 161 [ 389/390 (100%)]  Loss: 3.939 (3.18)  Time: 0.298s,  429.01/s  (0.313s,  409.39/s)  LR: 1.000e-07  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.308 (0.308)  Loss:  1.0156 (1.0156)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.7192 (1.0230)  Acc@1: 87.5000 (76.4000)  Acc@5: 100.0000 (95.4200)
Test: [Whole Val]  Time: 9.533  Loss: 1.0230  Acc@1: 76.4000 Pruned: 50.75% 
Test (EMA): [   0/78]  Time: 0.310 (0.310)  Loss:  1.0156 (1.0156)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.7192 (1.0230)  Acc@1: 87.5000 (76.4100)  Acc@5: 100.0000 (95.4100)
Test (EMA): [Whole Val]  Time: 9.541  Loss: 1.0230  Acc@1: 76.4100 Pruned: 50.75% 
Train: 162 [   0/390 (  0%)]  Loss: 3.559 (3.56)  Time: 0.746s,  171.65/s  (0.746s,  171.65/s)  LR: 1.000e-07  Data: 0.445 (0.445)
Train: 162 [ 100/390 ( 26%)]  Loss: 3.418 (3.21)  Time: 0.311s,  411.51/s  (0.315s,  405.78/s)  LR: 1.000e-07  Data: 0.011 (0.016)
Train: 162 [ 200/390 ( 51%)]  Loss: 3.744 (3.20)  Time: 0.311s,  411.60/s  (0.313s,  408.41/s)  LR: 1.000e-07  Data: 0.011 (0.013)
Train: 162 [ 300/390 ( 77%)]  Loss: 3.756 (3.20)  Time: 0.310s,  412.34/s  (0.313s,  409.39/s)  LR: 1.000e-07  Data: 0.011 (0.013)
Train: 162 [ 389/390 (100%)]  Loss: 2.576 (3.19)  Time: 0.299s,  428.75/s  (0.312s,  409.65/s)  LR: 1.000e-07  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.308 (0.308)  Loss:  1.0156 (1.0156)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.7192 (1.0231)  Acc@1: 87.5000 (76.4000)  Acc@5: 100.0000 (95.4100)
Test: [Whole Val]  Time: 9.522  Loss: 1.0231  Acc@1: 76.4000 Pruned: 50.75% 
Test (EMA): [   0/78]  Time: 0.310 (0.310)  Loss:  1.0156 (1.0156)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.7192 (1.0231)  Acc@1: 87.5000 (76.4100)  Acc@5: 100.0000 (95.4200)
Test (EMA): [Whole Val]  Time: 9.527  Loss: 1.0231  Acc@1: 76.4100 Pruned: 50.75% 
Train: 163 [   0/390 (  0%)]  Loss: 2.651 (2.65)  Time: 0.742s,  172.48/s  (0.742s,  172.48/s)  LR: 1.000e-07  Data: 0.441 (0.441)
Train: 163 [ 100/390 ( 26%)]  Loss: 3.675 (3.23)  Time: 0.311s,  411.72/s  (0.316s,  405.26/s)  LR: 1.000e-07  Data: 0.011 (0.016)
Train: 163 [ 200/390 ( 51%)]  Loss: 3.251 (3.20)  Time: 0.312s,  409.97/s  (0.314s,  408.14/s)  LR: 1.000e-07  Data: 0.012 (0.013)
Train: 163 [ 300/390 ( 77%)]  Loss: 3.162 (3.20)  Time: 0.311s,  411.83/s  (0.313s,  409.05/s)  LR: 1.000e-07  Data: 0.011 (0.013)
Train: 163 [ 389/390 (100%)]  Loss: 3.578 (3.19)  Time: 0.299s,  428.21/s  (0.313s,  409.58/s)  LR: 1.000e-07  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.375 (0.375)  Loss:  1.0156 (1.0156)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.7192 (1.0230)  Acc@1: 87.5000 (76.4200)  Acc@5: 100.0000 (95.4100)
Test: [Whole Val]  Time: 9.586  Loss: 1.0230  Acc@1: 76.4200 Pruned: 50.75% 
Test (EMA): [   0/78]  Time: 0.312 (0.312)  Loss:  1.0156 (1.0156)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.7192 (1.0230)  Acc@1: 87.5000 (76.4200)  Acc@5: 100.0000 (95.4200)
Test (EMA): [Whole Val]  Time: 9.546  Loss: 1.0230  Acc@1: 76.4200 Pruned: 50.75% 
Train: 164 [   0/390 (  0%)]  Loss: 2.536 (2.54)  Time: 0.701s,  182.51/s  (0.701s,  182.51/s)  LR: 1.000e-07  Data: 0.401 (0.401)
Train: 164 [ 100/390 ( 26%)]  Loss: 2.283 (3.09)  Time: 0.311s,  412.04/s  (0.316s,  405.57/s)  LR: 1.000e-07  Data: 0.011 (0.015)
Train: 164 [ 200/390 ( 51%)]  Loss: 3.547 (3.12)  Time: 0.312s,  410.37/s  (0.314s,  408.11/s)  LR: 1.000e-07  Data: 0.011 (0.013)
Train: 164 [ 300/390 ( 77%)]  Loss: 2.724 (3.11)  Time: 0.311s,  411.32/s  (0.313s,  408.92/s)  LR: 1.000e-07  Data: 0.011 (0.013)
Train: 164 [ 389/390 (100%)]  Loss: 3.788 (3.15)  Time: 0.298s,  428.86/s  (0.313s,  409.52/s)  LR: 1.000e-07  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.311 (0.311)  Loss:  1.0156 (1.0156)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.7188 (1.0229)  Acc@1: 87.5000 (76.4200)  Acc@5: 100.0000 (95.4200)
Test: [Whole Val]  Time: 9.548  Loss: 1.0229  Acc@1: 76.4200 Pruned: 50.75% 
Test (EMA): [   0/78]  Time: 0.310 (0.310)  Loss:  1.0156 (1.0156)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.7188 (1.0229)  Acc@1: 87.5000 (76.4100)  Acc@5: 100.0000 (95.4100)
Test (EMA): [Whole Val]  Time: 9.553  Loss: 1.0229  Acc@1: 76.4100 Pruned: 50.75% 
Train: 165 [   0/390 (  0%)]  Loss: 2.222 (2.22)  Time: 0.739s,  173.12/s  (0.739s,  173.12/s)  LR: 1.000e-07  Data: 0.438 (0.438)
Train: 165 [ 100/390 ( 26%)]  Loss: 3.514 (3.11)  Time: 0.311s,  411.28/s  (0.316s,  405.43/s)  LR: 1.000e-07  Data: 0.011 (0.016)
Train: 165 [ 200/390 ( 51%)]  Loss: 3.420 (3.09)  Time: 0.311s,  412.15/s  (0.314s,  407.99/s)  LR: 1.000e-07  Data: 0.011 (0.013)
Train: 165 [ 300/390 ( 77%)]  Loss: 3.119 (3.11)  Time: 0.312s,  410.35/s  (0.313s,  408.90/s)  LR: 1.000e-07  Data: 0.012 (0.013)
Train: 165 [ 389/390 (100%)]  Loss: 3.240 (3.14)  Time: 0.298s,  429.10/s  (0.313s,  409.41/s)  LR: 1.000e-07  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.316 (0.316)  Loss:  1.0156 (1.0156)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.7183 (1.0226)  Acc@1: 87.5000 (76.4100)  Acc@5: 100.0000 (95.4200)
Test: [Whole Val]  Time: 9.544  Loss: 1.0226  Acc@1: 76.4100 Pruned: 50.75% 
Test (EMA): [   0/78]  Time: 0.353 (0.353)  Loss:  1.0156 (1.0156)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.7183 (1.0226)  Acc@1: 87.5000 (76.4200)  Acc@5: 100.0000 (95.4200)
Test (EMA): [Whole Val]  Time: 9.577  Loss: 1.0226  Acc@1: 76.4200 Pruned: 50.75% 
Train: 166 [   0/390 (  0%)]  Loss: 3.547 (3.55)  Time: 0.773s,  165.60/s  (0.773s,  165.60/s)  LR: 1.000e-07  Data: 0.471 (0.471)
Train: 166 [ 100/390 ( 26%)]  Loss: 2.991 (3.24)  Time: 0.311s,  411.72/s  (0.317s,  403.97/s)  LR: 1.000e-07  Data: 0.011 (0.016)
Train: 166 [ 200/390 ( 51%)]  Loss: 3.434 (3.20)  Time: 0.311s,  410.94/s  (0.314s,  407.33/s)  LR: 1.000e-07  Data: 0.011 (0.014)
Train: 166 [ 300/390 ( 77%)]  Loss: 2.202 (3.19)  Time: 0.311s,  411.63/s  (0.313s,  408.55/s)  LR: 1.000e-07  Data: 0.011 (0.013)
Train: 166 [ 389/390 (100%)]  Loss: 3.180 (3.20)  Time: 0.298s,  429.40/s  (0.313s,  409.19/s)  LR: 1.000e-07  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.308 (0.308)  Loss:  1.0156 (1.0156)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.7183 (1.0227)  Acc@1: 87.5000 (76.4000)  Acc@5: 100.0000 (95.4200)
Test: [Whole Val]  Time: 9.524  Loss: 1.0227  Acc@1: 76.4000 Pruned: 50.75% 
Test (EMA): [   0/78]  Time: 0.300 (0.300)  Loss:  1.0156 (1.0156)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.7183 (1.0227)  Acc@1: 87.5000 (76.4100)  Acc@5: 100.0000 (95.4200)
Test (EMA): [Whole Val]  Time: 9.523  Loss: 1.0227  Acc@1: 76.4100 Pruned: 50.75% 
Train: 167 [   0/390 (  0%)]  Loss: 3.770 (3.77)  Time: 0.907s,  141.05/s  (0.907s,  141.05/s)  LR: 1.000e-07  Data: 0.607 (0.607)
Train: 167 [ 100/390 ( 26%)]  Loss: 3.300 (3.29)  Time: 0.311s,  411.35/s  (0.318s,  403.05/s)  LR: 1.000e-07  Data: 0.011 (0.017)
Train: 167 [ 200/390 ( 51%)]  Loss: 3.096 (3.25)  Time: 0.319s,  401.77/s  (0.315s,  406.89/s)  LR: 1.000e-07  Data: 0.011 (0.014)
Train: 167 [ 300/390 ( 77%)]  Loss: 3.397 (3.25)  Time: 0.311s,  411.53/s  (0.314s,  408.21/s)  LR: 1.000e-07  Data: 0.011 (0.013)
Train: 167 [ 389/390 (100%)]  Loss: 2.824 (3.23)  Time: 0.298s,  429.20/s  (0.313s,  409.00/s)  LR: 1.000e-07  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.303 (0.303)  Loss:  1.0156 (1.0156)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.7183 (1.0228)  Acc@1: 87.5000 (76.4100)  Acc@5: 100.0000 (95.4100)
Test: [Whole Val]  Time: 9.529  Loss: 1.0228  Acc@1: 76.4100 Pruned: 50.75% 
Test (EMA): [   0/78]  Time: 0.308 (0.308)  Loss:  1.0156 (1.0156)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.7183 (1.0228)  Acc@1: 87.5000 (76.4000)  Acc@5: 100.0000 (95.4200)
Test (EMA): [Whole Val]  Time: 9.542  Loss: 1.0228  Acc@1: 76.4000 Pruned: 50.75% 
Train: 168 [   0/390 (  0%)]  Loss: 2.583 (2.58)  Time: 0.718s,  178.34/s  (0.718s,  178.34/s)  LR: 1.000e-07  Data: 0.417 (0.417)
Train: 168 [ 100/390 ( 26%)]  Loss: 2.726 (3.24)  Time: 0.310s,  412.85/s  (0.316s,  405.21/s)  LR: 1.000e-07  Data: 0.011 (0.016)
Train: 168 [ 200/390 ( 51%)]  Loss: 2.366 (3.20)  Time: 0.312s,  410.84/s  (0.314s,  407.89/s)  LR: 1.000e-07  Data: 0.011 (0.013)
Train: 168 [ 300/390 ( 77%)]  Loss: 2.522 (3.18)  Time: 0.311s,  411.73/s  (0.313s,  408.87/s)  LR: 1.000e-07  Data: 0.011 (0.013)
Train: 168 [ 389/390 (100%)]  Loss: 2.593 (3.17)  Time: 0.299s,  428.60/s  (0.313s,  409.39/s)  LR: 1.000e-07  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.300 (0.300)  Loss:  1.0156 (1.0156)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.7183 (1.0227)  Acc@1: 87.5000 (76.4200)  Acc@5: 100.0000 (95.4200)
Test: [Whole Val]  Time: 9.538  Loss: 1.0227  Acc@1: 76.4200 Pruned: 50.75% 
Test (EMA): [   0/78]  Time: 0.314 (0.314)  Loss:  1.0156 (1.0156)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.7183 (1.0228)  Acc@1: 87.5000 (76.4200)  Acc@5: 100.0000 (95.4200)
Test (EMA): [Whole Val]  Time: 9.560  Loss: 1.0228  Acc@1: 76.4200 Pruned: 50.75% 
Train: 169 [   0/390 (  0%)]  Loss: 3.355 (3.35)  Time: 0.849s,  150.74/s  (0.849s,  150.74/s)  LR: 1.000e-07  Data: 0.548 (0.548)
Train: 169 [ 100/390 ( 26%)]  Loss: 3.638 (3.22)  Time: 0.312s,  410.77/s  (0.317s,  404.08/s)  LR: 1.000e-07  Data: 0.012 (0.017)
Train: 169 [ 200/390 ( 51%)]  Loss: 2.689 (3.21)  Time: 0.312s,  410.02/s  (0.315s,  406.64/s)  LR: 1.000e-07  Data: 0.011 (0.014)
Train: 169 [ 300/390 ( 77%)]  Loss: 3.767 (3.22)  Time: 0.311s,  411.33/s  (0.314s,  407.91/s)  LR: 1.000e-07  Data: 0.011 (0.013)
Train: 169 [ 389/390 (100%)]  Loss: 3.308 (3.22)  Time: 0.299s,  427.71/s  (0.313s,  408.75/s)  LR: 1.000e-07  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.305 (0.305)  Loss:  1.0156 (1.0156)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.7188 (1.0229)  Acc@1: 87.5000 (76.3800)  Acc@5: 100.0000 (95.4100)
Test: [Whole Val]  Time: 9.536  Loss: 1.0229  Acc@1: 76.3800 Pruned: 50.75% 
Test (EMA): [   0/78]  Time: 0.304 (0.304)  Loss:  1.0156 (1.0156)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.7192 (1.0229)  Acc@1: 87.5000 (76.3700)  Acc@5: 100.0000 (95.4200)
Test (EMA): [Whole Val]  Time: 9.539  Loss: 1.0229  Acc@1: 76.3700 Pruned: 50.75% 
*** Best metric: OrderedDict([('loss', 1.02293828125), ('top1', 76.37), ('top5', 95.42), ('pruned', 0.5074724036069652)]) (epoch 169)
