/home/zxy21/miniconda3/envs/ssfn/lib/python3.10/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Training with a single process on 1 GPUs.
Data processing configuration for current model + dataset:
	input_size: (3, 224, 224)
	interpolation: bicubic
	mean: (0.5, 0.5, 0.5)
	std: (0.5, 0.5, 0.5)
	crop_pct: 0.9
/home/zxy21/miniconda3/envs/ssfn/lib/python3.10/site-packages/torch_pruning/dependency.py:360: UserWarning: Unwrapped parameters detected: ['blocks.0.ssf_scale_2', 'blocks.2.attn.ssf_scale_1', 'blocks.4.ssf_scale_2', 'blocks.6.mlp.ssf_scale_2', 'blocks.10.mlp.ssf_scale_2', 'patch_embed.ssf_shift_1', 'blocks.2.mlp.ssf_shift_2', 'blocks.7.attn.ssf_shift_1', 'blocks.9.ssf_shift_2', 'blocks.11.attn.ssf_shift_1', 'blocks.0.mlp.ssf_scale_1', 'blocks.3.attn.ssf_scale_2', 'blocks.4.mlp.ssf_scale_1', 'blocks.7.ssf_scale_1', 'blocks.11.ssf_scale_1', 'blocks.3.ssf_shift_1', 'blocks.8.attn.ssf_shift_2', 'blocks.9.mlp.ssf_shift_1', 'blocks.0.attn.ssf_shift_1', 'blocks.1.mlp.ssf_scale_2', 'blocks.5.mlp.ssf_scale_2', 'blocks.6.attn.ssf_scale_1', 'blocks.8.ssf_scale_2', 'blocks.10.attn.ssf_scale_1', 'blocks.0.ssf_shift_2', 'blocks.2.attn.ssf_shift_1', 'blocks.4.ssf_shift_2', 'blocks.6.mlp.ssf_shift_2', 'blocks.10.mlp.ssf_shift_2', 'blocks.2.ssf_scale_1', 'blocks.7.attn.ssf_scale_2', 'blocks.8.mlp.ssf_scale_1', 'blocks.11.attn.ssf_scale_2', 'blocks.4.mlp.ssf_shift_1', 'blocks.0.mlp.ssf_shift_1', 'blocks.3.attn.ssf_shift_2', 'blocks.7.ssf_shift_1', 'blocks.11.ssf_shift_1', 'blocks.1.attn.ssf_scale_1', 'blocks.3.ssf_scale_2', 'blocks.5.attn.ssf_scale_1', 'blocks.9.mlp.ssf_scale_2', 'blocks.0.attn.ssf_scale_2', 'blocks.1.mlp.ssf_shift_2', 'blocks.5.mlp.ssf_shift_2', 'blocks.6.attn.ssf_shift_1', 'blocks.8.ssf_shift_2', 'blocks.10.attn.ssf_shift_1', 'blocks.2.attn.ssf_scale_2', 'blocks.3.mlp.ssf_scale_1', 'blocks.6.ssf_scale_1', 'blocks.10.ssf_scale_1', 'ssf_scale_1', 'blocks.2.ssf_shift_1', 'blocks.7.attn.ssf_shift_2', 'blocks.8.mlp.ssf_shift_1', 'blocks.11.attn.ssf_shift_2', 'blocks.0.mlp.ssf_scale_2', 'blocks.4.mlp.ssf_scale_2', 'blocks.7.ssf_scale_2', 'blocks.9.attn.ssf_scale_1', 'blocks.11.ssf_scale_2', 'blocks.1.attn.ssf_shift_1', 'blocks.3.ssf_shift_2', 'blocks.5.attn.ssf_shift_1', 'blocks.9.mlp.ssf_shift_2', 'blocks.0.attn.ssf_shift_2', 'blocks.1.ssf_scale_1', 'blocks.5.ssf_scale_1', 'blocks.6.attn.ssf_scale_2', 'blocks.7.mlp.ssf_scale_1', 'blocks.10.attn.ssf_scale_2', 'blocks.11.mlp.ssf_scale_1', 'blocks.2.attn.ssf_shift_2', 'blocks.3.mlp.ssf_shift_1', 'blocks.6.ssf_shift_1', 'blocks.10.ssf_shift_1', 'ssf_shift_1', 'blocks.2.ssf_scale_2', 'blocks.4.attn.ssf_scale_1', 'blocks.8.mlp.ssf_scale_2', 'blocks.0.mlp.ssf_shift_2', 'blocks.4.mlp.ssf_shift_2', 'blocks.7.ssf_shift_2', 'blocks.9.attn.ssf_shift_1', 'blocks.11.ssf_shift_2', 'blocks.1.attn.ssf_scale_2', 'blocks.2.mlp.ssf_scale_1', 'blocks.5.attn.ssf_scale_2', 'blocks.9.ssf_scale_1', 'blocks.1.ssf_shift_1', 'blocks.5.ssf_shift_1', 'blocks.6.attn.ssf_shift_2', 'blocks.7.mlp.ssf_shift_1', 'blocks.10.attn.ssf_shift_2', 'blocks.11.mlp.ssf_shift_1', 'blocks.3.mlp.ssf_scale_2', 'blocks.6.ssf_scale_2', 'blocks.8.attn.ssf_scale_1', 'blocks.10.ssf_scale_2', 'blocks.2.ssf_shift_2', 'blocks.4.attn.ssf_shift_1', 'blocks.8.mlp.ssf_shift_2', 'blocks.0.ssf_scale_1', 'blocks.4.ssf_scale_1', 'blocks.6.mlp.ssf_scale_1', 'blocks.9.attn.ssf_scale_2', 'blocks.10.mlp.ssf_scale_1', 'patch_embed.ssf_scale_1', 'blocks.1.attn.ssf_shift_2', 'blocks.2.mlp.ssf_shift_1', 'blocks.5.attn.ssf_shift_2', 'blocks.9.ssf_shift_1', 'blocks.1.ssf_scale_2', 'blocks.3.attn.ssf_scale_1', 'blocks.5.ssf_scale_2', 'blocks.7.mlp.ssf_scale_2', 'blocks.11.mlp.ssf_scale_2', 'blocks.3.mlp.ssf_shift_2', 'blocks.6.ssf_shift_2', 'blocks.8.attn.ssf_shift_1', 'blocks.10.ssf_shift_2', 'blocks.1.mlp.ssf_scale_1', 'blocks.4.attn.ssf_scale_2', 'blocks.5.mlp.ssf_scale_1', 'blocks.8.ssf_scale_1', 'blocks.0.ssf_shift_1', 'blocks.4.ssf_shift_1', 'blocks.6.mlp.ssf_shift_1', 'blocks.9.attn.ssf_shift_2', 'blocks.10.mlp.ssf_shift_1', 'blocks.2.mlp.ssf_scale_2', 'blocks.7.attn.ssf_scale_1', 'blocks.9.ssf_scale_2', 'blocks.11.attn.ssf_scale_1', 'blocks.1.ssf_shift_2', 'blocks.3.attn.ssf_shift_1', 'blocks.5.ssf_shift_2', 'blocks.7.mlp.ssf_shift_2', 'blocks.11.mlp.ssf_shift_2', 'blocks.3.ssf_scale_1', 'blocks.8.attn.ssf_scale_2', 'blocks.9.mlp.ssf_scale_1', 'blocks.5.mlp.ssf_shift_1', 'blocks.4.attn.ssf_shift_2', 'blocks.0.attn.ssf_scale_1', 'blocks.1.mlp.ssf_shift_1', 'blocks.8.ssf_shift_1'].
 Torch-Pruning will prune the last non-singleton dimension of a parameter. If you wish to customize this behavior, please provide an unwrapped_parameters argument.
  warnings.warn("Unwrapped parameters detected: {}.\n Torch-Pruning will prune the last non-singleton dimension of a parameter. If you wish to customize this behavior, please provide an unwrapped_parameters argument.".format([_param_to_name[p] for p in unwrapped_detected]))
Params: 86.0814 M
ops: 16.8553 G
ssf_scale_1
ssf_shift_1
patch_embed.ssf_scale_1
patch_embed.ssf_shift_1
blocks.0.ssf_scale_1
blocks.0.ssf_shift_1
blocks.0.ssf_scale_2
blocks.0.ssf_shift_2
blocks.0.attn.ssf_scale_1
blocks.0.attn.ssf_shift_1
blocks.0.attn.ssf_scale_2
blocks.0.attn.ssf_shift_2
blocks.0.mlp.ssf_scale_1
blocks.0.mlp.ssf_shift_1
blocks.0.mlp.ssf_scale_2
blocks.0.mlp.ssf_shift_2
blocks.1.ssf_scale_1
blocks.1.ssf_shift_1
blocks.1.ssf_scale_2
blocks.1.ssf_shift_2
blocks.1.attn.ssf_scale_1
blocks.1.attn.ssf_shift_1
blocks.1.attn.ssf_scale_2
blocks.1.attn.ssf_shift_2
blocks.1.mlp.ssf_scale_1
blocks.1.mlp.ssf_shift_1
blocks.1.mlp.ssf_scale_2
blocks.1.mlp.ssf_shift_2
blocks.2.ssf_scale_1
blocks.2.ssf_shift_1
blocks.2.ssf_scale_2
blocks.2.ssf_shift_2
blocks.2.attn.ssf_scale_1
blocks.2.attn.ssf_shift_1
blocks.2.attn.ssf_scale_2
blocks.2.attn.ssf_shift_2
blocks.2.mlp.ssf_scale_1
blocks.2.mlp.ssf_shift_1
blocks.2.mlp.ssf_scale_2
blocks.2.mlp.ssf_shift_2
blocks.3.ssf_scale_1
blocks.3.ssf_shift_1
blocks.3.ssf_scale_2
blocks.3.ssf_shift_2
blocks.3.attn.ssf_scale_1
blocks.3.attn.ssf_shift_1
blocks.3.attn.ssf_scale_2
blocks.3.attn.ssf_shift_2
blocks.3.mlp.ssf_scale_1
blocks.3.mlp.ssf_shift_1
blocks.3.mlp.ssf_scale_2
blocks.3.mlp.ssf_shift_2
blocks.4.ssf_scale_1
blocks.4.ssf_shift_1
blocks.4.ssf_scale_2
blocks.4.ssf_shift_2
blocks.4.attn.ssf_scale_1
blocks.4.attn.ssf_shift_1
blocks.4.attn.ssf_scale_2
blocks.4.attn.ssf_shift_2
blocks.4.mlp.ssf_scale_1
blocks.4.mlp.ssf_shift_1
blocks.4.mlp.ssf_scale_2
blocks.4.mlp.ssf_shift_2
blocks.5.ssf_scale_1
blocks.5.ssf_shift_1
blocks.5.ssf_scale_2
blocks.5.ssf_shift_2
blocks.5.attn.ssf_scale_1
blocks.5.attn.ssf_shift_1
blocks.5.attn.ssf_scale_2
blocks.5.attn.ssf_shift_2
blocks.5.mlp.ssf_scale_1
blocks.5.mlp.ssf_shift_1
blocks.5.mlp.ssf_scale_2
blocks.5.mlp.ssf_shift_2
blocks.6.ssf_scale_1
blocks.6.ssf_shift_1
blocks.6.ssf_scale_2
blocks.6.ssf_shift_2
blocks.6.attn.ssf_scale_1
blocks.6.attn.ssf_shift_1
blocks.6.attn.ssf_scale_2
blocks.6.attn.ssf_shift_2
blocks.6.mlp.ssf_scale_1
blocks.6.mlp.ssf_shift_1
blocks.6.mlp.ssf_scale_2
blocks.6.mlp.ssf_shift_2
blocks.7.ssf_scale_1
blocks.7.ssf_shift_1
blocks.7.ssf_scale_2
blocks.7.ssf_shift_2
blocks.7.attn.ssf_scale_1
blocks.7.attn.ssf_shift_1
blocks.7.attn.ssf_scale_2
blocks.7.attn.ssf_shift_2
blocks.7.mlp.ssf_scale_1
blocks.7.mlp.ssf_shift_1
blocks.7.mlp.ssf_scale_2
blocks.7.mlp.ssf_shift_2
blocks.8.ssf_scale_1
blocks.8.ssf_shift_1
blocks.8.ssf_scale_2
blocks.8.ssf_shift_2
blocks.8.attn.ssf_scale_1
blocks.8.attn.ssf_shift_1
blocks.8.attn.ssf_scale_2
blocks.8.attn.ssf_shift_2
blocks.8.mlp.ssf_scale_1
blocks.8.mlp.ssf_shift_1
blocks.8.mlp.ssf_scale_2
blocks.8.mlp.ssf_shift_2
blocks.9.ssf_scale_1
blocks.9.ssf_shift_1
blocks.9.ssf_scale_2
blocks.9.ssf_shift_2
blocks.9.attn.ssf_scale_1
blocks.9.attn.ssf_shift_1
blocks.9.attn.ssf_scale_2
blocks.9.attn.ssf_shift_2
blocks.9.mlp.ssf_scale_1
blocks.9.mlp.ssf_shift_1
blocks.9.mlp.ssf_scale_2
blocks.9.mlp.ssf_shift_2
blocks.10.ssf_scale_1
blocks.10.ssf_shift_1
blocks.10.ssf_scale_2
blocks.10.ssf_shift_2
blocks.10.attn.ssf_scale_1
blocks.10.attn.ssf_shift_1
blocks.10.attn.ssf_scale_2
blocks.10.attn.ssf_shift_2
blocks.10.mlp.ssf_scale_1
blocks.10.mlp.ssf_shift_1
blocks.10.mlp.ssf_scale_2
blocks.10.mlp.ssf_shift_2
blocks.11.ssf_scale_1
blocks.11.ssf_shift_1
blocks.11.ssf_scale_2
blocks.11.ssf_shift_2
blocks.11.attn.ssf_scale_1
blocks.11.attn.ssf_shift_1
blocks.11.attn.ssf_scale_2
blocks.11.attn.ssf_shift_2
blocks.11.mlp.ssf_scale_1
blocks.11.mlp.ssf_shift_1
blocks.11.mlp.ssf_scale_2
blocks.11.mlp.ssf_shift_2
head.weight
head.bias
freezing parameters finished!
Model vit_base_patch16_224_in21k created, param count:86081380
number of params for requires grad: 282724
Using native Torch AMP. Training in mixed precision.
Scheduled epochs: 110
Train: 0 [   0/390 (  0%)]  Loss: 5.723 (5.72)  Time: 3.954s,   32.37/s  (3.954s,   32.37/s)  LR: 1.000e-03  Data: 0.942 (0.942)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.498 (3.71)  Time: 0.315s,  406.42/s  (0.353s,  362.53/s)  LR: 1.000e-03  Data: 0.011 (0.022)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.159 (3.36)  Time: 0.319s,  401.51/s  (0.336s,  380.61/s)  LR: 1.000e-03  Data: 0.013 (0.017)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.063 (3.18)  Time: 0.318s,  402.88/s  (0.331s,  386.96/s)  LR: 1.000e-03  Data: 0.011 (0.016)
Train: 0 [ 389/390 (100%)]  Loss: 3.413 (3.10)  Time: 0.307s,  416.75/s  (0.329s,  389.57/s)  LR: 1.000e-03  Data: 0.000 (0.015)
Train: 0 [   0/390 (  0%)]  Loss: 2.019 (2.02)  Time: 0.857s,  149.35/s  (0.857s,  149.35/s)  LR: 1.000e-03  Data: 0.550 (0.550)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.835 (2.79)  Time: 0.319s,  401.56/s  (0.332s,  385.83/s)  LR: 1.000e-03  Data: 0.011 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.461 (2.76)  Time: 0.320s,  399.73/s  (0.328s,  390.77/s)  LR: 1.000e-03  Data: 0.013 (0.016)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.191 (2.79)  Time: 0.320s,  400.37/s  (0.327s,  391.84/s)  LR: 1.000e-03  Data: 0.010 (0.015)
Train: 0 [ 389/390 (100%)]  Loss: 2.223 (2.79)  Time: 0.308s,  415.59/s  (0.325s,  393.46/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 2.995 (2.99)  Time: 0.769s,  166.45/s  (0.769s,  166.45/s)  LR: 1.000e-03  Data: 0.462 (0.462)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.177 (2.76)  Time: 0.338s,  378.39/s  (0.332s,  385.93/s)  LR: 1.000e-03  Data: 0.015 (0.020)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.077 (2.73)  Time: 0.324s,  394.74/s  (0.328s,  390.10/s)  LR: 1.000e-03  Data: 0.014 (0.017)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.471 (2.74)  Time: 0.322s,  397.05/s  (0.328s,  389.89/s)  LR: 1.000e-03  Data: 0.012 (0.017)
Train: 0 [ 389/390 (100%)]  Loss: 2.704 (2.74)  Time: 0.308s,  415.28/s  (0.328s,  390.26/s)  LR: 1.000e-03  Data: 0.000 (0.016)
Train: 0 [   0/390 (  0%)]  Loss: 3.374 (3.37)  Time: 0.833s,  153.75/s  (0.833s,  153.75/s)  LR: 1.000e-03  Data: 0.514 (0.514)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.151 (2.68)  Time: 0.322s,  397.32/s  (0.331s,  386.50/s)  LR: 1.000e-03  Data: 0.013 (0.019)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.519 (2.71)  Time: 0.322s,  397.30/s  (0.330s,  388.38/s)  LR: 1.000e-03  Data: 0.015 (0.018)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.246 (2.71)  Time: 0.323s,  395.87/s  (0.330s,  388.26/s)  LR: 1.000e-03  Data: 0.014 (0.018)
Train: 0 [ 389/390 (100%)]  Loss: 2.637 (2.72)  Time: 0.307s,  417.52/s  (0.328s,  389.99/s)  LR: 1.000e-03  Data: 0.000 (0.017)
Train: 0 [   0/390 (  0%)]  Loss: 3.136 (3.14)  Time: 0.781s,  163.92/s  (0.781s,  163.92/s)  LR: 1.000e-03  Data: 0.473 (0.473)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.969 (2.75)  Time: 0.320s,  399.94/s  (0.325s,  394.43/s)  LR: 1.000e-03  Data: 0.013 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.421 (2.76)  Time: 0.317s,  403.28/s  (0.322s,  397.79/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.323 (2.78)  Time: 0.321s,  398.29/s  (0.322s,  398.11/s)  LR: 1.000e-03  Data: 0.014 (0.015)
Train: 0 [ 389/390 (100%)]  Loss: 3.196 (2.78)  Time: 0.305s,  419.33/s  (0.321s,  398.98/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 2.996 (3.00)  Time: 0.740s,  172.87/s  (0.740s,  172.87/s)  LR: 1.000e-03  Data: 0.434 (0.434)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.031 (2.83)  Time: 0.319s,  401.41/s  (0.324s,  395.53/s)  LR: 1.000e-03  Data: 0.013 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.446 (2.80)  Time: 0.317s,  403.38/s  (0.322s,  397.80/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.279 (2.78)  Time: 0.324s,  395.39/s  (0.321s,  398.71/s)  LR: 1.000e-03  Data: 0.015 (0.015)
Train: 0 [ 389/390 (100%)]  Loss: 3.012 (2.79)  Time: 0.305s,  419.58/s  (0.320s,  399.39/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 2.244 (2.24)  Time: 0.782s,  163.61/s  (0.782s,  163.61/s)  LR: 1.000e-03  Data: 0.473 (0.473)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.126 (2.86)  Time: 0.318s,  402.77/s  (0.324s,  394.51/s)  LR: 1.000e-03  Data: 0.012 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.177 (2.87)  Time: 0.315s,  406.10/s  (0.322s,  398.08/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.445 (2.84)  Time: 0.319s,  400.63/s  (0.321s,  398.96/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 2.406 (2.84)  Time: 0.309s,  414.81/s  (0.320s,  399.48/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 2.966 (2.97)  Time: 0.869s,  147.32/s  (0.869s,  147.32/s)  LR: 1.000e-03  Data: 0.563 (0.563)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.293 (2.82)  Time: 0.320s,  400.55/s  (0.325s,  393.63/s)  LR: 1.000e-03  Data: 0.012 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 1.866 (2.82)  Time: 0.316s,  404.54/s  (0.323s,  396.57/s)  LR: 1.000e-03  Data: 0.012 (0.016)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.936 (2.83)  Time: 0.319s,  401.53/s  (0.322s,  397.83/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 389/390 (100%)]  Loss: 3.286 (2.86)  Time: 0.307s,  417.48/s  (0.321s,  398.13/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 1.870 (1.87)  Time: 0.823s,  155.44/s  (0.823s,  155.44/s)  LR: 1.000e-03  Data: 0.511 (0.511)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.454 (2.86)  Time: 0.326s,  392.15/s  (0.324s,  395.66/s)  LR: 1.000e-03  Data: 0.016 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.265 (2.86)  Time: 0.321s,  398.58/s  (0.321s,  398.31/s)  LR: 1.000e-03  Data: 0.016 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.580 (2.89)  Time: 0.323s,  396.70/s  (0.321s,  399.25/s)  LR: 1.000e-03  Data: 0.017 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 2.044 (2.89)  Time: 0.305s,  419.51/s  (0.320s,  399.65/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.453 (3.45)  Time: 0.885s,  144.67/s  (0.885s,  144.67/s)  LR: 1.000e-03  Data: 0.579 (0.579)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.282 (2.85)  Time: 0.323s,  396.57/s  (0.324s,  395.61/s)  LR: 1.000e-03  Data: 0.012 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.031 (2.87)  Time: 0.317s,  403.63/s  (0.321s,  398.76/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 1.905 (2.88)  Time: 0.320s,  399.51/s  (0.320s,  399.86/s)  LR: 1.000e-03  Data: 0.014 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 2.089 (2.88)  Time: 0.306s,  418.16/s  (0.320s,  400.32/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 2.747 (2.75)  Time: 0.932s,  137.33/s  (0.932s,  137.33/s)  LR: 1.000e-03  Data: 0.624 (0.624)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.395 (2.92)  Time: 0.323s,  396.44/s  (0.324s,  394.55/s)  LR: 1.000e-03  Data: 0.016 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.521 (2.92)  Time: 0.320s,  400.26/s  (0.321s,  398.40/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.835 (2.93)  Time: 0.324s,  395.37/s  (0.320s,  399.53/s)  LR: 1.000e-03  Data: 0.018 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.195 (2.94)  Time: 0.305s,  420.23/s  (0.320s,  399.99/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 2.997 (3.00)  Time: 0.822s,  155.70/s  (0.822s,  155.70/s)  LR: 1.000e-03  Data: 0.496 (0.496)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.940 (2.92)  Time: 0.316s,  404.70/s  (0.325s,  393.84/s)  LR: 1.000e-03  Data: 0.011 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.668 (2.90)  Time: 0.317s,  403.67/s  (0.322s,  397.91/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.686 (2.90)  Time: 0.316s,  404.71/s  (0.321s,  398.94/s)  LR: 1.000e-03  Data: 0.011 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 1.886 (2.89)  Time: 0.307s,  417.47/s  (0.320s,  399.54/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.589 (3.59)  Time: 0.924s,  138.50/s  (0.924s,  138.50/s)  LR: 1.000e-03  Data: 0.594 (0.594)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.434 (3.03)  Time: 0.318s,  402.96/s  (0.325s,  393.62/s)  LR: 1.000e-03  Data: 0.012 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.476 (2.99)  Time: 0.318s,  402.45/s  (0.322s,  397.67/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.472 (2.98)  Time: 0.323s,  396.19/s  (0.321s,  398.70/s)  LR: 1.000e-03  Data: 0.017 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.471 (2.96)  Time: 0.306s,  418.42/s  (0.321s,  399.09/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 2.108 (2.11)  Time: 0.889s,  144.04/s  (0.889s,  144.04/s)  LR: 1.000e-03  Data: 0.582 (0.582)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.859 (3.00)  Time: 0.318s,  402.92/s  (0.324s,  394.73/s)  LR: 1.000e-03  Data: 0.011 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.350 (2.99)  Time: 0.318s,  401.94/s  (0.321s,  398.48/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.857 (2.98)  Time: 0.317s,  403.37/s  (0.321s,  399.38/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.481 (2.98)  Time: 0.307s,  416.93/s  (0.320s,  399.90/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.182 (3.18)  Time: 0.836s,  153.11/s  (0.836s,  153.11/s)  LR: 1.000e-03  Data: 0.524 (0.524)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.944 (2.87)  Time: 0.317s,  403.83/s  (0.324s,  395.20/s)  LR: 1.000e-03  Data: 0.013 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.157 (2.94)  Time: 0.321s,  398.83/s  (0.322s,  397.79/s)  LR: 1.000e-03  Data: 0.016 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.515 (2.95)  Time: 0.319s,  400.78/s  (0.321s,  399.00/s)  LR: 1.000e-03  Data: 0.013 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 2.683 (2.95)  Time: 0.306s,  418.00/s  (0.320s,  399.95/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.351 (3.35)  Time: 0.866s,  147.87/s  (0.866s,  147.87/s)  LR: 1.000e-03  Data: 0.559 (0.559)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.303 (3.06)  Time: 0.317s,  404.13/s  (0.324s,  395.53/s)  LR: 1.000e-03  Data: 0.012 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.287 (3.02)  Time: 0.318s,  403.08/s  (0.321s,  398.87/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.213 (3.02)  Time: 0.323s,  396.50/s  (0.320s,  400.02/s)  LR: 1.000e-03  Data: 0.014 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.085 (3.02)  Time: 0.306s,  418.73/s  (0.320s,  400.39/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.557 (3.56)  Time: 0.782s,  163.77/s  (0.782s,  163.77/s)  LR: 1.000e-03  Data: 0.479 (0.479)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.150 (3.00)  Time: 0.320s,  400.44/s  (0.323s,  396.70/s)  LR: 1.000e-03  Data: 0.012 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.031 (3.02)  Time: 0.323s,  396.74/s  (0.321s,  398.77/s)  LR: 1.000e-03  Data: 0.015 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.386 (3.03)  Time: 0.317s,  404.01/s  (0.321s,  399.10/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 2.912 (3.04)  Time: 0.306s,  418.53/s  (0.320s,  399.63/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.135 (3.14)  Time: 0.796s,  160.77/s  (0.796s,  160.77/s)  LR: 1.000e-03  Data: 0.489 (0.489)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.451 (3.09)  Time: 0.317s,  404.41/s  (0.323s,  395.82/s)  LR: 1.000e-03  Data: 0.011 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.319 (3.07)  Time: 0.318s,  402.80/s  (0.321s,  398.86/s)  LR: 1.000e-03  Data: 0.013 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.871 (3.02)  Time: 0.318s,  402.38/s  (0.321s,  399.37/s)  LR: 1.000e-03  Data: 0.011 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.339 (3.01)  Time: 0.306s,  418.55/s  (0.320s,  399.98/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.296 (3.30)  Time: 0.861s,  148.63/s  (0.861s,  148.63/s)  LR: 1.000e-03  Data: 0.542 (0.542)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.699 (3.13)  Time: 0.322s,  398.05/s  (0.324s,  394.72/s)  LR: 1.000e-03  Data: 0.012 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.080 (3.13)  Time: 0.318s,  402.43/s  (0.321s,  398.33/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.352 (3.11)  Time: 0.317s,  404.34/s  (0.321s,  399.19/s)  LR: 1.000e-03  Data: 0.011 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.319 (3.11)  Time: 0.308s,  415.68/s  (0.320s,  399.72/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 2.458 (2.46)  Time: 0.841s,  152.25/s  (0.841s,  152.25/s)  LR: 1.000e-03  Data: 0.535 (0.535)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.480 (3.09)  Time: 0.317s,  403.44/s  (0.324s,  394.86/s)  LR: 1.000e-03  Data: 0.012 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.762 (3.06)  Time: 0.316s,  404.50/s  (0.321s,  398.74/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.782 (3.06)  Time: 0.317s,  403.76/s  (0.320s,  399.60/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 2.695 (3.07)  Time: 0.307s,  416.94/s  (0.320s,  400.33/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.942 (3.94)  Time: 0.842s,  152.03/s  (0.842s,  152.03/s)  LR: 1.000e-03  Data: 0.537 (0.537)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.094 (3.09)  Time: 0.324s,  395.25/s  (0.323s,  395.80/s)  LR: 1.000e-03  Data: 0.013 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.424 (3.06)  Time: 0.322s,  397.53/s  (0.322s,  397.51/s)  LR: 1.000e-03  Data: 0.016 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.519 (3.07)  Time: 0.317s,  403.88/s  (0.321s,  398.79/s)  LR: 1.000e-03  Data: 0.011 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.435 (3.07)  Time: 0.306s,  417.69/s  (0.321s,  399.28/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.078 (3.08)  Time: 0.818s,  156.40/s  (0.818s,  156.40/s)  LR: 1.000e-03  Data: 0.512 (0.512)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.736 (3.11)  Time: 0.317s,  403.17/s  (0.324s,  395.08/s)  LR: 1.000e-03  Data: 0.012 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.856 (3.07)  Time: 0.316s,  405.57/s  (0.321s,  398.67/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.809 (3.10)  Time: 0.316s,  404.63/s  (0.320s,  399.59/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.485 (3.12)  Time: 0.305s,  419.51/s  (0.320s,  400.12/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 2.335 (2.34)  Time: 0.877s,  145.93/s  (0.877s,  145.93/s)  LR: 1.000e-03  Data: 0.566 (0.566)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.452 (3.13)  Time: 0.319s,  401.80/s  (0.324s,  395.37/s)  LR: 1.000e-03  Data: 0.012 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.749 (3.14)  Time: 0.317s,  403.62/s  (0.321s,  398.25/s)  LR: 1.000e-03  Data: 0.013 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.811 (3.16)  Time: 0.318s,  402.17/s  (0.320s,  399.42/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 2.917 (3.16)  Time: 0.308s,  415.01/s  (0.320s,  399.98/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.577 (3.58)  Time: 0.790s,  162.01/s  (0.790s,  162.01/s)  LR: 1.000e-03  Data: 0.483 (0.483)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.588 (3.10)  Time: 0.317s,  403.41/s  (0.323s,  395.88/s)  LR: 1.000e-03  Data: 0.012 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.448 (3.15)  Time: 0.328s,  390.49/s  (0.321s,  398.68/s)  LR: 1.000e-03  Data: 0.020 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.058 (3.17)  Time: 0.317s,  404.39/s  (0.320s,  399.76/s)  LR: 1.000e-03  Data: 0.011 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.745 (3.17)  Time: 0.306s,  418.91/s  (0.320s,  400.38/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.563 (3.56)  Time: 0.797s,  160.61/s  (0.797s,  160.61/s)  LR: 1.000e-03  Data: 0.478 (0.478)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.741 (3.21)  Time: 0.318s,  403.11/s  (0.325s,  394.42/s)  LR: 1.000e-03  Data: 0.012 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.601 (3.17)  Time: 0.319s,  401.52/s  (0.321s,  398.14/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.756 (3.18)  Time: 0.317s,  403.69/s  (0.321s,  399.34/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 2.394 (3.17)  Time: 0.307s,  416.82/s  (0.320s,  400.03/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.496 (3.50)  Time: 0.863s,  148.25/s  (0.863s,  148.25/s)  LR: 1.000e-03  Data: 0.557 (0.557)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.653 (3.16)  Time: 0.317s,  404.31/s  (0.324s,  394.89/s)  LR: 1.000e-03  Data: 0.012 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.373 (3.16)  Time: 0.330s,  387.59/s  (0.321s,  398.40/s)  LR: 1.000e-03  Data: 0.014 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.526 (3.17)  Time: 0.319s,  400.63/s  (0.320s,  399.75/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.749 (3.16)  Time: 0.308s,  416.16/s  (0.320s,  400.31/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.851 (3.85)  Time: 0.852s,  150.21/s  (0.852s,  150.21/s)  LR: 1.000e-03  Data: 0.545 (0.545)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.091 (3.20)  Time: 0.321s,  398.81/s  (0.324s,  395.45/s)  LR: 1.000e-03  Data: 0.012 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.580 (3.21)  Time: 0.318s,  402.59/s  (0.321s,  398.65/s)  LR: 1.000e-03  Data: 0.013 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.451 (3.22)  Time: 0.319s,  401.34/s  (0.320s,  399.74/s)  LR: 1.000e-03  Data: 0.013 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.103 (3.23)  Time: 0.304s,  420.42/s  (0.319s,  400.84/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.648 (3.65)  Time: 0.813s,  157.40/s  (0.813s,  157.40/s)  LR: 1.000e-03  Data: 0.502 (0.502)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.437 (3.24)  Time: 0.320s,  400.03/s  (0.326s,  393.08/s)  LR: 1.000e-03  Data: 0.014 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.536 (3.21)  Time: 0.325s,  393.47/s  (0.324s,  395.10/s)  LR: 1.000e-03  Data: 0.013 (0.016)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.433 (3.21)  Time: 0.324s,  395.48/s  (0.324s,  394.61/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 389/390 (100%)]  Loss: 3.721 (3.22)  Time: 0.311s,  411.72/s  (0.324s,  394.72/s)  LR: 1.000e-03  Data: 0.000 (0.015)
Train: 0 [   0/390 (  0%)]  Loss: 3.514 (3.51)  Time: 0.910s,  140.71/s  (0.910s,  140.71/s)  LR: 1.000e-03  Data: 0.582 (0.582)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.467 (3.21)  Time: 0.325s,  393.92/s  (0.331s,  386.98/s)  LR: 1.000e-03  Data: 0.015 (0.020)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.754 (3.21)  Time: 0.323s,  396.19/s  (0.329s,  389.17/s)  LR: 1.000e-03  Data: 0.015 (0.017)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.738 (3.22)  Time: 0.317s,  403.78/s  (0.327s,  391.54/s)  LR: 1.000e-03  Data: 0.011 (0.016)
Train: 0 [ 389/390 (100%)]  Loss: 3.610 (3.22)  Time: 0.306s,  418.80/s  (0.325s,  393.72/s)  LR: 1.000e-03  Data: 0.000 (0.015)
Train: 0 [   0/390 (  0%)]  Loss: 3.644 (3.64)  Time: 0.946s,  135.33/s  (0.946s,  135.33/s)  LR: 1.000e-03  Data: 0.631 (0.631)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.556 (3.29)  Time: 0.317s,  403.91/s  (0.324s,  394.65/s)  LR: 1.000e-03  Data: 0.012 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.870 (3.30)  Time: 0.317s,  403.21/s  (0.321s,  398.34/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.162 (3.29)  Time: 0.322s,  397.33/s  (0.321s,  399.18/s)  LR: 1.000e-03  Data: 0.013 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.683 (3.27)  Time: 0.309s,  413.63/s  (0.320s,  399.55/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 2.967 (2.97)  Time: 0.918s,  139.42/s  (0.918s,  139.42/s)  LR: 1.000e-03  Data: 0.597 (0.597)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.735 (3.36)  Time: 0.319s,  401.52/s  (0.325s,  393.78/s)  LR: 1.000e-03  Data: 0.013 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.078 (3.32)  Time: 0.315s,  405.90/s  (0.322s,  397.80/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.406 (3.32)  Time: 0.317s,  403.20/s  (0.321s,  398.76/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.705 (3.31)  Time: 0.306s,  418.78/s  (0.321s,  399.37/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.670 (3.67)  Time: 0.791s,  161.90/s  (0.791s,  161.90/s)  LR: 1.000e-03  Data: 0.482 (0.482)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.514 (3.21)  Time: 0.319s,  400.97/s  (0.323s,  395.73/s)  LR: 1.000e-03  Data: 0.012 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.662 (3.24)  Time: 0.323s,  396.03/s  (0.321s,  398.58/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.898 (3.26)  Time: 0.319s,  400.75/s  (0.320s,  399.54/s)  LR: 1.000e-03  Data: 0.011 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.071 (3.27)  Time: 0.306s,  417.85/s  (0.320s,  399.99/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 2.381 (2.38)  Time: 0.788s,  162.52/s  (0.788s,  162.52/s)  LR: 1.000e-03  Data: 0.481 (0.481)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.982 (3.30)  Time: 0.316s,  404.91/s  (0.323s,  396.66/s)  LR: 1.000e-03  Data: 0.011 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.898 (3.34)  Time: 0.317s,  403.58/s  (0.320s,  399.40/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.561 (3.33)  Time: 0.317s,  403.41/s  (0.320s,  400.41/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.756 (3.34)  Time: 0.307s,  416.64/s  (0.319s,  400.70/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 3.816 (3.82)  Time: 0.824s,  155.39/s  (0.824s,  155.39/s)  LR: 1.000e-03  Data: 0.490 (0.490)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.629 (3.36)  Time: 0.318s,  402.68/s  (0.324s,  395.08/s)  LR: 1.000e-03  Data: 0.012 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.628 (3.36)  Time: 0.318s,  402.90/s  (0.321s,  398.56/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.062 (3.35)  Time: 0.318s,  402.26/s  (0.320s,  399.96/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.613 (3.34)  Time: 0.306s,  418.58/s  (0.320s,  400.59/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 2.447 (2.45)  Time: 0.829s,  154.36/s  (0.829s,  154.36/s)  LR: 1.000e-03  Data: 0.523 (0.523)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.661 (3.32)  Time: 0.317s,  403.36/s  (0.324s,  395.02/s)  LR: 1.000e-03  Data: 0.012 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.807 (3.34)  Time: 0.322s,  397.72/s  (0.321s,  398.70/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.616 (3.35)  Time: 0.320s,  399.98/s  (0.320s,  399.83/s)  LR: 1.000e-03  Data: 0.013 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 2.858 (3.36)  Time: 0.306s,  418.02/s  (0.320s,  400.39/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.495 (3.50)  Time: 0.762s,  167.91/s  (0.762s,  167.91/s)  LR: 1.000e-03  Data: 0.447 (0.447)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.308 (3.33)  Time: 0.319s,  401.57/s  (0.323s,  396.76/s)  LR: 1.000e-03  Data: 0.014 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.920 (3.37)  Time: 0.319s,  401.85/s  (0.320s,  399.47/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.679 (3.38)  Time: 0.318s,  402.55/s  (0.320s,  400.23/s)  LR: 1.000e-03  Data: 0.013 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.638 (3.37)  Time: 0.305s,  419.29/s  (0.319s,  400.67/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.774 (3.77)  Time: 0.847s,  151.12/s  (0.847s,  151.12/s)  LR: 1.000e-03  Data: 0.521 (0.521)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.893 (3.40)  Time: 0.318s,  402.99/s  (0.323s,  395.69/s)  LR: 1.000e-03  Data: 0.012 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.393 (3.38)  Time: 0.317s,  403.77/s  (0.321s,  399.19/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.571 (3.39)  Time: 0.321s,  398.83/s  (0.320s,  400.11/s)  LR: 1.000e-03  Data: 0.016 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.921 (3.39)  Time: 0.306s,  418.44/s  (0.319s,  400.63/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.471 (3.47)  Time: 0.946s,  135.26/s  (0.946s,  135.26/s)  LR: 1.000e-03  Data: 0.641 (0.641)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.167 (3.32)  Time: 0.317s,  403.69/s  (0.324s,  394.71/s)  LR: 1.000e-03  Data: 0.011 (0.019)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.154 (3.33)  Time: 0.315s,  405.91/s  (0.322s,  397.66/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.759 (3.34)  Time: 0.318s,  402.65/s  (0.321s,  399.08/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 2.511 (3.34)  Time: 0.306s,  418.44/s  (0.320s,  399.84/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 2.683 (2.68)  Time: 0.800s,  159.96/s  (0.800s,  159.96/s)  LR: 1.000e-03  Data: 0.495 (0.495)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.793 (3.37)  Time: 0.321s,  398.99/s  (0.323s,  395.70/s)  LR: 1.000e-03  Data: 0.015 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.558 (3.35)  Time: 0.316s,  404.93/s  (0.321s,  398.77/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.096 (3.39)  Time: 0.324s,  395.56/s  (0.320s,  399.54/s)  LR: 1.000e-03  Data: 0.016 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.765 (3.41)  Time: 0.307s,  417.55/s  (0.320s,  399.79/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.794 (3.79)  Time: 0.880s,  145.46/s  (0.880s,  145.46/s)  LR: 1.000e-03  Data: 0.552 (0.552)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.362 (3.43)  Time: 0.318s,  403.05/s  (0.325s,  393.40/s)  LR: 1.000e-03  Data: 0.012 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.857 (3.40)  Time: 0.320s,  399.42/s  (0.322s,  397.63/s)  LR: 1.000e-03  Data: 0.014 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.857 (3.41)  Time: 0.318s,  402.16/s  (0.321s,  398.82/s)  LR: 1.000e-03  Data: 0.013 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 2.721 (3.45)  Time: 0.305s,  419.71/s  (0.320s,  399.84/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.893 (3.89)  Time: 0.872s,  146.81/s  (0.872s,  146.81/s)  LR: 1.000e-03  Data: 0.555 (0.555)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.523 (3.48)  Time: 0.318s,  402.99/s  (0.324s,  394.64/s)  LR: 1.000e-03  Data: 0.011 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.395 (3.44)  Time: 0.316s,  404.56/s  (0.322s,  397.99/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.051 (3.44)  Time: 0.320s,  399.74/s  (0.321s,  398.73/s)  LR: 1.000e-03  Data: 0.014 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.056 (3.43)  Time: 0.305s,  419.28/s  (0.320s,  399.52/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.963 (3.96)  Time: 0.775s,  165.21/s  (0.775s,  165.21/s)  LR: 1.000e-03  Data: 0.467 (0.467)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.064 (3.45)  Time: 0.318s,  402.51/s  (0.323s,  396.09/s)  LR: 1.000e-03  Data: 0.011 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.653 (3.44)  Time: 0.318s,  402.85/s  (0.321s,  398.76/s)  LR: 1.000e-03  Data: 0.013 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.857 (3.43)  Time: 0.317s,  403.45/s  (0.320s,  399.90/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.800 (3.46)  Time: 0.308s,  415.83/s  (0.320s,  400.39/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 4.022 (4.02)  Time: 0.807s,  158.56/s  (0.807s,  158.56/s)  LR: 1.000e-03  Data: 0.490 (0.490)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.850 (3.53)  Time: 0.324s,  395.09/s  (0.324s,  394.97/s)  LR: 1.000e-03  Data: 0.018 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.801 (3.51)  Time: 0.317s,  404.23/s  (0.322s,  398.10/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.934 (3.53)  Time: 0.319s,  400.77/s  (0.321s,  399.29/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.208 (3.51)  Time: 0.306s,  417.85/s  (0.320s,  399.73/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 2.812 (2.81)  Time: 0.821s,  155.85/s  (0.821s,  155.85/s)  LR: 1.000e-03  Data: 0.516 (0.516)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.383 (3.42)  Time: 0.316s,  404.78/s  (0.324s,  395.61/s)  LR: 1.000e-03  Data: 0.012 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.901 (3.45)  Time: 0.317s,  403.36/s  (0.322s,  397.85/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.881 (3.46)  Time: 0.316s,  404.44/s  (0.321s,  399.28/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.578 (3.47)  Time: 0.308s,  415.88/s  (0.320s,  399.69/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 2.775 (2.77)  Time: 0.825s,  155.23/s  (0.825s,  155.23/s)  LR: 1.000e-03  Data: 0.519 (0.519)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.853 (3.49)  Time: 0.318s,  402.77/s  (0.323s,  396.30/s)  LR: 1.000e-03  Data: 0.012 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.703 (3.48)  Time: 0.342s,  373.74/s  (0.321s,  399.35/s)  LR: 1.000e-03  Data: 0.019 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.323 (3.47)  Time: 0.316s,  405.17/s  (0.320s,  399.90/s)  LR: 1.000e-03  Data: 0.011 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.648 (3.48)  Time: 0.306s,  418.53/s  (0.320s,  400.40/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 2.887 (2.89)  Time: 0.777s,  164.67/s  (0.777s,  164.67/s)  LR: 1.000e-03  Data: 0.460 (0.460)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.060 (3.43)  Time: 0.318s,  402.72/s  (0.323s,  396.12/s)  LR: 1.000e-03  Data: 0.012 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.758 (3.46)  Time: 0.319s,  401.01/s  (0.321s,  398.88/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.322 (3.45)  Time: 0.320s,  400.40/s  (0.320s,  399.74/s)  LR: 1.000e-03  Data: 0.015 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.830 (3.46)  Time: 0.306s,  417.91/s  (0.320s,  400.35/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.650 (3.65)  Time: 0.863s,  148.27/s  (0.863s,  148.27/s)  LR: 1.000e-03  Data: 0.557 (0.557)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.693 (3.52)  Time: 0.316s,  405.34/s  (0.324s,  395.36/s)  LR: 1.000e-03  Data: 0.011 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 4.143 (3.49)  Time: 0.319s,  401.60/s  (0.321s,  398.47/s)  LR: 1.000e-03  Data: 0.013 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.975 (3.51)  Time: 0.318s,  402.93/s  (0.321s,  399.06/s)  LR: 1.000e-03  Data: 0.013 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 2.909 (3.51)  Time: 0.305s,  419.06/s  (0.320s,  399.84/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 4.117 (4.12)  Time: 0.950s,  134.68/s  (0.950s,  134.68/s)  LR: 1.000e-03  Data: 0.645 (0.645)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.587 (3.53)  Time: 0.316s,  405.36/s  (0.325s,  393.41/s)  LR: 1.000e-03  Data: 0.011 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.546 (3.52)  Time: 0.317s,  403.94/s  (0.322s,  397.54/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.750 (3.51)  Time: 0.321s,  399.02/s  (0.321s,  398.85/s)  LR: 1.000e-03  Data: 0.015 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.945 (3.51)  Time: 0.305s,  419.10/s  (0.320s,  399.51/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.420 (3.42)  Time: 0.887s,  144.34/s  (0.887s,  144.34/s)  LR: 1.000e-03  Data: 0.576 (0.576)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.718 (3.52)  Time: 0.321s,  398.96/s  (0.326s,  392.66/s)  LR: 1.000e-03  Data: 0.016 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.914 (3.52)  Time: 0.331s,  387.19/s  (0.323s,  396.22/s)  LR: 1.000e-03  Data: 0.013 (0.016)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.842 (3.54)  Time: 0.318s,  403.02/s  (0.322s,  397.86/s)  LR: 1.000e-03  Data: 0.013 (0.015)
Train: 0 [ 389/390 (100%)]  Loss: 3.861 (3.53)  Time: 0.310s,  413.55/s  (0.321s,  398.90/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.432 (3.43)  Time: 0.866s,  147.79/s  (0.866s,  147.79/s)  LR: 1.000e-03  Data: 0.536 (0.536)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.496 (3.54)  Time: 0.315s,  406.09/s  (0.325s,  393.85/s)  LR: 1.000e-03  Data: 0.011 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.198 (3.55)  Time: 0.318s,  402.66/s  (0.322s,  397.96/s)  LR: 1.000e-03  Data: 0.013 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.838 (3.56)  Time: 0.318s,  402.02/s  (0.321s,  399.37/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.947 (3.56)  Time: 0.306s,  418.09/s  (0.320s,  400.03/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.807 (3.81)  Time: 0.817s,  156.73/s  (0.817s,  156.73/s)  LR: 1.000e-03  Data: 0.512 (0.512)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.706 (3.58)  Time: 0.318s,  402.21/s  (0.323s,  396.54/s)  LR: 1.000e-03  Data: 0.012 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.826 (3.53)  Time: 0.316s,  404.52/s  (0.321s,  398.13/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.131 (3.54)  Time: 0.320s,  399.69/s  (0.321s,  399.13/s)  LR: 1.000e-03  Data: 0.013 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.092 (3.56)  Time: 0.306s,  418.73/s  (0.320s,  399.82/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.741 (3.74)  Time: 0.809s,  158.24/s  (0.809s,  158.24/s)  LR: 1.000e-03  Data: 0.501 (0.501)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.951 (3.58)  Time: 0.318s,  402.39/s  (0.323s,  395.70/s)  LR: 1.000e-03  Data: 0.012 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.799 (3.57)  Time: 0.318s,  402.42/s  (0.321s,  398.84/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.949 (3.56)  Time: 0.317s,  403.45/s  (0.320s,  400.06/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.722 (3.56)  Time: 0.305s,  419.07/s  (0.320s,  400.47/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.062 (3.06)  Time: 0.753s,  169.95/s  (0.753s,  169.95/s)  LR: 1.000e-03  Data: 0.447 (0.447)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.463 (3.58)  Time: 0.317s,  403.93/s  (0.322s,  397.31/s)  LR: 1.000e-03  Data: 0.012 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.774 (3.55)  Time: 0.317s,  403.24/s  (0.321s,  398.24/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.637 (3.57)  Time: 0.318s,  402.36/s  (0.320s,  399.62/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.152 (3.56)  Time: 0.305s,  420.24/s  (0.320s,  400.16/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 4.119 (4.12)  Time: 0.869s,  147.38/s  (0.869s,  147.38/s)  LR: 1.000e-03  Data: 0.554 (0.554)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.980 (3.63)  Time: 0.316s,  405.45/s  (0.324s,  394.93/s)  LR: 1.000e-03  Data: 0.011 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.619 (3.63)  Time: 0.318s,  402.99/s  (0.321s,  398.43/s)  LR: 1.000e-03  Data: 0.013 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.652 (3.60)  Time: 0.317s,  403.74/s  (0.321s,  398.99/s)  LR: 1.000e-03  Data: 0.011 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.998 (3.59)  Time: 0.307s,  417.31/s  (0.320s,  399.76/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.734 (3.73)  Time: 0.785s,  163.02/s  (0.785s,  163.02/s)  LR: 1.000e-03  Data: 0.479 (0.479)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.363 (3.55)  Time: 0.317s,  403.81/s  (0.323s,  396.28/s)  LR: 1.000e-03  Data: 0.012 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.957 (3.55)  Time: 0.315s,  406.16/s  (0.321s,  399.24/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.436 (3.56)  Time: 0.318s,  402.75/s  (0.320s,  399.70/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 4.047 (3.57)  Time: 0.305s,  419.49/s  (0.320s,  400.57/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.487 (3.49)  Time: 0.879s,  145.63/s  (0.879s,  145.63/s)  LR: 1.000e-03  Data: 0.570 (0.570)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.260 (3.60)  Time: 0.318s,  402.51/s  (0.324s,  395.02/s)  LR: 1.000e-03  Data: 0.012 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 4.001 (3.62)  Time: 0.316s,  404.44/s  (0.321s,  398.60/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.757 (3.61)  Time: 0.316s,  405.27/s  (0.320s,  399.83/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.756 (3.61)  Time: 0.307s,  417.14/s  (0.320s,  400.25/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.324 (3.32)  Time: 0.796s,  160.72/s  (0.796s,  160.72/s)  LR: 1.000e-03  Data: 0.482 (0.482)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.901 (3.56)  Time: 0.318s,  403.14/s  (0.323s,  396.63/s)  LR: 1.000e-03  Data: 0.013 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.278 (3.59)  Time: 0.318s,  402.40/s  (0.320s,  399.79/s)  LR: 1.000e-03  Data: 0.013 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.998 (3.61)  Time: 0.316s,  404.85/s  (0.320s,  400.39/s)  LR: 1.000e-03  Data: 0.011 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.921 (3.59)  Time: 0.305s,  419.50/s  (0.320s,  400.34/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 2.946 (2.95)  Time: 0.948s,  135.01/s  (0.948s,  135.01/s)  LR: 1.000e-03  Data: 0.633 (0.633)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.673 (3.63)  Time: 0.318s,  402.22/s  (0.325s,  394.20/s)  LR: 1.000e-03  Data: 0.012 (0.019)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.765 (3.63)  Time: 0.320s,  399.84/s  (0.321s,  398.19/s)  LR: 1.000e-03  Data: 0.015 (0.016)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.570 (3.65)  Time: 0.316s,  405.17/s  (0.320s,  399.54/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 389/390 (100%)]  Loss: 4.065 (3.66)  Time: 0.306s,  418.07/s  (0.320s,  400.16/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.264 (3.26)  Time: 0.753s,  170.07/s  (0.753s,  170.07/s)  LR: 1.000e-03  Data: 0.445 (0.445)
Train: 0 [ 100/390 ( 26%)]  Loss: 4.080 (3.63)  Time: 0.317s,  403.44/s  (0.323s,  396.55/s)  LR: 1.000e-03  Data: 0.011 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 4.078 (3.66)  Time: 0.316s,  405.26/s  (0.321s,  399.12/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.837 (3.65)  Time: 0.321s,  398.44/s  (0.320s,  400.08/s)  LR: 1.000e-03  Data: 0.013 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.555 (3.65)  Time: 0.304s,  420.68/s  (0.320s,  400.54/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.700 (3.70)  Time: 0.864s,  148.23/s  (0.864s,  148.23/s)  LR: 1.000e-03  Data: 0.552 (0.552)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.819 (3.60)  Time: 0.318s,  402.03/s  (0.324s,  394.83/s)  LR: 1.000e-03  Data: 0.013 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.873 (3.62)  Time: 0.319s,  401.79/s  (0.321s,  398.32/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 4.048 (3.64)  Time: 0.316s,  404.43/s  (0.320s,  399.68/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 4.156 (3.65)  Time: 0.306s,  417.80/s  (0.320s,  400.44/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.840 (3.84)  Time: 0.858s,  149.17/s  (0.858s,  149.17/s)  LR: 1.000e-03  Data: 0.552 (0.552)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.266 (3.70)  Time: 0.321s,  399.08/s  (0.324s,  395.01/s)  LR: 1.000e-03  Data: 0.015 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 4.028 (3.69)  Time: 0.319s,  401.61/s  (0.321s,  398.27/s)  LR: 1.000e-03  Data: 0.013 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.781 (3.69)  Time: 0.317s,  403.86/s  (0.320s,  399.69/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 4.073 (3.69)  Time: 0.307s,  417.02/s  (0.320s,  400.32/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.383 (3.38)  Time: 0.798s,  160.48/s  (0.798s,  160.48/s)  LR: 1.000e-03  Data: 0.491 (0.491)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.432 (3.66)  Time: 0.318s,  402.61/s  (0.323s,  396.48/s)  LR: 1.000e-03  Data: 0.013 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.988 (3.66)  Time: 0.316s,  404.58/s  (0.321s,  399.00/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 4.001 (3.68)  Time: 0.317s,  403.70/s  (0.320s,  400.00/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.581 (3.65)  Time: 0.305s,  419.94/s  (0.320s,  400.59/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 3.898 (3.90)  Time: 0.805s,  158.98/s  (0.805s,  158.98/s)  LR: 1.000e-03  Data: 0.500 (0.500)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.204 (3.66)  Time: 0.316s,  405.22/s  (0.322s,  397.11/s)  LR: 1.000e-03  Data: 0.012 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.947 (3.66)  Time: 0.316s,  404.72/s  (0.320s,  399.97/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.108 (3.68)  Time: 0.317s,  404.33/s  (0.320s,  400.60/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.797 (3.67)  Time: 0.308s,  415.51/s  (0.319s,  401.03/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 3.816 (3.82)  Time: 0.847s,  151.07/s  (0.847s,  151.07/s)  LR: 1.000e-03  Data: 0.526 (0.526)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.011 (3.68)  Time: 0.317s,  403.56/s  (0.324s,  395.63/s)  LR: 1.000e-03  Data: 0.012 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.503 (3.69)  Time: 0.316s,  404.62/s  (0.321s,  398.50/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.980 (3.70)  Time: 0.316s,  404.96/s  (0.320s,  399.56/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.779 (3.70)  Time: 0.306s,  418.52/s  (0.320s,  400.24/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.900 (3.90)  Time: 0.774s,  165.40/s  (0.774s,  165.40/s)  LR: 1.000e-03  Data: 0.469 (0.469)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.940 (3.69)  Time: 0.320s,  399.84/s  (0.322s,  396.94/s)  LR: 1.000e-03  Data: 0.012 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 4.136 (3.74)  Time: 0.316s,  404.49/s  (0.320s,  399.61/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.814 (3.72)  Time: 0.317s,  403.64/s  (0.320s,  400.59/s)  LR: 1.000e-03  Data: 0.013 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 4.198 (3.72)  Time: 0.306s,  417.99/s  (0.319s,  401.00/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.557 (3.56)  Time: 0.864s,  148.07/s  (0.864s,  148.07/s)  LR: 1.000e-03  Data: 0.543 (0.543)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.532 (3.66)  Time: 0.319s,  400.83/s  (0.324s,  394.74/s)  LR: 1.000e-03  Data: 0.013 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.448 (3.67)  Time: 0.317s,  403.17/s  (0.321s,  398.73/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 4.015 (3.69)  Time: 0.316s,  404.56/s  (0.320s,  400.12/s)  LR: 1.000e-03  Data: 0.011 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.952 (3.71)  Time: 0.306s,  418.56/s  (0.319s,  400.76/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.891 (3.89)  Time: 0.796s,  160.81/s  (0.796s,  160.81/s)  LR: 1.000e-03  Data: 0.489 (0.489)
Train: 0 [ 100/390 ( 26%)]  Loss: 4.143 (3.75)  Time: 0.318s,  402.76/s  (0.324s,  395.53/s)  LR: 1.000e-03  Data: 0.011 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 4.040 (3.74)  Time: 0.318s,  402.94/s  (0.321s,  398.73/s)  LR: 1.000e-03  Data: 0.013 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.995 (3.74)  Time: 0.319s,  401.88/s  (0.320s,  399.64/s)  LR: 1.000e-03  Data: 0.013 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 4.164 (3.76)  Time: 0.311s,  412.04/s  (0.320s,  400.28/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 4.068 (4.07)  Time: 0.745s,  171.91/s  (0.745s,  171.91/s)  LR: 1.000e-03  Data: 0.428 (0.428)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.177 (3.69)  Time: 0.321s,  398.20/s  (0.323s,  396.70/s)  LR: 1.000e-03  Data: 0.018 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.962 (3.70)  Time: 0.319s,  401.68/s  (0.321s,  399.19/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.759 (3.69)  Time: 0.321s,  398.75/s  (0.320s,  400.61/s)  LR: 1.000e-03  Data: 0.014 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.433 (3.71)  Time: 0.305s,  420.12/s  (0.319s,  400.68/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.857 (3.86)  Time: 0.776s,  165.05/s  (0.776s,  165.05/s)  LR: 1.000e-03  Data: 0.454 (0.454)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.659 (3.73)  Time: 0.320s,  399.71/s  (0.323s,  396.60/s)  LR: 1.000e-03  Data: 0.015 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.523 (3.72)  Time: 0.317s,  403.38/s  (0.321s,  398.52/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 4.075 (3.74)  Time: 0.325s,  394.14/s  (0.320s,  399.46/s)  LR: 1.000e-03  Data: 0.016 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.173 (3.74)  Time: 0.305s,  419.77/s  (0.320s,  399.86/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.136 (3.14)  Time: 0.752s,  170.11/s  (0.752s,  170.11/s)  LR: 1.000e-03  Data: 0.442 (0.442)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.391 (3.65)  Time: 0.317s,  404.15/s  (0.324s,  394.63/s)  LR: 1.000e-03  Data: 0.012 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.909 (3.69)  Time: 0.318s,  401.92/s  (0.323s,  396.60/s)  LR: 1.000e-03  Data: 0.012 (0.016)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.104 (3.67)  Time: 0.318s,  402.25/s  (0.322s,  398.10/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 389/390 (100%)]  Loss: 3.442 (3.70)  Time: 0.306s,  418.80/s  (0.321s,  398.66/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 4.188 (4.19)  Time: 0.924s,  138.59/s  (0.924s,  138.59/s)  LR: 1.000e-03  Data: 0.581 (0.581)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.953 (3.76)  Time: 0.318s,  402.82/s  (0.324s,  394.59/s)  LR: 1.000e-03  Data: 0.014 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.969 (3.78)  Time: 0.317s,  403.91/s  (0.321s,  398.40/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 4.034 (3.79)  Time: 0.315s,  406.39/s  (0.320s,  399.65/s)  LR: 1.000e-03  Data: 0.011 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 4.007 (3.77)  Time: 0.305s,  419.74/s  (0.320s,  400.40/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.324 (3.32)  Time: 0.785s,  162.97/s  (0.785s,  162.97/s)  LR: 1.000e-03  Data: 0.476 (0.476)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.392 (3.78)  Time: 0.330s,  387.72/s  (0.323s,  395.99/s)  LR: 1.000e-03  Data: 0.014 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.734 (3.78)  Time: 0.315s,  407.00/s  (0.320s,  399.55/s)  LR: 1.000e-03  Data: 0.010 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.483 (3.77)  Time: 0.318s,  403.03/s  (0.320s,  400.20/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 4.132 (3.75)  Time: 0.306s,  418.49/s  (0.320s,  400.54/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.002 (3.00)  Time: 0.803s,  159.37/s  (0.803s,  159.37/s)  LR: 1.000e-03  Data: 0.496 (0.496)
Train: 0 [ 100/390 ( 26%)]  Loss: 4.042 (3.78)  Time: 0.316s,  405.16/s  (0.323s,  395.82/s)  LR: 1.000e-03  Data: 0.012 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 4.080 (3.79)  Time: 0.317s,  403.96/s  (0.321s,  398.85/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.409 (3.78)  Time: 0.317s,  404.07/s  (0.320s,  399.96/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.578 (3.76)  Time: 0.306s,  418.04/s  (0.320s,  400.54/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.962 (3.96)  Time: 0.810s,  157.94/s  (0.810s,  157.94/s)  LR: 1.000e-03  Data: 0.493 (0.493)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.301 (3.71)  Time: 0.318s,  402.99/s  (0.324s,  395.53/s)  LR: 1.000e-03  Data: 0.011 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.807 (3.73)  Time: 0.318s,  402.08/s  (0.321s,  398.75/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.880 (3.76)  Time: 0.316s,  404.84/s  (0.320s,  400.01/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.778 (3.77)  Time: 0.305s,  419.32/s  (0.319s,  400.64/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.930 (3.93)  Time: 0.778s,  164.56/s  (0.778s,  164.56/s)  LR: 1.000e-03  Data: 0.466 (0.466)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.179 (3.68)  Time: 0.315s,  406.32/s  (0.323s,  396.77/s)  LR: 1.000e-03  Data: 0.011 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.864 (3.77)  Time: 0.318s,  403.14/s  (0.320s,  399.68/s)  LR: 1.000e-03  Data: 0.013 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 4.214 (3.75)  Time: 0.318s,  402.04/s  (0.319s,  400.86/s)  LR: 1.000e-03  Data: 0.014 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 4.281 (3.77)  Time: 0.305s,  419.31/s  (0.319s,  401.31/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 4.062 (4.06)  Time: 0.850s,  150.52/s  (0.850s,  150.52/s)  LR: 1.000e-03  Data: 0.544 (0.544)
Train: 0 [ 100/390 ( 26%)]  Loss: 4.118 (3.79)  Time: 0.318s,  402.43/s  (0.323s,  396.28/s)  LR: 1.000e-03  Data: 0.013 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 4.024 (3.78)  Time: 0.316s,  405.47/s  (0.320s,  399.74/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 4.159 (3.77)  Time: 0.320s,  400.27/s  (0.319s,  400.64/s)  LR: 1.000e-03  Data: 0.014 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.970 (3.78)  Time: 0.305s,  419.31/s  (0.319s,  401.13/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 4.027 (4.03)  Time: 0.889s,  143.91/s  (0.889s,  143.91/s)  LR: 1.000e-03  Data: 0.583 (0.583)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.367 (3.80)  Time: 0.318s,  402.75/s  (0.324s,  395.42/s)  LR: 1.000e-03  Data: 0.013 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.676 (3.80)  Time: 0.315s,  405.94/s  (0.321s,  398.19/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 4.118 (3.80)  Time: 0.319s,  401.35/s  (0.320s,  399.72/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.952 (3.79)  Time: 0.306s,  418.26/s  (0.320s,  400.38/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 4.064 (4.06)  Time: 0.773s,  165.67/s  (0.773s,  165.67/s)  LR: 1.000e-03  Data: 0.454 (0.454)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.586 (3.80)  Time: 0.317s,  403.22/s  (0.323s,  396.61/s)  LR: 1.000e-03  Data: 0.012 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.433 (3.81)  Time: 0.318s,  402.89/s  (0.320s,  399.53/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.656 (3.82)  Time: 0.319s,  401.11/s  (0.320s,  400.22/s)  LR: 1.000e-03  Data: 0.013 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.733 (3.81)  Time: 0.306s,  418.77/s  (0.319s,  400.64/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 4.003 (4.00)  Time: 0.849s,  150.84/s  (0.849s,  150.84/s)  LR: 1.000e-03  Data: 0.528 (0.528)
Train: 0 [ 100/390 ( 26%)]  Loss: 4.016 (3.85)  Time: 0.320s,  400.15/s  (0.324s,  395.31/s)  LR: 1.000e-03  Data: 0.015 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.727 (3.83)  Time: 0.318s,  403.14/s  (0.321s,  399.01/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.511 (3.82)  Time: 0.316s,  405.00/s  (0.320s,  399.67/s)  LR: 1.000e-03  Data: 0.011 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.540 (3.81)  Time: 0.305s,  420.14/s  (0.320s,  400.16/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 4.036 (4.04)  Time: 0.812s,  157.61/s  (0.812s,  157.61/s)  LR: 1.000e-03  Data: 0.502 (0.502)
Train: 0 [ 100/390 ( 26%)]  Loss: 4.053 (3.79)  Time: 0.320s,  400.15/s  (0.324s,  395.64/s)  LR: 1.000e-03  Data: 0.014 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.343 (3.81)  Time: 0.317s,  404.05/s  (0.321s,  399.11/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.819 (3.80)  Time: 0.323s,  396.14/s  (0.320s,  399.59/s)  LR: 1.000e-03  Data: 0.017 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 4.077 (3.80)  Time: 0.307s,  416.75/s  (0.320s,  399.57/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.682 (3.68)  Time: 0.837s,  152.97/s  (0.837s,  152.97/s)  LR: 1.000e-03  Data: 0.524 (0.524)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.989 (3.82)  Time: 0.318s,  402.62/s  (0.323s,  395.83/s)  LR: 1.000e-03  Data: 0.012 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 4.155 (3.80)  Time: 0.318s,  402.67/s  (0.321s,  399.13/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.894 (3.80)  Time: 0.317s,  403.36/s  (0.320s,  399.82/s)  LR: 1.000e-03  Data: 0.013 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 4.186 (3.81)  Time: 0.305s,  419.25/s  (0.320s,  400.27/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 2.999 (3.00)  Time: 0.788s,  162.42/s  (0.788s,  162.42/s)  LR: 1.000e-03  Data: 0.477 (0.477)
Train: 0 [ 100/390 ( 26%)]  Loss: 4.177 (3.81)  Time: 0.315s,  406.05/s  (0.322s,  396.91/s)  LR: 1.000e-03  Data: 0.011 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.834 (3.82)  Time: 0.317s,  404.03/s  (0.320s,  399.74/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 4.091 (3.83)  Time: 0.318s,  401.89/s  (0.319s,  400.78/s)  LR: 1.000e-03  Data: 0.013 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 4.282 (3.82)  Time: 0.305s,  419.78/s  (0.319s,  401.42/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 3.973 (3.97)  Time: 0.796s,  160.74/s  (0.796s,  160.74/s)  LR: 1.000e-03  Data: 0.487 (0.487)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.776 (3.76)  Time: 0.318s,  403.12/s  (0.324s,  395.01/s)  LR: 1.000e-03  Data: 0.012 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 4.167 (3.81)  Time: 0.322s,  398.13/s  (0.321s,  398.29/s)  LR: 1.000e-03  Data: 0.017 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 4.044 (3.81)  Time: 0.321s,  399.31/s  (0.320s,  399.68/s)  LR: 1.000e-03  Data: 0.015 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 4.118 (3.82)  Time: 0.304s,  420.81/s  (0.320s,  400.40/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.774 (3.77)  Time: 0.904s,  141.67/s  (0.904s,  141.67/s)  LR: 1.000e-03  Data: 0.593 (0.593)
Train: 0 [ 100/390 ( 26%)]  Loss: 4.092 (3.80)  Time: 0.318s,  402.64/s  (0.325s,  393.52/s)  LR: 1.000e-03  Data: 0.013 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 4.118 (3.80)  Time: 0.318s,  401.91/s  (0.323s,  396.65/s)  LR: 1.000e-03  Data: 0.012 (0.016)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.980 (3.81)  Time: 0.316s,  405.08/s  (0.321s,  398.64/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 389/390 (100%)]  Loss: 4.243 (3.80)  Time: 0.306s,  418.64/s  (0.321s,  398.77/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.601 (3.60)  Time: 0.810s,  157.97/s  (0.810s,  157.97/s)  LR: 1.000e-03  Data: 0.505 (0.505)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.599 (3.87)  Time: 0.316s,  404.56/s  (0.324s,  394.91/s)  LR: 1.000e-03  Data: 0.012 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.361 (3.85)  Time: 0.318s,  402.98/s  (0.321s,  398.21/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 4.190 (3.86)  Time: 0.317s,  403.27/s  (0.320s,  399.44/s)  LR: 1.000e-03  Data: 0.011 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 4.253 (3.86)  Time: 0.321s,  399.24/s  (0.320s,  399.95/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.828 (3.83)  Time: 0.861s,  148.60/s  (0.861s,  148.60/s)  LR: 1.000e-03  Data: 0.555 (0.555)
Train: 0 [ 100/390 ( 26%)]  Loss: 4.270 (3.85)  Time: 0.316s,  404.43/s  (0.324s,  395.39/s)  LR: 1.000e-03  Data: 0.012 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.147 (3.85)  Time: 0.319s,  400.85/s  (0.321s,  398.70/s)  LR: 1.000e-03  Data: 0.015 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 4.160 (3.83)  Time: 0.323s,  396.44/s  (0.320s,  399.39/s)  LR: 1.000e-03  Data: 0.015 (0.015)
Train: 0 [ 389/390 (100%)]  Loss: 4.216 (3.82)  Time: 0.305s,  420.02/s  (0.320s,  400.24/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.704 (3.70)  Time: 0.873s,  146.56/s  (0.873s,  146.56/s)  LR: 1.000e-03  Data: 0.567 (0.567)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.946 (3.88)  Time: 0.319s,  401.66/s  (0.323s,  396.09/s)  LR: 1.000e-03  Data: 0.012 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.473 (3.85)  Time: 0.318s,  402.44/s  (0.321s,  398.56/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.458 (3.83)  Time: 0.316s,  404.78/s  (0.320s,  399.78/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.293 (3.85)  Time: 0.306s,  418.10/s  (0.320s,  400.58/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 4.114 (4.11)  Time: 0.693s,  184.63/s  (0.693s,  184.63/s)  LR: 1.000e-03  Data: 0.378 (0.378)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.313 (3.87)  Time: 0.316s,  404.65/s  (0.322s,  397.53/s)  LR: 1.000e-03  Data: 0.012 (0.016)
Train: 0 [ 200/390 ( 51%)]  Loss: 4.070 (3.86)  Time: 0.318s,  402.62/s  (0.320s,  399.51/s)  LR: 1.000e-03  Data: 0.013 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.287 (3.87)  Time: 0.317s,  403.42/s  (0.319s,  400.63/s)  LR: 1.000e-03  Data: 0.014 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.727 (3.87)  Time: 0.305s,  419.74/s  (0.319s,  401.08/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.587 (3.59)  Time: 0.965s,  132.71/s  (0.965s,  132.71/s)  LR: 1.000e-03  Data: 0.640 (0.640)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.443 (3.83)  Time: 0.319s,  400.74/s  (0.326s,  392.06/s)  LR: 1.000e-03  Data: 0.013 (0.019)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.967 (3.81)  Time: 0.327s,  391.35/s  (0.324s,  395.29/s)  LR: 1.000e-03  Data: 0.014 (0.016)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.873 (3.80)  Time: 0.318s,  402.57/s  (0.323s,  396.21/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 389/390 (100%)]  Loss: 4.030 (3.82)  Time: 0.307s,  416.96/s  (0.322s,  397.08/s)  LR: 1.000e-03  Data: 0.000 (0.015)
Train: 0 [   0/390 (  0%)]  Loss: 3.545 (3.55)  Time: 0.880s,  145.43/s  (0.880s,  145.43/s)  LR: 1.000e-03  Data: 0.574 (0.574)
Train: 0 [ 100/390 ( 26%)]  Loss: 4.242 (3.85)  Time: 0.318s,  402.43/s  (0.326s,  392.48/s)  LR: 1.000e-03  Data: 0.013 (0.019)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.855 (3.86)  Time: 0.319s,  400.92/s  (0.324s,  395.08/s)  LR: 1.000e-03  Data: 0.014 (0.016)
Train: 0 [ 300/390 ( 77%)]  Loss: 4.195 (3.87)  Time: 0.321s,  398.52/s  (0.323s,  396.67/s)  LR: 1.000e-03  Data: 0.014 (0.015)
Train: 0 [ 389/390 (100%)]  Loss: 4.120 (3.87)  Time: 0.306s,  417.80/s  (0.322s,  397.41/s)  LR: 1.000e-03  Data: 0.000 (0.015)
Train: 0 [   0/390 (  0%)]  Loss: 3.777 (3.78)  Time: 0.940s,  136.17/s  (0.940s,  136.17/s)  LR: 1.000e-03  Data: 0.619 (0.619)
Train: 0 [ 100/390 ( 26%)]  Loss: 4.186 (3.91)  Time: 0.316s,  404.76/s  (0.325s,  394.17/s)  LR: 1.000e-03  Data: 0.011 (0.019)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.768 (3.89)  Time: 0.317s,  404.13/s  (0.322s,  398.06/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 4.155 (3.88)  Time: 0.319s,  400.66/s  (0.321s,  399.35/s)  LR: 1.000e-03  Data: 0.014 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 4.157 (3.89)  Time: 0.306s,  418.91/s  (0.320s,  400.07/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.552 (3.55)  Time: 0.847s,  151.07/s  (0.847s,  151.07/s)  LR: 1.000e-03  Data: 0.541 (0.541)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.589 (3.86)  Time: 0.319s,  400.76/s  (0.324s,  395.58/s)  LR: 1.000e-03  Data: 0.012 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.675 (3.87)  Time: 0.318s,  402.94/s  (0.321s,  399.03/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.176 (3.87)  Time: 0.317s,  403.46/s  (0.320s,  400.24/s)  LR: 1.000e-03  Data: 0.011 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 4.121 (3.86)  Time: 0.305s,  419.16/s  (0.319s,  400.77/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 4.122 (4.12)  Time: 0.887s,  144.24/s  (0.887s,  144.24/s)  LR: 1.000e-03  Data: 0.581 (0.581)
Train: 0 [ 100/390 ( 26%)]  Loss: 4.148 (3.89)  Time: 0.320s,  399.66/s  (0.323s,  396.20/s)  LR: 1.000e-03  Data: 0.013 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 4.028 (3.90)  Time: 0.316s,  405.64/s  (0.321s,  398.90/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.903 (3.88)  Time: 0.318s,  402.49/s  (0.320s,  399.69/s)  LR: 1.000e-03  Data: 0.013 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 4.163 (3.89)  Time: 0.306s,  417.90/s  (0.320s,  400.13/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 4.104 (4.10)  Time: 0.896s,  142.93/s  (0.896s,  142.93/s)  LR: 1.000e-03  Data: 0.586 (0.586)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.791 (3.88)  Time: 0.317s,  404.35/s  (0.323s,  395.74/s)  LR: 1.000e-03  Data: 0.012 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.789 (3.90)  Time: 0.316s,  404.55/s  (0.321s,  398.47/s)  LR: 1.000e-03  Data: 0.011 (0.016)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.938 (3.89)  Time: 0.318s,  402.37/s  (0.320s,  399.80/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 389/390 (100%)]  Loss: 3.846 (3.88)  Time: 0.306s,  418.75/s  (0.320s,  400.36/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.603 (3.60)  Time: 0.801s,  159.71/s  (0.801s,  159.71/s)  LR: 1.000e-03  Data: 0.486 (0.486)
Train: 0 [ 100/390 ( 26%)]  Loss: 4.128 (3.83)  Time: 0.316s,  405.20/s  (0.323s,  396.65/s)  LR: 1.000e-03  Data: 0.012 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 4.084 (3.85)  Time: 0.321s,  399.26/s  (0.320s,  399.40/s)  LR: 1.000e-03  Data: 0.014 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.514 (3.87)  Time: 0.315s,  405.74/s  (0.320s,  400.45/s)  LR: 1.000e-03  Data: 0.011 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 4.178 (3.87)  Time: 0.305s,  420.01/s  (0.319s,  401.03/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 4.257 (4.26)  Time: 0.805s,  158.96/s  (0.805s,  158.96/s)  LR: 1.000e-03  Data: 0.500 (0.500)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.413 (3.89)  Time: 0.315s,  406.25/s  (0.323s,  396.65/s)  LR: 1.000e-03  Data: 0.011 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.623 (3.89)  Time: 0.316s,  405.05/s  (0.320s,  399.72/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.603 (3.88)  Time: 0.317s,  403.73/s  (0.320s,  400.44/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.650 (3.87)  Time: 0.304s,  420.80/s  (0.319s,  400.97/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.858 (3.86)  Time: 0.847s,  151.17/s  (0.847s,  151.17/s)  LR: 1.000e-03  Data: 0.516 (0.516)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.770 (3.88)  Time: 0.322s,  398.12/s  (0.324s,  395.40/s)  LR: 1.000e-03  Data: 0.017 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.564 (3.88)  Time: 0.316s,  404.69/s  (0.321s,  398.94/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.320 (3.88)  Time: 0.318s,  401.97/s  (0.320s,  400.23/s)  LR: 1.000e-03  Data: 0.013 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.353 (3.87)  Time: 0.305s,  419.35/s  (0.319s,  400.89/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.989 (3.99)  Time: 0.878s,  145.87/s  (0.878s,  145.87/s)  LR: 1.000e-03  Data: 0.573 (0.573)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.504 (3.92)  Time: 0.317s,  403.60/s  (0.323s,  395.76/s)  LR: 1.000e-03  Data: 0.013 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 4.004 (3.86)  Time: 0.315s,  406.28/s  (0.321s,  399.37/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.226 (3.85)  Time: 0.319s,  400.68/s  (0.320s,  400.36/s)  LR: 1.000e-03  Data: 0.015 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 4.157 (3.86)  Time: 0.306s,  418.45/s  (0.319s,  400.90/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 4.092 (4.09)  Time: 0.942s,  135.94/s  (0.942s,  135.94/s)  LR: 1.000e-03  Data: 0.637 (0.637)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.860 (3.88)  Time: 0.316s,  404.98/s  (0.324s,  395.03/s)  LR: 1.000e-03  Data: 0.011 (0.019)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.908 (3.87)  Time: 0.314s,  407.02/s  (0.321s,  399.02/s)  LR: 1.000e-03  Data: 0.011 (0.016)
Train: 0 [ 300/390 ( 77%)]  Loss: 4.059 (3.87)  Time: 0.319s,  401.43/s  (0.320s,  400.42/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.678 (3.87)  Time: 0.308s,  415.19/s  (0.319s,  400.92/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Train: 0 [   0/390 (  0%)]  Loss: 3.318 (3.32)  Time: 0.967s,  132.43/s  (0.967s,  132.43/s)  LR: 1.000e-03  Data: 0.660 (0.660)
Train: 0 [ 100/390 ( 26%)]  Loss: 4.236 (3.85)  Time: 0.320s,  400.29/s  (0.324s,  394.52/s)  LR: 1.000e-03  Data: 0.014 (0.019)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.709 (3.87)  Time: 0.315s,  405.89/s  (0.322s,  398.11/s)  LR: 1.000e-03  Data: 0.010 (0.016)
Train: 0 [ 300/390 ( 77%)]  Loss: 4.129 (3.88)  Time: 0.322s,  397.64/s  (0.320s,  399.59/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 389/390 (100%)]  Loss: 4.071 (3.88)  Time: 0.305s,  419.17/s  (0.320s,  400.05/s)  LR: 1.000e-03  Data: 0.000 (0.014)
Test: [   0/78]  Time: 1.235 (1.235)  Loss:  2.4512 (2.4512)  Acc@1: 53.1250 (53.1250)  Acc@5: 78.9062 (78.9062)
Test: [  78/78]  Time: 0.077 (0.135)  Loss:  2.3379 (2.5241)  Acc@1: 56.2500 (46.6100)  Acc@5: 75.0000 (75.2900)
Test: [Whole Val]  Time: 10.641  Loss: 2.5241  Acc@1: 46.6100 Pruned: 75.41% 
*** Pruned results: OrderedDict([('loss', 2.524065625), ('top1', 46.61), ('top5', 75.29), ('pruned', 0.7541491759950248)])
Pruned: 50.00%
Train: 0 [   0/390 (  0%)]  Loss: 3.977 (3.98)  Time: 0.727s,  175.95/s  (0.727s,  175.95/s)  LR: 1.000e-07  Data: 0.409 (0.409)
Train: 0 [ 100/390 ( 26%)]  Loss: 4.203 (3.99)  Time: 0.315s,  406.21/s  (0.322s,  397.47/s)  LR: 1.000e-07  Data: 0.012 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 4.339 (3.98)  Time: 0.316s,  405.70/s  (0.319s,  401.31/s)  LR: 1.000e-07  Data: 0.014 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 4.164 (3.98)  Time: 0.315s,  405.73/s  (0.318s,  402.93/s)  LR: 1.000e-07  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 4.182 (3.99)  Time: 0.302s,  423.20/s  (0.317s,  403.61/s)  LR: 1.000e-07  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.330 (0.330)  Loss:  2.4453 (2.4453)  Acc@1: 53.9062 (53.9062)  Acc@5: 78.9062 (78.9062)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  2.3340 (2.5192)  Acc@1: 56.2500 (46.8200)  Acc@5: 75.0000 (75.4300)
Test: [Whole Val]  Time: 9.692  Loss: 2.5192  Acc@1: 46.8200 Pruned: 75.42% 
Test (EMA): [   0/78]  Time: 0.406 (0.406)  Loss:  2.4453 (2.4453)  Acc@1: 53.9062 (53.9062)  Acc@5: 78.9062 (78.9062)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  2.3340 (2.5193)  Acc@1: 56.2500 (46.8200)  Acc@5: 75.0000 (75.4200)
Test (EMA): [Whole Val]  Time: 9.712  Loss: 2.5193  Acc@1: 46.8200 Pruned: 75.42% 
Train: 1 [   0/390 (  0%)]  Loss: 4.133 (4.13)  Time: 0.910s,  140.60/s  (0.910s,  140.60/s)  LR: 1.001e-04  Data: 0.599 (0.599)
Train: 1 [ 100/390 ( 26%)]  Loss: 3.645 (3.88)  Time: 0.314s,  407.21/s  (0.321s,  398.42/s)  LR: 1.001e-04  Data: 0.012 (0.018)
Train: 1 [ 200/390 ( 51%)]  Loss: 4.133 (3.88)  Time: 0.322s,  397.57/s  (0.319s,  401.51/s)  LR: 1.001e-04  Data: 0.012 (0.015)
Train: 1 [ 300/390 ( 77%)]  Loss: 4.077 (3.88)  Time: 0.313s,  408.30/s  (0.318s,  402.85/s)  LR: 1.001e-04  Data: 0.012 (0.015)
Train: 1 [ 389/390 (100%)]  Loss: 4.177 (3.87)  Time: 0.304s,  421.19/s  (0.317s,  403.66/s)  LR: 1.001e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.320 (0.320)  Loss:  2.0703 (2.0703)  Acc@1: 53.9062 (53.9062)  Acc@5: 82.8125 (82.8125)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  2.0078 (2.1698)  Acc@1: 50.0000 (52.2700)  Acc@5: 75.0000 (80.4000)
Test: [Whole Val]  Time: 9.633  Loss: 2.1698  Acc@1: 52.2700 Pruned: 75.03% 
Test (EMA): [   0/78]  Time: 0.410 (0.410)  Loss:  2.0664 (2.0664)  Acc@1: 53.9062 (53.9062)  Acc@5: 82.0312 (82.0312)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  2.0156 (2.1647)  Acc@1: 50.0000 (52.5800)  Acc@5: 75.0000 (80.5300)
Test (EMA): [Whole Val]  Time: 9.733  Loss: 2.1647  Acc@1: 52.5800 Pruned: 75.06% 
Train: 2 [   0/390 (  0%)]  Loss: 4.094 (4.09)  Time: 0.769s,  166.40/s  (0.769s,  166.40/s)  LR: 2.001e-04  Data: 0.425 (0.425)
Train: 2 [ 100/390 ( 26%)]  Loss: 4.095 (3.86)  Time: 0.317s,  403.46/s  (0.320s,  399.98/s)  LR: 2.001e-04  Data: 0.013 (0.017)
Train: 2 [ 200/390 ( 51%)]  Loss: 4.070 (3.87)  Time: 0.316s,  405.67/s  (0.318s,  402.88/s)  LR: 2.001e-04  Data: 0.012 (0.015)
Train: 2 [ 300/390 ( 77%)]  Loss: 3.581 (3.85)  Time: 0.315s,  406.23/s  (0.317s,  403.22/s)  LR: 2.001e-04  Data: 0.013 (0.014)
Train: 2 [ 389/390 (100%)]  Loss: 3.510 (3.83)  Time: 0.303s,  422.68/s  (0.317s,  404.04/s)  LR: 2.001e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.325 (0.325)  Loss:  1.9570 (1.9570)  Acc@1: 55.4688 (55.4688)  Acc@5: 86.7188 (86.7188)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.8867 (2.0393)  Acc@1: 62.5000 (54.0100)  Acc@5: 81.2500 (82.0500)
Test: [Whole Val]  Time: 9.658  Loss: 2.0393  Acc@1: 54.0100 Pruned: 72.82% 
Test (EMA): [   0/78]  Time: 0.330 (0.330)  Loss:  1.9531 (1.9531)  Acc@1: 53.9062 (53.9062)  Acc@5: 85.1562 (85.1562)
Test (EMA): [  78/78]  Time: 0.023 (0.122)  Loss:  1.8789 (2.0246)  Acc@1: 56.2500 (54.5700)  Acc@5: 81.2500 (82.1300)
Test (EMA): [Whole Val]  Time: 9.635  Loss: 2.0246  Acc@1: 54.5700 Pruned: 72.91% 
Train: 3 [   0/390 (  0%)]  Loss: 3.504 (3.50)  Time: 0.885s,  144.61/s  (0.885s,  144.61/s)  LR: 3.001e-04  Data: 0.543 (0.543)
Train: 3 [ 100/390 ( 26%)]  Loss: 3.347 (3.80)  Time: 0.318s,  402.33/s  (0.321s,  398.23/s)  LR: 3.001e-04  Data: 0.014 (0.018)
Train: 3 [ 200/390 ( 51%)]  Loss: 3.975 (3.79)  Time: 0.313s,  408.33/s  (0.319s,  401.49/s)  LR: 3.001e-04  Data: 0.011 (0.015)
Train: 3 [ 300/390 ( 77%)]  Loss: 4.088 (3.81)  Time: 0.313s,  408.94/s  (0.317s,  403.24/s)  LR: 3.001e-04  Data: 0.011 (0.014)
Train: 3 [ 389/390 (100%)]  Loss: 3.803 (3.81)  Time: 0.302s,  423.24/s  (0.317s,  403.89/s)  LR: 3.001e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.434 (0.434)  Loss:  1.8945 (1.8945)  Acc@1: 57.0312 (57.0312)  Acc@5: 85.1562 (85.1562)
Test: [  78/78]  Time: 0.018 (0.124)  Loss:  1.8193 (1.9950)  Acc@1: 62.5000 (53.9700)  Acc@5: 87.5000 (82.0200)
Test: [Whole Val]  Time: 9.759  Loss: 1.9950  Acc@1: 53.9700 Pruned: 70.12% 
Test (EMA): [   0/78]  Time: 0.332 (0.332)  Loss:  1.8652 (1.8652)  Acc@1: 54.6875 (54.6875)  Acc@5: 87.5000 (87.5000)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  1.8018 (1.9710)  Acc@1: 62.5000 (54.6100)  Acc@5: 81.2500 (82.5300)
Test (EMA): [Whole Val]  Time: 9.667  Loss: 1.9710  Acc@1: 54.6100 Pruned: 70.19% 
Train: 4 [   0/390 (  0%)]  Loss: 3.936 (3.94)  Time: 0.817s,  156.59/s  (0.817s,  156.59/s)  LR: 4.001e-04  Data: 0.478 (0.478)
Train: 4 [ 100/390 ( 26%)]  Loss: 4.041 (3.84)  Time: 0.316s,  405.55/s  (0.321s,  399.06/s)  LR: 4.001e-04  Data: 0.012 (0.017)
Train: 4 [ 200/390 ( 51%)]  Loss: 4.219 (3.82)  Time: 0.315s,  406.35/s  (0.318s,  402.24/s)  LR: 4.001e-04  Data: 0.013 (0.015)
Train: 4 [ 300/390 ( 77%)]  Loss: 3.489 (3.82)  Time: 0.316s,  404.66/s  (0.317s,  403.33/s)  LR: 4.001e-04  Data: 0.012 (0.014)
Train: 4 [ 389/390 (100%)]  Loss: 4.130 (3.83)  Time: 0.302s,  423.95/s  (0.317s,  404.03/s)  LR: 4.001e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.399 (0.399)  Loss:  1.9023 (1.9023)  Acc@1: 53.1250 (53.1250)  Acc@5: 85.1562 (85.1562)
Test: [  78/78]  Time: 0.017 (0.123)  Loss:  1.8662 (2.0038)  Acc@1: 62.5000 (53.9700)  Acc@5: 81.2500 (82.0700)
Test: [Whole Val]  Time: 9.708  Loss: 2.0038  Acc@1: 53.9700 Pruned: 67.96% 
Test (EMA): [   0/78]  Time: 0.313 (0.313)  Loss:  1.8643 (1.8643)  Acc@1: 55.4688 (55.4688)  Acc@5: 85.9375 (85.9375)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  1.8066 (1.9720)  Acc@1: 62.5000 (54.5200)  Acc@5: 81.2500 (82.9300)
Test (EMA): [Whole Val]  Time: 9.642  Loss: 1.9720  Acc@1: 54.5200 Pruned: 68.00% 
Train: 5 [   0/390 (  0%)]  Loss: 3.308 (3.31)  Time: 0.808s,  158.47/s  (0.808s,  158.47/s)  LR: 5.000e-04  Data: 0.488 (0.488)
Train: 5 [ 100/390 ( 26%)]  Loss: 3.891 (3.76)  Time: 0.314s,  408.04/s  (0.320s,  399.88/s)  LR: 5.000e-04  Data: 0.012 (0.017)
Train: 5 [ 200/390 ( 51%)]  Loss: 3.373 (3.77)  Time: 0.318s,  403.12/s  (0.318s,  403.02/s)  LR: 5.000e-04  Data: 0.012 (0.015)
Train: 5 [ 300/390 ( 77%)]  Loss: 4.118 (3.79)  Time: 0.314s,  407.56/s  (0.317s,  403.96/s)  LR: 5.000e-04  Data: 0.012 (0.014)
Train: 5 [ 389/390 (100%)]  Loss: 4.011 (3.78)  Time: 0.304s,  420.91/s  (0.317s,  404.26/s)  LR: 5.000e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.440 (0.440)  Loss:  1.9092 (1.9092)  Acc@1: 54.6875 (54.6875)  Acc@5: 85.1562 (85.1562)
Test: [  78/78]  Time: 0.017 (0.124)  Loss:  1.7734 (1.9636)  Acc@1: 56.2500 (53.8600)  Acc@5: 87.5000 (81.9800)
Test: [Whole Val]  Time: 9.775  Loss: 1.9636  Acc@1: 53.8600 Pruned: 65.99% 
Test (EMA): [   0/78]  Time: 0.355 (0.355)  Loss:  1.8418 (1.8418)  Acc@1: 54.6875 (54.6875)  Acc@5: 86.7188 (86.7188)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  1.6943 (1.9203)  Acc@1: 62.5000 (55.0400)  Acc@5: 87.5000 (83.4600)
Test (EMA): [Whole Val]  Time: 9.671  Loss: 1.9203  Acc@1: 55.0400 Pruned: 66.02% 
Train: 6 [   0/390 (  0%)]  Loss: 4.112 (4.11)  Time: 0.853s,  150.03/s  (0.853s,  150.03/s)  LR: 6.000e-04  Data: 0.513 (0.513)
Train: 6 [ 100/390 ( 26%)]  Loss: 3.367 (3.79)  Time: 0.318s,  402.57/s  (0.324s,  394.56/s)  LR: 6.000e-04  Data: 0.014 (0.018)
Train: 6 [ 200/390 ( 51%)]  Loss: 3.448 (3.82)  Time: 0.314s,  407.02/s  (0.320s,  399.58/s)  LR: 6.000e-04  Data: 0.012 (0.016)
Train: 6 [ 300/390 ( 77%)]  Loss: 3.670 (3.81)  Time: 0.313s,  408.86/s  (0.319s,  401.73/s)  LR: 6.000e-04  Data: 0.012 (0.015)
Train: 6 [ 389/390 (100%)]  Loss: 3.999 (3.82)  Time: 0.303s,  422.11/s  (0.318s,  402.74/s)  LR: 6.000e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.428 (0.428)  Loss:  1.8750 (1.8750)  Acc@1: 56.2500 (56.2500)  Acc@5: 85.1562 (85.1562)
Test: [  78/78]  Time: 0.018 (0.124)  Loss:  1.7451 (1.9674)  Acc@1: 56.2500 (54.7000)  Acc@5: 81.2500 (82.5800)
Test: [Whole Val]  Time: 9.767  Loss: 1.9674  Acc@1: 54.7000 Pruned: 64.47% 
Test (EMA): [   0/78]  Time: 0.421 (0.421)  Loss:  1.8174 (1.8174)  Acc@1: 58.5938 (58.5938)  Acc@5: 84.3750 (84.3750)
Test (EMA): [  78/78]  Time: 0.018 (0.124)  Loss:  1.7100 (1.9129)  Acc@1: 56.2500 (55.9100)  Acc@5: 87.5000 (83.4400)
Test (EMA): [Whole Val]  Time: 9.760  Loss: 1.9129  Acc@1: 55.9100 Pruned: 64.54% 
Train: 7 [   0/390 (  0%)]  Loss: 3.946 (3.95)  Time: 0.901s,  142.10/s  (0.901s,  142.10/s)  LR: 7.000e-04  Data: 0.600 (0.600)
Train: 7 [ 100/390 ( 26%)]  Loss: 3.759 (3.76)  Time: 0.315s,  406.31/s  (0.322s,  397.91/s)  LR: 7.000e-04  Data: 0.012 (0.019)
Train: 7 [ 200/390 ( 51%)]  Loss: 4.141 (3.80)  Time: 0.315s,  406.18/s  (0.318s,  402.25/s)  LR: 7.000e-04  Data: 0.012 (0.015)
Train: 7 [ 300/390 ( 77%)]  Loss: 3.683 (3.80)  Time: 0.314s,  407.47/s  (0.317s,  403.29/s)  LR: 7.000e-04  Data: 0.012 (0.014)
Train: 7 [ 389/390 (100%)]  Loss: 3.783 (3.80)  Time: 0.304s,  421.71/s  (0.317s,  403.57/s)  LR: 7.000e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.374 (0.374)  Loss:  1.8057 (1.8057)  Acc@1: 59.3750 (59.3750)  Acc@5: 83.5938 (83.5938)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  1.7676 (1.9382)  Acc@1: 50.0000 (53.8800)  Acc@5: 81.2500 (82.3000)
Test: [Whole Val]  Time: 9.722  Loss: 1.9382  Acc@1: 53.8800 Pruned: 63.22% 
Test (EMA): [   0/78]  Time: 0.400 (0.400)  Loss:  1.7871 (1.7871)  Acc@1: 59.3750 (59.3750)  Acc@5: 83.5938 (83.5938)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  1.7061 (1.8999)  Acc@1: 56.2500 (55.3600)  Acc@5: 87.5000 (83.5600)
Test (EMA): [Whole Val]  Time: 9.719  Loss: 1.8999  Acc@1: 55.3600 Pruned: 63.26% 
Train: 8 [   0/390 (  0%)]  Loss: 4.081 (4.08)  Time: 0.948s,  135.08/s  (0.948s,  135.08/s)  LR: 8.000e-04  Data: 0.631 (0.631)
Train: 8 [ 100/390 ( 26%)]  Loss: 4.149 (3.81)  Time: 0.314s,  407.18/s  (0.322s,  397.22/s)  LR: 8.000e-04  Data: 0.012 (0.019)
Train: 8 [ 200/390 ( 51%)]  Loss: 3.939 (3.81)  Time: 0.327s,  391.43/s  (0.319s,  400.63/s)  LR: 8.000e-04  Data: 0.012 (0.016)
Train: 8 [ 300/390 ( 77%)]  Loss: 4.022 (3.81)  Time: 0.313s,  409.02/s  (0.318s,  402.17/s)  LR: 8.000e-04  Data: 0.011 (0.015)
Train: 8 [ 389/390 (100%)]  Loss: 3.362 (3.80)  Time: 0.303s,  422.42/s  (0.318s,  402.81/s)  LR: 8.000e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.364 (0.364)  Loss:  1.9004 (1.9004)  Acc@1: 56.2500 (56.2500)  Acc@5: 83.5938 (83.5938)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  1.7822 (1.9752)  Acc@1: 50.0000 (54.2300)  Acc@5: 87.5000 (82.1000)
Test: [Whole Val]  Time: 9.676  Loss: 1.9752  Acc@1: 54.2300 Pruned: 61.98% 
Test (EMA): [   0/78]  Time: 0.398 (0.398)  Loss:  1.8320 (1.8320)  Acc@1: 57.8125 (57.8125)  Acc@5: 84.3750 (84.3750)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  1.7305 (1.9110)  Acc@1: 50.0000 (55.5000)  Acc@5: 87.5000 (83.4200)
Test (EMA): [Whole Val]  Time: 9.739  Loss: 1.9110  Acc@1: 55.5000 Pruned: 62.00% 
Train: 9 [   0/390 (  0%)]  Loss: 4.116 (4.12)  Time: 1.051s,  121.84/s  (1.051s,  121.84/s)  LR: 9.000e-04  Data: 0.746 (0.746)
Train: 9 [ 100/390 ( 26%)]  Loss: 3.813 (3.85)  Time: 0.313s,  408.57/s  (0.324s,  394.47/s)  LR: 9.000e-04  Data: 0.011 (0.020)
Train: 9 [ 200/390 ( 51%)]  Loss: 3.929 (3.84)  Time: 0.316s,  404.88/s  (0.320s,  399.67/s)  LR: 9.000e-04  Data: 0.012 (0.016)
Train: 9 [ 300/390 ( 77%)]  Loss: 3.947 (3.83)  Time: 0.315s,  405.93/s  (0.319s,  401.73/s)  LR: 9.000e-04  Data: 0.011 (0.015)
Train: 9 [ 389/390 (100%)]  Loss: 4.108 (3.81)  Time: 0.301s,  424.70/s  (0.318s,  402.74/s)  LR: 9.000e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.374 (0.374)  Loss:  1.7549 (1.7549)  Acc@1: 59.3750 (59.3750)  Acc@5: 84.3750 (84.3750)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  1.8057 (1.8785)  Acc@1: 56.2500 (55.9800)  Acc@5: 75.0000 (83.4600)
Test: [Whole Val]  Time: 9.666  Loss: 1.8785  Acc@1: 55.9800 Pruned: 61.07% 
Test (EMA): [   0/78]  Time: 0.417 (0.417)  Loss:  1.7637 (1.7637)  Acc@1: 60.1562 (60.1562)  Acc@5: 84.3750 (84.3750)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  1.7969 (1.8660)  Acc@1: 56.2500 (56.4600)  Acc@5: 81.2500 (84.1300)
Test (EMA): [Whole Val]  Time: 9.736  Loss: 1.8660  Acc@1: 56.4600 Pruned: 61.09% 
Train: 10 [   0/390 (  0%)]  Loss: 3.589 (3.59)  Time: 0.839s,  152.49/s  (0.839s,  152.49/s)  LR: 9.755e-04  Data: 0.536 (0.536)
Train: 10 [ 100/390 ( 26%)]  Loss: 3.824 (3.75)  Time: 0.313s,  409.17/s  (0.324s,  395.24/s)  LR: 9.755e-04  Data: 0.011 (0.018)
Train: 10 [ 200/390 ( 51%)]  Loss: 4.018 (3.78)  Time: 0.314s,  407.54/s  (0.320s,  400.49/s)  LR: 9.755e-04  Data: 0.012 (0.015)
Train: 10 [ 300/390 ( 77%)]  Loss: 3.258 (3.81)  Time: 0.314s,  407.87/s  (0.318s,  402.29/s)  LR: 9.755e-04  Data: 0.012 (0.014)
Train: 10 [ 389/390 (100%)]  Loss: 3.974 (3.81)  Time: 0.302s,  424.38/s  (0.317s,  403.15/s)  LR: 9.755e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.319 (0.319)  Loss:  1.8115 (1.8115)  Acc@1: 57.8125 (57.8125)  Acc@5: 87.5000 (87.5000)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.7578 (1.8996)  Acc@1: 62.5000 (54.8200)  Acc@5: 75.0000 (83.0900)
Test: [Whole Val]  Time: 9.614  Loss: 1.8996  Acc@1: 54.8200 Pruned: 60.18% 
Test (EMA): [   0/78]  Time: 0.437 (0.437)  Loss:  1.7891 (1.7891)  Acc@1: 56.2500 (56.2500)  Acc@5: 85.9375 (85.9375)
Test (EMA): [  78/78]  Time: 0.017 (0.124)  Loss:  1.6816 (1.8722)  Acc@1: 62.5000 (56.1100)  Acc@5: 87.5000 (83.6800)
Test (EMA): [Whole Val]  Time: 9.763  Loss: 1.8722  Acc@1: 56.1100 Pruned: 60.21% 
Train: 11 [   0/390 (  0%)]  Loss: 4.134 (4.13)  Time: 0.712s,  179.87/s  (0.712s,  179.87/s)  LR: 9.704e-04  Data: 0.407 (0.407)
Train: 11 [ 100/390 ( 26%)]  Loss: 3.439 (3.75)  Time: 0.314s,  407.91/s  (0.321s,  398.27/s)  LR: 9.704e-04  Data: 0.012 (0.017)
Train: 11 [ 200/390 ( 51%)]  Loss: 3.729 (3.79)  Time: 0.313s,  408.45/s  (0.319s,  401.64/s)  LR: 9.704e-04  Data: 0.012 (0.015)
Train: 11 [ 300/390 ( 77%)]  Loss: 3.625 (3.79)  Time: 0.316s,  404.97/s  (0.318s,  402.86/s)  LR: 9.704e-04  Data: 0.012 (0.014)
Train: 11 [ 389/390 (100%)]  Loss: 3.564 (3.80)  Time: 0.302s,  424.39/s  (0.317s,  403.52/s)  LR: 9.704e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.355 (0.355)  Loss:  1.8828 (1.8828)  Acc@1: 56.2500 (56.2500)  Acc@5: 82.8125 (82.8125)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  1.8281 (1.9577)  Acc@1: 62.5000 (54.4200)  Acc@5: 87.5000 (83.0900)
Test: [Whole Val]  Time: 9.658  Loss: 1.9577  Acc@1: 54.4200 Pruned: 59.51% 
Test (EMA): [   0/78]  Time: 0.365 (0.365)  Loss:  1.8115 (1.8115)  Acc@1: 60.9375 (60.9375)  Acc@5: 83.5938 (83.5938)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  1.7129 (1.8816)  Acc@1: 62.5000 (56.5900)  Acc@5: 87.5000 (84.3800)
Test (EMA): [Whole Val]  Time: 9.628  Loss: 1.8816  Acc@1: 56.5900 Pruned: 59.54% 
Train: 12 [   0/390 (  0%)]  Loss: 4.025 (4.03)  Time: 0.846s,  151.29/s  (0.846s,  151.29/s)  LR: 9.649e-04  Data: 0.538 (0.538)
Train: 12 [ 100/390 ( 26%)]  Loss: 4.073 (3.80)  Time: 0.313s,  409.12/s  (0.321s,  398.92/s)  LR: 9.649e-04  Data: 0.011 (0.018)
Train: 12 [ 200/390 ( 51%)]  Loss: 4.132 (3.78)  Time: 0.328s,  390.74/s  (0.319s,  401.36/s)  LR: 9.649e-04  Data: 0.012 (0.015)
Train: 12 [ 300/390 ( 77%)]  Loss: 3.826 (3.79)  Time: 0.314s,  407.55/s  (0.318s,  402.91/s)  LR: 9.649e-04  Data: 0.012 (0.014)
Train: 12 [ 389/390 (100%)]  Loss: 4.016 (3.79)  Time: 0.302s,  423.64/s  (0.317s,  403.49/s)  LR: 9.649e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.382 (0.382)  Loss:  1.8594 (1.8594)  Acc@1: 57.0312 (57.0312)  Acc@5: 85.1562 (85.1562)
Test: [  78/78]  Time: 0.025 (0.123)  Loss:  1.6973 (1.9674)  Acc@1: 68.7500 (55.1100)  Acc@5: 87.5000 (83.6800)
Test: [Whole Val]  Time: 9.752  Loss: 1.9674  Acc@1: 55.1100 Pruned: 58.95% 
Test (EMA): [   0/78]  Time: 0.408 (0.408)  Loss:  1.7852 (1.7852)  Acc@1: 59.3750 (59.3750)  Acc@5: 88.2812 (88.2812)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  1.6084 (1.8880)  Acc@1: 68.7500 (56.8200)  Acc@5: 87.5000 (84.6300)
Test (EMA): [Whole Val]  Time: 9.717  Loss: 1.8880  Acc@1: 56.8200 Pruned: 58.99% 
Train: 13 [   0/390 (  0%)]  Loss: 3.739 (3.74)  Time: 0.802s,  159.61/s  (0.802s,  159.61/s)  LR: 9.589e-04  Data: 0.498 (0.498)
Train: 13 [ 100/390 ( 26%)]  Loss: 3.335 (3.77)  Time: 0.314s,  408.11/s  (0.321s,  399.20/s)  LR: 9.589e-04  Data: 0.012 (0.017)
Train: 13 [ 200/390 ( 51%)]  Loss: 4.070 (3.77)  Time: 0.313s,  409.60/s  (0.318s,  402.18/s)  LR: 9.589e-04  Data: 0.011 (0.015)
Train: 13 [ 300/390 ( 77%)]  Loss: 3.645 (3.77)  Time: 0.315s,  406.39/s  (0.317s,  403.36/s)  LR: 9.589e-04  Data: 0.012 (0.014)
Train: 13 [ 389/390 (100%)]  Loss: 3.727 (3.75)  Time: 0.302s,  423.96/s  (0.317s,  404.04/s)  LR: 9.589e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.416 (0.416)  Loss:  1.6953 (1.6953)  Acc@1: 61.7188 (61.7188)  Acc@5: 87.5000 (87.5000)
Test: [  78/78]  Time: 0.017 (0.123)  Loss:  1.6055 (1.8382)  Acc@1: 68.7500 (56.5500)  Acc@5: 87.5000 (83.8500)
Test: [Whole Val]  Time: 9.682  Loss: 1.8382  Acc@1: 56.5500 Pruned: 58.50% 
Test (EMA): [   0/78]  Time: 0.320 (0.320)  Loss:  1.6768 (1.6768)  Acc@1: 65.6250 (65.6250)  Acc@5: 87.5000 (87.5000)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  1.5840 (1.7862)  Acc@1: 68.7500 (57.8000)  Acc@5: 87.5000 (85.0400)
Test (EMA): [Whole Val]  Time: 9.624  Loss: 1.7862  Acc@1: 57.8000 Pruned: 58.50% 
Train: 14 [   0/390 (  0%)]  Loss: 3.711 (3.71)  Time: 0.852s,  150.20/s  (0.852s,  150.20/s)  LR: 9.524e-04  Data: 0.537 (0.537)
Train: 14 [ 100/390 ( 26%)]  Loss: 3.180 (3.81)  Time: 0.318s,  402.98/s  (0.321s,  398.64/s)  LR: 9.524e-04  Data: 0.014 (0.018)
Train: 14 [ 200/390 ( 51%)]  Loss: 3.285 (3.80)  Time: 0.314s,  407.77/s  (0.318s,  402.19/s)  LR: 9.524e-04  Data: 0.011 (0.015)
Train: 14 [ 300/390 ( 77%)]  Loss: 4.214 (3.78)  Time: 0.314s,  407.49/s  (0.317s,  403.48/s)  LR: 9.524e-04  Data: 0.012 (0.014)
Train: 14 [ 389/390 (100%)]  Loss: 4.004 (3.77)  Time: 0.303s,  421.78/s  (0.317s,  404.24/s)  LR: 9.524e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.425 (0.425)  Loss:  1.7256 (1.7256)  Acc@1: 54.6875 (54.6875)  Acc@5: 85.9375 (85.9375)
Test: [  78/78]  Time: 0.017 (0.123)  Loss:  1.6191 (1.8141)  Acc@1: 62.5000 (56.2000)  Acc@5: 81.2500 (84.2800)
Test: [Whole Val]  Time: 9.738  Loss: 1.8141  Acc@1: 56.2000 Pruned: 58.21% 
Test (EMA): [   0/78]  Time: 0.379 (0.379)  Loss:  1.7129 (1.7129)  Acc@1: 59.3750 (59.3750)  Acc@5: 87.5000 (87.5000)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  1.5703 (1.8007)  Acc@1: 68.7500 (57.4300)  Acc@5: 87.5000 (84.8000)
Test (EMA): [Whole Val]  Time: 9.665  Loss: 1.8007  Acc@1: 57.4300 Pruned: 58.19% 
Train: 15 [   0/390 (  0%)]  Loss: 4.003 (4.00)  Time: 0.835s,  153.24/s  (0.835s,  153.24/s)  LR: 9.455e-04  Data: 0.526 (0.526)
Train: 15 [ 100/390 ( 26%)]  Loss: 3.299 (3.76)  Time: 0.315s,  405.79/s  (0.320s,  399.43/s)  LR: 9.455e-04  Data: 0.012 (0.017)
Train: 15 [ 200/390 ( 51%)]  Loss: 3.705 (3.75)  Time: 0.313s,  408.32/s  (0.318s,  402.69/s)  LR: 9.455e-04  Data: 0.012 (0.015)
Train: 15 [ 300/390 ( 77%)]  Loss: 4.089 (3.74)  Time: 0.314s,  407.72/s  (0.317s,  403.35/s)  LR: 9.455e-04  Data: 0.011 (0.014)
Train: 15 [ 389/390 (100%)]  Loss: 4.034 (3.73)  Time: 0.304s,  421.70/s  (0.317s,  404.01/s)  LR: 9.455e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.422 (0.422)  Loss:  1.8086 (1.8086)  Acc@1: 57.0312 (57.0312)  Acc@5: 82.8125 (82.8125)
Test: [  78/78]  Time: 0.017 (0.123)  Loss:  1.6699 (1.8749)  Acc@1: 68.7500 (56.1200)  Acc@5: 81.2500 (83.9800)
Test: [Whole Val]  Time: 9.731  Loss: 1.8749  Acc@1: 56.1200 Pruned: 57.81% 
Test (EMA): [   0/78]  Time: 0.436 (0.436)  Loss:  1.7383 (1.7383)  Acc@1: 56.2500 (56.2500)  Acc@5: 83.5938 (83.5938)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  1.5957 (1.7869)  Acc@1: 68.7500 (58.3600)  Acc@5: 87.5000 (85.2600)
Test (EMA): [Whole Val]  Time: 9.748  Loss: 1.7869  Acc@1: 58.3600 Pruned: 57.86% 
Train: 16 [   0/390 (  0%)]  Loss: 4.076 (4.08)  Time: 0.874s,  146.45/s  (0.874s,  146.45/s)  LR: 9.382e-04  Data: 0.551 (0.551)
Train: 16 [ 100/390 ( 26%)]  Loss: 3.492 (3.76)  Time: 0.316s,  404.55/s  (0.322s,  397.64/s)  LR: 9.382e-04  Data: 0.012 (0.018)
Train: 16 [ 200/390 ( 51%)]  Loss: 4.123 (3.75)  Time: 0.314s,  408.03/s  (0.319s,  401.50/s)  LR: 9.382e-04  Data: 0.012 (0.015)
Train: 16 [ 300/390 ( 77%)]  Loss: 3.895 (3.77)  Time: 0.315s,  406.71/s  (0.318s,  403.06/s)  LR: 9.382e-04  Data: 0.012 (0.014)
Train: 16 [ 389/390 (100%)]  Loss: 3.426 (3.78)  Time: 0.303s,  421.81/s  (0.317s,  403.65/s)  LR: 9.382e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.423 (0.423)  Loss:  1.7695 (1.7695)  Acc@1: 56.2500 (56.2500)  Acc@5: 87.5000 (87.5000)
Test: [  78/78]  Time: 0.017 (0.123)  Loss:  1.6885 (1.8637)  Acc@1: 68.7500 (56.9100)  Acc@5: 81.2500 (84.8200)
Test: [Whole Val]  Time: 9.725  Loss: 1.8637  Acc@1: 56.9100 Pruned: 57.55% 
Test (EMA): [   0/78]  Time: 0.348 (0.348)  Loss:  1.7422 (1.7422)  Acc@1: 59.3750 (59.3750)  Acc@5: 85.9375 (85.9375)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  1.6123 (1.8271)  Acc@1: 68.7500 (57.8400)  Acc@5: 87.5000 (85.3500)
Test (EMA): [Whole Val]  Time: 9.666  Loss: 1.8271  Acc@1: 57.8400 Pruned: 57.58% 
Train: 17 [   0/390 (  0%)]  Loss: 3.942 (3.94)  Time: 0.827s,  154.86/s  (0.827s,  154.86/s)  LR: 9.304e-04  Data: 0.524 (0.524)
Train: 17 [ 100/390 ( 26%)]  Loss: 3.675 (3.73)  Time: 0.319s,  401.79/s  (0.321s,  398.99/s)  LR: 9.304e-04  Data: 0.012 (0.018)
Train: 17 [ 200/390 ( 51%)]  Loss: 4.134 (3.73)  Time: 0.314s,  408.00/s  (0.318s,  402.58/s)  LR: 9.304e-04  Data: 0.012 (0.015)
Train: 17 [ 300/390 ( 77%)]  Loss: 4.185 (3.75)  Time: 0.317s,  403.74/s  (0.317s,  403.75/s)  LR: 9.304e-04  Data: 0.015 (0.014)
Train: 17 [ 389/390 (100%)]  Loss: 3.473 (3.75)  Time: 0.302s,  423.64/s  (0.317s,  404.36/s)  LR: 9.304e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.410 (0.410)  Loss:  1.7842 (1.7842)  Acc@1: 57.0312 (57.0312)  Acc@5: 85.1562 (85.1562)
Test: [  78/78]  Time: 0.017 (0.123)  Loss:  1.8008 (1.8671)  Acc@1: 62.5000 (56.6200)  Acc@5: 81.2500 (83.8800)
Test: [Whole Val]  Time: 9.721  Loss: 1.8671  Acc@1: 56.6200 Pruned: 57.29% 
Test (EMA): [   0/78]  Time: 0.353 (0.353)  Loss:  1.7041 (1.7041)  Acc@1: 56.2500 (56.2500)  Acc@5: 87.5000 (87.5000)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  1.6914 (1.7946)  Acc@1: 62.5000 (58.4700)  Acc@5: 87.5000 (85.6800)
Test (EMA): [Whole Val]  Time: 9.643  Loss: 1.7946  Acc@1: 58.4700 Pruned: 57.30% 
Train: 18 [   0/390 (  0%)]  Loss: 3.777 (3.78)  Time: 0.884s,  144.85/s  (0.884s,  144.85/s)  LR: 9.222e-04  Data: 0.571 (0.571)
Train: 18 [ 100/390 ( 26%)]  Loss: 3.732 (3.73)  Time: 0.317s,  404.02/s  (0.321s,  398.38/s)  LR: 9.222e-04  Data: 0.012 (0.018)
Train: 18 [ 200/390 ( 51%)]  Loss: 3.767 (3.73)  Time: 0.315s,  405.87/s  (0.319s,  401.68/s)  LR: 9.222e-04  Data: 0.012 (0.015)
Train: 18 [ 300/390 ( 77%)]  Loss: 3.639 (3.72)  Time: 0.315s,  406.76/s  (0.317s,  403.30/s)  LR: 9.222e-04  Data: 0.012 (0.014)
Train: 18 [ 389/390 (100%)]  Loss: 3.842 (3.72)  Time: 0.304s,  421.39/s  (0.317s,  403.56/s)  LR: 9.222e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.313 (0.313)  Loss:  1.7031 (1.7031)  Acc@1: 58.5938 (58.5938)  Acc@5: 86.7188 (86.7188)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.6035 (1.7946)  Acc@1: 68.7500 (57.8100)  Acc@5: 81.2500 (85.4200)
Test: [Whole Val]  Time: 9.640  Loss: 1.7946  Acc@1: 57.8100 Pruned: 57.09% 
Test (EMA): [   0/78]  Time: 0.439 (0.439)  Loss:  1.6973 (1.6973)  Acc@1: 58.5938 (58.5938)  Acc@5: 88.2812 (88.2812)
Test (EMA): [  78/78]  Time: 0.018 (0.124)  Loss:  1.6016 (1.7771)  Acc@1: 68.7500 (58.8500)  Acc@5: 81.2500 (85.8900)
Test (EMA): [Whole Val]  Time: 9.760  Loss: 1.7771  Acc@1: 58.8500 Pruned: 57.09% 
Train: 19 [   0/390 (  0%)]  Loss: 3.410 (3.41)  Time: 0.906s,  141.34/s  (0.906s,  141.34/s)  LR: 9.135e-04  Data: 0.584 (0.584)
Train: 19 [ 100/390 ( 26%)]  Loss: 3.430 (3.74)  Time: 0.328s,  390.20/s  (0.321s,  398.19/s)  LR: 9.135e-04  Data: 0.014 (0.018)
Train: 19 [ 200/390 ( 51%)]  Loss: 3.469 (3.74)  Time: 0.316s,  404.90/s  (0.318s,  402.17/s)  LR: 9.135e-04  Data: 0.013 (0.015)
Train: 19 [ 300/390 ( 77%)]  Loss: 3.571 (3.75)  Time: 0.315s,  406.19/s  (0.317s,  403.37/s)  LR: 9.135e-04  Data: 0.012 (0.014)
Train: 19 [ 389/390 (100%)]  Loss: 3.976 (3.75)  Time: 0.302s,  423.37/s  (0.317s,  404.04/s)  LR: 9.135e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.400 (0.400)  Loss:  1.7646 (1.7646)  Acc@1: 59.3750 (59.3750)  Acc@5: 87.5000 (87.5000)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  1.6299 (1.8464)  Acc@1: 68.7500 (58.1400)  Acc@5: 75.0000 (85.4700)
Test: [Whole Val]  Time: 9.704  Loss: 1.8464  Acc@1: 58.1400 Pruned: 56.87% 
Test (EMA): [   0/78]  Time: 0.426 (0.426)  Loss:  1.6963 (1.6963)  Acc@1: 59.3750 (59.3750)  Acc@5: 87.5000 (87.5000)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  1.5225 (1.7645)  Acc@1: 68.7500 (59.2300)  Acc@5: 87.5000 (86.1500)
Test (EMA): [Whole Val]  Time: 9.719  Loss: 1.7645  Acc@1: 59.2300 Pruned: 56.86% 
Train: 20 [   0/390 (  0%)]  Loss: 4.057 (4.06)  Time: 0.823s,  155.47/s  (0.823s,  155.47/s)  LR: 9.045e-04  Data: 0.521 (0.521)
Train: 20 [ 100/390 ( 26%)]  Loss: 3.201 (3.75)  Time: 0.318s,  403.02/s  (0.322s,  397.23/s)  LR: 9.045e-04  Data: 0.015 (0.018)
Train: 20 [ 200/390 ( 51%)]  Loss: 3.231 (3.75)  Time: 0.318s,  402.46/s  (0.319s,  401.56/s)  LR: 9.045e-04  Data: 0.014 (0.015)
Train: 20 [ 300/390 ( 77%)]  Loss: 3.413 (3.74)  Time: 0.314s,  407.15/s  (0.318s,  403.00/s)  LR: 9.045e-04  Data: 0.012 (0.014)
Train: 20 [ 389/390 (100%)]  Loss: 3.515 (3.73)  Time: 0.303s,  423.02/s  (0.317s,  403.68/s)  LR: 9.045e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.430 (0.430)  Loss:  1.6953 (1.6953)  Acc@1: 59.3750 (59.3750)  Acc@5: 86.7188 (86.7188)
Test: [  78/78]  Time: 0.017 (0.123)  Loss:  1.5391 (1.7822)  Acc@1: 68.7500 (57.2500)  Acc@5: 87.5000 (84.8700)
Test: [Whole Val]  Time: 9.700  Loss: 1.7822  Acc@1: 57.2500 Pruned: 56.73% 
Test (EMA): [   0/78]  Time: 0.432 (0.432)  Loss:  1.6377 (1.6377)  Acc@1: 63.2812 (63.2812)  Acc@5: 88.2812 (88.2812)
Test (EMA): [  78/78]  Time: 0.017 (0.124)  Loss:  1.5918 (1.7431)  Acc@1: 68.7500 (58.7700)  Acc@5: 87.5000 (85.7900)
Test (EMA): [Whole Val]  Time: 9.770  Loss: 1.7431  Acc@1: 58.7700 Pruned: 56.77% 
Train: 21 [   0/390 (  0%)]  Loss: 4.086 (4.09)  Time: 0.831s,  154.05/s  (0.831s,  154.05/s)  LR: 8.951e-04  Data: 0.526 (0.526)
Train: 21 [ 100/390 ( 26%)]  Loss: 4.094 (3.72)  Time: 0.315s,  405.71/s  (0.321s,  398.25/s)  LR: 8.951e-04  Data: 0.012 (0.018)
Train: 21 [ 200/390 ( 51%)]  Loss: 3.819 (3.71)  Time: 0.315s,  405.88/s  (0.319s,  401.88/s)  LR: 8.951e-04  Data: 0.012 (0.015)
Train: 21 [ 300/390 ( 77%)]  Loss: 3.976 (3.71)  Time: 0.314s,  408.02/s  (0.318s,  403.10/s)  LR: 8.951e-04  Data: 0.011 (0.014)
Train: 21 [ 389/390 (100%)]  Loss: 3.763 (3.71)  Time: 0.302s,  423.69/s  (0.317s,  403.67/s)  LR: 8.951e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.302 (0.302)  Loss:  1.6514 (1.6514)  Acc@1: 62.5000 (62.5000)  Acc@5: 87.5000 (87.5000)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.6230 (1.7789)  Acc@1: 62.5000 (58.4200)  Acc@5: 87.5000 (85.7400)
Test: [Whole Val]  Time: 9.646  Loss: 1.7789  Acc@1: 58.4200 Pruned: 56.59% 
Test (EMA): [   0/78]  Time: 0.406 (0.406)  Loss:  1.6475 (1.6475)  Acc@1: 64.0625 (64.0625)  Acc@5: 85.1562 (85.1562)
Test (EMA): [  78/78]  Time: 0.018 (0.124)  Loss:  1.5850 (1.7620)  Acc@1: 68.7500 (59.3100)  Acc@5: 81.2500 (86.1600)
Test (EMA): [Whole Val]  Time: 9.757  Loss: 1.7620  Acc@1: 59.3100 Pruned: 56.57% 
Train: 22 [   0/390 (  0%)]  Loss: 3.803 (3.80)  Time: 0.808s,  158.34/s  (0.808s,  158.34/s)  LR: 8.853e-04  Data: 0.490 (0.490)
Train: 22 [ 100/390 ( 26%)]  Loss: 3.129 (3.72)  Time: 0.319s,  401.87/s  (0.323s,  396.59/s)  LR: 8.853e-04  Data: 0.016 (0.017)
Train: 22 [ 200/390 ( 51%)]  Loss: 2.865 (3.71)  Time: 0.314s,  407.58/s  (0.319s,  400.93/s)  LR: 8.853e-04  Data: 0.011 (0.015)
Train: 22 [ 300/390 ( 77%)]  Loss: 3.404 (3.71)  Time: 0.320s,  400.14/s  (0.318s,  402.34/s)  LR: 8.853e-04  Data: 0.011 (0.014)
Train: 22 [ 389/390 (100%)]  Loss: 3.906 (3.71)  Time: 0.302s,  423.31/s  (0.317s,  403.23/s)  LR: 8.853e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.406 (0.406)  Loss:  1.7412 (1.7412)  Acc@1: 58.5938 (58.5938)  Acc@5: 85.1562 (85.1562)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  1.6914 (1.8200)  Acc@1: 62.5000 (56.7000)  Acc@5: 81.2500 (84.5400)
Test: [Whole Val]  Time: 9.743  Loss: 1.8200  Acc@1: 56.7000 Pruned: 56.40% 
Test (EMA): [   0/78]  Time: 0.376 (0.376)  Loss:  1.6719 (1.6719)  Acc@1: 59.3750 (59.3750)  Acc@5: 86.7188 (86.7188)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  1.6172 (1.7422)  Acc@1: 62.5000 (58.8500)  Acc@5: 81.2500 (86.2000)
Test (EMA): [Whole Val]  Time: 9.699  Loss: 1.7422  Acc@1: 58.8500 Pruned: 56.40% 
Train: 23 [   0/390 (  0%)]  Loss: 4.133 (4.13)  Time: 0.840s,  152.43/s  (0.840s,  152.43/s)  LR: 8.751e-04  Data: 0.537 (0.537)
Train: 23 [ 100/390 ( 26%)]  Loss: 4.157 (3.68)  Time: 0.313s,  408.39/s  (0.321s,  398.46/s)  LR: 8.751e-04  Data: 0.012 (0.018)
Train: 23 [ 200/390 ( 51%)]  Loss: 4.070 (3.71)  Time: 0.321s,  398.98/s  (0.319s,  401.87/s)  LR: 8.751e-04  Data: 0.012 (0.015)
Train: 23 [ 300/390 ( 77%)]  Loss: 3.869 (3.71)  Time: 0.315s,  406.09/s  (0.317s,  403.44/s)  LR: 8.751e-04  Data: 0.012 (0.014)
Train: 23 [ 389/390 (100%)]  Loss: 3.167 (3.71)  Time: 0.303s,  422.88/s  (0.317s,  403.94/s)  LR: 8.751e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.327 (0.327)  Loss:  1.6465 (1.6465)  Acc@1: 61.7188 (61.7188)  Acc@5: 89.0625 (89.0625)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  1.6162 (1.7371)  Acc@1: 62.5000 (59.3300)  Acc@5: 87.5000 (85.9600)
Test: [Whole Val]  Time: 9.663  Loss: 1.7371  Acc@1: 59.3300 Pruned: 56.29% 
Test (EMA): [   0/78]  Time: 0.352 (0.352)  Loss:  1.6514 (1.6514)  Acc@1: 60.9375 (60.9375)  Acc@5: 88.2812 (88.2812)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  1.6113 (1.7356)  Acc@1: 62.5000 (59.6800)  Acc@5: 87.5000 (86.3400)
Test (EMA): [Whole Val]  Time: 9.649  Loss: 1.7356  Acc@1: 59.6800 Pruned: 56.29% 
Train: 24 [   0/390 (  0%)]  Loss: 3.056 (3.06)  Time: 0.768s,  166.74/s  (0.768s,  166.74/s)  LR: 8.645e-04  Data: 0.458 (0.458)
Train: 24 [ 100/390 ( 26%)]  Loss: 3.422 (3.69)  Time: 0.315s,  406.74/s  (0.321s,  399.22/s)  LR: 8.645e-04  Data: 0.012 (0.017)
Train: 24 [ 200/390 ( 51%)]  Loss: 3.461 (3.70)  Time: 0.314s,  407.30/s  (0.318s,  402.24/s)  LR: 8.645e-04  Data: 0.012 (0.015)
Train: 24 [ 300/390 ( 77%)]  Loss: 3.831 (3.69)  Time: 0.314s,  407.10/s  (0.317s,  403.30/s)  LR: 8.645e-04  Data: 0.013 (0.014)
Train: 24 [ 389/390 (100%)]  Loss: 3.993 (3.70)  Time: 0.303s,  422.36/s  (0.317s,  404.01/s)  LR: 8.645e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.421 (0.421)  Loss:  1.5684 (1.5684)  Acc@1: 64.0625 (64.0625)  Acc@5: 88.2812 (88.2812)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  1.5898 (1.7187)  Acc@1: 56.2500 (59.0300)  Acc@5: 87.5000 (85.8900)
Test: [Whole Val]  Time: 9.725  Loss: 1.7187  Acc@1: 59.0300 Pruned: 56.12% 
Test (EMA): [   0/78]  Time: 0.329 (0.329)  Loss:  1.5654 (1.5654)  Acc@1: 64.0625 (64.0625)  Acc@5: 89.0625 (89.0625)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  1.5469 (1.7012)  Acc@1: 62.5000 (60.1400)  Acc@5: 87.5000 (86.5800)
Test (EMA): [Whole Val]  Time: 9.609  Loss: 1.7012  Acc@1: 60.1400 Pruned: 56.16% 
Train: 25 [   0/390 (  0%)]  Loss: 3.996 (4.00)  Time: 0.897s,  142.73/s  (0.897s,  142.73/s)  LR: 8.536e-04  Data: 0.594 (0.594)
Train: 25 [ 100/390 ( 26%)]  Loss: 3.620 (3.68)  Time: 0.315s,  406.71/s  (0.322s,  397.44/s)  LR: 8.536e-04  Data: 0.012 (0.019)
Train: 25 [ 200/390 ( 51%)]  Loss: 4.267 (3.66)  Time: 0.315s,  406.43/s  (0.320s,  400.58/s)  LR: 8.536e-04  Data: 0.013 (0.016)
Train: 25 [ 300/390 ( 77%)]  Loss: 4.027 (3.69)  Time: 0.313s,  408.42/s  (0.318s,  402.16/s)  LR: 8.536e-04  Data: 0.012 (0.015)
Train: 25 [ 389/390 (100%)]  Loss: 4.064 (3.71)  Time: 0.303s,  422.43/s  (0.318s,  403.00/s)  LR: 8.536e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.418 (0.418)  Loss:  1.6914 (1.6914)  Acc@1: 62.5000 (62.5000)  Acc@5: 88.2812 (88.2812)
Test: [  78/78]  Time: 0.017 (0.123)  Loss:  1.4873 (1.7881)  Acc@1: 68.7500 (58.4900)  Acc@5: 87.5000 (85.7700)
Test: [Whole Val]  Time: 9.697  Loss: 1.7881  Acc@1: 58.4900 Pruned: 55.93% 
Test (EMA): [   0/78]  Time: 0.387 (0.387)  Loss:  1.6592 (1.6592)  Acc@1: 61.7188 (61.7188)  Acc@5: 85.9375 (85.9375)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  1.4688 (1.7525)  Acc@1: 68.7500 (59.8000)  Acc@5: 87.5000 (86.4700)
Test (EMA): [Whole Val]  Time: 9.709  Loss: 1.7525  Acc@1: 59.8000 Pruned: 55.95% 
Train: 26 [   0/390 (  0%)]  Loss: 4.090 (4.09)  Time: 0.756s,  169.42/s  (0.756s,  169.42/s)  LR: 8.423e-04  Data: 0.452 (0.452)
Train: 26 [ 100/390 ( 26%)]  Loss: 4.205 (3.74)  Time: 0.315s,  406.87/s  (0.321s,  399.08/s)  LR: 8.423e-04  Data: 0.012 (0.017)
Train: 26 [ 200/390 ( 51%)]  Loss: 3.689 (3.74)  Time: 0.313s,  409.43/s  (0.318s,  402.73/s)  LR: 8.423e-04  Data: 0.012 (0.015)
Train: 26 [ 300/390 ( 77%)]  Loss: 3.983 (3.72)  Time: 0.317s,  403.57/s  (0.317s,  403.18/s)  LR: 8.423e-04  Data: 0.015 (0.014)
Train: 26 [ 389/390 (100%)]  Loss: 3.179 (3.71)  Time: 0.303s,  422.70/s  (0.317s,  404.01/s)  LR: 8.423e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.315 (0.315)  Loss:  1.6416 (1.6416)  Acc@1: 60.1562 (60.1562)  Acc@5: 88.2812 (88.2812)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.5322 (1.7203)  Acc@1: 68.7500 (58.2400)  Acc@5: 81.2500 (85.6200)
Test: [Whole Val]  Time: 9.617  Loss: 1.7203  Acc@1: 58.2400 Pruned: 55.80% 
Test (EMA): [   0/78]  Time: 0.327 (0.327)  Loss:  1.6143 (1.6143)  Acc@1: 59.3750 (59.3750)  Acc@5: 88.2812 (88.2812)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  1.5312 (1.6853)  Acc@1: 68.7500 (60.2200)  Acc@5: 87.5000 (86.4000)
Test (EMA): [Whole Val]  Time: 9.617  Loss: 1.6853  Acc@1: 60.2200 Pruned: 55.81% 
Train: 27 [   0/390 (  0%)]  Loss: 3.970 (3.97)  Time: 0.887s,  144.36/s  (0.887s,  144.36/s)  LR: 8.307e-04  Data: 0.584 (0.584)
Train: 27 [ 100/390 ( 26%)]  Loss: 3.381 (3.62)  Time: 0.317s,  403.65/s  (0.321s,  398.15/s)  LR: 8.307e-04  Data: 0.013 (0.018)
Train: 27 [ 200/390 ( 51%)]  Loss: 3.257 (3.68)  Time: 0.316s,  405.31/s  (0.319s,  401.88/s)  LR: 8.307e-04  Data: 0.013 (0.015)
Train: 27 [ 300/390 ( 77%)]  Loss: 3.963 (3.70)  Time: 0.315s,  406.99/s  (0.317s,  403.31/s)  LR: 8.307e-04  Data: 0.012 (0.014)
Train: 27 [ 389/390 (100%)]  Loss: 3.094 (3.70)  Time: 0.302s,  423.74/s  (0.317s,  403.83/s)  LR: 8.307e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.427 (0.427)  Loss:  1.6514 (1.6514)  Acc@1: 61.7188 (61.7188)  Acc@5: 88.2812 (88.2812)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  1.6172 (1.7426)  Acc@1: 62.5000 (59.3200)  Acc@5: 87.5000 (86.0700)
Test: [Whole Val]  Time: 9.696  Loss: 1.7426  Acc@1: 59.3200 Pruned: 55.70% 
Test (EMA): [   0/78]  Time: 0.374 (0.374)  Loss:  1.6562 (1.6562)  Acc@1: 60.9375 (60.9375)  Acc@5: 87.5000 (87.5000)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  1.5859 (1.7451)  Acc@1: 62.5000 (59.9800)  Acc@5: 87.5000 (86.5300)
Test (EMA): [Whole Val]  Time: 9.671  Loss: 1.7451  Acc@1: 59.9800 Pruned: 55.71% 
Train: 28 [   0/390 (  0%)]  Loss: 3.528 (3.53)  Time: 0.897s,  142.77/s  (0.897s,  142.77/s)  LR: 8.187e-04  Data: 0.592 (0.592)
Train: 28 [ 100/390 ( 26%)]  Loss: 4.174 (3.72)  Time: 0.315s,  406.30/s  (0.321s,  398.69/s)  LR: 8.187e-04  Data: 0.012 (0.018)
Train: 28 [ 200/390 ( 51%)]  Loss: 2.955 (3.69)  Time: 0.315s,  406.08/s  (0.319s,  401.87/s)  LR: 8.187e-04  Data: 0.011 (0.015)
Train: 28 [ 300/390 ( 77%)]  Loss: 3.836 (3.68)  Time: 0.313s,  408.34/s  (0.318s,  402.67/s)  LR: 8.187e-04  Data: 0.011 (0.014)
Train: 28 [ 389/390 (100%)]  Loss: 2.829 (3.70)  Time: 0.305s,  420.33/s  (0.317s,  403.46/s)  LR: 8.187e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.349 (0.349)  Loss:  1.6318 (1.6318)  Acc@1: 62.5000 (62.5000)  Acc@5: 89.0625 (89.0625)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  1.5234 (1.7060)  Acc@1: 68.7500 (60.2600)  Acc@5: 81.2500 (87.1100)
Test: [Whole Val]  Time: 9.642  Loss: 1.7060  Acc@1: 60.2600 Pruned: 55.62% 
Test (EMA): [   0/78]  Time: 0.317 (0.317)  Loss:  1.5986 (1.5986)  Acc@1: 63.2812 (63.2812)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  1.5254 (1.6830)  Acc@1: 68.7500 (60.8600)  Acc@5: 81.2500 (87.1200)
Test (EMA): [Whole Val]  Time: 9.599  Loss: 1.6830  Acc@1: 60.8600 Pruned: 55.62% 
Train: 29 [   0/390 (  0%)]  Loss: 3.925 (3.92)  Time: 0.771s,  166.05/s  (0.771s,  166.05/s)  LR: 8.065e-04  Data: 0.462 (0.462)
Train: 29 [ 100/390 ( 26%)]  Loss: 2.790 (3.76)  Time: 0.314s,  407.03/s  (0.321s,  398.80/s)  LR: 8.065e-04  Data: 0.012 (0.017)
Train: 29 [ 200/390 ( 51%)]  Loss: 3.725 (3.73)  Time: 0.315s,  406.68/s  (0.319s,  401.74/s)  LR: 8.065e-04  Data: 0.012 (0.015)
Train: 29 [ 300/390 ( 77%)]  Loss: 3.093 (3.70)  Time: 0.317s,  404.00/s  (0.317s,  403.22/s)  LR: 8.065e-04  Data: 0.012 (0.014)
Train: 29 [ 389/390 (100%)]  Loss: 2.960 (3.70)  Time: 0.302s,  424.50/s  (0.317s,  403.67/s)  LR: 8.065e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.412 (0.412)  Loss:  1.6250 (1.6250)  Acc@1: 61.7188 (61.7188)  Acc@5: 88.2812 (88.2812)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  1.5459 (1.7102)  Acc@1: 62.5000 (60.1300)  Acc@5: 81.2500 (86.6800)
Test: [Whole Val]  Time: 9.692  Loss: 1.7102  Acc@1: 60.1300 Pruned: 55.49% 
Test (EMA): [   0/78]  Time: 0.370 (0.370)  Loss:  1.5820 (1.5820)  Acc@1: 61.7188 (61.7188)  Acc@5: 88.2812 (88.2812)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  1.5127 (1.6852)  Acc@1: 62.5000 (60.5700)  Acc@5: 87.5000 (87.0700)
Test (EMA): [Whole Val]  Time: 9.649  Loss: 1.6852  Acc@1: 60.5700 Pruned: 55.50% 
Train: 30 [   0/390 (  0%)]  Loss: 4.009 (4.01)  Time: 0.895s,  143.07/s  (0.895s,  143.07/s)  LR: 7.939e-04  Data: 0.583 (0.583)
Train: 30 [ 100/390 ( 26%)]  Loss: 3.743 (3.70)  Time: 0.316s,  404.55/s  (0.322s,  397.98/s)  LR: 7.939e-04  Data: 0.014 (0.018)
Train: 30 [ 200/390 ( 51%)]  Loss: 4.024 (3.69)  Time: 0.318s,  402.50/s  (0.319s,  401.74/s)  LR: 7.939e-04  Data: 0.015 (0.015)
Train: 30 [ 300/390 ( 77%)]  Loss: 3.824 (3.70)  Time: 0.315s,  406.98/s  (0.318s,  403.00/s)  LR: 7.939e-04  Data: 0.012 (0.014)
Train: 30 [ 389/390 (100%)]  Loss: 3.832 (3.68)  Time: 0.303s,  422.07/s  (0.317s,  403.66/s)  LR: 7.939e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.424 (0.424)  Loss:  1.5947 (1.5947)  Acc@1: 59.3750 (59.3750)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  1.5312 (1.6680)  Acc@1: 62.5000 (59.3900)  Acc@5: 81.2500 (86.0700)
Test: [Whole Val]  Time: 9.727  Loss: 1.6680  Acc@1: 59.3900 Pruned: 55.42% 
Test (EMA): [   0/78]  Time: 0.366 (0.366)  Loss:  1.5713 (1.5713)  Acc@1: 62.5000 (62.5000)  Acc@5: 89.8438 (89.8438)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  1.4492 (1.6316)  Acc@1: 68.7500 (60.9000)  Acc@5: 87.5000 (87.1500)
Test (EMA): [Whole Val]  Time: 9.691  Loss: 1.6316  Acc@1: 60.9000 Pruned: 55.42% 
Train: 31 [   0/390 (  0%)]  Loss: 3.368 (3.37)  Time: 0.942s,  135.93/s  (0.942s,  135.93/s)  LR: 7.811e-04  Data: 0.636 (0.636)
Train: 31 [ 100/390 ( 26%)]  Loss: 3.875 (3.65)  Time: 0.318s,  403.05/s  (0.324s,  395.06/s)  LR: 7.811e-04  Data: 0.015 (0.019)
Train: 31 [ 200/390 ( 51%)]  Loss: 4.011 (3.64)  Time: 0.313s,  409.44/s  (0.320s,  400.10/s)  LR: 7.811e-04  Data: 0.011 (0.016)
Train: 31 [ 300/390 ( 77%)]  Loss: 3.019 (3.65)  Time: 0.314s,  408.29/s  (0.318s,  401.90/s)  LR: 7.811e-04  Data: 0.012 (0.015)
Train: 31 [ 389/390 (100%)]  Loss: 3.106 (3.66)  Time: 0.304s,  421.57/s  (0.318s,  402.52/s)  LR: 7.811e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.348 (0.348)  Loss:  1.6025 (1.6025)  Acc@1: 60.9375 (60.9375)  Acc@5: 87.5000 (87.5000)
Test: [  78/78]  Time: 0.017 (0.123)  Loss:  1.5439 (1.6726)  Acc@1: 68.7500 (60.6200)  Acc@5: 87.5000 (87.4800)
Test: [Whole Val]  Time: 9.728  Loss: 1.6726  Acc@1: 60.6200 Pruned: 55.33% 
Test (EMA): [   0/78]  Time: 0.436 (0.436)  Loss:  1.5908 (1.5908)  Acc@1: 62.5000 (62.5000)  Acc@5: 86.7188 (86.7188)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  1.5322 (1.6657)  Acc@1: 62.5000 (60.7800)  Acc@5: 87.5000 (87.2900)
Test (EMA): [Whole Val]  Time: 9.731  Loss: 1.6657  Acc@1: 60.7800 Pruned: 55.31% 
Train: 32 [   0/390 (  0%)]  Loss: 3.253 (3.25)  Time: 0.811s,  157.77/s  (0.811s,  157.77/s)  LR: 7.679e-04  Data: 0.504 (0.504)
Train: 32 [ 100/390 ( 26%)]  Loss: 2.892 (3.62)  Time: 0.314s,  408.02/s  (0.321s,  398.60/s)  LR: 7.679e-04  Data: 0.011 (0.017)
Train: 32 [ 200/390 ( 51%)]  Loss: 3.821 (3.65)  Time: 0.317s,  404.35/s  (0.318s,  402.35/s)  LR: 7.679e-04  Data: 0.015 (0.015)
Train: 32 [ 300/390 ( 77%)]  Loss: 3.502 (3.65)  Time: 0.315s,  406.28/s  (0.317s,  403.47/s)  LR: 7.679e-04  Data: 0.012 (0.014)
Train: 32 [ 389/390 (100%)]  Loss: 3.459 (3.65)  Time: 0.302s,  424.22/s  (0.317s,  403.96/s)  LR: 7.679e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.322 (0.322)  Loss:  1.6250 (1.6250)  Acc@1: 59.3750 (59.3750)  Acc@5: 89.8438 (89.8438)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  1.5146 (1.7092)  Acc@1: 62.5000 (60.5700)  Acc@5: 87.5000 (87.0000)
Test: [Whole Val]  Time: 9.617  Loss: 1.7092  Acc@1: 60.5700 Pruned: 55.30% 
Test (EMA): [   0/78]  Time: 0.338 (0.338)  Loss:  1.6309 (1.6309)  Acc@1: 62.5000 (62.5000)  Acc@5: 87.5000 (87.5000)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  1.5156 (1.6929)  Acc@1: 62.5000 (60.8200)  Acc@5: 87.5000 (86.9900)
Test (EMA): [Whole Val]  Time: 9.655  Loss: 1.6929  Acc@1: 60.8200 Pruned: 55.32% 
Train: 33 [   0/390 (  0%)]  Loss: 3.259 (3.26)  Time: 0.868s,  147.44/s  (0.868s,  147.44/s)  LR: 7.545e-04  Data: 0.565 (0.565)
Train: 33 [ 100/390 ( 26%)]  Loss: 3.131 (3.65)  Time: 0.314s,  407.61/s  (0.321s,  398.42/s)  LR: 7.545e-04  Data: 0.012 (0.018)
Train: 33 [ 200/390 ( 51%)]  Loss: 3.775 (3.64)  Time: 0.320s,  399.76/s  (0.318s,  402.00/s)  LR: 7.545e-04  Data: 0.013 (0.015)
Train: 33 [ 300/390 ( 77%)]  Loss: 3.883 (3.65)  Time: 0.331s,  386.44/s  (0.317s,  403.35/s)  LR: 7.545e-04  Data: 0.012 (0.014)
Train: 33 [ 389/390 (100%)]  Loss: 3.819 (3.65)  Time: 0.302s,  423.52/s  (0.317s,  403.98/s)  LR: 7.545e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.414 (0.414)  Loss:  1.5898 (1.5898)  Acc@1: 59.3750 (59.3750)  Acc@5: 89.0625 (89.0625)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  1.4658 (1.6661)  Acc@1: 62.5000 (60.3000)  Acc@5: 87.5000 (86.8100)
Test: [Whole Val]  Time: 9.716  Loss: 1.6661  Acc@1: 60.3000 Pruned: 55.19% 
Test (EMA): [   0/78]  Time: 0.389 (0.389)  Loss:  1.5645 (1.5645)  Acc@1: 63.2812 (63.2812)  Acc@5: 89.8438 (89.8438)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  1.4668 (1.6455)  Acc@1: 62.5000 (61.4600)  Acc@5: 87.5000 (87.2100)
Test (EMA): [Whole Val]  Time: 9.717  Loss: 1.6455  Acc@1: 61.4600 Pruned: 55.20% 
Train: 34 [   0/390 (  0%)]  Loss: 2.949 (2.95)  Time: 0.726s,  176.26/s  (0.726s,  176.26/s)  LR: 7.409e-04  Data: 0.427 (0.427)
Train: 34 [ 100/390 ( 26%)]  Loss: 3.977 (3.65)  Time: 0.331s,  386.79/s  (0.320s,  400.35/s)  LR: 7.409e-04  Data: 0.014 (0.016)
Train: 34 [ 200/390 ( 51%)]  Loss: 3.628 (3.65)  Time: 0.315s,  406.80/s  (0.318s,  402.78/s)  LR: 7.409e-04  Data: 0.012 (0.015)
Train: 34 [ 300/390 ( 77%)]  Loss: 3.978 (3.66)  Time: 0.316s,  404.70/s  (0.317s,  403.74/s)  LR: 7.409e-04  Data: 0.012 (0.014)
Train: 34 [ 389/390 (100%)]  Loss: 3.829 (3.66)  Time: 0.302s,  424.33/s  (0.317s,  404.18/s)  LR: 7.409e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.369 (0.369)  Loss:  1.5918 (1.5918)  Acc@1: 60.1562 (60.1562)  Acc@5: 89.8438 (89.8438)
Test: [  78/78]  Time: 0.017 (0.123)  Loss:  1.4883 (1.6530)  Acc@1: 68.7500 (60.4100)  Acc@5: 81.2500 (87.1700)
Test: [Whole Val]  Time: 9.683  Loss: 1.6530  Acc@1: 60.4100 Pruned: 55.12% 
Test (EMA): [   0/78]  Time: 0.404 (0.404)  Loss:  1.5449 (1.5449)  Acc@1: 62.5000 (62.5000)  Acc@5: 89.8438 (89.8438)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  1.4502 (1.6240)  Acc@1: 68.7500 (61.8100)  Acc@5: 87.5000 (87.5300)
Test (EMA): [Whole Val]  Time: 9.718  Loss: 1.6240  Acc@1: 61.8100 Pruned: 55.12% 
Train: 35 [   0/390 (  0%)]  Loss: 3.931 (3.93)  Time: 0.873s,  146.58/s  (0.873s,  146.58/s)  LR: 7.270e-04  Data: 0.570 (0.570)
Train: 35 [ 100/390 ( 26%)]  Loss: 4.177 (3.69)  Time: 0.316s,  404.87/s  (0.323s,  396.36/s)  LR: 7.270e-04  Data: 0.012 (0.018)
Train: 35 [ 200/390 ( 51%)]  Loss: 3.906 (3.67)  Time: 0.315s,  406.15/s  (0.319s,  400.82/s)  LR: 7.270e-04  Data: 0.012 (0.015)
Train: 35 [ 300/390 ( 77%)]  Loss: 4.147 (3.65)  Time: 0.316s,  405.01/s  (0.318s,  402.15/s)  LR: 7.270e-04  Data: 0.012 (0.014)
Train: 35 [ 389/390 (100%)]  Loss: 3.296 (3.65)  Time: 0.303s,  423.02/s  (0.318s,  402.91/s)  LR: 7.270e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.346 (0.346)  Loss:  1.6045 (1.6045)  Acc@1: 62.5000 (62.5000)  Acc@5: 89.8438 (89.8438)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  1.3809 (1.7144)  Acc@1: 75.0000 (59.1500)  Acc@5: 93.7500 (86.6500)
Test: [Whole Val]  Time: 9.679  Loss: 1.7144  Acc@1: 59.1500 Pruned: 55.06% 
Test (EMA): [   0/78]  Time: 0.305 (0.305)  Loss:  1.5586 (1.5586)  Acc@1: 62.5000 (62.5000)  Acc@5: 89.8438 (89.8438)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  1.3887 (1.6461)  Acc@1: 68.7500 (61.0400)  Acc@5: 93.7500 (87.1300)
Test (EMA): [Whole Val]  Time: 9.637  Loss: 1.6461  Acc@1: 61.0400 Pruned: 55.05% 
Train: 36 [   0/390 (  0%)]  Loss: 3.967 (3.97)  Time: 0.944s,  135.66/s  (0.944s,  135.66/s)  LR: 7.129e-04  Data: 0.640 (0.640)
Train: 36 [ 100/390 ( 26%)]  Loss: 4.063 (3.63)  Time: 0.315s,  406.22/s  (0.322s,  397.27/s)  LR: 7.129e-04  Data: 0.014 (0.019)
Train: 36 [ 200/390 ( 51%)]  Loss: 3.988 (3.66)  Time: 0.317s,  403.19/s  (0.319s,  401.18/s)  LR: 7.129e-04  Data: 0.012 (0.016)
Train: 36 [ 300/390 ( 77%)]  Loss: 2.841 (3.64)  Time: 0.318s,  402.25/s  (0.318s,  402.76/s)  LR: 7.129e-04  Data: 0.013 (0.015)
Train: 36 [ 389/390 (100%)]  Loss: 3.782 (3.65)  Time: 0.303s,  422.87/s  (0.317s,  403.45/s)  LR: 7.129e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.392 (0.392)  Loss:  1.5645 (1.5645)  Acc@1: 61.7188 (61.7188)  Acc@5: 89.8438 (89.8438)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  1.4883 (1.6561)  Acc@1: 62.5000 (60.4900)  Acc@5: 87.5000 (87.1500)
Test: [Whole Val]  Time: 9.719  Loss: 1.6561  Acc@1: 60.4900 Pruned: 54.98% 
Test (EMA): [   0/78]  Time: 0.419 (0.419)  Loss:  1.5430 (1.5430)  Acc@1: 63.2812 (63.2812)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  1.3994 (1.6339)  Acc@1: 68.7500 (61.3900)  Acc@5: 87.5000 (87.8500)
Test (EMA): [Whole Val]  Time: 9.739  Loss: 1.6339  Acc@1: 61.3900 Pruned: 54.98% 
Train: 37 [   0/390 (  0%)]  Loss: 3.782 (3.78)  Time: 0.797s,  160.52/s  (0.797s,  160.52/s)  LR: 6.986e-04  Data: 0.483 (0.483)
Train: 37 [ 100/390 ( 26%)]  Loss: 4.063 (3.69)  Time: 0.318s,  402.02/s  (0.321s,  398.63/s)  LR: 6.986e-04  Data: 0.014 (0.017)
Train: 37 [ 200/390 ( 51%)]  Loss: 3.728 (3.68)  Time: 0.315s,  406.09/s  (0.319s,  401.81/s)  LR: 6.986e-04  Data: 0.012 (0.015)
Train: 37 [ 300/390 ( 77%)]  Loss: 3.064 (3.68)  Time: 0.316s,  404.67/s  (0.318s,  403.11/s)  LR: 6.986e-04  Data: 0.014 (0.014)
Train: 37 [ 389/390 (100%)]  Loss: 4.078 (3.68)  Time: 0.302s,  423.40/s  (0.317s,  403.77/s)  LR: 6.986e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.417 (0.417)  Loss:  1.6006 (1.6006)  Acc@1: 64.8438 (64.8438)  Acc@5: 89.0625 (89.0625)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  1.5322 (1.6678)  Acc@1: 62.5000 (60.9800)  Acc@5: 93.7500 (87.3700)
Test: [Whole Val]  Time: 9.731  Loss: 1.6678  Acc@1: 60.9800 Pruned: 54.93% 
Test (EMA): [   0/78]  Time: 0.307 (0.307)  Loss:  1.5762 (1.5762)  Acc@1: 65.6250 (65.6250)  Acc@5: 89.8438 (89.8438)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  1.4629 (1.6388)  Acc@1: 62.5000 (61.9600)  Acc@5: 93.7500 (87.6900)
Test (EMA): [Whole Val]  Time: 9.631  Loss: 1.6388  Acc@1: 61.9600 Pruned: 54.93% 
Train: 38 [   0/390 (  0%)]  Loss: 3.428 (3.43)  Time: 0.797s,  160.68/s  (0.797s,  160.68/s)  LR: 6.841e-04  Data: 0.488 (0.488)
Train: 38 [ 100/390 ( 26%)]  Loss: 4.088 (3.67)  Time: 0.313s,  408.74/s  (0.321s,  398.97/s)  LR: 6.841e-04  Data: 0.011 (0.017)
Train: 38 [ 200/390 ( 51%)]  Loss: 3.744 (3.65)  Time: 0.314s,  407.30/s  (0.319s,  401.58/s)  LR: 6.841e-04  Data: 0.012 (0.015)
Train: 38 [ 300/390 ( 77%)]  Loss: 3.973 (3.63)  Time: 0.314s,  407.19/s  (0.318s,  402.71/s)  LR: 6.841e-04  Data: 0.012 (0.014)
Train: 38 [ 389/390 (100%)]  Loss: 3.869 (3.63)  Time: 0.303s,  422.20/s  (0.317s,  403.49/s)  LR: 6.841e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.333 (0.333)  Loss:  1.5771 (1.5771)  Acc@1: 63.2812 (63.2812)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.4746 (1.6434)  Acc@1: 68.7500 (61.2900)  Acc@5: 81.2500 (87.1000)
Test: [Whole Val]  Time: 9.676  Loss: 1.6434  Acc@1: 61.2900 Pruned: 54.88% 
Test (EMA): [   0/78]  Time: 0.406 (0.406)  Loss:  1.5449 (1.5449)  Acc@1: 60.1562 (60.1562)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  1.4424 (1.5990)  Acc@1: 68.7500 (62.2500)  Acc@5: 81.2500 (87.9200)
Test (EMA): [Whole Val]  Time: 9.717  Loss: 1.5990  Acc@1: 62.2500 Pruned: 54.91% 
Train: 39 [   0/390 (  0%)]  Loss: 3.173 (3.17)  Time: 0.780s,  164.01/s  (0.780s,  164.01/s)  LR: 6.694e-04  Data: 0.469 (0.469)
Train: 39 [ 100/390 ( 26%)]  Loss: 3.749 (3.61)  Time: 0.317s,  403.88/s  (0.321s,  399.04/s)  LR: 6.694e-04  Data: 0.013 (0.017)
Train: 39 [ 200/390 ( 51%)]  Loss: 3.309 (3.61)  Time: 0.316s,  405.50/s  (0.318s,  402.08/s)  LR: 6.694e-04  Data: 0.013 (0.015)
Train: 39 [ 300/390 ( 77%)]  Loss: 3.837 (3.64)  Time: 0.314s,  407.80/s  (0.318s,  403.13/s)  LR: 6.694e-04  Data: 0.011 (0.014)
Train: 39 [ 389/390 (100%)]  Loss: 3.958 (3.65)  Time: 0.304s,  420.91/s  (0.317s,  403.65/s)  LR: 6.694e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.427 (0.427)  Loss:  1.5830 (1.5830)  Acc@1: 61.7188 (61.7188)  Acc@5: 89.0625 (89.0625)
Test: [  78/78]  Time: 0.018 (0.124)  Loss:  1.4844 (1.6503)  Acc@1: 62.5000 (60.6900)  Acc@5: 81.2500 (87.0700)
Test: [Whole Val]  Time: 9.790  Loss: 1.6503  Acc@1: 60.6900 Pruned: 54.80% 
Test (EMA): [   0/78]  Time: 0.362 (0.362)  Loss:  1.5479 (1.5479)  Acc@1: 63.2812 (63.2812)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  1.5059 (1.6324)  Acc@1: 62.5000 (61.6600)  Acc@5: 81.2500 (87.6300)
Test (EMA): [Whole Val]  Time: 9.686  Loss: 1.6324  Acc@1: 61.6600 Pruned: 54.80% 
Train: 40 [   0/390 (  0%)]  Loss: 3.872 (3.87)  Time: 0.935s,  136.97/s  (0.935s,  136.97/s)  LR: 6.545e-04  Data: 0.630 (0.630)
Train: 40 [ 100/390 ( 26%)]  Loss: 4.002 (3.62)  Time: 0.315s,  406.95/s  (0.323s,  396.35/s)  LR: 6.545e-04  Data: 0.012 (0.019)
Train: 40 [ 200/390 ( 51%)]  Loss: 4.008 (3.66)  Time: 0.316s,  404.97/s  (0.319s,  400.75/s)  LR: 6.545e-04  Data: 0.013 (0.016)
Train: 40 [ 300/390 ( 77%)]  Loss: 3.100 (3.65)  Time: 0.314s,  407.83/s  (0.318s,  402.43/s)  LR: 6.545e-04  Data: 0.013 (0.015)
Train: 40 [ 389/390 (100%)]  Loss: 3.599 (3.64)  Time: 0.303s,  421.80/s  (0.317s,  403.20/s)  LR: 6.545e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.315 (0.315)  Loss:  1.5801 (1.5801)  Acc@1: 65.6250 (65.6250)  Acc@5: 86.7188 (86.7188)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  1.5303 (1.6538)  Acc@1: 68.7500 (61.2100)  Acc@5: 81.2500 (87.2200)
Test: [Whole Val]  Time: 9.631  Loss: 1.6538  Acc@1: 61.2100 Pruned: 54.68% 
Test (EMA): [   0/78]  Time: 0.406 (0.406)  Loss:  1.5254 (1.5254)  Acc@1: 66.4062 (66.4062)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  1.4883 (1.5972)  Acc@1: 68.7500 (62.3500)  Acc@5: 81.2500 (88.0200)
Test (EMA): [Whole Val]  Time: 9.753  Loss: 1.5972  Acc@1: 62.3500 Pruned: 54.68% 
Train: 41 [   0/390 (  0%)]  Loss: 4.068 (4.07)  Time: 0.906s,  141.30/s  (0.906s,  141.30/s)  LR: 6.395e-04  Data: 0.601 (0.601)
Train: 41 [ 100/390 ( 26%)]  Loss: 3.876 (3.67)  Time: 0.319s,  401.77/s  (0.324s,  394.77/s)  LR: 6.395e-04  Data: 0.015 (0.019)
Train: 41 [ 200/390 ( 51%)]  Loss: 3.898 (3.65)  Time: 0.419s,  305.37/s  (0.322s,  397.18/s)  LR: 6.395e-04  Data: 0.012 (0.016)
Train: 41 [ 300/390 ( 77%)]  Loss: 3.525 (3.65)  Time: 0.314s,  407.28/s  (0.321s,  398.93/s)  LR: 6.395e-04  Data: 0.012 (0.015)
Train: 41 [ 389/390 (100%)]  Loss: 3.977 (3.64)  Time: 0.303s,  421.99/s  (0.320s,  400.11/s)  LR: 6.395e-04  Data: 0.000 (0.015)
Test: [   0/78]  Time: 0.315 (0.315)  Loss:  1.5801 (1.5801)  Acc@1: 58.5938 (58.5938)  Acc@5: 89.8438 (89.8438)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.4355 (1.6534)  Acc@1: 68.7500 (60.7500)  Acc@5: 93.7500 (87.5700)
Test: [Whole Val]  Time: 9.626  Loss: 1.6534  Acc@1: 60.7500 Pruned: 54.61% 
Test (EMA): [   0/78]  Time: 0.387 (0.387)  Loss:  1.5566 (1.5566)  Acc@1: 61.7188 (61.7188)  Acc@5: 89.8438 (89.8438)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  1.4238 (1.6329)  Acc@1: 68.7500 (61.5700)  Acc@5: 93.7500 (88.0100)
Test (EMA): [Whole Val]  Time: 9.687  Loss: 1.6329  Acc@1: 61.5700 Pruned: 54.64% 
Train: 42 [   0/390 (  0%)]  Loss: 3.364 (3.36)  Time: 0.802s,  159.61/s  (0.802s,  159.61/s)  LR: 6.244e-04  Data: 0.487 (0.487)
Train: 42 [ 100/390 ( 26%)]  Loss: 3.952 (3.65)  Time: 0.314s,  407.12/s  (0.324s,  394.56/s)  LR: 6.244e-04  Data: 0.012 (0.018)
Train: 42 [ 200/390 ( 51%)]  Loss: 3.791 (3.66)  Time: 0.320s,  400.10/s  (0.320s,  400.19/s)  LR: 6.244e-04  Data: 0.017 (0.015)
Train: 42 [ 300/390 ( 77%)]  Loss: 3.828 (3.64)  Time: 0.319s,  401.76/s  (0.318s,  402.00/s)  LR: 6.244e-04  Data: 0.011 (0.014)
Train: 42 [ 389/390 (100%)]  Loss: 3.486 (3.64)  Time: 0.300s,  426.85/s  (0.317s,  403.17/s)  LR: 6.244e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.329 (0.329)  Loss:  1.6182 (1.6182)  Acc@1: 62.5000 (62.5000)  Acc@5: 88.2812 (88.2812)
Test: [  78/78]  Time: 0.018 (0.121)  Loss:  1.4902 (1.6653)  Acc@1: 68.7500 (62.0000)  Acc@5: 87.5000 (87.8000)
Test: [Whole Val]  Time: 9.598  Loss: 1.6653  Acc@1: 62.0000 Pruned: 54.60% 
Test (EMA): [   0/78]  Time: 0.437 (0.437)  Loss:  1.6084 (1.6084)  Acc@1: 61.7188 (61.7188)  Acc@5: 89.0625 (89.0625)
Test (EMA): [  78/78]  Time: 0.017 (0.124)  Loss:  1.4785 (1.6630)  Acc@1: 62.5000 (61.8800)  Acc@5: 87.5000 (87.8800)
Test (EMA): [Whole Val]  Time: 9.821  Loss: 1.6630  Acc@1: 61.8800 Pruned: 54.62% 
Train: 43 [   0/390 (  0%)]  Loss: 3.932 (3.93)  Time: 0.772s,  165.77/s  (0.772s,  165.77/s)  LR: 6.091e-04  Data: 0.467 (0.467)
Train: 43 [ 100/390 ( 26%)]  Loss: 3.313 (3.61)  Time: 0.315s,  406.90/s  (0.320s,  399.46/s)  LR: 6.091e-04  Data: 0.013 (0.017)
Train: 43 [ 200/390 ( 51%)]  Loss: 3.757 (3.62)  Time: 0.315s,  406.31/s  (0.319s,  401.46/s)  LR: 6.091e-04  Data: 0.013 (0.015)
Train: 43 [ 300/390 ( 77%)]  Loss: 3.396 (3.61)  Time: 0.315s,  406.98/s  (0.318s,  402.78/s)  LR: 6.091e-04  Data: 0.012 (0.014)
Train: 43 [ 389/390 (100%)]  Loss: 3.738 (3.61)  Time: 0.304s,  421.53/s  (0.317s,  403.39/s)  LR: 6.091e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.424 (0.424)  Loss:  1.4980 (1.4980)  Acc@1: 64.0625 (64.0625)  Acc@5: 89.8438 (89.8438)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  1.4590 (1.5940)  Acc@1: 62.5000 (62.2400)  Acc@5: 81.2500 (87.8600)
Test: [Whole Val]  Time: 9.731  Loss: 1.5940  Acc@1: 62.2400 Pruned: 54.57% 
Test (EMA): [   0/78]  Time: 0.430 (0.430)  Loss:  1.4941 (1.4941)  Acc@1: 66.4062 (66.4062)  Acc@5: 89.8438 (89.8438)
Test (EMA): [  78/78]  Time: 0.017 (0.124)  Loss:  1.4375 (1.5760)  Acc@1: 62.5000 (62.6800)  Acc@5: 87.5000 (88.0600)
Test (EMA): [Whole Val]  Time: 9.762  Loss: 1.5760  Acc@1: 62.6800 Pruned: 54.59% 
Train: 44 [   0/390 (  0%)]  Loss: 3.719 (3.72)  Time: 1.000s,  128.05/s  (1.000s,  128.05/s)  LR: 5.937e-04  Data: 0.697 (0.697)
Train: 44 [ 100/390 ( 26%)]  Loss: 3.943 (3.65)  Time: 0.315s,  406.78/s  (0.323s,  396.71/s)  LR: 5.937e-04  Data: 0.013 (0.019)
Train: 44 [ 200/390 ( 51%)]  Loss: 3.363 (3.63)  Time: 0.315s,  406.05/s  (0.319s,  401.00/s)  LR: 5.937e-04  Data: 0.013 (0.016)
Train: 44 [ 300/390 ( 77%)]  Loss: 3.225 (3.62)  Time: 0.313s,  409.57/s  (0.318s,  402.22/s)  LR: 5.937e-04  Data: 0.010 (0.015)
Train: 44 [ 389/390 (100%)]  Loss: 2.873 (3.63)  Time: 0.304s,  420.74/s  (0.317s,  403.21/s)  LR: 5.937e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.380 (0.380)  Loss:  1.5107 (1.5107)  Acc@1: 65.6250 (65.6250)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  1.4609 (1.6227)  Acc@1: 68.7500 (62.1200)  Acc@5: 87.5000 (87.9000)
Test: [Whole Val]  Time: 9.658  Loss: 1.6227  Acc@1: 62.1200 Pruned: 54.55% 
Test (EMA): [   0/78]  Time: 0.437 (0.437)  Loss:  1.5146 (1.5146)  Acc@1: 64.8438 (64.8438)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.018 (0.124)  Loss:  1.4746 (1.6077)  Acc@1: 68.7500 (62.5300)  Acc@5: 87.5000 (88.1500)
Test (EMA): [Whole Val]  Time: 9.766  Loss: 1.6077  Acc@1: 62.5300 Pruned: 54.55% 
Train: 45 [   0/390 (  0%)]  Loss: 3.927 (3.93)  Time: 0.843s,  151.86/s  (0.843s,  151.86/s)  LR: 5.783e-04  Data: 0.527 (0.527)
Train: 45 [ 100/390 ( 26%)]  Loss: 3.948 (3.62)  Time: 0.316s,  405.54/s  (0.321s,  398.30/s)  LR: 5.783e-04  Data: 0.013 (0.017)
Train: 45 [ 200/390 ( 51%)]  Loss: 4.021 (3.61)  Time: 0.313s,  408.46/s  (0.318s,  402.10/s)  LR: 5.783e-04  Data: 0.012 (0.015)
Train: 45 [ 300/390 ( 77%)]  Loss: 3.299 (3.63)  Time: 0.315s,  405.95/s  (0.317s,  403.19/s)  LR: 5.783e-04  Data: 0.013 (0.014)
Train: 45 [ 389/390 (100%)]  Loss: 3.608 (3.62)  Time: 0.303s,  422.70/s  (0.317s,  403.77/s)  LR: 5.783e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.338 (0.338)  Loss:  1.5244 (1.5244)  Acc@1: 66.4062 (66.4062)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.5000 (1.6140)  Acc@1: 62.5000 (62.3400)  Acc@5: 87.5000 (87.9300)
Test: [Whole Val]  Time: 9.630  Loss: 1.6140  Acc@1: 62.3400 Pruned: 54.51% 
Test (EMA): [   0/78]  Time: 0.418 (0.418)  Loss:  1.5156 (1.5156)  Acc@1: 65.6250 (65.6250)  Acc@5: 89.8438 (89.8438)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  1.4883 (1.5981)  Acc@1: 62.5000 (62.5100)  Acc@5: 87.5000 (88.1400)
Test (EMA): [Whole Val]  Time: 9.710  Loss: 1.5981  Acc@1: 62.5100 Pruned: 54.49% 
Train: 46 [   0/390 (  0%)]  Loss: 3.285 (3.29)  Time: 0.767s,  166.92/s  (0.767s,  166.92/s)  LR: 5.627e-04  Data: 0.452 (0.452)
Train: 46 [ 100/390 ( 26%)]  Loss: 4.147 (3.64)  Time: 0.319s,  401.44/s  (0.320s,  399.51/s)  LR: 5.627e-04  Data: 0.016 (0.017)
Train: 46 [ 200/390 ( 51%)]  Loss: 3.999 (3.62)  Time: 0.313s,  408.74/s  (0.318s,  402.31/s)  LR: 5.627e-04  Data: 0.011 (0.015)
Train: 46 [ 300/390 ( 77%)]  Loss: 4.069 (3.63)  Time: 0.316s,  405.05/s  (0.317s,  403.57/s)  LR: 5.627e-04  Data: 0.013 (0.014)
Train: 46 [ 389/390 (100%)]  Loss: 2.741 (3.62)  Time: 0.302s,  423.87/s  (0.317s,  404.00/s)  LR: 5.627e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.419 (0.419)  Loss:  1.4727 (1.4727)  Acc@1: 64.8438 (64.8438)  Acc@5: 89.8438 (89.8438)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  1.4980 (1.6033)  Acc@1: 56.2500 (62.1800)  Acc@5: 81.2500 (87.7400)
Test: [Whole Val]  Time: 9.732  Loss: 1.6033  Acc@1: 62.1800 Pruned: 54.49% 
Test (EMA): [   0/78]  Time: 0.318 (0.318)  Loss:  1.4766 (1.4766)  Acc@1: 65.6250 (65.6250)  Acc@5: 89.0625 (89.0625)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  1.4658 (1.5761)  Acc@1: 62.5000 (62.8500)  Acc@5: 87.5000 (88.1100)
Test (EMA): [Whole Val]  Time: 9.619  Loss: 1.5761  Acc@1: 62.8500 Pruned: 54.48% 
Train: 47 [   0/390 (  0%)]  Loss: 3.514 (3.51)  Time: 0.802s,  159.54/s  (0.802s,  159.54/s)  LR: 5.471e-04  Data: 0.497 (0.497)
Train: 47 [ 100/390 ( 26%)]  Loss: 3.861 (3.60)  Time: 0.314s,  407.35/s  (0.320s,  399.53/s)  LR: 5.471e-04  Data: 0.012 (0.017)
Train: 47 [ 200/390 ( 51%)]  Loss: 4.091 (3.60)  Time: 0.315s,  406.27/s  (0.318s,  402.53/s)  LR: 5.471e-04  Data: 0.011 (0.015)
Train: 47 [ 300/390 ( 77%)]  Loss: 3.312 (3.58)  Time: 0.316s,  405.13/s  (0.317s,  403.46/s)  LR: 5.471e-04  Data: 0.012 (0.014)
Train: 47 [ 389/390 (100%)]  Loss: 3.727 (3.58)  Time: 0.305s,  420.09/s  (0.317s,  403.55/s)  LR: 5.471e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.406 (0.406)  Loss:  1.5020 (1.5020)  Acc@1: 68.7500 (68.7500)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.017 (0.123)  Loss:  1.5303 (1.5839)  Acc@1: 75.0000 (62.4700)  Acc@5: 87.5000 (88.0000)
Test: [Whole Val]  Time: 9.733  Loss: 1.5839  Acc@1: 62.4700 Pruned: 54.44% 
Test (EMA): [   0/78]  Time: 0.427 (0.427)  Loss:  1.5000 (1.5000)  Acc@1: 64.0625 (64.0625)  Acc@5: 89.8438 (89.8438)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  1.5078 (1.5773)  Acc@1: 68.7500 (62.6700)  Acc@5: 81.2500 (88.0800)
Test (EMA): [Whole Val]  Time: 9.740  Loss: 1.5773  Acc@1: 62.6700 Pruned: 54.44% 
Train: 48 [   0/390 (  0%)]  Loss: 3.756 (3.76)  Time: 0.773s,  165.55/s  (0.773s,  165.55/s)  LR: 5.314e-04  Data: 0.470 (0.470)
Train: 48 [ 100/390 ( 26%)]  Loss: 3.923 (3.63)  Time: 0.314s,  407.68/s  (0.321s,  399.36/s)  LR: 5.314e-04  Data: 0.012 (0.017)
Train: 48 [ 200/390 ( 51%)]  Loss: 2.886 (3.59)  Time: 0.315s,  406.58/s  (0.318s,  402.18/s)  LR: 5.314e-04  Data: 0.013 (0.015)
Train: 48 [ 300/390 ( 77%)]  Loss: 2.937 (3.61)  Time: 0.314s,  407.60/s  (0.317s,  403.17/s)  LR: 5.314e-04  Data: 0.012 (0.014)
Train: 48 [ 389/390 (100%)]  Loss: 3.038 (3.63)  Time: 0.302s,  424.29/s  (0.317s,  403.70/s)  LR: 5.314e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.421 (0.421)  Loss:  1.5166 (1.5166)  Acc@1: 66.4062 (66.4062)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.017 (0.123)  Loss:  1.4062 (1.6260)  Acc@1: 68.7500 (62.2900)  Acc@5: 87.5000 (87.5600)
Test: [Whole Val]  Time: 9.715  Loss: 1.6260  Acc@1: 62.2900 Pruned: 54.42% 
Test (EMA): [   0/78]  Time: 0.354 (0.354)  Loss:  1.4902 (1.4902)  Acc@1: 65.6250 (65.6250)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  1.4180 (1.5947)  Acc@1: 68.7500 (63.1600)  Acc@5: 81.2500 (88.0800)
Test (EMA): [Whole Val]  Time: 9.682  Loss: 1.5947  Acc@1: 63.1600 Pruned: 54.40% 
Train: 49 [   0/390 (  0%)]  Loss: 4.016 (4.02)  Time: 0.790s,  161.94/s  (0.790s,  161.94/s)  LR: 5.158e-04  Data: 0.474 (0.474)
Train: 49 [ 100/390 ( 26%)]  Loss: 3.059 (3.60)  Time: 0.314s,  407.02/s  (0.321s,  398.67/s)  LR: 5.158e-04  Data: 0.011 (0.017)
Train: 49 [ 200/390 ( 51%)]  Loss: 3.332 (3.59)  Time: 0.315s,  405.92/s  (0.319s,  401.58/s)  LR: 5.158e-04  Data: 0.013 (0.015)
Train: 49 [ 300/390 ( 77%)]  Loss: 3.183 (3.59)  Time: 0.316s,  404.92/s  (0.318s,  402.96/s)  LR: 5.158e-04  Data: 0.013 (0.014)
Train: 49 [ 389/390 (100%)]  Loss: 3.500 (3.59)  Time: 0.302s,  423.17/s  (0.317s,  403.56/s)  LR: 5.158e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.398 (0.398)  Loss:  1.4824 (1.4824)  Acc@1: 67.9688 (67.9688)  Acc@5: 89.8438 (89.8438)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  1.4277 (1.5816)  Acc@1: 81.2500 (62.7500)  Acc@5: 87.5000 (87.8400)
Test: [Whole Val]  Time: 9.674  Loss: 1.5816  Acc@1: 62.7500 Pruned: 54.34% 
Test (EMA): [   0/78]  Time: 0.320 (0.320)  Loss:  1.4688 (1.4688)  Acc@1: 68.7500 (68.7500)  Acc@5: 89.8438 (89.8438)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  1.4238 (1.5628)  Acc@1: 62.5000 (63.5400)  Acc@5: 87.5000 (88.2100)
Test (EMA): [Whole Val]  Time: 9.648  Loss: 1.5628  Acc@1: 63.5400 Pruned: 54.34% 
Train: 50 [   0/390 (  0%)]  Loss: 3.850 (3.85)  Time: 0.782s,  163.73/s  (0.782s,  163.73/s)  LR: 5.000e-04  Data: 0.476 (0.476)
Train: 50 [ 100/390 ( 26%)]  Loss: 4.016 (3.57)  Time: 0.316s,  405.36/s  (0.321s,  399.26/s)  LR: 5.000e-04  Data: 0.012 (0.017)
Train: 50 [ 200/390 ( 51%)]  Loss: 3.789 (3.62)  Time: 0.314s,  407.50/s  (0.318s,  402.57/s)  LR: 5.000e-04  Data: 0.012 (0.015)
Train: 50 [ 300/390 ( 77%)]  Loss: 3.793 (3.62)  Time: 0.312s,  409.63/s  (0.317s,  403.75/s)  LR: 5.000e-04  Data: 0.011 (0.014)
Train: 50 [ 389/390 (100%)]  Loss: 3.556 (3.60)  Time: 0.303s,  422.33/s  (0.317s,  404.26/s)  LR: 5.000e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.413 (0.413)  Loss:  1.5332 (1.5332)  Acc@1: 62.5000 (62.5000)  Acc@5: 88.2812 (88.2812)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  1.4277 (1.6224)  Acc@1: 62.5000 (62.3300)  Acc@5: 87.5000 (87.5300)
Test: [Whole Val]  Time: 9.713  Loss: 1.6224  Acc@1: 62.3300 Pruned: 54.30% 
Test (EMA): [   0/78]  Time: 0.324 (0.324)  Loss:  1.5059 (1.5059)  Acc@1: 65.6250 (65.6250)  Acc@5: 89.8438 (89.8438)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  1.4219 (1.5816)  Acc@1: 62.5000 (63.3900)  Acc@5: 87.5000 (88.2000)
Test (EMA): [Whole Val]  Time: 9.635  Loss: 1.5816  Acc@1: 63.3900 Pruned: 54.29% 
Train: 51 [   0/390 (  0%)]  Loss: 3.700 (3.70)  Time: 0.761s,  168.09/s  (0.761s,  168.09/s)  LR: 4.843e-04  Data: 0.456 (0.456)
Train: 51 [ 100/390 ( 26%)]  Loss: 3.782 (3.51)  Time: 0.323s,  395.80/s  (0.321s,  398.31/s)  LR: 4.843e-04  Data: 0.015 (0.017)
Train: 51 [ 200/390 ( 51%)]  Loss: 4.074 (3.55)  Time: 0.317s,  404.18/s  (0.319s,  401.67/s)  LR: 4.843e-04  Data: 0.013 (0.015)
Train: 51 [ 300/390 ( 77%)]  Loss: 3.158 (3.57)  Time: 0.318s,  402.03/s  (0.318s,  403.03/s)  LR: 4.843e-04  Data: 0.013 (0.014)
Train: 51 [ 389/390 (100%)]  Loss: 3.674 (3.59)  Time: 0.304s,  420.82/s  (0.317s,  403.67/s)  LR: 4.843e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.377 (0.377)  Loss:  1.5322 (1.5322)  Acc@1: 65.6250 (65.6250)  Acc@5: 89.8438 (89.8438)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  1.4668 (1.6139)  Acc@1: 62.5000 (62.9700)  Acc@5: 87.5000 (87.6700)
Test: [Whole Val]  Time: 9.679  Loss: 1.6139  Acc@1: 62.9700 Pruned: 54.28% 
Test (EMA): [   0/78]  Time: 0.303 (0.303)  Loss:  1.5059 (1.5059)  Acc@1: 64.0625 (64.0625)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  1.4844 (1.5935)  Acc@1: 62.5000 (63.4600)  Acc@5: 81.2500 (88.3900)
Test (EMA): [Whole Val]  Time: 9.635  Loss: 1.5935  Acc@1: 63.4600 Pruned: 54.27% 
Train: 52 [   0/390 (  0%)]  Loss: 3.939 (3.94)  Time: 0.789s,  162.28/s  (0.789s,  162.28/s)  LR: 4.687e-04  Data: 0.482 (0.482)
Train: 52 [ 100/390 ( 26%)]  Loss: 3.467 (3.61)  Time: 0.315s,  406.56/s  (0.321s,  398.85/s)  LR: 4.687e-04  Data: 0.012 (0.017)
Train: 52 [ 200/390 ( 51%)]  Loss: 3.793 (3.59)  Time: 0.313s,  408.68/s  (0.318s,  402.30/s)  LR: 4.687e-04  Data: 0.012 (0.015)
Train: 52 [ 300/390 ( 77%)]  Loss: 3.266 (3.59)  Time: 0.314s,  407.33/s  (0.317s,  403.28/s)  LR: 4.687e-04  Data: 0.012 (0.014)
Train: 52 [ 389/390 (100%)]  Loss: 3.659 (3.58)  Time: 0.303s,  422.99/s  (0.317s,  403.90/s)  LR: 4.687e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.312 (0.312)  Loss:  1.4980 (1.4980)  Acc@1: 63.2812 (63.2812)  Acc@5: 89.8438 (89.8438)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.4365 (1.5762)  Acc@1: 62.5000 (62.5200)  Acc@5: 81.2500 (88.2600)
Test: [Whole Val]  Time: 9.626  Loss: 1.5762  Acc@1: 62.5200 Pruned: 54.25% 
Test (EMA): [   0/78]  Time: 0.410 (0.410)  Loss:  1.4814 (1.4814)  Acc@1: 64.8438 (64.8438)  Acc@5: 89.8438 (89.8438)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  1.4004 (1.5565)  Acc@1: 62.5000 (63.5200)  Acc@5: 81.2500 (88.6800)
Test (EMA): [Whole Val]  Time: 9.706  Loss: 1.5565  Acc@1: 63.5200 Pruned: 54.26% 
Train: 53 [   0/390 (  0%)]  Loss: 4.195 (4.20)  Time: 0.889s,  143.94/s  (0.889s,  143.94/s)  LR: 4.530e-04  Data: 0.579 (0.579)
Train: 53 [ 100/390 ( 26%)]  Loss: 3.273 (3.60)  Time: 0.315s,  406.78/s  (0.321s,  398.89/s)  LR: 4.530e-04  Data: 0.012 (0.018)
Train: 53 [ 200/390 ( 51%)]  Loss: 3.968 (3.59)  Time: 0.315s,  406.23/s  (0.318s,  402.20/s)  LR: 4.530e-04  Data: 0.013 (0.015)
Train: 53 [ 300/390 ( 77%)]  Loss: 3.932 (3.58)  Time: 0.316s,  404.48/s  (0.317s,  403.50/s)  LR: 4.530e-04  Data: 0.013 (0.014)
Train: 53 [ 389/390 (100%)]  Loss: 3.111 (3.59)  Time: 0.304s,  420.83/s  (0.317s,  404.15/s)  LR: 4.530e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.414 (0.414)  Loss:  1.4863 (1.4863)  Acc@1: 64.8438 (64.8438)  Acc@5: 89.0625 (89.0625)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  1.3525 (1.5875)  Acc@1: 75.0000 (63.1100)  Acc@5: 87.5000 (88.1400)
Test: [Whole Val]  Time: 9.703  Loss: 1.5875  Acc@1: 63.1100 Pruned: 54.20% 
Test (EMA): [   0/78]  Time: 0.414 (0.414)  Loss:  1.4785 (1.4785)  Acc@1: 62.5000 (62.5000)  Acc@5: 89.0625 (89.0625)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  1.3789 (1.5763)  Acc@1: 68.7500 (63.1900)  Acc@5: 81.2500 (88.2900)
Test (EMA): [Whole Val]  Time: 9.717  Loss: 1.5763  Acc@1: 63.1900 Pruned: 54.20% 
Train: 54 [   0/390 (  0%)]  Loss: 3.727 (3.73)  Time: 0.821s,  155.96/s  (0.821s,  155.96/s)  LR: 4.374e-04  Data: 0.516 (0.516)
Train: 54 [ 100/390 ( 26%)]  Loss: 4.005 (3.64)  Time: 0.314s,  407.88/s  (0.320s,  399.98/s)  LR: 4.374e-04  Data: 0.012 (0.017)
Train: 54 [ 200/390 ( 51%)]  Loss: 3.032 (3.60)  Time: 0.318s,  402.56/s  (0.318s,  402.44/s)  LR: 4.374e-04  Data: 0.016 (0.015)
Train: 54 [ 300/390 ( 77%)]  Loss: 3.090 (3.60)  Time: 0.315s,  406.35/s  (0.317s,  403.21/s)  LR: 4.374e-04  Data: 0.012 (0.014)
Train: 54 [ 389/390 (100%)]  Loss: 3.899 (3.60)  Time: 0.303s,  422.72/s  (0.317s,  403.90/s)  LR: 4.374e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.409 (0.409)  Loss:  1.5146 (1.5146)  Acc@1: 62.5000 (62.5000)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.017 (0.123)  Loss:  1.4287 (1.5876)  Acc@1: 68.7500 (62.9500)  Acc@5: 81.2500 (88.4800)
Test: [Whole Val]  Time: 9.709  Loss: 1.5876  Acc@1: 62.9500 Pruned: 54.18% 
Test (EMA): [   0/78]  Time: 0.380 (0.380)  Loss:  1.4971 (1.4971)  Acc@1: 62.5000 (62.5000)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  1.4268 (1.5701)  Acc@1: 62.5000 (63.1800)  Acc@5: 81.2500 (88.7000)
Test (EMA): [Whole Val]  Time: 9.694  Loss: 1.5701  Acc@1: 63.1800 Pruned: 54.18% 
Train: 55 [   0/390 (  0%)]  Loss: 3.738 (3.74)  Time: 0.784s,  163.34/s  (0.784s,  163.34/s)  LR: 4.218e-04  Data: 0.477 (0.477)
Train: 55 [ 100/390 ( 26%)]  Loss: 4.056 (3.68)  Time: 0.314s,  407.70/s  (0.321s,  398.36/s)  LR: 4.218e-04  Data: 0.011 (0.017)
Train: 55 [ 200/390 ( 51%)]  Loss: 3.864 (3.62)  Time: 0.314s,  407.42/s  (0.318s,  402.21/s)  LR: 4.218e-04  Data: 0.012 (0.015)
Train: 55 [ 300/390 ( 77%)]  Loss: 3.637 (3.63)  Time: 0.319s,  401.88/s  (0.317s,  403.38/s)  LR: 4.218e-04  Data: 0.013 (0.014)
Train: 55 [ 389/390 (100%)]  Loss: 2.987 (3.62)  Time: 0.304s,  421.66/s  (0.317s,  404.01/s)  LR: 4.218e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.322 (0.322)  Loss:  1.4854 (1.4854)  Acc@1: 64.0625 (64.0625)  Acc@5: 89.8438 (89.8438)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.4756 (1.5714)  Acc@1: 68.7500 (63.2400)  Acc@5: 81.2500 (88.8900)
Test: [Whole Val]  Time: 9.617  Loss: 1.5714  Acc@1: 63.2400 Pruned: 54.17% 
Test (EMA): [   0/78]  Time: 0.315 (0.315)  Loss:  1.5010 (1.5010)  Acc@1: 64.0625 (64.0625)  Acc@5: 89.8438 (89.8438)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  1.4473 (1.5763)  Acc@1: 68.7500 (63.6700)  Acc@5: 81.2500 (88.7800)
Test (EMA): [Whole Val]  Time: 9.627  Loss: 1.5763  Acc@1: 63.6700 Pruned: 54.17% 
Train: 56 [   0/390 (  0%)]  Loss: 3.609 (3.61)  Time: 0.753s,  170.04/s  (0.753s,  170.04/s)  LR: 4.064e-04  Data: 0.439 (0.439)
Train: 56 [ 100/390 ( 26%)]  Loss: 2.821 (3.58)  Time: 0.316s,  404.83/s  (0.320s,  400.44/s)  LR: 4.064e-04  Data: 0.013 (0.017)
Train: 56 [ 200/390 ( 51%)]  Loss: 3.304 (3.59)  Time: 0.313s,  409.21/s  (0.318s,  402.85/s)  LR: 4.064e-04  Data: 0.011 (0.015)
Train: 56 [ 300/390 ( 77%)]  Loss: 3.935 (3.57)  Time: 0.315s,  406.35/s  (0.317s,  404.01/s)  LR: 4.064e-04  Data: 0.012 (0.014)
Train: 56 [ 389/390 (100%)]  Loss: 3.128 (3.57)  Time: 0.303s,  422.75/s  (0.316s,  404.48/s)  LR: 4.064e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.358 (0.358)  Loss:  1.4658 (1.4658)  Acc@1: 64.0625 (64.0625)  Acc@5: 89.8438 (89.8438)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.4365 (1.5373)  Acc@1: 68.7500 (63.8500)  Acc@5: 81.2500 (88.9200)
Test: [Whole Val]  Time: 9.672  Loss: 1.5373  Acc@1: 63.8500 Pruned: 54.17% 
Test (EMA): [   0/78]  Time: 0.316 (0.316)  Loss:  1.4561 (1.4561)  Acc@1: 65.6250 (65.6250)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  1.4121 (1.5327)  Acc@1: 68.7500 (63.9000)  Acc@5: 81.2500 (88.8300)
Test (EMA): [Whole Val]  Time: 9.621  Loss: 1.5327  Acc@1: 63.9000 Pruned: 54.16% 
Train: 57 [   0/390 (  0%)]  Loss: 3.933 (3.93)  Time: 0.819s,  156.33/s  (0.819s,  156.33/s)  LR: 3.910e-04  Data: 0.511 (0.511)
Train: 57 [ 100/390 ( 26%)]  Loss: 3.590 (3.60)  Time: 0.315s,  406.39/s  (0.321s,  399.04/s)  LR: 3.910e-04  Data: 0.012 (0.017)
Train: 57 [ 200/390 ( 51%)]  Loss: 3.292 (3.61)  Time: 0.315s,  406.17/s  (0.318s,  402.17/s)  LR: 3.910e-04  Data: 0.012 (0.015)
Train: 57 [ 300/390 ( 77%)]  Loss: 3.890 (3.62)  Time: 0.316s,  405.51/s  (0.318s,  402.84/s)  LR: 3.910e-04  Data: 0.012 (0.014)
Train: 57 [ 389/390 (100%)]  Loss: 3.505 (3.61)  Time: 0.303s,  423.02/s  (0.317s,  403.57/s)  LR: 3.910e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.382 (0.382)  Loss:  1.4697 (1.4697)  Acc@1: 64.0625 (64.0625)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  1.3643 (1.5378)  Acc@1: 75.0000 (63.4800)  Acc@5: 87.5000 (88.6400)
Test: [Whole Val]  Time: 9.653  Loss: 1.5378  Acc@1: 63.4800 Pruned: 54.14% 
Test (EMA): [   0/78]  Time: 0.439 (0.439)  Loss:  1.4668 (1.4668)  Acc@1: 64.8438 (64.8438)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  1.3613 (1.5328)  Acc@1: 68.7500 (63.6500)  Acc@5: 87.5000 (88.7700)
Test (EMA): [Whole Val]  Time: 9.747  Loss: 1.5328  Acc@1: 63.6500 Pruned: 54.14% 
Train: 58 [   0/390 (  0%)]  Loss: 4.080 (4.08)  Time: 0.805s,  158.91/s  (0.805s,  158.91/s)  LR: 3.757e-04  Data: 0.502 (0.502)
Train: 58 [ 100/390 ( 26%)]  Loss: 3.012 (3.55)  Time: 0.315s,  406.79/s  (0.321s,  398.92/s)  LR: 3.757e-04  Data: 0.012 (0.017)
Train: 58 [ 200/390 ( 51%)]  Loss: 4.023 (3.59)  Time: 0.313s,  408.91/s  (0.318s,  402.44/s)  LR: 3.757e-04  Data: 0.011 (0.015)
Train: 58 [ 300/390 ( 77%)]  Loss: 3.925 (3.60)  Time: 0.313s,  409.07/s  (0.317s,  403.67/s)  LR: 3.757e-04  Data: 0.011 (0.014)
Train: 58 [ 389/390 (100%)]  Loss: 3.702 (3.59)  Time: 0.302s,  423.68/s  (0.317s,  404.19/s)  LR: 3.757e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.326 (0.326)  Loss:  1.4863 (1.4863)  Acc@1: 63.2812 (63.2812)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.4307 (1.5615)  Acc@1: 68.7500 (63.7300)  Acc@5: 87.5000 (88.9800)
Test: [Whole Val]  Time: 9.614  Loss: 1.5615  Acc@1: 63.7300 Pruned: 54.08% 
Test (EMA): [   0/78]  Time: 0.339 (0.339)  Loss:  1.4980 (1.4980)  Acc@1: 62.5000 (62.5000)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  1.4229 (1.5593)  Acc@1: 68.7500 (63.3500)  Acc@5: 93.7500 (89.1700)
Test (EMA): [Whole Val]  Time: 9.655  Loss: 1.5593  Acc@1: 63.3500 Pruned: 54.09% 
Train: 59 [   0/390 (  0%)]  Loss: 3.770 (3.77)  Time: 0.779s,  164.28/s  (0.779s,  164.28/s)  LR: 3.606e-04  Data: 0.476 (0.476)
Train: 59 [ 100/390 ( 26%)]  Loss: 2.927 (3.56)  Time: 0.316s,  404.77/s  (0.320s,  399.77/s)  LR: 3.606e-04  Data: 0.012 (0.017)
Train: 59 [ 200/390 ( 51%)]  Loss: 3.970 (3.58)  Time: 0.318s,  402.48/s  (0.318s,  402.57/s)  LR: 3.606e-04  Data: 0.015 (0.015)
Train: 59 [ 300/390 ( 77%)]  Loss: 3.012 (3.59)  Time: 0.314s,  408.16/s  (0.317s,  403.66/s)  LR: 3.606e-04  Data: 0.012 (0.014)
Train: 59 [ 389/390 (100%)]  Loss: 4.070 (3.60)  Time: 0.304s,  421.29/s  (0.317s,  404.25/s)  LR: 3.606e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.422 (0.422)  Loss:  1.4863 (1.4863)  Acc@1: 64.0625 (64.0625)  Acc@5: 89.0625 (89.0625)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  1.4043 (1.5541)  Acc@1: 75.0000 (63.2900)  Acc@5: 81.2500 (88.7200)
Test: [Whole Val]  Time: 9.705  Loss: 1.5541  Acc@1: 63.2900 Pruned: 54.11% 
Test (EMA): [   0/78]  Time: 0.411 (0.411)  Loss:  1.4746 (1.4746)  Acc@1: 67.9688 (67.9688)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  1.4043 (1.5500)  Acc@1: 68.7500 (63.5800)  Acc@5: 81.2500 (89.0400)
Test (EMA): [Whole Val]  Time: 9.726  Loss: 1.5500  Acc@1: 63.5800 Pruned: 54.10% 
Train: 60 [   0/390 (  0%)]  Loss: 3.979 (3.98)  Time: 0.785s,  163.04/s  (0.785s,  163.04/s)  LR: 3.456e-04  Data: 0.468 (0.468)
Train: 60 [ 100/390 ( 26%)]  Loss: 3.936 (3.55)  Time: 0.322s,  397.04/s  (0.320s,  399.52/s)  LR: 3.456e-04  Data: 0.021 (0.017)
Train: 60 [ 200/390 ( 51%)]  Loss: 3.750 (3.59)  Time: 0.316s,  405.22/s  (0.318s,  402.52/s)  LR: 3.456e-04  Data: 0.013 (0.015)
Train: 60 [ 300/390 ( 77%)]  Loss: 3.887 (3.59)  Time: 0.312s,  409.93/s  (0.317s,  404.31/s)  LR: 3.456e-04  Data: 0.011 (0.014)
Train: 60 [ 389/390 (100%)]  Loss: 3.887 (3.58)  Time: 0.307s,  417.11/s  (0.317s,  404.08/s)  LR: 3.456e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.365 (0.365)  Loss:  1.4941 (1.4941)  Acc@1: 62.5000 (62.5000)  Acc@5: 89.8438 (89.8438)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  1.3809 (1.5541)  Acc@1: 75.0000 (63.4800)  Acc@5: 81.2500 (88.3900)
Test: [Whole Val]  Time: 9.681  Loss: 1.5541  Acc@1: 63.4800 Pruned: 54.06% 
Test (EMA): [   0/78]  Time: 0.329 (0.329)  Loss:  1.4795 (1.4795)  Acc@1: 64.8438 (64.8438)  Acc@5: 88.2812 (88.2812)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  1.3496 (1.5307)  Acc@1: 75.0000 (63.9400)  Acc@5: 87.5000 (88.7200)
Test (EMA): [Whole Val]  Time: 9.663  Loss: 1.5307  Acc@1: 63.9400 Pruned: 54.05% 
Train: 61 [   0/390 (  0%)]  Loss: 3.921 (3.92)  Time: 0.847s,  151.08/s  (0.847s,  151.08/s)  LR: 3.307e-04  Data: 0.541 (0.541)
Train: 61 [ 100/390 ( 26%)]  Loss: 3.965 (3.55)  Time: 0.317s,  403.93/s  (0.322s,  397.42/s)  LR: 3.307e-04  Data: 0.013 (0.018)
Train: 61 [ 200/390 ( 51%)]  Loss: 3.844 (3.57)  Time: 0.317s,  404.00/s  (0.319s,  401.24/s)  LR: 3.307e-04  Data: 0.013 (0.015)
Train: 61 [ 300/390 ( 77%)]  Loss: 2.961 (3.57)  Time: 0.315s,  406.18/s  (0.318s,  402.29/s)  LR: 3.307e-04  Data: 0.012 (0.014)
Train: 61 [ 389/390 (100%)]  Loss: 3.895 (3.58)  Time: 0.303s,  423.05/s  (0.318s,  402.93/s)  LR: 3.307e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.425 (0.425)  Loss:  1.4668 (1.4668)  Acc@1: 64.0625 (64.0625)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.017 (0.123)  Loss:  1.4492 (1.5580)  Acc@1: 68.7500 (63.8100)  Acc@5: 81.2500 (88.9800)
Test: [Whole Val]  Time: 9.750  Loss: 1.5580  Acc@1: 63.8100 Pruned: 54.05% 
Test (EMA): [   0/78]  Time: 0.377 (0.377)  Loss:  1.4707 (1.4707)  Acc@1: 64.8438 (64.8438)  Acc@5: 89.8438 (89.8438)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  1.4219 (1.5515)  Acc@1: 68.7500 (64.1700)  Acc@5: 81.2500 (89.1600)
Test (EMA): [Whole Val]  Time: 9.677  Loss: 1.5515  Acc@1: 64.1700 Pruned: 54.04% 
Train: 62 [   0/390 (  0%)]  Loss: 3.280 (3.28)  Time: 0.743s,  172.29/s  (0.743s,  172.29/s)  LR: 3.160e-04  Data: 0.440 (0.440)
Train: 62 [ 100/390 ( 26%)]  Loss: 3.852 (3.63)  Time: 0.317s,  403.18/s  (0.320s,  400.09/s)  LR: 3.160e-04  Data: 0.014 (0.017)
Train: 62 [ 200/390 ( 51%)]  Loss: 3.726 (3.60)  Time: 0.323s,  396.66/s  (0.318s,  402.59/s)  LR: 3.160e-04  Data: 0.012 (0.015)
Train: 62 [ 300/390 ( 77%)]  Loss: 4.065 (3.58)  Time: 0.315s,  406.48/s  (0.317s,  403.64/s)  LR: 3.160e-04  Data: 0.012 (0.014)
Train: 62 [ 389/390 (100%)]  Loss: 3.204 (3.57)  Time: 0.304s,  421.67/s  (0.317s,  403.99/s)  LR: 3.160e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.396 (0.396)  Loss:  1.4551 (1.4551)  Acc@1: 63.2812 (63.2812)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  1.4150 (1.5330)  Acc@1: 75.0000 (63.8900)  Acc@5: 81.2500 (89.1400)
Test: [Whole Val]  Time: 9.701  Loss: 1.5330  Acc@1: 63.8900 Pruned: 54.00% 
Test (EMA): [   0/78]  Time: 0.332 (0.332)  Loss:  1.4541 (1.4541)  Acc@1: 62.5000 (62.5000)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  1.3711 (1.5395)  Acc@1: 75.0000 (63.8200)  Acc@5: 87.5000 (88.9400)
Test (EMA): [Whole Val]  Time: 9.642  Loss: 1.5395  Acc@1: 63.8200 Pruned: 54.01% 
Train: 63 [   0/390 (  0%)]  Loss: 3.864 (3.86)  Time: 0.872s,  146.72/s  (0.872s,  146.72/s)  LR: 3.015e-04  Data: 0.568 (0.568)
Train: 63 [ 100/390 ( 26%)]  Loss: 3.196 (3.57)  Time: 0.314s,  407.85/s  (0.321s,  398.62/s)  LR: 3.015e-04  Data: 0.011 (0.018)
Train: 63 [ 200/390 ( 51%)]  Loss: 2.832 (3.58)  Time: 0.315s,  406.71/s  (0.318s,  402.05/s)  LR: 3.015e-04  Data: 0.012 (0.015)
Train: 63 [ 300/390 ( 77%)]  Loss: 3.522 (3.60)  Time: 0.314s,  407.95/s  (0.317s,  403.33/s)  LR: 3.015e-04  Data: 0.012 (0.014)
Train: 63 [ 389/390 (100%)]  Loss: 3.061 (3.59)  Time: 0.303s,  423.03/s  (0.317s,  403.87/s)  LR: 3.015e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.408 (0.408)  Loss:  1.4570 (1.4570)  Acc@1: 67.9688 (67.9688)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  1.4131 (1.5486)  Acc@1: 68.7500 (63.7100)  Acc@5: 87.5000 (88.8800)
Test: [Whole Val]  Time: 9.710  Loss: 1.5486  Acc@1: 63.7100 Pruned: 53.99% 
Test (EMA): [   0/78]  Time: 0.345 (0.345)  Loss:  1.4531 (1.4531)  Acc@1: 66.4062 (66.4062)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  1.4297 (1.5499)  Acc@1: 68.7500 (63.8800)  Acc@5: 87.5000 (88.9300)
Test (EMA): [Whole Val]  Time: 9.668  Loss: 1.5499  Acc@1: 63.8800 Pruned: 53.99% 
Train: 64 [   0/390 (  0%)]  Loss: 4.042 (4.04)  Time: 0.937s,  136.67/s  (0.937s,  136.67/s)  LR: 2.872e-04  Data: 0.602 (0.602)
Train: 64 [ 100/390 ( 26%)]  Loss: 3.745 (3.58)  Time: 0.315s,  405.98/s  (0.322s,  397.06/s)  LR: 2.872e-04  Data: 0.012 (0.019)
Train: 64 [ 200/390 ( 51%)]  Loss: 3.474 (3.57)  Time: 0.315s,  406.49/s  (0.320s,  400.42/s)  LR: 2.872e-04  Data: 0.013 (0.016)
Train: 64 [ 300/390 ( 77%)]  Loss: 3.207 (3.58)  Time: 0.314s,  407.81/s  (0.318s,  402.02/s)  LR: 2.872e-04  Data: 0.012 (0.014)
Train: 64 [ 389/390 (100%)]  Loss: 3.254 (3.59)  Time: 0.303s,  422.79/s  (0.318s,  403.03/s)  LR: 2.872e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.368 (0.368)  Loss:  1.5000 (1.5000)  Acc@1: 64.0625 (64.0625)  Acc@5: 89.8438 (89.8438)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  1.3936 (1.5736)  Acc@1: 68.7500 (63.7100)  Acc@5: 81.2500 (89.1400)
Test: [Whole Val]  Time: 9.697  Loss: 1.5736  Acc@1: 63.7100 Pruned: 53.99% 
Test (EMA): [   0/78]  Time: 0.325 (0.325)  Loss:  1.4697 (1.4697)  Acc@1: 67.1875 (67.1875)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  1.3809 (1.5535)  Acc@1: 68.7500 (63.9500)  Acc@5: 81.2500 (89.0900)
Test (EMA): [Whole Val]  Time: 9.620  Loss: 1.5535  Acc@1: 63.9500 Pruned: 53.99% 
Train: 65 [   0/390 (  0%)]  Loss: 3.269 (3.27)  Time: 0.802s,  159.53/s  (0.802s,  159.53/s)  LR: 2.731e-04  Data: 0.499 (0.499)
Train: 65 [ 100/390 ( 26%)]  Loss: 3.175 (3.55)  Time: 0.317s,  403.64/s  (0.320s,  399.67/s)  LR: 2.731e-04  Data: 0.013 (0.017)
Train: 65 [ 200/390 ( 51%)]  Loss: 3.931 (3.55)  Time: 0.317s,  404.26/s  (0.318s,  402.83/s)  LR: 2.731e-04  Data: 0.012 (0.015)
Train: 65 [ 300/390 ( 77%)]  Loss: 3.257 (3.55)  Time: 0.322s,  397.43/s  (0.317s,  403.92/s)  LR: 2.731e-04  Data: 0.012 (0.014)
Train: 65 [ 389/390 (100%)]  Loss: 3.900 (3.56)  Time: 0.303s,  423.00/s  (0.317s,  404.39/s)  LR: 2.731e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.317 (0.317)  Loss:  1.4473 (1.4473)  Acc@1: 65.6250 (65.6250)  Acc@5: 88.2812 (88.2812)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.4258 (1.5425)  Acc@1: 62.5000 (63.6700)  Acc@5: 87.5000 (88.9200)
Test: [Whole Val]  Time: 9.621  Loss: 1.5425  Acc@1: 63.6700 Pruned: 53.95% 
Test (EMA): [   0/78]  Time: 0.422 (0.422)  Loss:  1.4463 (1.4463)  Acc@1: 66.4062 (66.4062)  Acc@5: 89.0625 (89.0625)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  1.3887 (1.5304)  Acc@1: 68.7500 (63.9900)  Acc@5: 87.5000 (89.1700)
Test (EMA): [Whole Val]  Time: 9.743  Loss: 1.5304  Acc@1: 63.9900 Pruned: 53.95% 
Train: 66 [   0/390 (  0%)]  Loss: 3.991 (3.99)  Time: 0.819s,  156.25/s  (0.819s,  156.25/s)  LR: 2.592e-04  Data: 0.497 (0.497)
Train: 66 [ 100/390 ( 26%)]  Loss: 3.829 (3.53)  Time: 0.325s,  393.67/s  (0.326s,  392.07/s)  LR: 2.592e-04  Data: 0.013 (0.019)
Train: 66 [ 200/390 ( 51%)]  Loss: 3.846 (3.49)  Time: 0.323s,  396.59/s  (0.323s,  396.74/s)  LR: 2.592e-04  Data: 0.013 (0.016)
Train: 66 [ 300/390 ( 77%)]  Loss: 3.785 (3.51)  Time: 0.315s,  406.11/s  (0.321s,  399.28/s)  LR: 2.592e-04  Data: 0.013 (0.015)
Train: 66 [ 389/390 (100%)]  Loss: 3.656 (3.53)  Time: 0.302s,  423.31/s  (0.319s,  400.69/s)  LR: 2.592e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.385 (0.385)  Loss:  1.4551 (1.4551)  Acc@1: 65.6250 (65.6250)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  1.4502 (1.5314)  Acc@1: 68.7500 (64.1100)  Acc@5: 87.5000 (89.3000)
Test: [Whole Val]  Time: 9.710  Loss: 1.5314  Acc@1: 64.1100 Pruned: 53.94% 
Test (EMA): [   0/78]  Time: 0.397 (0.397)  Loss:  1.4375 (1.4375)  Acc@1: 68.7500 (68.7500)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  1.4307 (1.5227)  Acc@1: 68.7500 (64.4100)  Acc@5: 87.5000 (89.3100)
Test (EMA): [Whole Val]  Time: 9.723  Loss: 1.5227  Acc@1: 64.4100 Pruned: 53.95% 
Train: 67 [   0/390 (  0%)]  Loss: 3.950 (3.95)  Time: 0.862s,  148.50/s  (0.862s,  148.50/s)  LR: 2.456e-04  Data: 0.558 (0.558)
Train: 67 [ 100/390 ( 26%)]  Loss: 3.887 (3.57)  Time: 0.314s,  408.19/s  (0.322s,  396.97/s)  LR: 2.456e-04  Data: 0.012 (0.018)
Train: 67 [ 200/390 ( 51%)]  Loss: 3.859 (3.57)  Time: 0.315s,  406.53/s  (0.319s,  400.82/s)  LR: 2.456e-04  Data: 0.012 (0.015)
Train: 67 [ 300/390 ( 77%)]  Loss: 3.577 (3.55)  Time: 0.317s,  403.76/s  (0.319s,  401.55/s)  LR: 2.456e-04  Data: 0.014 (0.015)
Train: 67 [ 389/390 (100%)]  Loss: 3.821 (3.55)  Time: 0.303s,  421.76/s  (0.318s,  402.41/s)  LR: 2.456e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.342 (0.342)  Loss:  1.4619 (1.4619)  Acc@1: 62.5000 (62.5000)  Acc@5: 89.0625 (89.0625)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.4111 (1.5282)  Acc@1: 62.5000 (63.9400)  Acc@5: 87.5000 (89.3000)
Test: [Whole Val]  Time: 9.672  Loss: 1.5282  Acc@1: 63.9400 Pruned: 53.93% 
Test (EMA): [   0/78]  Time: 0.427 (0.427)  Loss:  1.4492 (1.4492)  Acc@1: 65.6250 (65.6250)  Acc@5: 89.0625 (89.0625)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  1.3916 (1.5156)  Acc@1: 68.7500 (64.2200)  Acc@5: 81.2500 (89.3500)
Test (EMA): [Whole Val]  Time: 9.725  Loss: 1.5156  Acc@1: 64.2200 Pruned: 53.94% 
Train: 68 [   0/390 (  0%)]  Loss: 3.353 (3.35)  Time: 0.859s,  149.03/s  (0.859s,  149.03/s)  LR: 2.322e-04  Data: 0.551 (0.551)
Train: 68 [ 100/390 ( 26%)]  Loss: 3.555 (3.53)  Time: 0.315s,  406.30/s  (0.321s,  398.38/s)  LR: 2.322e-04  Data: 0.012 (0.018)
Train: 68 [ 200/390 ( 51%)]  Loss: 3.425 (3.52)  Time: 0.315s,  406.31/s  (0.319s,  401.85/s)  LR: 2.322e-04  Data: 0.012 (0.015)
Train: 68 [ 300/390 ( 77%)]  Loss: 2.917 (3.54)  Time: 0.314s,  407.93/s  (0.317s,  403.29/s)  LR: 2.322e-04  Data: 0.012 (0.014)
Train: 68 [ 389/390 (100%)]  Loss: 4.056 (3.56)  Time: 0.303s,  422.95/s  (0.317s,  404.03/s)  LR: 2.322e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.317 (0.317)  Loss:  1.4346 (1.4346)  Acc@1: 68.7500 (68.7500)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.4121 (1.5272)  Acc@1: 68.7500 (64.4200)  Acc@5: 81.2500 (89.4900)
Test: [Whole Val]  Time: 9.617  Loss: 1.5272  Acc@1: 64.4200 Pruned: 53.90% 
Test (EMA): [   0/78]  Time: 0.391 (0.391)  Loss:  1.4365 (1.4365)  Acc@1: 70.3125 (70.3125)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.020 (0.123)  Loss:  1.4033 (1.5262)  Acc@1: 62.5000 (64.3900)  Acc@5: 81.2500 (89.4600)
Test (EMA): [Whole Val]  Time: 9.680  Loss: 1.5262  Acc@1: 64.3900 Pruned: 53.90% 
Train: 69 [   0/390 (  0%)]  Loss: 3.781 (3.78)  Time: 1.020s,  125.54/s  (1.020s,  125.54/s)  LR: 2.190e-04  Data: 0.704 (0.704)
Train: 69 [ 100/390 ( 26%)]  Loss: 3.964 (3.61)  Time: 0.320s,  400.09/s  (0.322s,  397.58/s)  LR: 2.190e-04  Data: 0.016 (0.019)
Train: 69 [ 200/390 ( 51%)]  Loss: 2.962 (3.58)  Time: 0.315s,  405.78/s  (0.319s,  401.62/s)  LR: 2.190e-04  Data: 0.011 (0.016)
Train: 69 [ 300/390 ( 77%)]  Loss: 3.798 (3.56)  Time: 0.320s,  400.37/s  (0.318s,  403.01/s)  LR: 2.190e-04  Data: 0.014 (0.015)
Train: 69 [ 389/390 (100%)]  Loss: 3.905 (3.57)  Time: 0.303s,  422.38/s  (0.317s,  403.75/s)  LR: 2.190e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.423 (0.423)  Loss:  1.4248 (1.4248)  Acc@1: 64.0625 (64.0625)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.019 (0.123)  Loss:  1.3906 (1.5188)  Acc@1: 68.7500 (64.0500)  Acc@5: 81.2500 (89.5000)
Test: [Whole Val]  Time: 9.704  Loss: 1.5188  Acc@1: 64.0500 Pruned: 53.89% 
Test (EMA): [   0/78]  Time: 0.429 (0.429)  Loss:  1.4268 (1.4268)  Acc@1: 64.8438 (64.8438)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  1.3936 (1.5196)  Acc@1: 68.7500 (64.2300)  Acc@5: 81.2500 (89.5100)
Test (EMA): [Whole Val]  Time: 9.743  Loss: 1.5196  Acc@1: 64.2300 Pruned: 53.88% 
Train: 70 [   0/390 (  0%)]  Loss: 3.578 (3.58)  Time: 0.784s,  163.19/s  (0.784s,  163.19/s)  LR: 2.062e-04  Data: 0.480 (0.480)
Train: 70 [ 100/390 ( 26%)]  Loss: 3.840 (3.54)  Time: 0.314s,  407.10/s  (0.320s,  399.44/s)  LR: 2.062e-04  Data: 0.012 (0.017)
Train: 70 [ 200/390 ( 51%)]  Loss: 3.525 (3.57)  Time: 0.313s,  408.67/s  (0.318s,  401.97/s)  LR: 2.062e-04  Data: 0.012 (0.015)
Train: 70 [ 300/390 ( 77%)]  Loss: 3.765 (3.57)  Time: 0.315s,  406.38/s  (0.318s,  403.02/s)  LR: 2.062e-04  Data: 0.012 (0.014)
Train: 70 [ 389/390 (100%)]  Loss: 3.328 (3.59)  Time: 0.302s,  423.29/s  (0.317s,  403.44/s)  LR: 2.062e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.328 (0.328)  Loss:  1.4434 (1.4434)  Acc@1: 67.1875 (67.1875)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  1.4492 (1.5479)  Acc@1: 68.7500 (64.4100)  Acc@5: 81.2500 (89.2600)
Test: [Whole Val]  Time: 9.630  Loss: 1.5479  Acc@1: 64.4100 Pruned: 53.93% 
Test (EMA): [   0/78]  Time: 0.326 (0.326)  Loss:  1.4434 (1.4434)  Acc@1: 67.1875 (67.1875)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  1.4424 (1.5412)  Acc@1: 68.7500 (64.5500)  Acc@5: 81.2500 (89.4000)
Test (EMA): [Whole Val]  Time: 9.619  Loss: 1.5412  Acc@1: 64.5500 Pruned: 53.91% 
Train: 71 [   0/390 (  0%)]  Loss: 3.863 (3.86)  Time: 0.847s,  151.15/s  (0.847s,  151.15/s)  LR: 1.936e-04  Data: 0.520 (0.520)
Train: 71 [ 100/390 ( 26%)]  Loss: 3.549 (3.60)  Time: 0.314s,  407.25/s  (0.322s,  397.59/s)  LR: 1.936e-04  Data: 0.012 (0.017)
Train: 71 [ 200/390 ( 51%)]  Loss: 2.998 (3.57)  Time: 0.317s,  403.87/s  (0.319s,  401.82/s)  LR: 1.936e-04  Data: 0.013 (0.015)
Train: 71 [ 300/390 ( 77%)]  Loss: 3.187 (3.54)  Time: 0.314s,  408.28/s  (0.318s,  402.62/s)  LR: 1.936e-04  Data: 0.011 (0.014)
Train: 71 [ 389/390 (100%)]  Loss: 3.230 (3.55)  Time: 0.304s,  420.99/s  (0.317s,  403.35/s)  LR: 1.936e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.445 (0.445)  Loss:  1.4199 (1.4199)  Acc@1: 67.9688 (67.9688)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.018 (0.124)  Loss:  1.3789 (1.5262)  Acc@1: 68.7500 (64.5300)  Acc@5: 81.2500 (89.4100)
Test: [Whole Val]  Time: 9.765  Loss: 1.5262  Acc@1: 64.5300 Pruned: 53.92% 
Test (EMA): [   0/78]  Time: 0.398 (0.398)  Loss:  1.4180 (1.4180)  Acc@1: 67.1875 (67.1875)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  1.3545 (1.5189)  Acc@1: 75.0000 (64.5300)  Acc@5: 81.2500 (89.4300)
Test (EMA): [Whole Val]  Time: 9.718  Loss: 1.5189  Acc@1: 64.5300 Pruned: 53.93% 
Train: 72 [   0/390 (  0%)]  Loss: 2.995 (2.99)  Time: 0.937s,  136.60/s  (0.937s,  136.60/s)  LR: 1.814e-04  Data: 0.634 (0.634)
Train: 72 [ 100/390 ( 26%)]  Loss: 3.483 (3.52)  Time: 0.315s,  405.83/s  (0.322s,  398.10/s)  LR: 1.814e-04  Data: 0.012 (0.018)
Train: 72 [ 200/390 ( 51%)]  Loss: 3.545 (3.54)  Time: 0.313s,  408.61/s  (0.319s,  401.75/s)  LR: 1.814e-04  Data: 0.012 (0.015)
Train: 72 [ 300/390 ( 77%)]  Loss: 3.936 (3.54)  Time: 0.314s,  408.25/s  (0.318s,  402.79/s)  LR: 1.814e-04  Data: 0.012 (0.014)
Train: 72 [ 389/390 (100%)]  Loss: 3.415 (3.55)  Time: 0.303s,  422.87/s  (0.317s,  403.58/s)  LR: 1.814e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.319 (0.319)  Loss:  1.4287 (1.4287)  Acc@1: 66.4062 (66.4062)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  1.3926 (1.5328)  Acc@1: 75.0000 (64.3200)  Acc@5: 87.5000 (89.3800)
Test: [Whole Val]  Time: 9.607  Loss: 1.5328  Acc@1: 64.3200 Pruned: 53.90% 
Test (EMA): [   0/78]  Time: 0.442 (0.442)  Loss:  1.4219 (1.4219)  Acc@1: 67.1875 (67.1875)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  1.4072 (1.5217)  Acc@1: 68.7500 (64.4900)  Acc@5: 81.2500 (89.5000)
Test (EMA): [Whole Val]  Time: 9.750  Loss: 1.5217  Acc@1: 64.4900 Pruned: 53.89% 
Train: 73 [   0/390 (  0%)]  Loss: 2.831 (2.83)  Time: 0.859s,  149.07/s  (0.859s,  149.07/s)  LR: 1.694e-04  Data: 0.554 (0.554)
Train: 73 [ 100/390 ( 26%)]  Loss: 3.629 (3.54)  Time: 0.314s,  408.24/s  (0.321s,  398.47/s)  LR: 1.694e-04  Data: 0.012 (0.018)
Train: 73 [ 200/390 ( 51%)]  Loss: 3.914 (3.54)  Time: 0.314s,  407.40/s  (0.318s,  402.08/s)  LR: 1.694e-04  Data: 0.012 (0.015)
Train: 73 [ 300/390 ( 77%)]  Loss: 3.046 (3.55)  Time: 0.316s,  404.79/s  (0.317s,  403.24/s)  LR: 1.694e-04  Data: 0.014 (0.014)
Train: 73 [ 389/390 (100%)]  Loss: 3.979 (3.57)  Time: 0.303s,  421.94/s  (0.317s,  403.89/s)  LR: 1.694e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.402 (0.402)  Loss:  1.4316 (1.4316)  Acc@1: 67.1875 (67.1875)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  1.3506 (1.5215)  Acc@1: 75.0000 (64.7200)  Acc@5: 81.2500 (89.4500)
Test: [Whole Val]  Time: 9.706  Loss: 1.5215  Acc@1: 64.7200 Pruned: 53.90% 
Test (EMA): [   0/78]  Time: 0.415 (0.415)  Loss:  1.4326 (1.4326)  Acc@1: 66.4062 (66.4062)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.017 (0.124)  Loss:  1.3555 (1.5239)  Acc@1: 75.0000 (64.8100)  Acc@5: 81.2500 (89.4700)
Test (EMA): [Whole Val]  Time: 9.758  Loss: 1.5239  Acc@1: 64.8100 Pruned: 53.91% 
Train: 74 [   0/390 (  0%)]  Loss: 3.478 (3.48)  Time: 0.916s,  139.79/s  (0.916s,  139.79/s)  LR: 1.578e-04  Data: 0.603 (0.603)
Train: 74 [ 100/390 ( 26%)]  Loss: 3.678 (3.55)  Time: 0.319s,  401.71/s  (0.323s,  395.95/s)  LR: 1.578e-04  Data: 0.015 (0.018)
Train: 74 [ 200/390 ( 51%)]  Loss: 3.634 (3.53)  Time: 0.315s,  406.79/s  (0.319s,  401.02/s)  LR: 1.578e-04  Data: 0.012 (0.015)
Train: 74 [ 300/390 ( 77%)]  Loss: 3.372 (3.56)  Time: 0.314s,  407.28/s  (0.318s,  402.61/s)  LR: 1.578e-04  Data: 0.011 (0.014)
Train: 74 [ 389/390 (100%)]  Loss: 3.918 (3.55)  Time: 0.302s,  423.18/s  (0.317s,  403.38/s)  LR: 1.578e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.396 (0.396)  Loss:  1.4062 (1.4062)  Acc@1: 67.9688 (67.9688)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.017 (0.123)  Loss:  1.3350 (1.5006)  Acc@1: 68.7500 (65.0200)  Acc@5: 81.2500 (89.5300)
Test: [Whole Val]  Time: 9.700  Loss: 1.5006  Acc@1: 65.0200 Pruned: 53.89% 
Test (EMA): [   0/78]  Time: 0.388 (0.388)  Loss:  1.4160 (1.4160)  Acc@1: 67.1875 (67.1875)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.017 (0.123)  Loss:  1.3398 (1.4999)  Acc@1: 68.7500 (65.0000)  Acc@5: 81.2500 (89.5900)
Test (EMA): [Whole Val]  Time: 9.678  Loss: 1.4999  Acc@1: 65.0000 Pruned: 53.89% 
Train: 75 [   0/390 (  0%)]  Loss: 3.723 (3.72)  Time: 0.763s,  167.84/s  (0.763s,  167.84/s)  LR: 1.465e-04  Data: 0.450 (0.450)
Train: 75 [ 100/390 ( 26%)]  Loss: 3.372 (3.52)  Time: 0.314s,  407.20/s  (0.320s,  399.89/s)  LR: 1.465e-04  Data: 0.012 (0.017)
Train: 75 [ 200/390 ( 51%)]  Loss: 2.922 (3.53)  Time: 0.314s,  407.34/s  (0.317s,  403.25/s)  LR: 1.465e-04  Data: 0.012 (0.015)
Train: 75 [ 300/390 ( 77%)]  Loss: 3.405 (3.52)  Time: 0.314s,  407.69/s  (0.317s,  404.06/s)  LR: 1.465e-04  Data: 0.011 (0.014)
Train: 75 [ 389/390 (100%)]  Loss: 2.938 (3.51)  Time: 0.305s,  419.84/s  (0.316s,  404.65/s)  LR: 1.465e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.428 (0.428)  Loss:  1.4170 (1.4170)  Acc@1: 64.0625 (64.0625)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.017 (0.123)  Loss:  1.3164 (1.5029)  Acc@1: 75.0000 (64.5700)  Acc@5: 81.2500 (89.4300)
Test: [Whole Val]  Time: 9.732  Loss: 1.5029  Acc@1: 64.5700 Pruned: 53.87% 
Test (EMA): [   0/78]  Time: 0.347 (0.347)  Loss:  1.4141 (1.4141)  Acc@1: 64.8438 (64.8438)  Acc@5: 89.8438 (89.8438)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  1.3174 (1.4968)  Acc@1: 75.0000 (64.8200)  Acc@5: 81.2500 (89.6200)
Test (EMA): [Whole Val]  Time: 9.659  Loss: 1.4968  Acc@1: 64.8200 Pruned: 53.86% 
Train: 76 [   0/390 (  0%)]  Loss: 3.777 (3.78)  Time: 0.799s,  160.13/s  (0.799s,  160.13/s)  LR: 1.356e-04  Data: 0.497 (0.497)
Train: 76 [ 100/390 ( 26%)]  Loss: 3.838 (3.55)  Time: 0.314s,  407.21/s  (0.320s,  400.19/s)  LR: 1.356e-04  Data: 0.013 (0.017)
Train: 76 [ 200/390 ( 51%)]  Loss: 3.483 (3.55)  Time: 0.316s,  405.60/s  (0.318s,  402.73/s)  LR: 1.356e-04  Data: 0.013 (0.015)
Train: 76 [ 300/390 ( 77%)]  Loss: 3.859 (3.57)  Time: 0.316s,  404.65/s  (0.317s,  403.63/s)  LR: 1.356e-04  Data: 0.012 (0.014)
Train: 76 [ 389/390 (100%)]  Loss: 3.544 (3.57)  Time: 0.305s,  420.19/s  (0.317s,  404.15/s)  LR: 1.356e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.319 (0.319)  Loss:  1.4424 (1.4424)  Acc@1: 65.6250 (65.6250)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  1.3281 (1.5255)  Acc@1: 75.0000 (64.4100)  Acc@5: 81.2500 (89.4200)
Test: [Whole Val]  Time: 9.668  Loss: 1.5255  Acc@1: 64.4100 Pruned: 53.86% 
Test (EMA): [   0/78]  Time: 0.311 (0.311)  Loss:  1.4385 (1.4385)  Acc@1: 66.4062 (66.4062)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  1.3281 (1.5212)  Acc@1: 75.0000 (64.5200)  Acc@5: 81.2500 (89.4600)
Test (EMA): [Whole Val]  Time: 9.674  Loss: 1.5212  Acc@1: 64.5200 Pruned: 53.86% 
Train: 77 [   0/390 (  0%)]  Loss: 2.789 (2.79)  Time: 0.779s,  164.26/s  (0.779s,  164.26/s)  LR: 1.250e-04  Data: 0.476 (0.476)
Train: 77 [ 100/390 ( 26%)]  Loss: 2.914 (3.49)  Time: 0.315s,  406.40/s  (0.320s,  399.66/s)  LR: 1.250e-04  Data: 0.013 (0.017)
Train: 77 [ 200/390 ( 51%)]  Loss: 3.660 (3.53)  Time: 0.314s,  407.00/s  (0.318s,  402.11/s)  LR: 1.250e-04  Data: 0.012 (0.015)
Train: 77 [ 300/390 ( 77%)]  Loss: 3.471 (3.54)  Time: 0.314s,  407.04/s  (0.317s,  403.27/s)  LR: 1.250e-04  Data: 0.012 (0.014)
Train: 77 [ 389/390 (100%)]  Loss: 3.226 (3.54)  Time: 0.303s,  422.39/s  (0.317s,  403.80/s)  LR: 1.250e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.374 (0.374)  Loss:  1.4014 (1.4014)  Acc@1: 68.7500 (68.7500)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  1.3506 (1.5112)  Acc@1: 75.0000 (64.6700)  Acc@5: 81.2500 (89.4700)
Test: [Whole Val]  Time: 9.657  Loss: 1.5112  Acc@1: 64.6700 Pruned: 53.87% 
Test (EMA): [   0/78]  Time: 0.336 (0.336)  Loss:  1.3975 (1.3975)  Acc@1: 69.5312 (69.5312)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  1.3350 (1.5058)  Acc@1: 75.0000 (64.8900)  Acc@5: 81.2500 (89.6000)
Test (EMA): [Whole Val]  Time: 9.646  Loss: 1.5058  Acc@1: 64.8900 Pruned: 53.86% 
Train: 78 [   0/390 (  0%)]  Loss: 3.911 (3.91)  Time: 0.819s,  156.27/s  (0.819s,  156.27/s)  LR: 1.148e-04  Data: 0.514 (0.514)
Train: 78 [ 100/390 ( 26%)]  Loss: 4.066 (3.62)  Time: 0.315s,  406.62/s  (0.321s,  398.22/s)  LR: 1.148e-04  Data: 0.012 (0.017)
Train: 78 [ 200/390 ( 51%)]  Loss: 3.963 (3.56)  Time: 0.312s,  410.38/s  (0.318s,  402.59/s)  LR: 1.148e-04  Data: 0.011 (0.015)
Train: 78 [ 300/390 ( 77%)]  Loss: 3.304 (3.54)  Time: 0.314s,  407.20/s  (0.317s,  403.55/s)  LR: 1.148e-04  Data: 0.011 (0.014)
Train: 78 [ 389/390 (100%)]  Loss: 2.951 (3.55)  Time: 0.304s,  420.40/s  (0.317s,  403.99/s)  LR: 1.148e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.399 (0.399)  Loss:  1.4414 (1.4414)  Acc@1: 64.8438 (64.8438)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.018 (0.123)  Loss:  1.3320 (1.5116)  Acc@1: 75.0000 (64.6100)  Acc@5: 87.5000 (89.6300)
Test: [Whole Val]  Time: 9.704  Loss: 1.5116  Acc@1: 64.6100 Pruned: 53.84% 
Test (EMA): [   0/78]  Time: 0.321 (0.321)  Loss:  1.4395 (1.4395)  Acc@1: 65.6250 (65.6250)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  1.3232 (1.5133)  Acc@1: 75.0000 (64.6200)  Acc@5: 87.5000 (89.5500)
Test (EMA): [Whole Val]  Time: 9.639  Loss: 1.5133  Acc@1: 64.6200 Pruned: 53.84% 
Train: 79 [   0/390 (  0%)]  Loss: 3.474 (3.47)  Time: 0.787s,  162.64/s  (0.787s,  162.64/s)  LR: 1.050e-04  Data: 0.481 (0.481)
Train: 79 [ 100/390 ( 26%)]  Loss: 3.879 (3.41)  Time: 0.316s,  404.54/s  (0.321s,  398.47/s)  LR: 1.050e-04  Data: 0.013 (0.017)
Train: 79 [ 200/390 ( 51%)]  Loss: 3.922 (3.46)  Time: 0.315s,  405.97/s  (0.319s,  401.45/s)  LR: 1.050e-04  Data: 0.013 (0.015)
Train: 79 [ 300/390 ( 77%)]  Loss: 3.733 (3.50)  Time: 0.315s,  406.01/s  (0.318s,  402.54/s)  LR: 1.050e-04  Data: 0.012 (0.014)
Train: 79 [ 389/390 (100%)]  Loss: 3.290 (3.50)  Time: 0.302s,  424.04/s  (0.318s,  402.44/s)  LR: 1.050e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.322 (0.322)  Loss:  1.4111 (1.4111)  Acc@1: 67.9688 (67.9688)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.3213 (1.4976)  Acc@1: 75.0000 (64.7200)  Acc@5: 81.2500 (89.5100)
Test: [Whole Val]  Time: 9.565  Loss: 1.4976  Acc@1: 64.7200 Pruned: 53.82% 
Test (EMA): [   0/78]  Time: 0.297 (0.297)  Loss:  1.4023 (1.4023)  Acc@1: 67.1875 (67.1875)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.3213 (1.4907)  Acc@1: 75.0000 (65.0400)  Acc@5: 81.2500 (89.6300)
Test (EMA): [Whole Val]  Time: 9.539  Loss: 1.4907  Acc@1: 65.0400 Pruned: 53.81% 
Train: 80 [   0/390 (  0%)]  Loss: 3.855 (3.86)  Time: 0.769s,  166.55/s  (0.769s,  166.55/s)  LR: 9.558e-05  Data: 0.467 (0.467)
Train: 80 [ 100/390 ( 26%)]  Loss: 2.741 (3.62)  Time: 0.312s,  409.91/s  (0.317s,  404.19/s)  LR: 9.558e-05  Data: 0.011 (0.016)
Train: 80 [ 200/390 ( 51%)]  Loss: 3.722 (3.58)  Time: 0.313s,  409.26/s  (0.315s,  406.88/s)  LR: 9.558e-05  Data: 0.012 (0.014)
Train: 80 [ 300/390 ( 77%)]  Loss: 2.972 (3.58)  Time: 0.313s,  409.37/s  (0.314s,  407.09/s)  LR: 9.558e-05  Data: 0.012 (0.013)
Train: 80 [ 389/390 (100%)]  Loss: 3.076 (3.58)  Time: 0.302s,  424.31/s  (0.314s,  407.60/s)  LR: 9.558e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.312 (0.312)  Loss:  1.4141 (1.4141)  Acc@1: 68.7500 (68.7500)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.3135 (1.5124)  Acc@1: 75.0000 (64.9400)  Acc@5: 81.2500 (89.6600)
Test: [Whole Val]  Time: 9.567  Loss: 1.5124  Acc@1: 64.9400 Pruned: 53.82% 
Test (EMA): [   0/78]  Time: 0.346 (0.346)  Loss:  1.4121 (1.4121)  Acc@1: 69.5312 (69.5312)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  1.3096 (1.5123)  Acc@1: 75.0000 (64.9800)  Acc@5: 81.2500 (89.6800)
Test (EMA): [Whole Val]  Time: 9.608  Loss: 1.5123  Acc@1: 64.9800 Pruned: 53.82% 
Train: 81 [   0/390 (  0%)]  Loss: 2.692 (2.69)  Time: 0.766s,  167.00/s  (0.766s,  167.00/s)  LR: 8.655e-05  Data: 0.464 (0.464)
Train: 81 [ 100/390 ( 26%)]  Loss: 3.202 (3.51)  Time: 0.313s,  409.52/s  (0.317s,  403.70/s)  LR: 8.655e-05  Data: 0.011 (0.016)
Train: 81 [ 200/390 ( 51%)]  Loss: 3.770 (3.53)  Time: 0.312s,  410.08/s  (0.315s,  406.54/s)  LR: 8.655e-05  Data: 0.011 (0.014)
Train: 81 [ 300/390 ( 77%)]  Loss: 4.026 (3.54)  Time: 0.313s,  409.18/s  (0.314s,  407.52/s)  LR: 8.655e-05  Data: 0.012 (0.013)
Train: 81 [ 389/390 (100%)]  Loss: 3.183 (3.53)  Time: 0.301s,  425.75/s  (0.314s,  407.92/s)  LR: 8.655e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.330 (0.330)  Loss:  1.4102 (1.4102)  Acc@1: 67.1875 (67.1875)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.3203 (1.4939)  Acc@1: 75.0000 (64.6800)  Acc@5: 87.5000 (89.6500)
Test: [Whole Val]  Time: 9.571  Loss: 1.4939  Acc@1: 64.6800 Pruned: 53.83% 
Test (EMA): [   0/78]  Time: 0.300 (0.300)  Loss:  1.4121 (1.4121)  Acc@1: 67.1875 (67.1875)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.3311 (1.4941)  Acc@1: 75.0000 (64.8300)  Acc@5: 81.2500 (89.6700)
Test (EMA): [Whole Val]  Time: 9.551  Loss: 1.4941  Acc@1: 64.8300 Pruned: 53.83% 
Train: 82 [   0/390 (  0%)]  Loss: 4.051 (4.05)  Time: 0.752s,  170.20/s  (0.752s,  170.20/s)  LR: 7.793e-05  Data: 0.443 (0.443)
Train: 82 [ 100/390 ( 26%)]  Loss: 3.732 (3.57)  Time: 0.312s,  409.70/s  (0.317s,  404.09/s)  LR: 7.793e-05  Data: 0.011 (0.016)
Train: 82 [ 200/390 ( 51%)]  Loss: 3.933 (3.59)  Time: 0.312s,  410.23/s  (0.315s,  406.83/s)  LR: 7.793e-05  Data: 0.011 (0.013)
Train: 82 [ 300/390 ( 77%)]  Loss: 2.925 (3.58)  Time: 0.312s,  410.73/s  (0.314s,  407.80/s)  LR: 7.793e-05  Data: 0.011 (0.013)
Train: 82 [ 389/390 (100%)]  Loss: 3.827 (3.57)  Time: 0.301s,  425.02/s  (0.314s,  408.25/s)  LR: 7.793e-05  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.350 (0.350)  Loss:  1.4023 (1.4023)  Acc@1: 67.9688 (67.9688)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.3262 (1.5010)  Acc@1: 75.0000 (64.7600)  Acc@5: 81.2500 (89.6800)
Test: [Whole Val]  Time: 9.610  Loss: 1.5010  Acc@1: 64.7600 Pruned: 53.82% 
Test (EMA): [   0/78]  Time: 0.311 (0.311)  Loss:  1.3984 (1.3984)  Acc@1: 68.7500 (68.7500)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.3271 (1.4991)  Acc@1: 75.0000 (64.9200)  Acc@5: 81.2500 (89.6900)
Test (EMA): [Whole Val]  Time: 9.555  Loss: 1.4991  Acc@1: 64.9200 Pruned: 53.82% 
Train: 83 [   0/390 (  0%)]  Loss: 2.955 (2.95)  Time: 0.823s,  155.46/s  (0.823s,  155.46/s)  LR: 6.972e-05  Data: 0.522 (0.522)
Train: 83 [ 100/390 ( 26%)]  Loss: 3.697 (3.58)  Time: 0.314s,  408.29/s  (0.317s,  403.49/s)  LR: 6.972e-05  Data: 0.011 (0.016)
Train: 83 [ 200/390 ( 51%)]  Loss: 3.919 (3.54)  Time: 0.311s,  411.02/s  (0.315s,  406.60/s)  LR: 6.972e-05  Data: 0.011 (0.014)
Train: 83 [ 300/390 ( 77%)]  Loss: 2.977 (3.52)  Time: 0.312s,  410.06/s  (0.314s,  407.39/s)  LR: 6.972e-05  Data: 0.011 (0.013)
Train: 83 [ 389/390 (100%)]  Loss: 3.708 (3.52)  Time: 0.301s,  424.64/s  (0.314s,  408.00/s)  LR: 6.972e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.429 (0.429)  Loss:  1.3945 (1.3945)  Acc@1: 67.9688 (67.9688)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.3115 (1.4916)  Acc@1: 75.0000 (65.0100)  Acc@5: 81.2500 (89.6100)
Test: [Whole Val]  Time: 9.675  Loss: 1.4916  Acc@1: 65.0100 Pruned: 53.81% 
Test (EMA): [   0/78]  Time: 0.305 (0.305)  Loss:  1.3984 (1.3984)  Acc@1: 66.4062 (66.4062)  Acc@5: 89.8438 (89.8438)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.3115 (1.4947)  Acc@1: 75.0000 (65.0900)  Acc@5: 81.2500 (89.4700)
Test (EMA): [Whole Val]  Time: 9.555  Loss: 1.4947  Acc@1: 65.0900 Pruned: 53.81% 
Train: 84 [   0/390 (  0%)]  Loss: 3.960 (3.96)  Time: 0.765s,  167.30/s  (0.765s,  167.30/s)  LR: 6.194e-05  Data: 0.465 (0.465)
Train: 84 [ 100/390 ( 26%)]  Loss: 2.870 (3.49)  Time: 0.313s,  409.08/s  (0.317s,  403.74/s)  LR: 6.194e-05  Data: 0.011 (0.016)
Train: 84 [ 200/390 ( 51%)]  Loss: 3.579 (3.51)  Time: 0.313s,  409.02/s  (0.315s,  406.36/s)  LR: 6.194e-05  Data: 0.012 (0.014)
Train: 84 [ 300/390 ( 77%)]  Loss: 3.430 (3.54)  Time: 0.312s,  410.16/s  (0.314s,  407.26/s)  LR: 6.194e-05  Data: 0.011 (0.013)
Train: 84 [ 389/390 (100%)]  Loss: 3.286 (3.53)  Time: 0.301s,  424.99/s  (0.314s,  407.71/s)  LR: 6.194e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.379 (0.379)  Loss:  1.3994 (1.3994)  Acc@1: 67.1875 (67.1875)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.3359 (1.4924)  Acc@1: 75.0000 (64.9400)  Acc@5: 81.2500 (89.8700)
Test: [Whole Val]  Time: 9.659  Loss: 1.4924  Acc@1: 64.9400 Pruned: 53.79% 
Test (EMA): [   0/78]  Time: 0.292 (0.292)  Loss:  1.3984 (1.3984)  Acc@1: 68.7500 (68.7500)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.3281 (1.4901)  Acc@1: 75.0000 (64.9300)  Acc@5: 81.2500 (89.9400)
Test (EMA): [Whole Val]  Time: 9.548  Loss: 1.4901  Acc@1: 64.9300 Pruned: 53.79% 
Train: 85 [   0/390 (  0%)]  Loss: 3.892 (3.89)  Time: 0.795s,  161.10/s  (0.795s,  161.10/s)  LR: 5.459e-05  Data: 0.494 (0.494)
Train: 85 [ 100/390 ( 26%)]  Loss: 3.849 (3.53)  Time: 0.313s,  409.56/s  (0.318s,  403.09/s)  LR: 5.459e-05  Data: 0.011 (0.016)
Train: 85 [ 200/390 ( 51%)]  Loss: 3.956 (3.56)  Time: 0.312s,  410.48/s  (0.315s,  406.07/s)  LR: 5.459e-05  Data: 0.011 (0.014)
Train: 85 [ 300/390 ( 77%)]  Loss: 3.683 (3.54)  Time: 0.312s,  410.33/s  (0.314s,  407.18/s)  LR: 5.459e-05  Data: 0.011 (0.013)
Train: 85 [ 389/390 (100%)]  Loss: 3.915 (3.52)  Time: 0.301s,  425.20/s  (0.314s,  407.82/s)  LR: 5.459e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.355 (0.355)  Loss:  1.4062 (1.4062)  Acc@1: 67.1875 (67.1875)  Acc@5: 89.8438 (89.8438)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.3213 (1.4962)  Acc@1: 75.0000 (64.7900)  Acc@5: 81.2500 (89.6200)
Test: [Whole Val]  Time: 9.596  Loss: 1.4962  Acc@1: 64.7900 Pruned: 53.78% 
Test (EMA): [   0/78]  Time: 0.308 (0.308)  Loss:  1.4053 (1.4053)  Acc@1: 67.9688 (67.9688)  Acc@5: 89.8438 (89.8438)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.3086 (1.4928)  Acc@1: 75.0000 (64.9800)  Acc@5: 81.2500 (89.7100)
Test (EMA): [Whole Val]  Time: 9.534  Loss: 1.4928  Acc@1: 64.9800 Pruned: 53.79% 
Train: 86 [   0/390 (  0%)]  Loss: 2.863 (2.86)  Time: 0.819s,  156.37/s  (0.819s,  156.37/s)  LR: 4.768e-05  Data: 0.518 (0.518)
Train: 86 [ 100/390 ( 26%)]  Loss: 3.514 (3.49)  Time: 0.312s,  409.73/s  (0.317s,  403.83/s)  LR: 4.768e-05  Data: 0.011 (0.016)
Train: 86 [ 200/390 ( 51%)]  Loss: 3.697 (3.49)  Time: 0.312s,  409.88/s  (0.314s,  407.09/s)  LR: 4.768e-05  Data: 0.011 (0.014)
Train: 86 [ 300/390 ( 77%)]  Loss: 3.832 (3.51)  Time: 0.311s,  411.42/s  (0.314s,  408.24/s)  LR: 4.768e-05  Data: 0.011 (0.013)
Train: 86 [ 389/390 (100%)]  Loss: 3.307 (3.52)  Time: 0.301s,  425.86/s  (0.313s,  408.72/s)  LR: 4.768e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.313 (0.313)  Loss:  1.3887 (1.3887)  Acc@1: 68.7500 (68.7500)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.018 (0.121)  Loss:  1.3047 (1.4863)  Acc@1: 75.0000 (64.9800)  Acc@5: 81.2500 (89.6700)
Test: [Whole Val]  Time: 9.536  Loss: 1.4863  Acc@1: 64.9800 Pruned: 53.80% 
Test (EMA): [   0/78]  Time: 0.314 (0.314)  Loss:  1.3945 (1.3945)  Acc@1: 68.7500 (68.7500)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.3066 (1.4867)  Acc@1: 75.0000 (65.0000)  Acc@5: 81.2500 (89.7100)
Test (EMA): [Whole Val]  Time: 9.534  Loss: 1.4867  Acc@1: 65.0000 Pruned: 53.80% 
Train: 87 [   0/390 (  0%)]  Loss: 2.997 (3.00)  Time: 0.731s,  175.05/s  (0.731s,  175.05/s)  LR: 4.122e-05  Data: 0.430 (0.430)
Train: 87 [ 100/390 ( 26%)]  Loss: 3.724 (3.52)  Time: 0.312s,  410.60/s  (0.317s,  403.99/s)  LR: 4.122e-05  Data: 0.011 (0.015)
Train: 87 [ 200/390 ( 51%)]  Loss: 3.553 (3.53)  Time: 0.312s,  410.23/s  (0.314s,  407.21/s)  LR: 4.122e-05  Data: 0.012 (0.013)
Train: 87 [ 300/390 ( 77%)]  Loss: 3.919 (3.54)  Time: 0.312s,  410.06/s  (0.313s,  408.33/s)  LR: 4.122e-05  Data: 0.011 (0.013)
Train: 87 [ 389/390 (100%)]  Loss: 3.974 (3.53)  Time: 0.301s,  425.93/s  (0.313s,  408.82/s)  LR: 4.122e-05  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.301 (0.301)  Loss:  1.3975 (1.3975)  Acc@1: 68.7500 (68.7500)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  1.3193 (1.4862)  Acc@1: 75.0000 (65.0400)  Acc@5: 81.2500 (89.5900)
Test: [Whole Val]  Time: 9.515  Loss: 1.4862  Acc@1: 65.0400 Pruned: 53.80% 
Test (EMA): [   0/78]  Time: 0.306 (0.306)  Loss:  1.3955 (1.3955)  Acc@1: 69.5312 (69.5312)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.3174 (1.4864)  Acc@1: 75.0000 (65.1100)  Acc@5: 81.2500 (89.6600)
Test (EMA): [Whole Val]  Time: 9.522  Loss: 1.4864  Acc@1: 65.1100 Pruned: 53.80% 
Train: 88 [   0/390 (  0%)]  Loss: 3.350 (3.35)  Time: 0.790s,  162.04/s  (0.790s,  162.04/s)  LR: 3.521e-05  Data: 0.486 (0.486)
Train: 88 [ 100/390 ( 26%)]  Loss: 3.550 (3.57)  Time: 0.312s,  410.11/s  (0.317s,  404.42/s)  LR: 3.521e-05  Data: 0.011 (0.016)
Train: 88 [ 200/390 ( 51%)]  Loss: 3.531 (3.56)  Time: 0.312s,  410.39/s  (0.314s,  407.38/s)  LR: 3.521e-05  Data: 0.012 (0.014)
Train: 88 [ 300/390 ( 77%)]  Loss: 3.897 (3.57)  Time: 0.313s,  409.20/s  (0.313s,  408.35/s)  LR: 3.521e-05  Data: 0.011 (0.013)
Train: 88 [ 389/390 (100%)]  Loss: 3.643 (3.55)  Time: 0.300s,  427.29/s  (0.313s,  408.81/s)  LR: 3.521e-05  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.317 (0.317)  Loss:  1.3926 (1.3926)  Acc@1: 68.7500 (68.7500)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.3174 (1.4864)  Acc@1: 75.0000 (65.1000)  Acc@5: 81.2500 (89.8100)
Test: [Whole Val]  Time: 9.558  Loss: 1.4864  Acc@1: 65.1000 Pruned: 53.79% 
Test (EMA): [   0/78]  Time: 0.307 (0.307)  Loss:  1.3926 (1.3926)  Acc@1: 67.9688 (67.9688)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.3184 (1.4856)  Acc@1: 75.0000 (64.9800)  Acc@5: 81.2500 (89.7700)
Test (EMA): [Whole Val]  Time: 9.529  Loss: 1.4856  Acc@1: 64.9800 Pruned: 53.79% 
Train: 89 [   0/390 (  0%)]  Loss: 3.276 (3.28)  Time: 0.741s,  172.74/s  (0.741s,  172.74/s)  LR: 2.966e-05  Data: 0.442 (0.442)
Train: 89 [ 100/390 ( 26%)]  Loss: 3.293 (3.60)  Time: 0.312s,  410.91/s  (0.316s,  404.88/s)  LR: 2.966e-05  Data: 0.011 (0.015)
Train: 89 [ 200/390 ( 51%)]  Loss: 3.506 (3.57)  Time: 0.313s,  409.18/s  (0.314s,  407.63/s)  LR: 2.966e-05  Data: 0.012 (0.013)
Train: 89 [ 300/390 ( 77%)]  Loss: 3.412 (3.56)  Time: 0.312s,  410.57/s  (0.313s,  408.57/s)  LR: 2.966e-05  Data: 0.011 (0.013)
Train: 89 [ 389/390 (100%)]  Loss: 4.021 (3.55)  Time: 0.299s,  427.74/s  (0.313s,  409.05/s)  LR: 2.966e-05  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.303 (0.303)  Loss:  1.3975 (1.3975)  Acc@1: 68.7500 (68.7500)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.3369 (1.4926)  Acc@1: 75.0000 (65.0100)  Acc@5: 81.2500 (89.7000)
Test: [Whole Val]  Time: 9.542  Loss: 1.4926  Acc@1: 65.0100 Pruned: 53.78% 
Test (EMA): [   0/78]  Time: 0.307 (0.307)  Loss:  1.3945 (1.3945)  Acc@1: 69.5312 (69.5312)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.3330 (1.4912)  Acc@1: 75.0000 (65.0200)  Acc@5: 81.2500 (89.7400)
Test (EMA): [Whole Val]  Time: 9.526  Loss: 1.4912  Acc@1: 65.0200 Pruned: 53.78% 
Train: 90 [   0/390 (  0%)]  Loss: 3.475 (3.48)  Time: 0.808s,  158.33/s  (0.808s,  158.33/s)  LR: 2.457e-05  Data: 0.507 (0.507)
Train: 90 [ 100/390 ( 26%)]  Loss: 3.104 (3.55)  Time: 0.393s,  325.33/s  (0.318s,  403.02/s)  LR: 2.457e-05  Data: 0.011 (0.016)
Train: 90 [ 200/390 ( 51%)]  Loss: 3.033 (3.52)  Time: 0.311s,  410.96/s  (0.315s,  406.66/s)  LR: 2.457e-05  Data: 0.011 (0.014)
Train: 90 [ 300/390 ( 77%)]  Loss: 3.787 (3.54)  Time: 0.313s,  408.71/s  (0.314s,  407.77/s)  LR: 2.457e-05  Data: 0.011 (0.013)
Train: 90 [ 389/390 (100%)]  Loss: 2.924 (3.54)  Time: 0.300s,  426.03/s  (0.313s,  408.47/s)  LR: 2.457e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.307 (0.307)  Loss:  1.4082 (1.4082)  Acc@1: 67.9688 (67.9688)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.3086 (1.4951)  Acc@1: 75.0000 (65.0000)  Acc@5: 81.2500 (89.7200)
Test: [Whole Val]  Time: 9.533  Loss: 1.4951  Acc@1: 65.0000 Pruned: 53.78% 
Test (EMA): [   0/78]  Time: 0.300 (0.300)  Loss:  1.4082 (1.4082)  Acc@1: 67.9688 (67.9688)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.3135 (1.4953)  Acc@1: 75.0000 (65.0100)  Acc@5: 81.2500 (89.7300)
Test (EMA): [Whole Val]  Time: 9.522  Loss: 1.4953  Acc@1: 65.0100 Pruned: 53.78% 
Train: 91 [   0/390 (  0%)]  Loss: 3.995 (3.99)  Time: 0.755s,  169.54/s  (0.755s,  169.54/s)  LR: 1.995e-05  Data: 0.453 (0.453)
Train: 91 [ 100/390 ( 26%)]  Loss: 3.298 (3.61)  Time: 0.312s,  410.32/s  (0.316s,  404.49/s)  LR: 1.995e-05  Data: 0.011 (0.016)
Train: 91 [ 200/390 ( 51%)]  Loss: 2.742 (3.61)  Time: 0.312s,  409.65/s  (0.314s,  407.33/s)  LR: 1.995e-05  Data: 0.012 (0.014)
Train: 91 [ 300/390 ( 77%)]  Loss: 2.873 (3.58)  Time: 0.311s,  411.42/s  (0.313s,  408.36/s)  LR: 1.995e-05  Data: 0.011 (0.013)
Train: 91 [ 389/390 (100%)]  Loss: 3.269 (3.57)  Time: 0.299s,  427.47/s  (0.313s,  408.96/s)  LR: 1.995e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.313 (0.313)  Loss:  1.4004 (1.4004)  Acc@1: 69.5312 (69.5312)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.3164 (1.4906)  Acc@1: 75.0000 (65.1800)  Acc@5: 81.2500 (89.6400)
Test: [Whole Val]  Time: 9.537  Loss: 1.4906  Acc@1: 65.1800 Pruned: 53.77% 
Test (EMA): [   0/78]  Time: 0.328 (0.328)  Loss:  1.3984 (1.3984)  Acc@1: 69.5312 (69.5312)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.3193 (1.4896)  Acc@1: 75.0000 (65.2400)  Acc@5: 81.2500 (89.6600)
Test (EMA): [Whole Val]  Time: 9.547  Loss: 1.4896  Acc@1: 65.2400 Pruned: 53.77% 
Train: 92 [   0/390 (  0%)]  Loss: 3.904 (3.90)  Time: 0.753s,  170.07/s  (0.753s,  170.07/s)  LR: 1.581e-05  Data: 0.450 (0.450)
Train: 92 [ 100/390 ( 26%)]  Loss: 3.602 (3.54)  Time: 0.311s,  411.12/s  (0.316s,  404.82/s)  LR: 1.581e-05  Data: 0.011 (0.016)
Train: 92 [ 200/390 ( 51%)]  Loss: 3.517 (3.56)  Time: 0.311s,  412.13/s  (0.314s,  407.73/s)  LR: 1.581e-05  Data: 0.011 (0.013)
Train: 92 [ 300/390 ( 77%)]  Loss: 4.017 (3.57)  Time: 0.311s,  412.12/s  (0.313s,  408.66/s)  LR: 1.581e-05  Data: 0.011 (0.013)
Train: 92 [ 389/390 (100%)]  Loss: 3.944 (3.57)  Time: 0.301s,  425.72/s  (0.313s,  409.17/s)  LR: 1.581e-05  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.305 (0.305)  Loss:  1.4043 (1.4043)  Acc@1: 68.7500 (68.7500)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.3184 (1.4959)  Acc@1: 75.0000 (65.1000)  Acc@5: 81.2500 (89.7600)
Test: [Whole Val]  Time: 9.522  Loss: 1.4959  Acc@1: 65.1000 Pruned: 53.78% 
Test (EMA): [   0/78]  Time: 0.334 (0.334)  Loss:  1.4043 (1.4043)  Acc@1: 67.9688 (67.9688)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.3174 (1.4962)  Acc@1: 75.0000 (65.1500)  Acc@5: 81.2500 (89.7500)
Test (EMA): [Whole Val]  Time: 9.545  Loss: 1.4962  Acc@1: 65.1500 Pruned: 53.78% 
Train: 93 [   0/390 (  0%)]  Loss: 3.179 (3.18)  Time: 0.748s,  171.14/s  (0.748s,  171.14/s)  LR: 1.214e-05  Data: 0.446 (0.446)
Train: 93 [ 100/390 ( 26%)]  Loss: 3.875 (3.49)  Time: 0.311s,  411.69/s  (0.316s,  405.03/s)  LR: 1.214e-05  Data: 0.011 (0.016)
Train: 93 [ 200/390 ( 51%)]  Loss: 3.402 (3.51)  Time: 0.312s,  410.08/s  (0.314s,  407.74/s)  LR: 1.214e-05  Data: 0.012 (0.013)
Train: 93 [ 300/390 ( 77%)]  Loss: 3.934 (3.53)  Time: 0.311s,  411.05/s  (0.313s,  408.34/s)  LR: 1.214e-05  Data: 0.011 (0.013)
Train: 93 [ 389/390 (100%)]  Loss: 3.401 (3.54)  Time: 0.299s,  428.30/s  (0.313s,  408.82/s)  LR: 1.214e-05  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.303 (0.303)  Loss:  1.4053 (1.4053)  Acc@1: 68.7500 (68.7500)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.3193 (1.4962)  Acc@1: 75.0000 (65.0200)  Acc@5: 81.2500 (89.7000)
Test: [Whole Val]  Time: 9.521  Loss: 1.4962  Acc@1: 65.0200 Pruned: 53.76% 
Test (EMA): [   0/78]  Time: 0.364 (0.364)  Loss:  1.4043 (1.4043)  Acc@1: 68.7500 (68.7500)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.3174 (1.4959)  Acc@1: 75.0000 (65.0200)  Acc@5: 81.2500 (89.7000)
Test (EMA): [Whole Val]  Time: 9.573  Loss: 1.4959  Acc@1: 65.0200 Pruned: 53.77% 
Train: 94 [   0/390 (  0%)]  Loss: 3.948 (3.95)  Time: 0.808s,  158.35/s  (0.808s,  158.35/s)  LR: 8.955e-06  Data: 0.508 (0.508)
Train: 94 [ 100/390 ( 26%)]  Loss: 3.958 (3.55)  Time: 0.313s,  409.48/s  (0.317s,  404.21/s)  LR: 8.955e-06  Data: 0.012 (0.016)
Train: 94 [ 200/390 ( 51%)]  Loss: 2.917 (3.55)  Time: 0.311s,  411.03/s  (0.314s,  407.23/s)  LR: 8.955e-06  Data: 0.011 (0.014)
Train: 94 [ 300/390 ( 77%)]  Loss: 3.082 (3.55)  Time: 0.312s,  410.78/s  (0.314s,  408.21/s)  LR: 8.955e-06  Data: 0.011 (0.013)
Train: 94 [ 389/390 (100%)]  Loss: 3.659 (3.56)  Time: 0.300s,  426.65/s  (0.313s,  408.78/s)  LR: 8.955e-06  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.315 (0.315)  Loss:  1.4023 (1.4023)  Acc@1: 68.7500 (68.7500)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.3174 (1.4928)  Acc@1: 75.0000 (65.0800)  Acc@5: 81.2500 (89.7100)
Test: [Whole Val]  Time: 9.528  Loss: 1.4928  Acc@1: 65.0800 Pruned: 53.76% 
Test (EMA): [   0/78]  Time: 0.301 (0.301)  Loss:  1.4014 (1.4014)  Acc@1: 68.7500 (68.7500)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.3193 (1.4929)  Acc@1: 75.0000 (65.0600)  Acc@5: 81.2500 (89.7100)
Test (EMA): [Whole Val]  Time: 9.523  Loss: 1.4929  Acc@1: 65.0600 Pruned: 53.77% 
Train: 95 [   0/390 (  0%)]  Loss: 3.636 (3.64)  Time: 0.822s,  155.71/s  (0.822s,  155.71/s)  LR: 6.255e-06  Data: 0.519 (0.519)
Train: 95 [ 100/390 ( 26%)]  Loss: 3.956 (3.52)  Time: 0.312s,  410.25/s  (0.317s,  403.93/s)  LR: 6.255e-06  Data: 0.011 (0.016)
Train: 95 [ 200/390 ( 51%)]  Loss: 3.502 (3.51)  Time: 0.312s,  410.83/s  (0.314s,  407.16/s)  LR: 6.255e-06  Data: 0.012 (0.014)
Train: 95 [ 300/390 ( 77%)]  Loss: 3.348 (3.51)  Time: 0.312s,  410.41/s  (0.313s,  408.31/s)  LR: 6.255e-06  Data: 0.011 (0.013)
Train: 95 [ 389/390 (100%)]  Loss: 3.646 (3.53)  Time: 0.301s,  425.13/s  (0.313s,  408.84/s)  LR: 6.255e-06  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.356 (0.356)  Loss:  1.3975 (1.3975)  Acc@1: 68.7500 (68.7500)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.3184 (1.4919)  Acc@1: 75.0000 (65.1000)  Acc@5: 81.2500 (89.7000)
Test: [Whole Val]  Time: 9.596  Loss: 1.4919  Acc@1: 65.1000 Pruned: 53.76% 
Test (EMA): [   0/78]  Time: 0.358 (0.358)  Loss:  1.3975 (1.3975)  Acc@1: 68.7500 (68.7500)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  1.3184 (1.4917)  Acc@1: 75.0000 (65.0800)  Acc@5: 81.2500 (89.7200)
Test (EMA): [Whole Val]  Time: 9.611  Loss: 1.4917  Acc@1: 65.0800 Pruned: 53.76% 
Train: 96 [   0/390 (  0%)]  Loss: 2.894 (2.89)  Time: 0.744s,  172.16/s  (0.744s,  172.16/s)  LR: 4.042e-06  Data: 0.441 (0.441)
Train: 96 [ 100/390 ( 26%)]  Loss: 2.937 (3.56)  Time: 0.313s,  409.36/s  (0.316s,  404.88/s)  LR: 4.042e-06  Data: 0.011 (0.015)
Train: 96 [ 200/390 ( 51%)]  Loss: 3.889 (3.51)  Time: 0.312s,  410.91/s  (0.314s,  407.67/s)  LR: 4.042e-06  Data: 0.011 (0.013)
Train: 96 [ 300/390 ( 77%)]  Loss: 3.974 (3.52)  Time: 0.312s,  410.05/s  (0.314s,  408.24/s)  LR: 4.042e-06  Data: 0.012 (0.013)
Train: 96 [ 389/390 (100%)]  Loss: 3.452 (3.52)  Time: 0.299s,  428.05/s  (0.313s,  408.75/s)  LR: 4.042e-06  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.303 (0.303)  Loss:  1.3965 (1.3965)  Acc@1: 68.7500 (68.7500)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.3213 (1.4908)  Acc@1: 75.0000 (65.1400)  Acc@5: 81.2500 (89.7400)
Test: [Whole Val]  Time: 9.545  Loss: 1.4908  Acc@1: 65.1400 Pruned: 53.76% 
Test (EMA): [   0/78]  Time: 0.335 (0.335)  Loss:  1.3965 (1.3965)  Acc@1: 68.7500 (68.7500)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.3203 (1.4909)  Acc@1: 75.0000 (65.1300)  Acc@5: 81.2500 (89.7500)
Test (EMA): [Whole Val]  Time: 9.570  Loss: 1.4909  Acc@1: 65.1300 Pruned: 53.76% 
Train: 97 [   0/390 (  0%)]  Loss: 2.972 (2.97)  Time: 0.730s,  175.29/s  (0.730s,  175.29/s)  LR: 2.319e-06  Data: 0.428 (0.428)
Train: 97 [ 100/390 ( 26%)]  Loss: 2.605 (3.49)  Time: 0.314s,  408.06/s  (0.316s,  404.51/s)  LR: 2.319e-06  Data: 0.011 (0.016)
Train: 97 [ 200/390 ( 51%)]  Loss: 3.846 (3.51)  Time: 0.312s,  410.43/s  (0.314s,  407.29/s)  LR: 2.319e-06  Data: 0.011 (0.013)
Train: 97 [ 300/390 ( 77%)]  Loss: 3.918 (3.50)  Time: 0.312s,  410.26/s  (0.314s,  408.25/s)  LR: 2.319e-06  Data: 0.011 (0.013)
Train: 97 [ 389/390 (100%)]  Loss: 3.815 (3.48)  Time: 0.301s,  424.79/s  (0.313s,  408.82/s)  LR: 2.319e-06  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.311 (0.311)  Loss:  1.3965 (1.3965)  Acc@1: 67.9688 (67.9688)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.3203 (1.4889)  Acc@1: 75.0000 (65.1300)  Acc@5: 81.2500 (89.7500)
Test: [Whole Val]  Time: 9.565  Loss: 1.4889  Acc@1: 65.1300 Pruned: 53.77% 
Test (EMA): [   0/78]  Time: 0.301 (0.301)  Loss:  1.3955 (1.3955)  Acc@1: 67.9688 (67.9688)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.3203 (1.4889)  Acc@1: 75.0000 (65.1700)  Acc@5: 81.2500 (89.7600)
Test (EMA): [Whole Val]  Time: 9.548  Loss: 1.4889  Acc@1: 65.1700 Pruned: 53.77% 
Train: 98 [   0/390 (  0%)]  Loss: 3.719 (3.72)  Time: 0.809s,  158.16/s  (0.809s,  158.16/s)  LR: 1.087e-06  Data: 0.506 (0.506)
Train: 98 [ 100/390 ( 26%)]  Loss: 2.893 (3.49)  Time: 0.316s,  405.52/s  (0.317s,  403.74/s)  LR: 1.087e-06  Data: 0.011 (0.016)
Train: 98 [ 200/390 ( 51%)]  Loss: 3.651 (3.49)  Time: 0.312s,  410.53/s  (0.314s,  407.04/s)  LR: 1.087e-06  Data: 0.012 (0.014)
Train: 98 [ 300/390 ( 77%)]  Loss: 2.708 (3.51)  Time: 0.313s,  409.38/s  (0.314s,  408.10/s)  LR: 1.087e-06  Data: 0.011 (0.013)
Train: 98 [ 389/390 (100%)]  Loss: 2.796 (3.51)  Time: 0.300s,  426.52/s  (0.313s,  408.63/s)  LR: 1.087e-06  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.306 (0.306)  Loss:  1.3965 (1.3965)  Acc@1: 67.9688 (67.9688)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.3213 (1.4888)  Acc@1: 75.0000 (65.1200)  Acc@5: 81.2500 (89.7400)
Test: [Whole Val]  Time: 9.539  Loss: 1.4888  Acc@1: 65.1200 Pruned: 53.76% 
Test (EMA): [   0/78]  Time: 0.306 (0.306)  Loss:  1.3965 (1.3965)  Acc@1: 67.9688 (67.9688)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.3223 (1.4888)  Acc@1: 75.0000 (65.1400)  Acc@5: 81.2500 (89.7500)
Test (EMA): [Whole Val]  Time: 9.547  Loss: 1.4888  Acc@1: 65.1400 Pruned: 53.76% 
Train: 99 [   0/390 (  0%)]  Loss: 3.865 (3.87)  Time: 0.820s,  156.15/s  (0.820s,  156.15/s)  LR: 3.467e-07  Data: 0.518 (0.518)
Train: 99 [ 100/390 ( 26%)]  Loss: 3.556 (3.52)  Time: 0.312s,  410.61/s  (0.317s,  403.77/s)  LR: 3.467e-07  Data: 0.011 (0.016)
Train: 99 [ 200/390 ( 51%)]  Loss: 2.553 (3.50)  Time: 0.319s,  401.51/s  (0.314s,  407.07/s)  LR: 3.467e-07  Data: 0.011 (0.014)
Train: 99 [ 300/390 ( 77%)]  Loss: 3.865 (3.52)  Time: 0.313s,  409.33/s  (0.314s,  408.07/s)  LR: 3.467e-07  Data: 0.012 (0.013)
Train: 99 [ 389/390 (100%)]  Loss: 3.867 (3.53)  Time: 0.301s,  425.23/s  (0.313s,  408.58/s)  LR: 3.467e-07  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.309 (0.309)  Loss:  1.3965 (1.3965)  Acc@1: 67.9688 (67.9688)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.3223 (1.4887)  Acc@1: 75.0000 (65.1400)  Acc@5: 81.2500 (89.7700)
Test: [Whole Val]  Time: 9.550  Loss: 1.4887  Acc@1: 65.1400 Pruned: 53.76% 
Test (EMA): [   0/78]  Time: 0.304 (0.304)  Loss:  1.3965 (1.3965)  Acc@1: 67.9688 (67.9688)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.3223 (1.4887)  Acc@1: 75.0000 (65.1600)  Acc@5: 81.2500 (89.7800)
Test (EMA): [Whole Val]  Time: 9.539  Loss: 1.4887  Acc@1: 65.1600 Pruned: 53.76% 
Train: 100 [   0/390 (  0%)]  Loss: 3.804 (3.80)  Time: 0.814s,  157.29/s  (0.814s,  157.29/s)  LR: 1.000e-07  Data: 0.512 (0.512)
Train: 100 [ 100/390 ( 26%)]  Loss: 3.895 (3.57)  Time: 0.312s,  410.05/s  (0.318s,  402.72/s)  LR: 1.000e-07  Data: 0.012 (0.016)
Train: 100 [ 200/390 ( 51%)]  Loss: 3.178 (3.58)  Time: 0.312s,  410.09/s  (0.315s,  406.38/s)  LR: 1.000e-07  Data: 0.011 (0.014)
Train: 100 [ 300/390 ( 77%)]  Loss: 3.296 (3.56)  Time: 0.312s,  409.84/s  (0.314s,  407.65/s)  LR: 1.000e-07  Data: 0.011 (0.013)
Train: 100 [ 389/390 (100%)]  Loss: 3.908 (3.56)  Time: 0.301s,  425.24/s  (0.313s,  408.33/s)  LR: 1.000e-07  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.346 (0.346)  Loss:  1.3965 (1.3965)  Acc@1: 67.9688 (67.9688)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.3223 (1.4888)  Acc@1: 75.0000 (65.1300)  Acc@5: 81.2500 (89.7700)
Test: [Whole Val]  Time: 9.552  Loss: 1.4888  Acc@1: 65.1300 Pruned: 53.76% 
Test (EMA): [   0/78]  Time: 0.306 (0.306)  Loss:  1.3965 (1.3965)  Acc@1: 67.9688 (67.9688)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.3223 (1.4888)  Acc@1: 75.0000 (65.1200)  Acc@5: 81.2500 (89.7500)
Test (EMA): [Whole Val]  Time: 9.522  Loss: 1.4888  Acc@1: 65.1200 Pruned: 53.76% 
Train: 101 [   0/390 (  0%)]  Loss: 3.919 (3.92)  Time: 0.772s,  165.79/s  (0.772s,  165.79/s)  LR: 1.000e-07  Data: 0.471 (0.471)
Train: 101 [ 100/390 ( 26%)]  Loss: 3.071 (3.50)  Time: 0.312s,  409.88/s  (0.316s,  404.55/s)  LR: 1.000e-07  Data: 0.011 (0.016)
Train: 101 [ 200/390 ( 51%)]  Loss: 3.192 (3.51)  Time: 0.314s,  408.14/s  (0.314s,  407.52/s)  LR: 1.000e-07  Data: 0.013 (0.014)
Train: 101 [ 300/390 ( 77%)]  Loss: 4.040 (3.51)  Time: 0.311s,  411.11/s  (0.313s,  408.54/s)  LR: 1.000e-07  Data: 0.011 (0.013)
Train: 101 [ 389/390 (100%)]  Loss: 4.109 (3.52)  Time: 0.300s,  426.70/s  (0.313s,  409.07/s)  LR: 1.000e-07  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.311 (0.311)  Loss:  1.3965 (1.3965)  Acc@1: 67.9688 (67.9688)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.3223 (1.4888)  Acc@1: 75.0000 (65.1400)  Acc@5: 81.2500 (89.7700)
Test: [Whole Val]  Time: 9.525  Loss: 1.4888  Acc@1: 65.1400 Pruned: 53.76% 
Test (EMA): [   0/78]  Time: 0.338 (0.338)  Loss:  1.3965 (1.3965)  Acc@1: 67.9688 (67.9688)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.3223 (1.4888)  Acc@1: 75.0000 (65.1500)  Acc@5: 81.2500 (89.7600)
Test (EMA): [Whole Val]  Time: 9.548  Loss: 1.4888  Acc@1: 65.1500 Pruned: 53.76% 
Train: 102 [   0/390 (  0%)]  Loss: 3.949 (3.95)  Time: 0.736s,  174.00/s  (0.736s,  174.00/s)  LR: 1.000e-07  Data: 0.434 (0.434)
Train: 102 [ 100/390 ( 26%)]  Loss: 3.721 (3.55)  Time: 0.312s,  410.83/s  (0.316s,  405.29/s)  LR: 1.000e-07  Data: 0.011 (0.015)
Train: 102 [ 200/390 ( 51%)]  Loss: 3.984 (3.54)  Time: 0.311s,  411.11/s  (0.314s,  407.94/s)  LR: 1.000e-07  Data: 0.011 (0.013)
Train: 102 [ 300/390 ( 77%)]  Loss: 3.960 (3.53)  Time: 0.312s,  410.33/s  (0.313s,  408.82/s)  LR: 1.000e-07  Data: 0.011 (0.013)
Train: 102 [ 389/390 (100%)]  Loss: 2.993 (3.53)  Time: 0.300s,  426.72/s  (0.313s,  409.21/s)  LR: 1.000e-07  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.360 (0.360)  Loss:  1.3965 (1.3965)  Acc@1: 67.9688 (67.9688)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.3223 (1.4887)  Acc@1: 75.0000 (65.1200)  Acc@5: 81.2500 (89.7500)
Test: [Whole Val]  Time: 9.577  Loss: 1.4887  Acc@1: 65.1200 Pruned: 53.76% 
Test (EMA): [   0/78]  Time: 0.310 (0.310)  Loss:  1.3965 (1.3965)  Acc@1: 67.9688 (67.9688)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.3223 (1.4888)  Acc@1: 75.0000 (65.1500)  Acc@5: 81.2500 (89.7600)
Test (EMA): [Whole Val]  Time: 9.523  Loss: 1.4888  Acc@1: 65.1500 Pruned: 53.76% 
Train: 103 [   0/390 (  0%)]  Loss: 3.073 (3.07)  Time: 0.760s,  168.36/s  (0.760s,  168.36/s)  LR: 1.000e-07  Data: 0.459 (0.459)
Train: 103 [ 100/390 ( 26%)]  Loss: 4.013 (3.57)  Time: 0.311s,  411.87/s  (0.317s,  403.81/s)  LR: 1.000e-07  Data: 0.011 (0.016)
Train: 103 [ 200/390 ( 51%)]  Loss: 3.616 (3.55)  Time: 0.312s,  410.07/s  (0.315s,  406.98/s)  LR: 1.000e-07  Data: 0.011 (0.014)
Train: 103 [ 300/390 ( 77%)]  Loss: 3.562 (3.55)  Time: 0.312s,  409.81/s  (0.314s,  408.04/s)  LR: 1.000e-07  Data: 0.011 (0.013)
Train: 103 [ 389/390 (100%)]  Loss: 3.970 (3.54)  Time: 0.300s,  426.60/s  (0.313s,  408.61/s)  LR: 1.000e-07  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.305 (0.305)  Loss:  1.3965 (1.3965)  Acc@1: 68.7500 (68.7500)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.3213 (1.4887)  Acc@1: 75.0000 (65.1400)  Acc@5: 81.2500 (89.7500)
Test: [Whole Val]  Time: 9.521  Loss: 1.4887  Acc@1: 65.1400 Pruned: 53.76% 
Test (EMA): [   0/78]  Time: 0.306 (0.306)  Loss:  1.3965 (1.3965)  Acc@1: 67.9688 (67.9688)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.3213 (1.4888)  Acc@1: 75.0000 (65.1100)  Acc@5: 81.2500 (89.7600)
Test (EMA): [Whole Val]  Time: 9.529  Loss: 1.4888  Acc@1: 65.1100 Pruned: 53.76% 
Train: 104 [   0/390 (  0%)]  Loss: 3.005 (3.00)  Time: 0.728s,  175.87/s  (0.728s,  175.87/s)  LR: 1.000e-07  Data: 0.425 (0.425)
Train: 104 [ 100/390 ( 26%)]  Loss: 2.777 (3.44)  Time: 0.312s,  410.61/s  (0.316s,  405.12/s)  LR: 1.000e-07  Data: 0.011 (0.015)
Train: 104 [ 200/390 ( 51%)]  Loss: 3.917 (3.48)  Time: 0.312s,  409.94/s  (0.314s,  407.69/s)  LR: 1.000e-07  Data: 0.011 (0.013)
Train: 104 [ 300/390 ( 77%)]  Loss: 3.071 (3.47)  Time: 0.311s,  410.96/s  (0.313s,  408.53/s)  LR: 1.000e-07  Data: 0.011 (0.013)
Train: 104 [ 389/390 (100%)]  Loss: 4.009 (3.50)  Time: 0.300s,  426.54/s  (0.313s,  408.99/s)  LR: 1.000e-07  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.307 (0.307)  Loss:  1.3965 (1.3965)  Acc@1: 68.7500 (68.7500)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.3223 (1.4887)  Acc@1: 75.0000 (65.1500)  Acc@5: 81.2500 (89.7600)
Test: [Whole Val]  Time: 9.544  Loss: 1.4887  Acc@1: 65.1500 Pruned: 53.76% 
Test (EMA): [   0/78]  Time: 0.307 (0.307)  Loss:  1.3955 (1.3955)  Acc@1: 67.9688 (67.9688)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.3223 (1.4887)  Acc@1: 75.0000 (65.1600)  Acc@5: 81.2500 (89.7500)
Test (EMA): [Whole Val]  Time: 9.532  Loss: 1.4887  Acc@1: 65.1600 Pruned: 53.76% 
Train: 105 [   0/390 (  0%)]  Loss: 2.794 (2.79)  Time: 0.799s,  160.29/s  (0.799s,  160.29/s)  LR: 1.000e-07  Data: 0.492 (0.492)
Train: 105 [ 100/390 ( 26%)]  Loss: 3.888 (3.47)  Time: 0.312s,  410.49/s  (0.316s,  404.46/s)  LR: 1.000e-07  Data: 0.011 (0.016)
Train: 105 [ 200/390 ( 51%)]  Loss: 3.740 (3.46)  Time: 0.311s,  411.11/s  (0.314s,  407.45/s)  LR: 1.000e-07  Data: 0.011 (0.014)
Train: 105 [ 300/390 ( 77%)]  Loss: 3.475 (3.47)  Time: 0.312s,  409.98/s  (0.313s,  408.42/s)  LR: 1.000e-07  Data: 0.012 (0.013)
Train: 105 [ 389/390 (100%)]  Loss: 3.547 (3.49)  Time: 0.301s,  425.81/s  (0.313s,  408.87/s)  LR: 1.000e-07  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.307 (0.307)  Loss:  1.3955 (1.3955)  Acc@1: 68.7500 (68.7500)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.3223 (1.4886)  Acc@1: 75.0000 (65.1500)  Acc@5: 81.2500 (89.7700)
Test: [Whole Val]  Time: 9.529  Loss: 1.4886  Acc@1: 65.1500 Pruned: 53.76% 
Test (EMA): [   0/78]  Time: 0.301 (0.301)  Loss:  1.3965 (1.3965)  Acc@1: 67.9688 (67.9688)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  1.3223 (1.4886)  Acc@1: 75.0000 (65.1500)  Acc@5: 81.2500 (89.7500)
Test (EMA): [Whole Val]  Time: 9.515  Loss: 1.4886  Acc@1: 65.1500 Pruned: 53.76% 
Train: 106 [   0/390 (  0%)]  Loss: 3.933 (3.93)  Time: 0.853s,  150.02/s  (0.853s,  150.02/s)  LR: 1.000e-07  Data: 0.548 (0.548)
Train: 106 [ 100/390 ( 26%)]  Loss: 3.360 (3.58)  Time: 0.312s,  410.10/s  (0.319s,  400.67/s)  LR: 1.000e-07  Data: 0.011 (0.017)
Train: 106 [ 200/390 ( 51%)]  Loss: 3.730 (3.54)  Time: 0.311s,  411.12/s  (0.316s,  404.55/s)  LR: 1.000e-07  Data: 0.011 (0.014)
Train: 106 [ 300/390 ( 77%)]  Loss: 2.678 (3.54)  Time: 0.312s,  410.20/s  (0.315s,  406.51/s)  LR: 1.000e-07  Data: 0.011 (0.013)
Train: 106 [ 389/390 (100%)]  Loss: 3.539 (3.54)  Time: 0.301s,  425.87/s  (0.314s,  407.37/s)  LR: 1.000e-07  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.301 (0.301)  Loss:  1.3965 (1.3965)  Acc@1: 67.9688 (67.9688)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.3223 (1.4887)  Acc@1: 75.0000 (65.1500)  Acc@5: 81.2500 (89.7600)
Test: [Whole Val]  Time: 9.528  Loss: 1.4887  Acc@1: 65.1500 Pruned: 53.76% 
Test (EMA): [   0/78]  Time: 0.310 (0.310)  Loss:  1.3965 (1.3965)  Acc@1: 67.9688 (67.9688)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.3223 (1.4888)  Acc@1: 75.0000 (65.1300)  Acc@5: 81.2500 (89.7400)
Test (EMA): [Whole Val]  Time: 9.526  Loss: 1.4888  Acc@1: 65.1300 Pruned: 53.76% 
Train: 107 [   0/390 (  0%)]  Loss: 3.968 (3.97)  Time: 0.748s,  171.14/s  (0.748s,  171.14/s)  LR: 1.000e-07  Data: 0.447 (0.447)
Train: 107 [ 100/390 ( 26%)]  Loss: 3.719 (3.62)  Time: 0.311s,  411.16/s  (0.316s,  404.94/s)  LR: 1.000e-07  Data: 0.011 (0.016)
Train: 107 [ 200/390 ( 51%)]  Loss: 3.474 (3.59)  Time: 0.312s,  410.77/s  (0.314s,  407.66/s)  LR: 1.000e-07  Data: 0.011 (0.013)
Train: 107 [ 300/390 ( 77%)]  Loss: 3.685 (3.59)  Time: 0.311s,  411.12/s  (0.313s,  408.59/s)  LR: 1.000e-07  Data: 0.011 (0.013)
Train: 107 [ 389/390 (100%)]  Loss: 3.198 (3.57)  Time: 0.299s,  428.26/s  (0.313s,  409.11/s)  LR: 1.000e-07  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.307 (0.307)  Loss:  1.3955 (1.3955)  Acc@1: 68.7500 (68.7500)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.3223 (1.4888)  Acc@1: 75.0000 (65.1600)  Acc@5: 81.2500 (89.7300)
Test: [Whole Val]  Time: 9.533  Loss: 1.4888  Acc@1: 65.1600 Pruned: 53.76% 
Test (EMA): [   0/78]  Time: 0.334 (0.334)  Loss:  1.3965 (1.3965)  Acc@1: 68.7500 (68.7500)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.3223 (1.4888)  Acc@1: 75.0000 (65.1300)  Acc@5: 81.2500 (89.7600)
Test (EMA): [Whole Val]  Time: 9.543  Loss: 1.4888  Acc@1: 65.1300 Pruned: 53.76% 
Train: 108 [   0/390 (  0%)]  Loss: 2.903 (2.90)  Time: 0.797s,  160.58/s  (0.797s,  160.58/s)  LR: 1.000e-07  Data: 0.496 (0.496)
Train: 108 [ 100/390 ( 26%)]  Loss: 3.176 (3.58)  Time: 0.312s,  410.46/s  (0.317s,  404.41/s)  LR: 1.000e-07  Data: 0.011 (0.016)
Train: 108 [ 200/390 ( 51%)]  Loss: 2.676 (3.55)  Time: 0.311s,  410.97/s  (0.314s,  407.55/s)  LR: 1.000e-07  Data: 0.011 (0.014)
Train: 108 [ 300/390 ( 77%)]  Loss: 2.946 (3.53)  Time: 0.312s,  410.83/s  (0.313s,  408.57/s)  LR: 1.000e-07  Data: 0.011 (0.013)
Train: 108 [ 389/390 (100%)]  Loss: 3.055 (3.52)  Time: 0.299s,  427.95/s  (0.313s,  409.06/s)  LR: 1.000e-07  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.349 (0.349)  Loss:  1.3965 (1.3965)  Acc@1: 67.9688 (67.9688)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.3223 (1.4888)  Acc@1: 75.0000 (65.1200)  Acc@5: 81.2500 (89.7400)
Test: [Whole Val]  Time: 9.562  Loss: 1.4888  Acc@1: 65.1200 Pruned: 53.76% 
Test (EMA): [   0/78]  Time: 0.304 (0.304)  Loss:  1.3955 (1.3955)  Acc@1: 68.7500 (68.7500)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.3223 (1.4888)  Acc@1: 75.0000 (65.1600)  Acc@5: 81.2500 (89.7400)
Test (EMA): [Whole Val]  Time: 9.528  Loss: 1.4888  Acc@1: 65.1600 Pruned: 53.76% 
Train: 109 [   0/390 (  0%)]  Loss: 3.602 (3.60)  Time: 0.804s,  159.19/s  (0.804s,  159.19/s)  LR: 1.000e-07  Data: 0.502 (0.502)
Train: 109 [ 100/390 ( 26%)]  Loss: 3.921 (3.56)  Time: 0.312s,  410.42/s  (0.316s,  404.52/s)  LR: 1.000e-07  Data: 0.012 (0.016)
Train: 109 [ 200/390 ( 51%)]  Loss: 3.104 (3.55)  Time: 0.312s,  410.48/s  (0.314s,  407.59/s)  LR: 1.000e-07  Data: 0.011 (0.014)
Train: 109 [ 300/390 ( 77%)]  Loss: 4.020 (3.56)  Time: 0.312s,  409.78/s  (0.314s,  408.27/s)  LR: 1.000e-07  Data: 0.012 (0.013)
Train: 109 [ 389/390 (100%)]  Loss: 3.530 (3.56)  Time: 0.300s,  427.35/s  (0.313s,  408.84/s)  LR: 1.000e-07  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.352 (0.352)  Loss:  1.3965 (1.3965)  Acc@1: 68.7500 (68.7500)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.3223 (1.4888)  Acc@1: 75.0000 (65.1400)  Acc@5: 81.2500 (89.7500)
Test: [Whole Val]  Time: 9.555  Loss: 1.4888  Acc@1: 65.1400 Pruned: 53.76% 
Test (EMA): [   0/78]  Time: 0.302 (0.302)  Loss:  1.3965 (1.3965)  Acc@1: 68.7500 (68.7500)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.3223 (1.4888)  Acc@1: 75.0000 (65.1500)  Acc@5: 81.2500 (89.7400)
Test (EMA): [Whole Val]  Time: 9.525  Loss: 1.4888  Acc@1: 65.1500 Pruned: 53.76% 
*** Best metric: OrderedDict([('loss', 1.488790625), ('top1', 65.15), ('top5', 89.74), ('pruned', 0.5376340951492538)]) (epoch 109)
