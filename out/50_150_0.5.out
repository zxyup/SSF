/home/zxy21/miniconda3/envs/ssfn/lib/python3.10/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Training with a single process on 1 GPUs.
Data processing configuration for current model + dataset:
	input_size: (3, 224, 224)
	interpolation: bicubic
	mean: (0.5, 0.5, 0.5)
	std: (0.5, 0.5, 0.5)
	crop_pct: 0.9
/home/zxy21/miniconda3/envs/ssfn/lib/python3.10/site-packages/torch_pruning/dependency.py:360: UserWarning: Unwrapped parameters detected: ['blocks.3.ssf_shift_1', 'blocks.8.attn.ssf_shift_2', 'blocks.9.mlp.ssf_shift_1', 'blocks.0.attn.ssf_scale_1', 'blocks.1.mlp.ssf_scale_2', 'blocks.5.mlp.ssf_scale_2', 'blocks.8.ssf_scale_2', 'blocks.10.attn.ssf_scale_1', 'blocks.0.ssf_shift_2', 'blocks.2.attn.ssf_shift_1', 'blocks.4.ssf_shift_2', 'blocks.6.attn.ssf_shift_1', 'blocks.6.mlp.ssf_shift_2', 'blocks.10.mlp.ssf_shift_2', 'patch_embed.ssf_shift_1', 'blocks.2.ssf_scale_1', 'blocks.7.attn.ssf_scale_2', 'blocks.8.mlp.ssf_scale_1', 'blocks.11.attn.ssf_scale_2', 'blocks.0.mlp.ssf_shift_1', 'blocks.3.attn.ssf_shift_2', 'blocks.4.mlp.ssf_shift_1', 'blocks.7.ssf_shift_1', 'blocks.11.ssf_shift_1', 'blocks.5.attn.ssf_scale_1', 'blocks.1.attn.ssf_scale_1', 'blocks.3.ssf_scale_2', 'blocks.9.mlp.ssf_scale_2', 'blocks.0.attn.ssf_shift_1', 'blocks.1.mlp.ssf_shift_2', 'blocks.5.mlp.ssf_shift_2', 'blocks.8.ssf_shift_2', 'blocks.10.attn.ssf_shift_1', 'blocks.2.attn.ssf_scale_2', 'blocks.3.mlp.ssf_scale_1', 'blocks.6.ssf_scale_1', 'blocks.6.attn.ssf_scale_2', 'blocks.10.ssf_scale_1', 'blocks.2.ssf_shift_1', 'blocks.7.attn.ssf_shift_2', 'blocks.8.mlp.ssf_shift_1', 'blocks.11.attn.ssf_shift_2', 'blocks.0.mlp.ssf_scale_2', 'blocks.4.mlp.ssf_scale_2', 'blocks.7.ssf_scale_2', 'blocks.9.attn.ssf_scale_1', 'blocks.11.ssf_scale_2', 'blocks.1.attn.ssf_shift_1', 'blocks.3.ssf_shift_2', 'blocks.5.attn.ssf_shift_1', 'blocks.9.mlp.ssf_shift_2', 'blocks.0.attn.ssf_scale_2', 'blocks.1.ssf_scale_1', 'blocks.5.ssf_scale_1', 'blocks.7.mlp.ssf_scale_1', 'blocks.10.attn.ssf_scale_2', 'blocks.11.mlp.ssf_scale_1', 'blocks.2.attn.ssf_shift_2', 'blocks.3.mlp.ssf_shift_1', 'blocks.6.ssf_shift_1', 'blocks.6.attn.ssf_shift_2', 'blocks.10.ssf_shift_1', 'ssf_scale_1', 'blocks.2.ssf_scale_2', 'blocks.4.attn.ssf_scale_1', 'blocks.8.mlp.ssf_scale_2', 'blocks.0.mlp.ssf_shift_2', 'blocks.4.mlp.ssf_shift_2', 'blocks.7.ssf_shift_2', 'blocks.9.attn.ssf_shift_1', 'blocks.11.ssf_shift_2', 'blocks.5.attn.ssf_scale_2', 'blocks.1.attn.ssf_scale_2', 'blocks.2.mlp.ssf_scale_1', 'blocks.9.ssf_scale_1', 'blocks.0.attn.ssf_shift_2', 'blocks.1.ssf_shift_1', 'blocks.5.ssf_shift_1', 'blocks.7.mlp.ssf_shift_1', 'blocks.10.attn.ssf_shift_2', 'blocks.11.mlp.ssf_shift_1', 'blocks.3.mlp.ssf_scale_2', 'blocks.6.ssf_scale_2', 'blocks.8.attn.ssf_scale_1', 'blocks.10.ssf_scale_2', 'ssf_shift_1', 'blocks.2.ssf_shift_2', 'blocks.4.attn.ssf_shift_1', 'blocks.8.mlp.ssf_shift_2', 'blocks.0.ssf_scale_1', 'blocks.4.ssf_scale_1', 'blocks.6.mlp.ssf_scale_1', 'blocks.9.attn.ssf_scale_2', 'blocks.10.mlp.ssf_scale_1', 'blocks.1.attn.ssf_shift_2', 'blocks.2.mlp.ssf_shift_1', 'blocks.5.attn.ssf_shift_2', 'blocks.9.ssf_shift_1', 'blocks.1.ssf_scale_2', 'blocks.3.attn.ssf_scale_1', 'blocks.5.ssf_scale_2', 'blocks.7.mlp.ssf_scale_2', 'blocks.11.mlp.ssf_scale_2', 'blocks.3.mlp.ssf_shift_2', 'blocks.6.ssf_shift_2', 'blocks.8.attn.ssf_shift_1', 'blocks.10.ssf_shift_2', 'blocks.1.mlp.ssf_scale_1', 'blocks.4.attn.ssf_scale_2', 'blocks.5.mlp.ssf_scale_1', 'blocks.8.ssf_scale_1', 'blocks.0.ssf_shift_1', 'blocks.4.ssf_shift_1', 'blocks.6.mlp.ssf_shift_1', 'blocks.9.attn.ssf_shift_2', 'blocks.10.mlp.ssf_shift_1', 'blocks.2.mlp.ssf_scale_2', 'blocks.7.attn.ssf_scale_1', 'blocks.9.ssf_scale_2', 'blocks.11.attn.ssf_scale_1', 'blocks.1.ssf_shift_2', 'blocks.3.attn.ssf_shift_1', 'blocks.5.ssf_shift_2', 'blocks.7.mlp.ssf_shift_2', 'blocks.11.mlp.ssf_shift_2', 'blocks.3.ssf_scale_1', 'blocks.8.attn.ssf_scale_2', 'blocks.9.mlp.ssf_scale_1', 'blocks.5.mlp.ssf_shift_1', 'blocks.1.mlp.ssf_shift_1', 'blocks.4.attn.ssf_shift_2', 'blocks.8.ssf_shift_1', 'blocks.0.ssf_scale_2', 'blocks.2.attn.ssf_scale_1', 'blocks.4.ssf_scale_2', 'blocks.6.attn.ssf_scale_1', 'blocks.6.mlp.ssf_scale_2', 'blocks.10.mlp.ssf_scale_2', 'patch_embed.ssf_scale_1', 'blocks.2.mlp.ssf_shift_2', 'blocks.7.attn.ssf_shift_1', 'blocks.9.ssf_shift_2', 'blocks.11.attn.ssf_shift_1', 'blocks.0.mlp.ssf_scale_1', 'blocks.3.attn.ssf_scale_2', 'blocks.4.mlp.ssf_scale_1', 'blocks.7.ssf_scale_1', 'blocks.11.ssf_scale_1'].
 Torch-Pruning will prune the last non-singleton dimension of a parameter. If you wish to customize this behavior, please provide an unwrapped_parameters argument.
  warnings.warn("Unwrapped parameters detected: {}.\n Torch-Pruning will prune the last non-singleton dimension of a parameter. If you wish to customize this behavior, please provide an unwrapped_parameters argument.".format([_param_to_name[p] for p in unwrapped_detected]))
Params: 86.0814 M
ops: 16.8553 G
ssf_scale_1
ssf_shift_1
patch_embed.ssf_scale_1
patch_embed.ssf_shift_1
blocks.0.ssf_scale_1
blocks.0.ssf_shift_1
blocks.0.ssf_scale_2
blocks.0.ssf_shift_2
blocks.0.attn.ssf_scale_1
blocks.0.attn.ssf_shift_1
blocks.0.attn.ssf_scale_2
blocks.0.attn.ssf_shift_2
blocks.0.mlp.ssf_scale_1
blocks.0.mlp.ssf_shift_1
blocks.0.mlp.ssf_scale_2
blocks.0.mlp.ssf_shift_2
blocks.1.ssf_scale_1
blocks.1.ssf_shift_1
blocks.1.ssf_scale_2
blocks.1.ssf_shift_2
blocks.1.attn.ssf_scale_1
blocks.1.attn.ssf_shift_1
blocks.1.attn.ssf_scale_2
blocks.1.attn.ssf_shift_2
blocks.1.mlp.ssf_scale_1
blocks.1.mlp.ssf_shift_1
blocks.1.mlp.ssf_scale_2
blocks.1.mlp.ssf_shift_2
blocks.2.ssf_scale_1
blocks.2.ssf_shift_1
blocks.2.ssf_scale_2
blocks.2.ssf_shift_2
blocks.2.attn.ssf_scale_1
blocks.2.attn.ssf_shift_1
blocks.2.attn.ssf_scale_2
blocks.2.attn.ssf_shift_2
blocks.2.mlp.ssf_scale_1
blocks.2.mlp.ssf_shift_1
blocks.2.mlp.ssf_scale_2
blocks.2.mlp.ssf_shift_2
blocks.3.ssf_scale_1
blocks.3.ssf_shift_1
blocks.3.ssf_scale_2
blocks.3.ssf_shift_2
blocks.3.attn.ssf_scale_1
blocks.3.attn.ssf_shift_1
blocks.3.attn.ssf_scale_2
blocks.3.attn.ssf_shift_2
blocks.3.mlp.ssf_scale_1
blocks.3.mlp.ssf_shift_1
blocks.3.mlp.ssf_scale_2
blocks.3.mlp.ssf_shift_2
blocks.4.ssf_scale_1
blocks.4.ssf_shift_1
blocks.4.ssf_scale_2
blocks.4.ssf_shift_2
blocks.4.attn.ssf_scale_1
blocks.4.attn.ssf_shift_1
blocks.4.attn.ssf_scale_2
blocks.4.attn.ssf_shift_2
blocks.4.mlp.ssf_scale_1
blocks.4.mlp.ssf_shift_1
blocks.4.mlp.ssf_scale_2
blocks.4.mlp.ssf_shift_2
blocks.5.ssf_scale_1
blocks.5.ssf_shift_1
blocks.5.ssf_scale_2
blocks.5.ssf_shift_2
blocks.5.attn.ssf_scale_1
blocks.5.attn.ssf_shift_1
blocks.5.attn.ssf_scale_2
blocks.5.attn.ssf_shift_2
blocks.5.mlp.ssf_scale_1
blocks.5.mlp.ssf_shift_1
blocks.5.mlp.ssf_scale_2
blocks.5.mlp.ssf_shift_2
blocks.6.ssf_scale_1
blocks.6.ssf_shift_1
blocks.6.ssf_scale_2
blocks.6.ssf_shift_2
blocks.6.attn.ssf_scale_1
blocks.6.attn.ssf_shift_1
blocks.6.attn.ssf_scale_2
blocks.6.attn.ssf_shift_2
blocks.6.mlp.ssf_scale_1
blocks.6.mlp.ssf_shift_1
blocks.6.mlp.ssf_scale_2
blocks.6.mlp.ssf_shift_2
blocks.7.ssf_scale_1
blocks.7.ssf_shift_1
blocks.7.ssf_scale_2
blocks.7.ssf_shift_2
blocks.7.attn.ssf_scale_1
blocks.7.attn.ssf_shift_1
blocks.7.attn.ssf_scale_2
blocks.7.attn.ssf_shift_2
blocks.7.mlp.ssf_scale_1
blocks.7.mlp.ssf_shift_1
blocks.7.mlp.ssf_scale_2
blocks.7.mlp.ssf_shift_2
blocks.8.ssf_scale_1
blocks.8.ssf_shift_1
blocks.8.ssf_scale_2
blocks.8.ssf_shift_2
blocks.8.attn.ssf_scale_1
blocks.8.attn.ssf_shift_1
blocks.8.attn.ssf_scale_2
blocks.8.attn.ssf_shift_2
blocks.8.mlp.ssf_scale_1
blocks.8.mlp.ssf_shift_1
blocks.8.mlp.ssf_scale_2
blocks.8.mlp.ssf_shift_2
blocks.9.ssf_scale_1
blocks.9.ssf_shift_1
blocks.9.ssf_scale_2
blocks.9.ssf_shift_2
blocks.9.attn.ssf_scale_1
blocks.9.attn.ssf_shift_1
blocks.9.attn.ssf_scale_2
blocks.9.attn.ssf_shift_2
blocks.9.mlp.ssf_scale_1
blocks.9.mlp.ssf_shift_1
blocks.9.mlp.ssf_scale_2
blocks.9.mlp.ssf_shift_2
blocks.10.ssf_scale_1
blocks.10.ssf_shift_1
blocks.10.ssf_scale_2
blocks.10.ssf_shift_2
blocks.10.attn.ssf_scale_1
blocks.10.attn.ssf_shift_1
blocks.10.attn.ssf_scale_2
blocks.10.attn.ssf_shift_2
blocks.10.mlp.ssf_scale_1
blocks.10.mlp.ssf_shift_1
blocks.10.mlp.ssf_scale_2
blocks.10.mlp.ssf_shift_2
blocks.11.ssf_scale_1
blocks.11.ssf_shift_1
blocks.11.ssf_scale_2
blocks.11.ssf_shift_2
blocks.11.attn.ssf_scale_1
blocks.11.attn.ssf_shift_1
blocks.11.attn.ssf_scale_2
blocks.11.attn.ssf_shift_2
blocks.11.mlp.ssf_scale_1
blocks.11.mlp.ssf_shift_1
blocks.11.mlp.ssf_scale_2
blocks.11.mlp.ssf_shift_2
head.weight
head.bias
freezing parameters finished!
Model vit_base_patch16_224_in21k created, param count:86081380
number of params for requires grad: 282724
Using native Torch AMP. Training in mixed precision.
Scheduled epochs: 160
Train: 0 [   0/390 (  0%)]  Loss: 5.723 (5.72)  Time: 7.209s,   17.76/s  (7.209s,   17.76/s)  LR: 1.000e-03  Data: 1.124 (1.124)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.498 (3.71)  Time: 0.325s,  393.60/s  (0.402s,  318.45/s)  LR: 1.000e-03  Data: 0.012 (0.041)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.159 (3.36)  Time: 0.315s,  406.19/s  (0.361s,  354.58/s)  LR: 1.000e-03  Data: 0.011 (0.027)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.063 (3.18)  Time: 0.326s,  393.16/s  (0.348s,  367.36/s)  LR: 1.000e-03  Data: 0.013 (0.022)
Train: 0 [ 389/390 (100%)]  Loss: 3.413 (3.10)  Time: 0.303s,  422.09/s  (0.341s,  375.47/s)  LR: 1.000e-03  Data: 0.000 (0.020)
Train: 0 [   0/390 (  0%)]  Loss: 2.019 (2.02)  Time: 0.970s,  131.93/s  (0.970s,  131.93/s)  LR: 1.000e-03  Data: 0.642 (0.642)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.835 (2.79)  Time: 0.317s,  404.23/s  (0.323s,  395.95/s)  LR: 1.000e-03  Data: 0.012 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.461 (2.76)  Time: 0.317s,  403.19/s  (0.320s,  399.71/s)  LR: 1.000e-03  Data: 0.013 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.191 (2.79)  Time: 0.324s,  395.51/s  (0.319s,  401.07/s)  LR: 1.000e-03  Data: 0.011 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 2.223 (2.79)  Time: 0.303s,  421.75/s  (0.318s,  401.98/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 2.995 (2.99)  Time: 0.887s,  144.36/s  (0.887s,  144.36/s)  LR: 1.000e-03  Data: 0.584 (0.584)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.177 (2.76)  Time: 0.312s,  409.67/s  (0.326s,  392.46/s)  LR: 1.000e-03  Data: 0.010 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.077 (2.73)  Time: 0.316s,  405.05/s  (0.321s,  398.47/s)  LR: 1.000e-03  Data: 0.010 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.471 (2.74)  Time: 0.315s,  405.75/s  (0.320s,  400.51/s)  LR: 1.000e-03  Data: 0.011 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 2.704 (2.74)  Time: 0.305s,  419.61/s  (0.319s,  401.58/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 3.374 (3.37)  Time: 0.779s,  164.26/s  (0.779s,  164.26/s)  LR: 1.000e-03  Data: 0.461 (0.461)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.151 (2.68)  Time: 0.314s,  407.68/s  (0.321s,  398.85/s)  LR: 1.000e-03  Data: 0.010 (0.016)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.519 (2.71)  Time: 0.329s,  388.47/s  (0.319s,  401.21/s)  LR: 1.000e-03  Data: 0.011 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.246 (2.71)  Time: 0.330s,  388.17/s  (0.319s,  401.19/s)  LR: 1.000e-03  Data: 0.011 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 2.637 (2.72)  Time: 0.323s,  396.17/s  (0.318s,  402.04/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 3.136 (3.14)  Time: 0.858s,  149.26/s  (0.858s,  149.26/s)  LR: 1.000e-03  Data: 0.547 (0.547)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.969 (2.75)  Time: 0.315s,  406.86/s  (0.323s,  396.48/s)  LR: 1.000e-03  Data: 0.012 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.421 (2.76)  Time: 0.315s,  406.29/s  (0.320s,  399.98/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.323 (2.78)  Time: 0.314s,  407.98/s  (0.320s,  400.53/s)  LR: 1.000e-03  Data: 0.011 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.196 (2.78)  Time: 0.309s,  413.94/s  (0.319s,  400.94/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 2.996 (3.00)  Time: 0.807s,  158.51/s  (0.807s,  158.51/s)  LR: 1.000e-03  Data: 0.501 (0.501)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.031 (2.83)  Time: 0.314s,  407.90/s  (0.323s,  396.02/s)  LR: 1.000e-03  Data: 0.010 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.446 (2.80)  Time: 0.315s,  406.13/s  (0.321s,  398.86/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.279 (2.78)  Time: 0.330s,  388.16/s  (0.320s,  399.73/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.012 (2.79)  Time: 0.304s,  420.85/s  (0.320s,  400.32/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 2.244 (2.24)  Time: 0.930s,  137.64/s  (0.930s,  137.64/s)  LR: 1.000e-03  Data: 0.601 (0.601)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.126 (2.86)  Time: 0.311s,  411.07/s  (0.321s,  399.06/s)  LR: 1.000e-03  Data: 0.010 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.177 (2.87)  Time: 0.314s,  407.36/s  (0.321s,  399.16/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.445 (2.84)  Time: 0.314s,  407.78/s  (0.320s,  399.81/s)  LR: 1.000e-03  Data: 0.011 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 2.406 (2.84)  Time: 0.304s,  421.62/s  (0.320s,  400.59/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 2.966 (2.97)  Time: 0.951s,  134.64/s  (0.951s,  134.64/s)  LR: 1.000e-03  Data: 0.640 (0.640)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.293 (2.82)  Time: 0.318s,  402.93/s  (0.323s,  396.87/s)  LR: 1.000e-03  Data: 0.011 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 1.866 (2.82)  Time: 0.314s,  407.79/s  (0.321s,  399.02/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.936 (2.83)  Time: 0.329s,  388.63/s  (0.320s,  399.89/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.286 (2.86)  Time: 0.308s,  415.90/s  (0.319s,  400.86/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 1.870 (1.87)  Time: 0.963s,  132.93/s  (0.963s,  132.93/s)  LR: 1.000e-03  Data: 0.654 (0.654)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.454 (2.86)  Time: 0.314s,  407.20/s  (0.324s,  395.25/s)  LR: 1.000e-03  Data: 0.010 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.265 (2.86)  Time: 0.317s,  403.32/s  (0.321s,  398.27/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.580 (2.89)  Time: 0.314s,  407.63/s  (0.320s,  399.60/s)  LR: 1.000e-03  Data: 0.010 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 2.044 (2.89)  Time: 0.304s,  421.34/s  (0.319s,  400.90/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 3.453 (3.45)  Time: 1.050s,  121.90/s  (1.050s,  121.90/s)  LR: 1.000e-03  Data: 0.727 (0.727)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.282 (2.85)  Time: 0.316s,  404.46/s  (0.324s,  395.49/s)  LR: 1.000e-03  Data: 0.011 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.031 (2.87)  Time: 0.331s,  386.56/s  (0.320s,  399.65/s)  LR: 1.000e-03  Data: 0.015 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 1.905 (2.88)  Time: 0.317s,  403.56/s  (0.320s,  400.18/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 2.089 (2.88)  Time: 0.304s,  420.89/s  (0.320s,  399.74/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 2.747 (2.75)  Time: 0.859s,  148.98/s  (0.859s,  148.98/s)  LR: 1.000e-03  Data: 0.556 (0.556)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.395 (2.92)  Time: 0.316s,  405.19/s  (0.321s,  399.04/s)  LR: 1.000e-03  Data: 0.013 (0.016)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.521 (2.92)  Time: 0.314s,  407.94/s  (0.318s,  401.98/s)  LR: 1.000e-03  Data: 0.011 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.835 (2.93)  Time: 0.317s,  404.37/s  (0.318s,  402.99/s)  LR: 1.000e-03  Data: 0.013 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 3.195 (2.94)  Time: 0.302s,  423.32/s  (0.317s,  403.45/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 2.997 (3.00)  Time: 0.837s,  152.97/s  (0.837s,  152.97/s)  LR: 1.000e-03  Data: 0.523 (0.523)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.940 (2.92)  Time: 0.315s,  406.10/s  (0.323s,  396.31/s)  LR: 1.000e-03  Data: 0.011 (0.016)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.668 (2.90)  Time: 0.313s,  409.01/s  (0.320s,  400.43/s)  LR: 1.000e-03  Data: 0.010 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.686 (2.90)  Time: 0.315s,  406.84/s  (0.318s,  402.23/s)  LR: 1.000e-03  Data: 0.010 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 1.886 (2.89)  Time: 0.303s,  422.90/s  (0.318s,  402.74/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 3.589 (3.59)  Time: 0.937s,  136.55/s  (0.937s,  136.55/s)  LR: 1.000e-03  Data: 0.622 (0.622)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.434 (3.03)  Time: 0.314s,  407.39/s  (0.322s,  397.93/s)  LR: 1.000e-03  Data: 0.010 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.476 (2.99)  Time: 0.317s,  403.96/s  (0.319s,  401.49/s)  LR: 1.000e-03  Data: 0.010 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.472 (2.98)  Time: 0.315s,  406.42/s  (0.318s,  402.04/s)  LR: 1.000e-03  Data: 0.011 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 3.471 (2.96)  Time: 0.303s,  422.03/s  (0.318s,  402.65/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 2.108 (2.11)  Time: 0.851s,  150.39/s  (0.851s,  150.39/s)  LR: 1.000e-03  Data: 0.545 (0.545)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.859 (3.00)  Time: 0.315s,  406.18/s  (0.328s,  390.83/s)  LR: 1.000e-03  Data: 0.013 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.350 (2.99)  Time: 0.318s,  402.31/s  (0.321s,  398.15/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.857 (2.98)  Time: 0.312s,  410.46/s  (0.320s,  399.80/s)  LR: 1.000e-03  Data: 0.010 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 3.481 (2.98)  Time: 0.304s,  421.63/s  (0.319s,  401.26/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 3.182 (3.18)  Time: 0.711s,  179.98/s  (0.711s,  179.98/s)  LR: 1.000e-03  Data: 0.407 (0.407)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.944 (2.87)  Time: 0.334s,  383.38/s  (0.322s,  397.07/s)  LR: 1.000e-03  Data: 0.010 (0.015)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.157 (2.94)  Time: 0.315s,  406.79/s  (0.320s,  399.49/s)  LR: 1.000e-03  Data: 0.010 (0.013)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.515 (2.95)  Time: 0.313s,  409.12/s  (0.321s,  398.51/s)  LR: 1.000e-03  Data: 0.010 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 2.683 (2.95)  Time: 0.305s,  419.69/s  (0.320s,  399.92/s)  LR: 1.000e-03  Data: 0.000 (0.012)
Train: 0 [   0/390 (  0%)]  Loss: 3.351 (3.35)  Time: 0.984s,  130.09/s  (0.984s,  130.09/s)  LR: 1.000e-03  Data: 0.678 (0.678)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.303 (3.06)  Time: 0.314s,  407.20/s  (0.323s,  396.82/s)  LR: 1.000e-03  Data: 0.012 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.287 (3.02)  Time: 0.319s,  400.72/s  (0.319s,  400.94/s)  LR: 1.000e-03  Data: 0.014 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.213 (3.02)  Time: 0.313s,  408.95/s  (0.318s,  402.23/s)  LR: 1.000e-03  Data: 0.011 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 3.085 (3.02)  Time: 0.318s,  402.99/s  (0.318s,  402.27/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 3.557 (3.56)  Time: 0.850s,  150.63/s  (0.850s,  150.63/s)  LR: 1.000e-03  Data: 0.536 (0.536)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.150 (3.00)  Time: 0.322s,  397.18/s  (0.322s,  397.78/s)  LR: 1.000e-03  Data: 0.016 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.031 (3.02)  Time: 0.326s,  392.44/s  (0.320s,  400.57/s)  LR: 1.000e-03  Data: 0.010 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.386 (3.03)  Time: 0.319s,  401.58/s  (0.320s,  399.88/s)  LR: 1.000e-03  Data: 0.010 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 2.912 (3.04)  Time: 0.304s,  420.84/s  (0.319s,  401.30/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 3.135 (3.14)  Time: 0.901s,  142.06/s  (0.901s,  142.06/s)  LR: 1.000e-03  Data: 0.597 (0.597)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.451 (3.09)  Time: 0.315s,  406.52/s  (0.322s,  397.35/s)  LR: 1.000e-03  Data: 0.011 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.319 (3.07)  Time: 0.319s,  401.16/s  (0.319s,  401.17/s)  LR: 1.000e-03  Data: 0.015 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.871 (3.02)  Time: 0.314s,  407.94/s  (0.318s,  402.49/s)  LR: 1.000e-03  Data: 0.010 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 3.339 (3.01)  Time: 0.303s,  422.22/s  (0.317s,  403.42/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 3.296 (3.30)  Time: 0.807s,  158.70/s  (0.807s,  158.70/s)  LR: 1.000e-03  Data: 0.494 (0.494)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.699 (3.13)  Time: 0.316s,  405.39/s  (0.321s,  398.62/s)  LR: 1.000e-03  Data: 0.012 (0.016)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.080 (3.13)  Time: 0.314s,  407.06/s  (0.318s,  402.21/s)  LR: 1.000e-03  Data: 0.010 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.352 (3.11)  Time: 0.315s,  406.59/s  (0.317s,  403.53/s)  LR: 1.000e-03  Data: 0.010 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 3.319 (3.11)  Time: 0.305s,  419.43/s  (0.317s,  404.22/s)  LR: 1.000e-03  Data: 0.000 (0.012)
Train: 0 [   0/390 (  0%)]  Loss: 2.458 (2.46)  Time: 0.933s,  137.15/s  (0.933s,  137.15/s)  LR: 1.000e-03  Data: 0.629 (0.629)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.480 (3.09)  Time: 0.320s,  400.43/s  (0.325s,  393.55/s)  LR: 1.000e-03  Data: 0.015 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.762 (3.06)  Time: 0.315s,  406.97/s  (0.321s,  399.29/s)  LR: 1.000e-03  Data: 0.010 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.782 (3.06)  Time: 0.315s,  406.30/s  (0.319s,  401.37/s)  LR: 1.000e-03  Data: 0.012 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 2.695 (3.07)  Time: 0.325s,  393.26/s  (0.319s,  401.62/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 3.942 (3.94)  Time: 0.916s,  139.69/s  (0.916s,  139.69/s)  LR: 1.000e-03  Data: 0.608 (0.608)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.094 (3.09)  Time: 0.313s,  409.07/s  (0.324s,  395.61/s)  LR: 1.000e-03  Data: 0.010 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.424 (3.06)  Time: 0.314s,  408.17/s  (0.321s,  399.33/s)  LR: 1.000e-03  Data: 0.010 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.519 (3.07)  Time: 0.313s,  409.37/s  (0.319s,  401.60/s)  LR: 1.000e-03  Data: 0.010 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 3.435 (3.07)  Time: 0.303s,  421.89/s  (0.318s,  402.39/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 3.078 (3.08)  Time: 0.796s,  160.81/s  (0.796s,  160.81/s)  LR: 1.000e-03  Data: 0.481 (0.481)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.736 (3.11)  Time: 0.315s,  405.98/s  (0.320s,  400.27/s)  LR: 1.000e-03  Data: 0.011 (0.016)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.856 (3.07)  Time: 0.317s,  403.43/s  (0.318s,  402.91/s)  LR: 1.000e-03  Data: 0.014 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.809 (3.10)  Time: 0.314s,  407.74/s  (0.317s,  403.81/s)  LR: 1.000e-03  Data: 0.011 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 3.485 (3.12)  Time: 0.305s,  420.31/s  (0.317s,  403.48/s)  LR: 1.000e-03  Data: 0.000 (0.012)
Train: 0 [   0/390 (  0%)]  Loss: 2.335 (2.34)  Time: 0.869s,  147.37/s  (0.869s,  147.37/s)  LR: 1.000e-03  Data: 0.565 (0.565)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.452 (3.13)  Time: 0.314s,  408.12/s  (0.323s,  396.31/s)  LR: 1.000e-03  Data: 0.011 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.749 (3.14)  Time: 0.313s,  409.01/s  (0.320s,  400.11/s)  LR: 1.000e-03  Data: 0.010 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.811 (3.16)  Time: 0.315s,  406.53/s  (0.318s,  402.06/s)  LR: 1.000e-03  Data: 0.011 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 2.917 (3.16)  Time: 0.303s,  421.81/s  (0.317s,  403.18/s)  LR: 1.000e-03  Data: 0.000 (0.012)
Train: 0 [   0/390 (  0%)]  Loss: 3.577 (3.58)  Time: 0.866s,  147.73/s  (0.866s,  147.73/s)  LR: 1.000e-03  Data: 0.543 (0.543)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.588 (3.10)  Time: 0.313s,  408.46/s  (0.323s,  396.00/s)  LR: 1.000e-03  Data: 0.010 (0.016)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.448 (3.15)  Time: 0.331s,  387.29/s  (0.322s,  397.83/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.058 (3.17)  Time: 0.314s,  407.26/s  (0.324s,  395.36/s)  LR: 1.000e-03  Data: 0.012 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 3.745 (3.17)  Time: 0.304s,  421.59/s  (0.322s,  397.13/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 3.563 (3.56)  Time: 0.848s,  150.95/s  (0.848s,  150.95/s)  LR: 1.000e-03  Data: 0.540 (0.540)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.741 (3.21)  Time: 0.314s,  407.41/s  (0.323s,  396.79/s)  LR: 1.000e-03  Data: 0.012 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.601 (3.17)  Time: 0.321s,  398.88/s  (0.319s,  401.72/s)  LR: 1.000e-03  Data: 0.011 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.756 (3.18)  Time: 0.322s,  397.62/s  (0.318s,  402.42/s)  LR: 1.000e-03  Data: 0.014 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 2.394 (3.17)  Time: 0.303s,  422.27/s  (0.318s,  403.02/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 3.496 (3.50)  Time: 0.823s,  155.58/s  (0.823s,  155.58/s)  LR: 1.000e-03  Data: 0.511 (0.511)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.653 (3.16)  Time: 0.334s,  383.05/s  (0.327s,  391.90/s)  LR: 1.000e-03  Data: 0.012 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.373 (3.16)  Time: 0.316s,  405.21/s  (0.322s,  397.60/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.526 (3.17)  Time: 0.321s,  399.08/s  (0.321s,  398.92/s)  LR: 1.000e-03  Data: 0.011 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 3.749 (3.16)  Time: 0.302s,  423.28/s  (0.320s,  399.80/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 3.851 (3.85)  Time: 0.810s,  157.96/s  (0.810s,  157.96/s)  LR: 1.000e-03  Data: 0.503 (0.503)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.091 (3.20)  Time: 0.324s,  394.98/s  (0.321s,  398.24/s)  LR: 1.000e-03  Data: 0.012 (0.016)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.580 (3.21)  Time: 0.314s,  407.29/s  (0.320s,  400.55/s)  LR: 1.000e-03  Data: 0.011 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.451 (3.22)  Time: 0.318s,  402.62/s  (0.320s,  400.42/s)  LR: 1.000e-03  Data: 0.015 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 3.103 (3.23)  Time: 0.305s,  420.36/s  (0.319s,  401.87/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 3.648 (3.65)  Time: 0.844s,  151.66/s  (0.844s,  151.66/s)  LR: 1.000e-03  Data: 0.528 (0.528)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.437 (3.24)  Time: 0.325s,  394.12/s  (0.319s,  401.35/s)  LR: 1.000e-03  Data: 0.010 (0.016)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.536 (3.21)  Time: 0.314s,  407.82/s  (0.322s,  397.51/s)  LR: 1.000e-03  Data: 0.011 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.433 (3.21)  Time: 0.314s,  408.07/s  (0.320s,  399.93/s)  LR: 1.000e-03  Data: 0.011 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 3.721 (3.22)  Time: 0.304s,  421.71/s  (0.319s,  400.72/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 3.514 (3.51)  Time: 0.933s,  137.26/s  (0.933s,  137.26/s)  LR: 1.000e-03  Data: 0.630 (0.630)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.467 (3.21)  Time: 0.317s,  404.03/s  (0.323s,  396.55/s)  LR: 1.000e-03  Data: 0.013 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.754 (3.21)  Time: 0.314s,  408.12/s  (0.320s,  400.40/s)  LR: 1.000e-03  Data: 0.011 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.738 (3.22)  Time: 0.324s,  395.50/s  (0.319s,  401.40/s)  LR: 1.000e-03  Data: 0.014 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.610 (3.22)  Time: 0.306s,  418.40/s  (0.319s,  401.68/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 3.644 (3.64)  Time: 0.800s,  159.90/s  (0.800s,  159.90/s)  LR: 1.000e-03  Data: 0.493 (0.493)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.556 (3.29)  Time: 0.315s,  406.30/s  (0.326s,  392.50/s)  LR: 1.000e-03  Data: 0.010 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.870 (3.30)  Time: 0.324s,  395.48/s  (0.322s,  397.64/s)  LR: 1.000e-03  Data: 0.014 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.162 (3.29)  Time: 0.322s,  397.42/s  (0.321s,  399.27/s)  LR: 1.000e-03  Data: 0.014 (0.014)
Train: 0 [ 389/390 (100%)]  Loss: 3.683 (3.27)  Time: 0.304s,  421.39/s  (0.320s,  400.35/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 2.967 (2.97)  Time: 0.773s,  165.68/s  (0.773s,  165.68/s)  LR: 1.000e-03  Data: 0.468 (0.468)
Train: 0 [ 100/390 ( 26%)]  Loss: 2.735 (3.36)  Time: 0.315s,  406.09/s  (0.321s,  399.06/s)  LR: 1.000e-03  Data: 0.011 (0.016)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.078 (3.32)  Time: 0.313s,  408.35/s  (0.318s,  402.09/s)  LR: 1.000e-03  Data: 0.009 (0.013)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.406 (3.32)  Time: 0.313s,  408.37/s  (0.318s,  402.84/s)  LR: 1.000e-03  Data: 0.011 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 3.705 (3.31)  Time: 0.303s,  422.35/s  (0.317s,  403.64/s)  LR: 1.000e-03  Data: 0.000 (0.012)
Train: 0 [   0/390 (  0%)]  Loss: 3.670 (3.67)  Time: 0.902s,  141.96/s  (0.902s,  141.96/s)  LR: 1.000e-03  Data: 0.598 (0.598)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.514 (3.21)  Time: 0.317s,  403.95/s  (0.322s,  397.23/s)  LR: 1.000e-03  Data: 0.010 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.662 (3.24)  Time: 0.314s,  407.68/s  (0.319s,  401.47/s)  LR: 1.000e-03  Data: 0.011 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.898 (3.26)  Time: 0.313s,  408.35/s  (0.318s,  402.07/s)  LR: 1.000e-03  Data: 0.011 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 3.071 (3.27)  Time: 0.303s,  422.87/s  (0.317s,  403.21/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 2.381 (2.38)  Time: 0.861s,  148.68/s  (0.861s,  148.68/s)  LR: 1.000e-03  Data: 0.529 (0.529)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.982 (3.30)  Time: 0.315s,  406.93/s  (0.322s,  397.07/s)  LR: 1.000e-03  Data: 0.011 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.898 (3.34)  Time: 0.324s,  395.07/s  (0.322s,  396.99/s)  LR: 1.000e-03  Data: 0.015 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.561 (3.33)  Time: 0.313s,  408.33/s  (0.320s,  400.24/s)  LR: 1.000e-03  Data: 0.011 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 3.756 (3.34)  Time: 0.304s,  421.12/s  (0.319s,  401.74/s)  LR: 1.000e-03  Data: 0.000 (0.012)
Train: 0 [   0/390 (  0%)]  Loss: 3.816 (3.82)  Time: 0.905s,  141.44/s  (0.905s,  141.44/s)  LR: 1.000e-03  Data: 0.601 (0.601)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.629 (3.36)  Time: 0.313s,  409.31/s  (0.323s,  396.36/s)  LR: 1.000e-03  Data: 0.010 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.628 (3.36)  Time: 0.341s,  375.11/s  (0.319s,  400.95/s)  LR: 1.000e-03  Data: 0.016 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.062 (3.35)  Time: 0.312s,  409.80/s  (0.318s,  402.72/s)  LR: 1.000e-03  Data: 0.010 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 3.613 (3.34)  Time: 0.303s,  421.92/s  (0.318s,  402.33/s)  LR: 1.000e-03  Data: 0.000 (0.012)
Train: 0 [   0/390 (  0%)]  Loss: 2.447 (2.45)  Time: 0.939s,  136.26/s  (0.939s,  136.26/s)  LR: 1.000e-03  Data: 0.624 (0.624)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.661 (3.32)  Time: 0.314s,  407.94/s  (0.325s,  394.03/s)  LR: 1.000e-03  Data: 0.010 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.807 (3.34)  Time: 0.320s,  399.61/s  (0.323s,  395.78/s)  LR: 1.000e-03  Data: 0.010 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.616 (3.35)  Time: 0.318s,  403.11/s  (0.322s,  396.95/s)  LR: 1.000e-03  Data: 0.014 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 2.858 (3.36)  Time: 0.303s,  422.42/s  (0.321s,  398.15/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 3.495 (3.50)  Time: 0.809s,  158.27/s  (0.809s,  158.27/s)  LR: 1.000e-03  Data: 0.501 (0.501)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.308 (3.33)  Time: 0.313s,  408.61/s  (0.325s,  394.16/s)  LR: 1.000e-03  Data: 0.010 (0.016)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.920 (3.37)  Time: 0.330s,  387.80/s  (0.321s,  399.02/s)  LR: 1.000e-03  Data: 0.011 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.679 (3.38)  Time: 0.314s,  407.83/s  (0.320s,  399.63/s)  LR: 1.000e-03  Data: 0.010 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 3.638 (3.37)  Time: 0.303s,  423.13/s  (0.320s,  400.59/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 3.774 (3.77)  Time: 0.854s,  149.95/s  (0.854s,  149.95/s)  LR: 1.000e-03  Data: 0.551 (0.551)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.893 (3.40)  Time: 0.313s,  409.50/s  (0.320s,  399.42/s)  LR: 1.000e-03  Data: 0.010 (0.016)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.393 (3.38)  Time: 0.312s,  410.61/s  (0.318s,  402.56/s)  LR: 1.000e-03  Data: 0.009 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.571 (3.39)  Time: 0.316s,  404.50/s  (0.317s,  403.17/s)  LR: 1.000e-03  Data: 0.011 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 3.921 (3.39)  Time: 0.305s,  419.23/s  (0.317s,  403.57/s)  LR: 1.000e-03  Data: 0.000 (0.012)
Train: 0 [   0/390 (  0%)]  Loss: 3.471 (3.47)  Time: 0.758s,  168.94/s  (0.758s,  168.94/s)  LR: 1.000e-03  Data: 0.452 (0.452)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.167 (3.32)  Time: 0.317s,  404.02/s  (0.326s,  392.49/s)  LR: 1.000e-03  Data: 0.013 (0.016)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.154 (3.33)  Time: 0.315s,  406.09/s  (0.322s,  396.90/s)  LR: 1.000e-03  Data: 0.011 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.759 (3.34)  Time: 0.315s,  405.76/s  (0.320s,  399.53/s)  LR: 1.000e-03  Data: 0.010 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 2.511 (3.34)  Time: 0.303s,  421.96/s  (0.319s,  400.81/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 2.683 (2.68)  Time: 0.902s,  141.98/s  (0.902s,  141.98/s)  LR: 1.000e-03  Data: 0.598 (0.598)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.793 (3.37)  Time: 0.315s,  406.50/s  (0.330s,  387.60/s)  LR: 1.000e-03  Data: 0.011 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.558 (3.35)  Time: 0.333s,  384.28/s  (0.326s,  392.71/s)  LR: 1.000e-03  Data: 0.012 (0.015)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.096 (3.39)  Time: 0.313s,  408.59/s  (0.323s,  396.28/s)  LR: 1.000e-03  Data: 0.010 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 3.765 (3.41)  Time: 0.312s,  409.83/s  (0.322s,  397.67/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 3.794 (3.79)  Time: 0.832s,  153.87/s  (0.832s,  153.87/s)  LR: 1.000e-03  Data: 0.522 (0.522)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.362 (3.43)  Time: 0.314s,  407.48/s  (0.321s,  398.86/s)  LR: 1.000e-03  Data: 0.010 (0.016)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.857 (3.40)  Time: 0.315s,  406.80/s  (0.319s,  401.61/s)  LR: 1.000e-03  Data: 0.011 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.857 (3.41)  Time: 0.315s,  406.73/s  (0.320s,  399.91/s)  LR: 1.000e-03  Data: 0.011 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 2.721 (3.45)  Time: 0.306s,  418.37/s  (0.320s,  400.54/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 3.893 (3.89)  Time: 0.850s,  150.66/s  (0.850s,  150.66/s)  LR: 1.000e-03  Data: 0.544 (0.544)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.523 (3.48)  Time: 0.313s,  409.09/s  (0.321s,  398.47/s)  LR: 1.000e-03  Data: 0.011 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.395 (3.44)  Time: 0.318s,  402.75/s  (0.318s,  402.20/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.051 (3.44)  Time: 0.314s,  407.45/s  (0.317s,  403.19/s)  LR: 1.000e-03  Data: 0.011 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 3.056 (3.43)  Time: 0.310s,  413.46/s  (0.318s,  402.99/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 3.963 (3.96)  Time: 0.835s,  153.23/s  (0.835s,  153.23/s)  LR: 1.000e-03  Data: 0.504 (0.504)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.064 (3.45)  Time: 0.314s,  407.69/s  (0.321s,  398.47/s)  LR: 1.000e-03  Data: 0.011 (0.016)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.653 (3.44)  Time: 0.314s,  407.22/s  (0.318s,  402.44/s)  LR: 1.000e-03  Data: 0.011 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.857 (3.43)  Time: 0.315s,  406.30/s  (0.318s,  402.27/s)  LR: 1.000e-03  Data: 0.012 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 3.800 (3.46)  Time: 0.304s,  421.51/s  (0.317s,  403.44/s)  LR: 1.000e-03  Data: 0.000 (0.012)
Train: 0 [   0/390 (  0%)]  Loss: 4.022 (4.02)  Time: 0.996s,  128.51/s  (0.996s,  128.51/s)  LR: 1.000e-03  Data: 0.688 (0.688)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.850 (3.53)  Time: 0.316s,  404.71/s  (0.322s,  397.77/s)  LR: 1.000e-03  Data: 0.011 (0.018)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.801 (3.51)  Time: 0.314s,  408.21/s  (0.318s,  402.09/s)  LR: 1.000e-03  Data: 0.010 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.934 (3.53)  Time: 0.315s,  406.96/s  (0.319s,  401.63/s)  LR: 1.000e-03  Data: 0.011 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 3.208 (3.51)  Time: 0.303s,  422.36/s  (0.318s,  402.90/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 2.812 (2.81)  Time: 0.864s,  148.16/s  (0.864s,  148.16/s)  LR: 1.000e-03  Data: 0.554 (0.554)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.383 (3.42)  Time: 0.316s,  405.26/s  (0.323s,  396.56/s)  LR: 1.000e-03  Data: 0.013 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 2.901 (3.45)  Time: 0.313s,  409.06/s  (0.319s,  401.02/s)  LR: 1.000e-03  Data: 0.010 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.881 (3.46)  Time: 0.332s,  385.85/s  (0.318s,  402.04/s)  LR: 1.000e-03  Data: 0.016 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 3.578 (3.47)  Time: 0.303s,  422.18/s  (0.319s,  401.77/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 2.775 (2.77)  Time: 0.788s,  162.44/s  (0.788s,  162.44/s)  LR: 1.000e-03  Data: 0.472 (0.472)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.853 (3.49)  Time: 0.316s,  405.55/s  (0.321s,  398.84/s)  LR: 1.000e-03  Data: 0.011 (0.016)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.703 (3.48)  Time: 0.319s,  400.89/s  (0.322s,  397.52/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.323 (3.47)  Time: 0.327s,  391.63/s  (0.320s,  399.58/s)  LR: 1.000e-03  Data: 0.011 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 3.648 (3.48)  Time: 0.309s,  414.46/s  (0.320s,  399.42/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 2.887 (2.89)  Time: 0.801s,  159.85/s  (0.801s,  159.85/s)  LR: 1.000e-03  Data: 0.495 (0.495)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.060 (3.43)  Time: 0.316s,  404.55/s  (0.323s,  396.02/s)  LR: 1.000e-03  Data: 0.013 (0.016)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.758 (3.46)  Time: 0.316s,  405.51/s  (0.321s,  399.34/s)  LR: 1.000e-03  Data: 0.011 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.322 (3.45)  Time: 0.316s,  405.07/s  (0.320s,  399.83/s)  LR: 1.000e-03  Data: 0.012 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 3.830 (3.46)  Time: 0.318s,  403.02/s  (0.319s,  400.88/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 3.650 (3.65)  Time: 0.804s,  159.28/s  (0.804s,  159.28/s)  LR: 1.000e-03  Data: 0.489 (0.489)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.693 (3.52)  Time: 0.314s,  407.65/s  (0.322s,  397.75/s)  LR: 1.000e-03  Data: 0.011 (0.016)
Train: 0 [ 200/390 ( 51%)]  Loss: 4.143 (3.49)  Time: 0.317s,  403.30/s  (0.319s,  400.73/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.975 (3.51)  Time: 0.320s,  400.39/s  (0.318s,  402.18/s)  LR: 1.000e-03  Data: 0.015 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 2.909 (3.51)  Time: 0.303s,  422.03/s  (0.318s,  402.87/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 4.117 (4.12)  Time: 0.927s,  138.09/s  (0.927s,  138.09/s)  LR: 1.000e-03  Data: 0.623 (0.623)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.587 (3.53)  Time: 0.315s,  406.79/s  (0.328s,  390.71/s)  LR: 1.000e-03  Data: 0.011 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.546 (3.52)  Time: 0.313s,  408.72/s  (0.321s,  398.17/s)  LR: 1.000e-03  Data: 0.010 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 2.750 (3.51)  Time: 0.313s,  409.41/s  (0.319s,  400.84/s)  LR: 1.000e-03  Data: 0.010 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 3.945 (3.51)  Time: 0.306s,  418.06/s  (0.319s,  401.82/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 3.420 (3.42)  Time: 0.896s,  142.93/s  (0.896s,  142.93/s)  LR: 1.000e-03  Data: 0.591 (0.591)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.718 (3.52)  Time: 0.316s,  405.57/s  (0.320s,  400.57/s)  LR: 1.000e-03  Data: 0.012 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.914 (3.52)  Time: 0.334s,  382.89/s  (0.320s,  400.36/s)  LR: 1.000e-03  Data: 0.012 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.842 (3.54)  Time: 0.334s,  383.75/s  (0.319s,  401.81/s)  LR: 1.000e-03  Data: 0.016 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 3.861 (3.53)  Time: 0.303s,  421.90/s  (0.319s,  401.69/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Train: 0 [   0/390 (  0%)]  Loss: 3.432 (3.43)  Time: 0.855s,  149.73/s  (0.855s,  149.73/s)  LR: 1.000e-03  Data: 0.551 (0.551)
Train: 0 [ 100/390 ( 26%)]  Loss: 3.496 (3.54)  Time: 0.326s,  393.21/s  (0.322s,  397.60/s)  LR: 1.000e-03  Data: 0.010 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 3.198 (3.55)  Time: 0.313s,  408.99/s  (0.319s,  401.57/s)  LR: 1.000e-03  Data: 0.010 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 3.838 (3.56)  Time: 0.313s,  408.91/s  (0.318s,  402.38/s)  LR: 1.000e-03  Data: 0.010 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 3.947 (3.56)  Time: 0.317s,  403.59/s  (0.318s,  403.03/s)  LR: 1.000e-03  Data: 0.000 (0.013)
Test: [   0/78]  Time: 1.267 (1.267)  Loss:  4.5859 (4.5859)  Acc@1:  0.7812 ( 0.7812)  Acc@5:  7.0312 ( 7.0312)
Test: [  78/78]  Time: 0.086 (0.133)  Loss:  4.4023 (4.6461)  Acc@1: 12.5000 ( 1.0000)  Acc@5: 18.7500 ( 7.9300)
Test: [Whole Val]  Time: 10.470  Loss: 4.6461  Acc@1:  1.0000 Pruned: 57.01% 
*** Pruned results: OrderedDict([('loss', 4.64614375), ('top1', 1.0), ('top5', 7.93), ('pruned', 0.5700598569651741)])
Pruned: 50.00%
Train: 0 [   0/390 (  0%)]  Loss: 4.716 (4.72)  Time: 0.943s,  135.80/s  (0.943s,  135.80/s)  LR: 1.000e-07  Data: 0.639 (0.639)
Train: 0 [ 100/390 ( 26%)]  Loss: 4.714 (4.70)  Time: 0.315s,  406.00/s  (0.322s,  397.39/s)  LR: 1.000e-07  Data: 0.010 (0.017)
Train: 0 [ 200/390 ( 51%)]  Loss: 4.688 (4.70)  Time: 0.325s,  394.22/s  (0.318s,  402.04/s)  LR: 1.000e-07  Data: 0.011 (0.014)
Train: 0 [ 300/390 ( 77%)]  Loss: 4.655 (4.70)  Time: 0.328s,  390.62/s  (0.319s,  400.91/s)  LR: 1.000e-07  Data: 0.013 (0.013)
Train: 0 [ 389/390 (100%)]  Loss: 4.647 (4.70)  Time: 0.305s,  419.46/s  (0.319s,  401.46/s)  LR: 1.000e-07  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.394 (0.394)  Loss:  4.5820 (4.5820)  Acc@1:  0.7812 ( 0.7812)  Acc@5:  7.0312 ( 7.0312)
Test: [  78/78]  Time: 0.018 (0.121)  Loss:  4.4023 (4.6439)  Acc@1: 12.5000 ( 1.0000)  Acc@5: 18.7500 ( 7.9200)
Test: [Whole Val]  Time: 9.549  Loss: 4.6439  Acc@1:  1.0000 Pruned: 57.01% 
Test (EMA): [   0/78]  Time: 0.347 (0.347)  Loss:  4.5820 (4.5820)  Acc@1:  0.7812 ( 0.7812)  Acc@5:  7.0312 ( 7.0312)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  4.4023 (4.6439)  Acc@1: 12.5000 ( 1.0000)  Acc@5: 18.7500 ( 7.9100)
Test (EMA): [Whole Val]  Time: 9.460  Loss: 4.6439  Acc@1:  1.0000 Pruned: 57.01% 
Train: 1 [   0/390 (  0%)]  Loss: 4.685 (4.68)  Time: 0.898s,  142.58/s  (0.898s,  142.58/s)  LR: 1.001e-04  Data: 0.581 (0.581)
Train: 1 [ 100/390 ( 26%)]  Loss: 4.560 (4.60)  Time: 0.318s,  403.00/s  (0.320s,  399.56/s)  LR: 1.001e-04  Data: 0.010 (0.017)
Train: 1 [ 200/390 ( 51%)]  Loss: 4.571 (4.58)  Time: 0.311s,  411.27/s  (0.317s,  403.93/s)  LR: 1.001e-04  Data: 0.010 (0.014)
Train: 1 [ 300/390 ( 77%)]  Loss: 4.484 (4.56)  Time: 0.312s,  410.24/s  (0.316s,  405.45/s)  LR: 1.001e-04  Data: 0.010 (0.013)
Train: 1 [ 389/390 (100%)]  Loss: 4.471 (4.53)  Time: 0.301s,  424.88/s  (0.315s,  406.53/s)  LR: 1.001e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.356 (0.356)  Loss:  3.8008 (3.8008)  Acc@1: 25.0000 (25.0000)  Acc@5: 59.3750 (59.3750)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  3.6504 (3.8309)  Acc@1: 25.0000 (23.4300)  Acc@5: 68.7500 (54.0400)
Test: [Whole Val]  Time: 9.496  Loss: 3.8309  Acc@1: 23.4300 Pruned: 56.77% 
Test (EMA): [   0/78]  Time: 0.335 (0.335)  Loss:  3.8320 (3.8320)  Acc@1: 23.4375 (23.4375)  Acc@5: 57.0312 (57.0312)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  3.7246 (3.8622)  Acc@1: 25.0000 (22.9900)  Acc@5: 68.7500 (52.9300)
Test (EMA): [Whole Val]  Time: 9.488  Loss: 3.8622  Acc@1: 22.9900 Pruned: 56.80% 
Train: 2 [   0/390 (  0%)]  Loss: 4.275 (4.27)  Time: 0.767s,  166.96/s  (0.767s,  166.96/s)  LR: 2.001e-04  Data: 0.463 (0.463)
Train: 2 [ 100/390 ( 26%)]  Loss: 4.191 (4.24)  Time: 0.311s,  411.44/s  (0.318s,  403.08/s)  LR: 2.001e-04  Data: 0.011 (0.015)
Train: 2 [ 200/390 ( 51%)]  Loss: 4.088 (4.10)  Time: 0.313s,  409.55/s  (0.316s,  404.50/s)  LR: 2.001e-04  Data: 0.011 (0.013)
Train: 2 [ 300/390 ( 77%)]  Loss: 4.044 (4.04)  Time: 0.309s,  414.07/s  (0.316s,  405.07/s)  LR: 2.001e-04  Data: 0.010 (0.013)
Train: 2 [ 389/390 (100%)]  Loss: 3.580 (3.98)  Time: 0.303s,  422.92/s  (0.315s,  406.16/s)  LR: 2.001e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.426 (0.426)  Loss:  1.9434 (1.9434)  Acc@1: 60.1562 (60.1562)  Acc@5: 85.1562 (85.1562)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  1.7002 (2.0554)  Acc@1: 62.5000 (55.1100)  Acc@5: 93.7500 (84.2000)
Test: [Whole Val]  Time: 9.602  Loss: 2.0554  Acc@1: 55.1100 Pruned: 54.97% 
Test (EMA): [   0/78]  Time: 0.410 (0.410)  Loss:  1.9229 (1.9229)  Acc@1: 59.3750 (59.3750)  Acc@5: 84.3750 (84.3750)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.6699 (2.0428)  Acc@1: 68.7500 (55.5500)  Acc@5: 93.7500 (84.5000)
Test (EMA): [Whole Val]  Time: 9.562  Loss: 2.0428  Acc@1: 55.5500 Pruned: 55.00% 
Train: 3 [   0/390 (  0%)]  Loss: 4.119 (4.12)  Time: 0.869s,  147.32/s  (0.869s,  147.32/s)  LR: 3.001e-04  Data: 0.545 (0.545)
Train: 3 [ 100/390 ( 26%)]  Loss: 4.157 (3.82)  Time: 0.315s,  406.07/s  (0.320s,  400.23/s)  LR: 3.001e-04  Data: 0.010 (0.016)
Train: 3 [ 200/390 ( 51%)]  Loss: 3.759 (3.81)  Time: 0.312s,  410.31/s  (0.316s,  404.74/s)  LR: 3.001e-04  Data: 0.011 (0.014)
Train: 3 [ 300/390 ( 77%)]  Loss: 3.682 (3.77)  Time: 0.337s,  380.03/s  (0.318s,  403.09/s)  LR: 3.001e-04  Data: 0.011 (0.013)
Train: 3 [ 389/390 (100%)]  Loss: 4.182 (3.75)  Time: 0.301s,  425.68/s  (0.317s,  403.94/s)  LR: 3.001e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.480 (0.480)  Loss:  1.7139 (1.7139)  Acc@1: 57.8125 (57.8125)  Acc@5: 87.5000 (87.5000)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  1.4736 (1.7676)  Acc@1: 68.7500 (59.2600)  Acc@5: 93.7500 (86.8400)
Test: [Whole Val]  Time: 9.623  Loss: 1.7676  Acc@1: 59.2600 Pruned: 54.28% 
Test (EMA): [   0/78]  Time: 0.438 (0.438)  Loss:  1.6709 (1.6709)  Acc@1: 58.5938 (58.5938)  Acc@5: 85.9375 (85.9375)
Test (EMA): [  78/78]  Time: 0.018 (0.121)  Loss:  1.4502 (1.7397)  Acc@1: 75.0000 (60.3400)  Acc@5: 93.7500 (87.2200)
Test (EMA): [Whole Val]  Time: 9.586  Loss: 1.7397  Acc@1: 60.3400 Pruned: 54.27% 
Train: 4 [   0/390 (  0%)]  Loss: 3.885 (3.89)  Time: 0.864s,  148.20/s  (0.864s,  148.20/s)  LR: 4.001e-04  Data: 0.550 (0.550)
Train: 4 [ 100/390 ( 26%)]  Loss: 3.484 (3.69)  Time: 0.314s,  408.17/s  (0.320s,  400.36/s)  LR: 4.001e-04  Data: 0.012 (0.017)
Train: 4 [ 200/390 ( 51%)]  Loss: 3.035 (3.67)  Time: 0.326s,  392.48/s  (0.318s,  402.36/s)  LR: 4.001e-04  Data: 0.013 (0.014)
Train: 4 [ 300/390 ( 77%)]  Loss: 3.481 (3.66)  Time: 0.316s,  404.95/s  (0.319s,  401.15/s)  LR: 4.001e-04  Data: 0.014 (0.013)
Train: 4 [ 389/390 (100%)]  Loss: 4.048 (3.67)  Time: 0.317s,  404.17/s  (0.318s,  402.52/s)  LR: 4.001e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.481 (0.481)  Loss:  1.6367 (1.6367)  Acc@1: 61.7188 (61.7188)  Acc@5: 85.9375 (85.9375)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  1.3359 (1.6926)  Acc@1: 75.0000 (60.5400)  Acc@5: 93.7500 (87.3000)
Test: [Whole Val]  Time: 9.609  Loss: 1.6926  Acc@1: 60.5400 Pruned: 53.93% 
Test (EMA): [   0/78]  Time: 0.435 (0.435)  Loss:  1.5820 (1.5820)  Acc@1: 62.5000 (62.5000)  Acc@5: 89.0625 (89.0625)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.2314 (1.6364)  Acc@1: 75.0000 (62.3200)  Acc@5: 87.5000 (88.4400)
Test (EMA): [Whole Val]  Time: 9.590  Loss: 1.6364  Acc@1: 62.3200 Pruned: 53.94% 
Train: 5 [   0/390 (  0%)]  Loss: 3.644 (3.64)  Time: 0.772s,  165.81/s  (0.772s,  165.81/s)  LR: 5.000e-04  Data: 0.469 (0.469)
Train: 5 [ 100/390 ( 26%)]  Loss: 3.327 (3.67)  Time: 0.312s,  410.36/s  (0.320s,  399.98/s)  LR: 5.000e-04  Data: 0.011 (0.016)
Train: 5 [ 200/390 ( 51%)]  Loss: 4.079 (3.68)  Time: 0.311s,  411.59/s  (0.316s,  404.60/s)  LR: 5.000e-04  Data: 0.010 (0.013)
Train: 5 [ 300/390 ( 77%)]  Loss: 4.031 (3.66)  Time: 0.312s,  409.90/s  (0.315s,  405.88/s)  LR: 5.000e-04  Data: 0.012 (0.013)
Train: 5 [ 389/390 (100%)]  Loss: 3.733 (3.66)  Time: 0.315s,  406.37/s  (0.315s,  406.46/s)  LR: 5.000e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.392 (0.392)  Loss:  1.5762 (1.5762)  Acc@1: 61.7188 (61.7188)  Acc@5: 85.1562 (85.1562)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  1.2285 (1.6258)  Acc@1: 81.2500 (61.0600)  Acc@5: 87.5000 (88.0800)
Test: [Whole Val]  Time: 9.515  Loss: 1.6258  Acc@1: 61.0600 Pruned: 53.73% 
Test (EMA): [   0/78]  Time: 0.410 (0.410)  Loss:  1.5693 (1.5693)  Acc@1: 64.0625 (64.0625)  Acc@5: 89.8438 (89.8438)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.3105 (1.6097)  Acc@1: 68.7500 (62.7100)  Acc@5: 87.5000 (89.0100)
Test (EMA): [Whole Val]  Time: 9.553  Loss: 1.6097  Acc@1: 62.7100 Pruned: 53.74% 
Train: 6 [   0/390 (  0%)]  Loss: 3.360 (3.36)  Time: 0.921s,  138.93/s  (0.921s,  138.93/s)  LR: 6.000e-04  Data: 0.619 (0.619)
Train: 6 [ 100/390 ( 26%)]  Loss: 3.785 (3.59)  Time: 0.334s,  383.05/s  (0.322s,  397.84/s)  LR: 6.000e-04  Data: 0.019 (0.017)
Train: 6 [ 200/390 ( 51%)]  Loss: 3.059 (3.61)  Time: 0.325s,  394.14/s  (0.321s,  398.36/s)  LR: 6.000e-04  Data: 0.011 (0.014)
Train: 6 [ 300/390 ( 77%)]  Loss: 3.967 (3.63)  Time: 0.310s,  412.49/s  (0.319s,  400.93/s)  LR: 6.000e-04  Data: 0.010 (0.013)
Train: 6 [ 389/390 (100%)]  Loss: 3.959 (3.61)  Time: 0.304s,  420.54/s  (0.318s,  402.35/s)  LR: 6.000e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.307 (0.307)  Loss:  1.5791 (1.5791)  Acc@1: 60.1562 (60.1562)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.120)  Loss:  1.2520 (1.6249)  Acc@1: 75.0000 (62.1900)  Acc@5: 93.7500 (88.6500)
Test: [Whole Val]  Time: 9.443  Loss: 1.6249  Acc@1: 62.1900 Pruned: 53.57% 
Test (EMA): [   0/78]  Time: 0.365 (0.365)  Loss:  1.4834 (1.4834)  Acc@1: 62.5000 (62.5000)  Acc@5: 90.6250 (90.6250)
Test (EMA): [  78/78]  Time: 0.018 (0.120)  Loss:  1.1963 (1.5482)  Acc@1: 75.0000 (63.4300)  Acc@5: 93.7500 (89.3600)
Test (EMA): [Whole Val]  Time: 9.513  Loss: 1.5482  Acc@1: 63.4300 Pruned: 53.55% 
Train: 7 [   0/390 (  0%)]  Loss: 2.909 (2.91)  Time: 0.974s,  131.40/s  (0.974s,  131.40/s)  LR: 7.000e-04  Data: 0.657 (0.657)
Train: 7 [ 100/390 ( 26%)]  Loss: 2.810 (3.63)  Time: 0.312s,  409.65/s  (0.320s,  399.94/s)  LR: 7.000e-04  Data: 0.011 (0.017)
Train: 7 [ 200/390 ( 51%)]  Loss: 3.850 (3.63)  Time: 0.313s,  408.80/s  (0.317s,  404.10/s)  LR: 7.000e-04  Data: 0.014 (0.014)
Train: 7 [ 300/390 ( 77%)]  Loss: 3.557 (3.64)  Time: 0.311s,  411.51/s  (0.315s,  406.00/s)  LR: 7.000e-04  Data: 0.010 (0.013)
Train: 7 [ 389/390 (100%)]  Loss: 3.998 (3.65)  Time: 0.317s,  404.23/s  (0.316s,  405.27/s)  LR: 7.000e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.401 (0.401)  Loss:  1.5693 (1.5693)  Acc@1: 61.7188 (61.7188)  Acc@5: 89.0625 (89.0625)
Test: [  78/78]  Time: 0.018 (0.120)  Loss:  1.4395 (1.6424)  Acc@1: 62.5000 (62.3700)  Acc@5: 87.5000 (89.3300)
Test: [Whole Val]  Time: 9.511  Loss: 1.6424  Acc@1: 62.3700 Pruned: 53.46% 
Test (EMA): [   0/78]  Time: 0.329 (0.329)  Loss:  1.5459 (1.5459)  Acc@1: 64.8438 (64.8438)  Acc@5: 89.8438 (89.8438)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  1.2881 (1.5884)  Acc@1: 68.7500 (64.0800)  Acc@5: 87.5000 (89.9100)
Test (EMA): [Whole Val]  Time: 9.474  Loss: 1.5884  Acc@1: 64.0800 Pruned: 53.46% 
Train: 8 [   0/390 (  0%)]  Loss: 3.173 (3.17)  Time: 0.715s,  179.02/s  (0.715s,  179.02/s)  LR: 8.000e-04  Data: 0.415 (0.415)
Train: 8 [ 100/390 ( 26%)]  Loss: 4.008 (3.60)  Time: 0.315s,  406.42/s  (0.318s,  402.51/s)  LR: 8.000e-04  Data: 0.015 (0.015)
Train: 8 [ 200/390 ( 51%)]  Loss: 3.991 (3.63)  Time: 0.318s,  402.41/s  (0.316s,  404.75/s)  LR: 8.000e-04  Data: 0.010 (0.013)
Train: 8 [ 300/390 ( 77%)]  Loss: 3.553 (3.61)  Time: 0.311s,  411.91/s  (0.315s,  406.02/s)  LR: 8.000e-04  Data: 0.010 (0.012)
Train: 8 [ 389/390 (100%)]  Loss: 3.605 (3.61)  Time: 0.302s,  423.97/s  (0.316s,  404.69/s)  LR: 8.000e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.400 (0.400)  Loss:  1.5449 (1.5449)  Acc@1: 62.5000 (62.5000)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.3447 (1.5847)  Acc@1: 68.7500 (63.2400)  Acc@5: 87.5000 (89.0200)
Test: [Whole Val]  Time: 9.525  Loss: 1.5847  Acc@1: 63.2400 Pruned: 53.28% 
Test (EMA): [   0/78]  Time: 0.431 (0.431)  Loss:  1.4736 (1.4736)  Acc@1: 64.0625 (64.0625)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.2100 (1.5323)  Acc@1: 75.0000 (64.8300)  Acc@5: 81.2500 (90.2500)
Test (EMA): [Whole Val]  Time: 9.529  Loss: 1.5323  Acc@1: 64.8300 Pruned: 53.29% 
Train: 9 [   0/390 (  0%)]  Loss: 3.575 (3.58)  Time: 0.779s,  164.34/s  (0.779s,  164.34/s)  LR: 9.000e-04  Data: 0.466 (0.466)
Train: 9 [ 100/390 ( 26%)]  Loss: 3.847 (3.57)  Time: 0.310s,  412.57/s  (0.319s,  400.64/s)  LR: 9.000e-04  Data: 0.011 (0.016)
Train: 9 [ 200/390 ( 51%)]  Loss: 3.991 (3.57)  Time: 0.313s,  408.34/s  (0.316s,  404.77/s)  LR: 9.000e-04  Data: 0.011 (0.013)
Train: 9 [ 300/390 ( 77%)]  Loss: 3.932 (3.59)  Time: 0.309s,  413.76/s  (0.315s,  406.27/s)  LR: 9.000e-04  Data: 0.010 (0.013)
Train: 9 [ 389/390 (100%)]  Loss: 4.092 (3.60)  Time: 0.303s,  422.04/s  (0.314s,  407.20/s)  LR: 9.000e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.390 (0.390)  Loss:  1.5059 (1.5059)  Acc@1: 65.6250 (65.6250)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  1.2109 (1.5549)  Acc@1: 75.0000 (63.7600)  Acc@5: 93.7500 (89.6700)
Test: [Whole Val]  Time: 9.496  Loss: 1.5549  Acc@1: 63.7600 Pruned: 53.19% 
Test (EMA): [   0/78]  Time: 0.318 (0.318)  Loss:  1.4385 (1.4385)  Acc@1: 70.3125 (70.3125)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  1.2061 (1.5014)  Acc@1: 75.0000 (65.1900)  Acc@5: 87.5000 (90.3400)
Test (EMA): [Whole Val]  Time: 9.445  Loss: 1.5014  Acc@1: 65.1900 Pruned: 53.18% 
Train: 10 [   0/390 (  0%)]  Loss: 3.802 (3.80)  Time: 0.826s,  154.89/s  (0.826s,  154.89/s)  LR: 9.891e-04  Data: 0.516 (0.516)
Train: 10 [ 100/390 ( 26%)]  Loss: 3.250 (3.61)  Time: 0.313s,  408.99/s  (0.321s,  398.92/s)  LR: 9.891e-04  Data: 0.013 (0.016)
Train: 10 [ 200/390 ( 51%)]  Loss: 4.110 (3.60)  Time: 0.312s,  410.90/s  (0.317s,  403.85/s)  LR: 9.891e-04  Data: 0.011 (0.014)
Train: 10 [ 300/390 ( 77%)]  Loss: 3.631 (3.61)  Time: 0.311s,  411.32/s  (0.316s,  405.39/s)  LR: 9.891e-04  Data: 0.010 (0.013)
Train: 10 [ 389/390 (100%)]  Loss: 4.036 (3.61)  Time: 0.319s,  400.98/s  (0.316s,  405.31/s)  LR: 9.891e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.465 (0.465)  Loss:  1.4893 (1.4893)  Acc@1: 65.6250 (65.6250)  Acc@5: 88.2812 (88.2812)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.3809 (1.5705)  Acc@1: 68.7500 (62.6600)  Acc@5: 81.2500 (88.7700)
Test: [Whole Val]  Time: 9.618  Loss: 1.5705  Acc@1: 62.6600 Pruned: 53.08% 
Test (EMA): [   0/78]  Time: 0.450 (0.450)  Loss:  1.3945 (1.3945)  Acc@1: 67.1875 (67.1875)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.1963 (1.4588)  Acc@1: 68.7500 (65.1200)  Acc@5: 87.5000 (90.3600)
Test (EMA): [Whole Val]  Time: 9.581  Loss: 1.4588  Acc@1: 65.1200 Pruned: 53.09% 
Train: 11 [   0/390 (  0%)]  Loss: 3.098 (3.10)  Time: 0.717s,  178.60/s  (0.717s,  178.60/s)  LR: 9.868e-04  Data: 0.416 (0.416)
Train: 11 [ 100/390 ( 26%)]  Loss: 3.350 (3.57)  Time: 0.311s,  411.65/s  (0.320s,  399.78/s)  LR: 9.868e-04  Data: 0.010 (0.015)
Train: 11 [ 200/390 ( 51%)]  Loss: 4.104 (3.56)  Time: 0.313s,  409.50/s  (0.317s,  404.05/s)  LR: 9.868e-04  Data: 0.012 (0.013)
Train: 11 [ 300/390 ( 77%)]  Loss: 3.985 (3.57)  Time: 0.314s,  407.26/s  (0.315s,  405.74/s)  LR: 9.868e-04  Data: 0.011 (0.012)
Train: 11 [ 389/390 (100%)]  Loss: 3.294 (3.54)  Time: 0.317s,  404.21/s  (0.315s,  405.82/s)  LR: 9.868e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.372 (0.372)  Loss:  1.3701 (1.3701)  Acc@1: 66.4062 (66.4062)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.018 (0.120)  Loss:  1.2676 (1.4817)  Acc@1: 68.7500 (63.9200)  Acc@5: 87.5000 (90.2700)
Test: [Whole Val]  Time: 9.512  Loss: 1.4817  Acc@1: 63.9200 Pruned: 53.00% 
Test (EMA): [   0/78]  Time: 0.366 (0.366)  Loss:  1.3672 (1.3672)  Acc@1: 64.0625 (64.0625)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  1.1846 (1.4438)  Acc@1: 68.7500 (65.0200)  Acc@5: 87.5000 (90.6800)
Test (EMA): [Whole Val]  Time: 9.472  Loss: 1.4438  Acc@1: 65.0200 Pruned: 53.01% 
Train: 12 [   0/390 (  0%)]  Loss: 3.728 (3.73)  Time: 0.790s,  161.98/s  (0.790s,  161.98/s)  LR: 9.843e-04  Data: 0.482 (0.482)
Train: 12 [ 100/390 ( 26%)]  Loss: 2.857 (3.51)  Time: 0.313s,  409.51/s  (0.318s,  402.10/s)  LR: 9.843e-04  Data: 0.010 (0.016)
Train: 12 [ 200/390 ( 51%)]  Loss: 3.851 (3.53)  Time: 0.311s,  411.69/s  (0.316s,  405.32/s)  LR: 9.843e-04  Data: 0.011 (0.013)
Train: 12 [ 300/390 ( 77%)]  Loss: 2.952 (3.55)  Time: 0.311s,  411.74/s  (0.315s,  406.61/s)  LR: 9.843e-04  Data: 0.010 (0.013)
Train: 12 [ 389/390 (100%)]  Loss: 3.707 (3.55)  Time: 0.305s,  419.71/s  (0.314s,  407.12/s)  LR: 9.843e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.311 (0.311)  Loss:  1.4570 (1.4570)  Acc@1: 62.5000 (62.5000)  Acc@5: 89.8438 (89.8438)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  1.2041 (1.4619)  Acc@1: 81.2500 (64.2100)  Acc@5: 87.5000 (90.1700)
Test: [Whole Val]  Time: 9.444  Loss: 1.4619  Acc@1: 64.2100 Pruned: 52.91% 
Test (EMA): [   0/78]  Time: 0.312 (0.312)  Loss:  1.3848 (1.3848)  Acc@1: 67.1875 (67.1875)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.119)  Loss:  1.1934 (1.4159)  Acc@1: 75.0000 (66.5300)  Acc@5: 87.5000 (91.3000)
Test (EMA): [Whole Val]  Time: 9.435  Loss: 1.4159  Acc@1: 66.5300 Pruned: 52.93% 
Train: 13 [   0/390 (  0%)]  Loss: 3.913 (3.91)  Time: 0.837s,  152.90/s  (0.837s,  152.90/s)  LR: 9.816e-04  Data: 0.532 (0.532)
Train: 13 [ 100/390 ( 26%)]  Loss: 2.852 (3.56)  Time: 0.310s,  412.56/s  (0.318s,  402.02/s)  LR: 9.816e-04  Data: 0.010 (0.016)
Train: 13 [ 200/390 ( 51%)]  Loss: 3.424 (3.54)  Time: 0.313s,  408.95/s  (0.316s,  404.68/s)  LR: 9.816e-04  Data: 0.011 (0.014)
Train: 13 [ 300/390 ( 77%)]  Loss: 3.669 (3.55)  Time: 0.314s,  407.07/s  (0.315s,  405.78/s)  LR: 9.816e-04  Data: 0.011 (0.013)
Train: 13 [ 389/390 (100%)]  Loss: 3.672 (3.54)  Time: 0.317s,  403.42/s  (0.316s,  404.44/s)  LR: 9.816e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.418 (0.418)  Loss:  1.4346 (1.4346)  Acc@1: 63.2812 (63.2812)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.022 (0.121)  Loss:  1.2178 (1.4628)  Acc@1: 68.7500 (64.9900)  Acc@5: 87.5000 (90.3300)
Test: [Whole Val]  Time: 9.585  Loss: 1.4628  Acc@1: 64.9900 Pruned: 52.86% 
Test (EMA): [   0/78]  Time: 0.328 (0.328)  Loss:  1.3877 (1.3877)  Acc@1: 66.4062 (66.4062)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  1.1377 (1.4204)  Acc@1: 68.7500 (66.9700)  Acc@5: 87.5000 (91.2100)
Test (EMA): [Whole Val]  Time: 9.454  Loss: 1.4204  Acc@1: 66.9700 Pruned: 52.86% 
Train: 14 [   0/390 (  0%)]  Loss: 3.709 (3.71)  Time: 0.809s,  158.20/s  (0.809s,  158.20/s)  LR: 9.787e-04  Data: 0.504 (0.504)
Train: 14 [ 100/390 ( 26%)]  Loss: 2.703 (3.51)  Time: 0.314s,  408.25/s  (0.320s,  400.23/s)  LR: 9.787e-04  Data: 0.012 (0.017)
Train: 14 [ 200/390 ( 51%)]  Loss: 3.962 (3.56)  Time: 0.323s,  396.74/s  (0.318s,  402.61/s)  LR: 9.787e-04  Data: 0.017 (0.015)
Train: 14 [ 300/390 ( 77%)]  Loss: 3.649 (3.54)  Time: 0.313s,  409.36/s  (0.317s,  403.88/s)  LR: 9.787e-04  Data: 0.011 (0.014)
Train: 14 [ 389/390 (100%)]  Loss: 4.036 (3.54)  Time: 0.301s,  425.56/s  (0.316s,  404.57/s)  LR: 9.787e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.407 (0.407)  Loss:  1.4072 (1.4072)  Acc@1: 63.2812 (63.2812)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.0918 (1.4313)  Acc@1: 75.0000 (65.6100)  Acc@5: 87.5000 (90.5700)
Test: [Whole Val]  Time: 9.540  Loss: 1.4313  Acc@1: 65.6100 Pruned: 52.74% 
Test (EMA): [   0/78]  Time: 0.458 (0.458)  Loss:  1.3896 (1.3896)  Acc@1: 60.1562 (60.1562)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  1.0859 (1.4016)  Acc@1: 68.7500 (66.8500)  Acc@5: 81.2500 (91.3100)
Test (EMA): [Whole Val]  Time: 9.600  Loss: 1.4016  Acc@1: 66.8500 Pruned: 52.74% 
Train: 15 [   0/390 (  0%)]  Loss: 3.368 (3.37)  Time: 0.819s,  156.34/s  (0.819s,  156.34/s)  LR: 9.755e-04  Data: 0.500 (0.500)
Train: 15 [ 100/390 ( 26%)]  Loss: 3.210 (3.47)  Time: 0.324s,  394.70/s  (0.319s,  400.83/s)  LR: 9.755e-04  Data: 0.011 (0.016)
Train: 15 [ 200/390 ( 51%)]  Loss: 3.337 (3.48)  Time: 0.315s,  406.39/s  (0.316s,  404.95/s)  LR: 9.755e-04  Data: 0.011 (0.014)
Train: 15 [ 300/390 ( 77%)]  Loss: 3.608 (3.50)  Time: 0.313s,  408.55/s  (0.315s,  406.12/s)  LR: 9.755e-04  Data: 0.012 (0.013)
Train: 15 [ 389/390 (100%)]  Loss: 3.811 (3.52)  Time: 0.303s,  422.07/s  (0.315s,  406.90/s)  LR: 9.755e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.392 (0.392)  Loss:  1.3662 (1.3662)  Acc@1: 66.4062 (66.4062)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.2979 (1.4323)  Acc@1: 75.0000 (67.2300)  Acc@5: 81.2500 (91.2000)
Test: [Whole Val]  Time: 9.531  Loss: 1.4323  Acc@1: 67.2300 Pruned: 52.66% 
Test (EMA): [   0/78]  Time: 0.376 (0.376)  Loss:  1.3428 (1.3428)  Acc@1: 64.8438 (64.8438)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  1.2402 (1.4086)  Acc@1: 75.0000 (68.1100)  Acc@5: 81.2500 (91.5600)
Test (EMA): [Whole Val]  Time: 9.510  Loss: 1.4086  Acc@1: 68.1100 Pruned: 52.67% 
Train: 16 [   0/390 (  0%)]  Loss: 3.719 (3.72)  Time: 0.817s,  156.76/s  (0.817s,  156.76/s)  LR: 9.722e-04  Data: 0.515 (0.515)
Train: 16 [ 100/390 ( 26%)]  Loss: 4.043 (3.55)  Time: 0.311s,  411.99/s  (0.320s,  399.70/s)  LR: 9.722e-04  Data: 0.010 (0.016)
Train: 16 [ 200/390 ( 51%)]  Loss: 4.013 (3.54)  Time: 0.314s,  407.52/s  (0.317s,  404.05/s)  LR: 9.722e-04  Data: 0.011 (0.014)
Train: 16 [ 300/390 ( 77%)]  Loss: 2.762 (3.54)  Time: 0.315s,  405.81/s  (0.316s,  405.53/s)  LR: 9.722e-04  Data: 0.016 (0.013)
Train: 16 [ 389/390 (100%)]  Loss: 3.906 (3.55)  Time: 0.308s,  416.19/s  (0.315s,  405.78/s)  LR: 9.722e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.425 (0.425)  Loss:  1.3535 (1.3535)  Acc@1: 67.9688 (67.9688)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.1348 (1.4239)  Acc@1: 75.0000 (66.5100)  Acc@5: 81.2500 (91.2200)
Test: [Whole Val]  Time: 9.566  Loss: 1.4239  Acc@1: 66.5100 Pruned: 52.60% 
Test (EMA): [   0/78]  Time: 0.306 (0.306)  Loss:  1.3320 (1.3320)  Acc@1: 67.9688 (67.9688)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.120)  Loss:  1.1172 (1.3899)  Acc@1: 75.0000 (67.9600)  Acc@5: 87.5000 (91.9900)
Test (EMA): [Whole Val]  Time: 9.470  Loss: 1.3899  Acc@1: 67.9600 Pruned: 52.60% 
Train: 17 [   0/390 (  0%)]  Loss: 3.806 (3.81)  Time: 0.923s,  138.65/s  (0.923s,  138.65/s)  LR: 9.686e-04  Data: 0.614 (0.614)
Train: 17 [ 100/390 ( 26%)]  Loss: 2.747 (3.46)  Time: 0.314s,  407.85/s  (0.324s,  395.43/s)  LR: 9.686e-04  Data: 0.013 (0.018)
Train: 17 [ 200/390 ( 51%)]  Loss: 3.760 (3.46)  Time: 0.311s,  411.06/s  (0.322s,  397.50/s)  LR: 9.686e-04  Data: 0.011 (0.015)
Train: 17 [ 300/390 ( 77%)]  Loss: 3.620 (3.46)  Time: 0.326s,  393.16/s  (0.320s,  399.69/s)  LR: 9.686e-04  Data: 0.012 (0.014)
Train: 17 [ 389/390 (100%)]  Loss: 2.948 (3.48)  Time: 0.302s,  423.25/s  (0.319s,  401.43/s)  LR: 9.686e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.336 (0.336)  Loss:  1.3857 (1.3857)  Acc@1: 64.8438 (64.8438)  Acc@5: 89.8438 (89.8438)
Test: [  78/78]  Time: 0.021 (0.121)  Loss:  1.2627 (1.4166)  Acc@1: 68.7500 (66.8200)  Acc@5: 81.2500 (91.1600)
Test: [Whole Val]  Time: 9.538  Loss: 1.4166  Acc@1: 66.8200 Pruned: 52.57% 
Test (EMA): [   0/78]  Time: 0.399 (0.399)  Loss:  1.3506 (1.3506)  Acc@1: 67.9688 (67.9688)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.018 (0.121)  Loss:  1.1748 (1.3769)  Acc@1: 75.0000 (67.7500)  Acc@5: 81.2500 (91.7900)
Test (EMA): [Whole Val]  Time: 9.534  Loss: 1.3769  Acc@1: 67.7500 Pruned: 52.56% 
Train: 18 [   0/390 (  0%)]  Loss: 3.628 (3.63)  Time: 0.820s,  156.04/s  (0.820s,  156.04/s)  LR: 9.649e-04  Data: 0.488 (0.488)
Train: 18 [ 100/390 ( 26%)]  Loss: 3.450 (3.49)  Time: 0.316s,  405.06/s  (0.318s,  402.43/s)  LR: 9.649e-04  Data: 0.015 (0.016)
Train: 18 [ 200/390 ( 51%)]  Loss: 3.196 (3.48)  Time: 0.312s,  410.35/s  (0.318s,  402.69/s)  LR: 9.649e-04  Data: 0.012 (0.014)
Train: 18 [ 300/390 ( 77%)]  Loss: 3.806 (3.50)  Time: 0.312s,  410.22/s  (0.316s,  404.52/s)  LR: 9.649e-04  Data: 0.010 (0.013)
Train: 18 [ 389/390 (100%)]  Loss: 2.763 (3.50)  Time: 0.302s,  423.38/s  (0.317s,  403.99/s)  LR: 9.649e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.399 (0.399)  Loss:  1.4033 (1.4033)  Acc@1: 65.6250 (65.6250)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.120)  Loss:  1.1143 (1.4491)  Acc@1: 75.0000 (66.1500)  Acc@5: 87.5000 (90.8300)
Test: [Whole Val]  Time: 9.509  Loss: 1.4491  Acc@1: 66.1500 Pruned: 52.47% 
Test (EMA): [   0/78]  Time: 0.412 (0.412)  Loss:  1.3311 (1.3311)  Acc@1: 65.6250 (65.6250)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.018 (0.121)  Loss:  1.0713 (1.3763)  Acc@1: 75.0000 (68.4700)  Acc@5: 81.2500 (92.1600)
Test (EMA): [Whole Val]  Time: 9.550  Loss: 1.3763  Acc@1: 68.4700 Pruned: 52.48% 
Train: 19 [   0/390 (  0%)]  Loss: 2.828 (2.83)  Time: 0.801s,  159.73/s  (0.801s,  159.73/s)  LR: 9.609e-04  Data: 0.497 (0.497)
Train: 19 [ 100/390 ( 26%)]  Loss: 2.979 (3.38)  Time: 0.313s,  408.30/s  (0.319s,  401.60/s)  LR: 9.609e-04  Data: 0.013 (0.017)
Train: 19 [ 200/390 ( 51%)]  Loss: 3.490 (3.42)  Time: 0.312s,  410.75/s  (0.315s,  405.80/s)  LR: 9.609e-04  Data: 0.011 (0.014)
Train: 19 [ 300/390 ( 77%)]  Loss: 3.000 (3.40)  Time: 0.311s,  411.44/s  (0.314s,  407.18/s)  LR: 9.609e-04  Data: 0.011 (0.013)
Train: 19 [ 389/390 (100%)]  Loss: 3.175 (3.44)  Time: 0.301s,  425.30/s  (0.314s,  407.45/s)  LR: 9.609e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.316 (0.316)  Loss:  1.2891 (1.2891)  Acc@1: 69.5312 (69.5312)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.120)  Loss:  1.0635 (1.3233)  Acc@1: 75.0000 (68.2700)  Acc@5: 93.7500 (91.8800)
Test: [Whole Val]  Time: 9.444  Loss: 1.3233  Acc@1: 68.2700 Pruned: 52.42% 
Test (EMA): [   0/78]  Time: 0.301 (0.301)  Loss:  1.3086 (1.3086)  Acc@1: 67.1875 (67.1875)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  1.0986 (1.3466)  Acc@1: 75.0000 (68.5300)  Acc@5: 87.5000 (92.4200)
Test (EMA): [Whole Val]  Time: 9.455  Loss: 1.3466  Acc@1: 68.5300 Pruned: 52.43% 
Train: 20 [   0/390 (  0%)]  Loss: 3.877 (3.88)  Time: 0.915s,  139.91/s  (0.915s,  139.91/s)  LR: 9.568e-04  Data: 0.613 (0.613)
Train: 20 [ 100/390 ( 26%)]  Loss: 3.722 (3.52)  Time: 0.318s,  402.21/s  (0.320s,  400.48/s)  LR: 9.568e-04  Data: 0.013 (0.017)
Train: 20 [ 200/390 ( 51%)]  Loss: 3.961 (3.52)  Time: 0.310s,  412.45/s  (0.320s,  399.88/s)  LR: 9.568e-04  Data: 0.011 (0.014)
Train: 20 [ 300/390 ( 77%)]  Loss: 3.861 (3.52)  Time: 0.310s,  412.49/s  (0.318s,  403.06/s)  LR: 9.568e-04  Data: 0.010 (0.013)
Train: 20 [ 389/390 (100%)]  Loss: 3.706 (3.50)  Time: 0.315s,  406.34/s  (0.318s,  402.98/s)  LR: 9.568e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.391 (0.391)  Loss:  1.2822 (1.2822)  Acc@1: 66.4062 (66.4062)  Acc@5: 96.8750 (96.8750)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  1.0742 (1.3676)  Acc@1: 75.0000 (67.2500)  Acc@5: 87.5000 (91.4800)
Test: [Whole Val]  Time: 9.508  Loss: 1.3676  Acc@1: 67.2500 Pruned: 52.34% 
Test (EMA): [   0/78]  Time: 0.406 (0.406)  Loss:  1.2207 (1.2207)  Acc@1: 67.1875 (67.1875)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9912 (1.2758)  Acc@1: 75.0000 (69.2000)  Acc@5: 81.2500 (92.3600)
Test (EMA): [Whole Val]  Time: 9.579  Loss: 1.2758  Acc@1: 69.2000 Pruned: 52.35% 
Train: 21 [   0/390 (  0%)]  Loss: 2.890 (2.89)  Time: 0.789s,  162.14/s  (0.789s,  162.14/s)  LR: 9.524e-04  Data: 0.487 (0.487)
Train: 21 [ 100/390 ( 26%)]  Loss: 2.993 (3.48)  Time: 0.321s,  398.84/s  (0.319s,  401.27/s)  LR: 9.524e-04  Data: 0.010 (0.016)
Train: 21 [ 200/390 ( 51%)]  Loss: 3.639 (3.50)  Time: 0.316s,  405.60/s  (0.316s,  405.02/s)  LR: 9.524e-04  Data: 0.013 (0.014)
Train: 21 [ 300/390 ( 77%)]  Loss: 3.100 (3.48)  Time: 0.311s,  411.65/s  (0.315s,  405.85/s)  LR: 9.524e-04  Data: 0.010 (0.013)
Train: 21 [ 389/390 (100%)]  Loss: 3.807 (3.46)  Time: 0.301s,  424.66/s  (0.316s,  405.60/s)  LR: 9.524e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.324 (0.324)  Loss:  1.2529 (1.2529)  Acc@1: 67.1875 (67.1875)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.120)  Loss:  0.9688 (1.2757)  Acc@1: 75.0000 (68.7700)  Acc@5: 93.7500 (92.2300)
Test: [Whole Val]  Time: 9.514  Loss: 1.2757  Acc@1: 68.7700 Pruned: 52.30% 
Test (EMA): [   0/78]  Time: 0.440 (0.440)  Loss:  1.2393 (1.2393)  Acc@1: 67.9688 (67.9688)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.9468 (1.2522)  Acc@1: 75.0000 (69.4000)  Acc@5: 87.5000 (92.6200)
Test (EMA): [Whole Val]  Time: 9.599  Loss: 1.2522  Acc@1: 69.4000 Pruned: 52.31% 
Train: 22 [   0/390 (  0%)]  Loss: 2.584 (2.58)  Time: 0.853s,  150.08/s  (0.853s,  150.08/s)  LR: 9.479e-04  Data: 0.544 (0.544)
Train: 22 [ 100/390 ( 26%)]  Loss: 3.732 (3.51)  Time: 0.313s,  409.43/s  (0.321s,  399.28/s)  LR: 9.479e-04  Data: 0.010 (0.017)
Train: 22 [ 200/390 ( 51%)]  Loss: 4.077 (3.49)  Time: 0.314s,  407.82/s  (0.317s,  403.71/s)  LR: 9.479e-04  Data: 0.013 (0.014)
Train: 22 [ 300/390 ( 77%)]  Loss: 3.132 (3.48)  Time: 0.311s,  411.18/s  (0.316s,  405.65/s)  LR: 9.479e-04  Data: 0.010 (0.013)
Train: 22 [ 389/390 (100%)]  Loss: 3.299 (3.46)  Time: 0.301s,  424.75/s  (0.315s,  406.02/s)  LR: 9.479e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.326 (0.326)  Loss:  1.2490 (1.2490)  Acc@1: 67.1875 (67.1875)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.018 (0.120)  Loss:  1.1025 (1.3174)  Acc@1: 81.2500 (68.8300)  Acc@5: 81.2500 (91.8800)
Test: [Whole Val]  Time: 9.515  Loss: 1.3174  Acc@1: 68.8300 Pruned: 52.27% 
Test (EMA): [   0/78]  Time: 0.299 (0.299)  Loss:  1.2139 (1.2139)  Acc@1: 67.9688 (67.9688)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.018 (0.120)  Loss:  1.0215 (1.2605)  Acc@1: 75.0000 (69.5400)  Acc@5: 87.5000 (92.5800)
Test (EMA): [Whole Val]  Time: 9.466  Loss: 1.2605  Acc@1: 69.5400 Pruned: 52.28% 
Train: 23 [   0/390 (  0%)]  Loss: 3.769 (3.77)  Time: 0.811s,  157.75/s  (0.811s,  157.75/s)  LR: 9.431e-04  Data: 0.498 (0.498)
Train: 23 [ 100/390 ( 26%)]  Loss: 3.020 (3.37)  Time: 0.331s,  386.54/s  (0.324s,  394.67/s)  LR: 9.431e-04  Data: 0.010 (0.016)
Train: 23 [ 200/390 ( 51%)]  Loss: 3.291 (3.42)  Time: 0.311s,  411.80/s  (0.319s,  401.11/s)  LR: 9.431e-04  Data: 0.017 (0.014)
Train: 23 [ 300/390 ( 77%)]  Loss: 3.546 (3.44)  Time: 0.315s,  405.89/s  (0.318s,  402.98/s)  LR: 9.431e-04  Data: 0.015 (0.013)
Train: 23 [ 389/390 (100%)]  Loss: 3.449 (3.45)  Time: 0.301s,  425.93/s  (0.316s,  404.44/s)  LR: 9.431e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.394 (0.394)  Loss:  1.2422 (1.2422)  Acc@1: 71.0938 (71.0938)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.018 (0.121)  Loss:  1.2021 (1.3536)  Acc@1: 75.0000 (68.9000)  Acc@5: 81.2500 (92.1000)
Test: [Whole Val]  Time: 9.548  Loss: 1.3536  Acc@1: 68.9000 Pruned: 52.20% 
Test (EMA): [   0/78]  Time: 0.413 (0.413)  Loss:  1.2344 (1.2344)  Acc@1: 67.9688 (67.9688)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.018 (0.121)  Loss:  1.1279 (1.3019)  Acc@1: 75.0000 (69.4300)  Acc@5: 81.2500 (92.4800)
Test (EMA): [Whole Val]  Time: 9.564  Loss: 1.3019  Acc@1: 69.4300 Pruned: 52.20% 
Train: 24 [   0/390 (  0%)]  Loss: 3.650 (3.65)  Time: 0.814s,  157.30/s  (0.814s,  157.30/s)  LR: 9.382e-04  Data: 0.510 (0.510)
Train: 24 [ 100/390 ( 26%)]  Loss: 2.587 (3.32)  Time: 0.310s,  413.48/s  (0.323s,  396.45/s)  LR: 9.382e-04  Data: 0.009 (0.016)
Train: 24 [ 200/390 ( 51%)]  Loss: 3.622 (3.42)  Time: 0.314s,  407.96/s  (0.318s,  402.83/s)  LR: 9.382e-04  Data: 0.012 (0.014)
Train: 24 [ 300/390 ( 77%)]  Loss: 3.824 (3.41)  Time: 0.312s,  410.65/s  (0.316s,  404.80/s)  LR: 9.382e-04  Data: 0.010 (0.013)
Train: 24 [ 389/390 (100%)]  Loss: 3.983 (3.42)  Time: 0.302s,  423.55/s  (0.316s,  405.42/s)  LR: 9.382e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.372 (0.372)  Loss:  1.2227 (1.2227)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.1455 (1.3174)  Acc@1: 75.0000 (68.7500)  Acc@5: 87.5000 (91.9800)
Test: [Whole Val]  Time: 9.520  Loss: 1.3174  Acc@1: 68.7500 Pruned: 52.18% 
Test (EMA): [   0/78]  Time: 0.346 (0.346)  Loss:  1.2236 (1.2236)  Acc@1: 70.3125 (70.3125)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.018 (0.121)  Loss:  1.1045 (1.2868)  Acc@1: 75.0000 (70.1000)  Acc@5: 81.2500 (92.5300)
Test (EMA): [Whole Val]  Time: 9.534  Loss: 1.2868  Acc@1: 70.1000 Pruned: 52.18% 
Train: 25 [   0/390 (  0%)]  Loss: 3.899 (3.90)  Time: 0.957s,  133.72/s  (0.957s,  133.72/s)  LR: 9.330e-04  Data: 0.656 (0.656)
Train: 25 [ 100/390 ( 26%)]  Loss: 3.883 (3.45)  Time: 0.319s,  401.07/s  (0.320s,  399.73/s)  LR: 9.330e-04  Data: 0.010 (0.017)
Train: 25 [ 200/390 ( 51%)]  Loss: 3.701 (3.43)  Time: 0.311s,  410.96/s  (0.317s,  403.42/s)  LR: 9.330e-04  Data: 0.011 (0.015)
Train: 25 [ 300/390 ( 77%)]  Loss: 3.768 (3.42)  Time: 0.327s,  391.30/s  (0.317s,  403.30/s)  LR: 9.330e-04  Data: 0.013 (0.013)
Train: 25 [ 389/390 (100%)]  Loss: 3.628 (3.44)  Time: 0.314s,  407.10/s  (0.317s,  403.62/s)  LR: 9.330e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.305 (0.305)  Loss:  1.2920 (1.2920)  Acc@1: 68.7500 (68.7500)  Acc@5: 90.6250 (90.6250)
Test: [  78/78]  Time: 0.018 (0.120)  Loss:  1.1826 (1.3561)  Acc@1: 75.0000 (68.2100)  Acc@5: 81.2500 (92.2200)
Test: [Whole Val]  Time: 9.470  Loss: 1.3561  Acc@1: 68.2100 Pruned: 52.13% 
Test (EMA): [   0/78]  Time: 0.383 (0.383)  Loss:  1.2598 (1.2598)  Acc@1: 71.0938 (71.0938)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  1.1582 (1.3054)  Acc@1: 75.0000 (69.8800)  Acc@5: 81.2500 (92.9000)
Test (EMA): [Whole Val]  Time: 9.544  Loss: 1.3054  Acc@1: 69.8800 Pruned: 52.12% 
Train: 26 [   0/390 (  0%)]  Loss: 3.652 (3.65)  Time: 0.827s,  154.77/s  (0.827s,  154.77/s)  LR: 9.277e-04  Data: 0.493 (0.493)
Train: 26 [ 100/390 ( 26%)]  Loss: 2.808 (3.43)  Time: 0.314s,  407.22/s  (0.322s,  397.24/s)  LR: 9.277e-04  Data: 0.014 (0.016)
Train: 26 [ 200/390 ( 51%)]  Loss: 3.548 (3.44)  Time: 0.312s,  409.89/s  (0.321s,  399.07/s)  LR: 9.277e-04  Data: 0.010 (0.014)
Train: 26 [ 300/390 ( 77%)]  Loss: 3.784 (3.43)  Time: 0.312s,  410.11/s  (0.319s,  400.81/s)  LR: 9.277e-04  Data: 0.011 (0.013)
Train: 26 [ 389/390 (100%)]  Loss: 3.626 (3.43)  Time: 0.302s,  424.33/s  (0.318s,  402.91/s)  LR: 9.277e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.292 (0.292)  Loss:  1.2412 (1.2412)  Acc@1: 71.8750 (71.8750)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.119)  Loss:  1.0693 (1.3296)  Acc@1: 75.0000 (68.5200)  Acc@5: 81.2500 (92.1700)
Test: [Whole Val]  Time: 9.427  Loss: 1.3296  Acc@1: 68.5200 Pruned: 52.05% 
Test (EMA): [   0/78]  Time: 0.382 (0.382)  Loss:  1.2080 (1.2080)  Acc@1: 68.7500 (68.7500)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.018 (0.121)  Loss:  1.0352 (1.2802)  Acc@1: 75.0000 (70.0200)  Acc@5: 87.5000 (92.7300)
Test (EMA): [Whole Val]  Time: 9.545  Loss: 1.2802  Acc@1: 70.0200 Pruned: 52.05% 
Train: 27 [   0/390 (  0%)]  Loss: 3.780 (3.78)  Time: 0.776s,  165.05/s  (0.776s,  165.05/s)  LR: 9.222e-04  Data: 0.472 (0.472)
Train: 27 [ 100/390 ( 26%)]  Loss: 3.128 (3.45)  Time: 0.316s,  405.56/s  (0.320s,  399.93/s)  LR: 9.222e-04  Data: 0.011 (0.016)
Train: 27 [ 200/390 ( 51%)]  Loss: 2.707 (3.46)  Time: 0.314s,  407.82/s  (0.317s,  404.40/s)  LR: 9.222e-04  Data: 0.011 (0.013)
Train: 27 [ 300/390 ( 77%)]  Loss: 3.218 (3.46)  Time: 0.311s,  411.50/s  (0.316s,  405.01/s)  LR: 9.222e-04  Data: 0.011 (0.013)
Train: 27 [ 389/390 (100%)]  Loss: 3.363 (3.45)  Time: 0.306s,  418.81/s  (0.316s,  405.36/s)  LR: 9.222e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.376 (0.376)  Loss:  1.2471 (1.2471)  Acc@1: 67.9688 (67.9688)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.018 (0.121)  Loss:  1.0117 (1.3193)  Acc@1: 81.2500 (69.5000)  Acc@5: 87.5000 (92.6700)
Test: [Whole Val]  Time: 9.530  Loss: 1.3193  Acc@1: 69.5000 Pruned: 52.01% 
Test (EMA): [   0/78]  Time: 0.404 (0.404)  Loss:  1.2217 (1.2217)  Acc@1: 69.5312 (69.5312)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.020 (0.121)  Loss:  0.9951 (1.2870)  Acc@1: 81.2500 (70.6900)  Acc@5: 87.5000 (93.0400)
Test (EMA): [Whole Val]  Time: 9.590  Loss: 1.2870  Acc@1: 70.6900 Pruned: 52.02% 
Train: 28 [   0/390 (  0%)]  Loss: 3.361 (3.36)  Time: 0.969s,  132.05/s  (0.969s,  132.05/s)  LR: 9.165e-04  Data: 0.668 (0.668)
Train: 28 [ 100/390 ( 26%)]  Loss: 3.806 (3.46)  Time: 0.312s,  410.40/s  (0.319s,  401.27/s)  LR: 9.165e-04  Data: 0.010 (0.017)
Train: 28 [ 200/390 ( 51%)]  Loss: 3.382 (3.45)  Time: 0.310s,  412.62/s  (0.316s,  404.74/s)  LR: 9.165e-04  Data: 0.011 (0.014)
Train: 28 [ 300/390 ( 77%)]  Loss: 3.203 (3.45)  Time: 0.313s,  408.57/s  (0.315s,  406.05/s)  LR: 9.165e-04  Data: 0.010 (0.013)
Train: 28 [ 389/390 (100%)]  Loss: 2.818 (3.43)  Time: 0.300s,  426.35/s  (0.315s,  406.68/s)  LR: 9.165e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.406 (0.406)  Loss:  1.2148 (1.2148)  Acc@1: 68.7500 (68.7500)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.121)  Loss:  0.9771 (1.2593)  Acc@1: 75.0000 (69.1500)  Acc@5: 81.2500 (92.1000)
Test: [Whole Val]  Time: 9.532  Loss: 1.2593  Acc@1: 69.1500 Pruned: 51.95% 
Test (EMA): [   0/78]  Time: 0.315 (0.315)  Loss:  1.1699 (1.1699)  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  1.0098 (1.2365)  Acc@1: 75.0000 (70.5200)  Acc@5: 81.2500 (92.8900)
Test (EMA): [Whole Val]  Time: 9.455  Loss: 1.2365  Acc@1: 70.5200 Pruned: 51.96% 
Train: 29 [   0/390 (  0%)]  Loss: 3.671 (3.67)  Time: 1.008s,  127.00/s  (1.008s,  127.00/s)  LR: 9.106e-04  Data: 0.705 (0.705)
Train: 29 [ 100/390 ( 26%)]  Loss: 3.723 (3.40)  Time: 0.311s,  410.92/s  (0.324s,  394.74/s)  LR: 9.106e-04  Data: 0.010 (0.018)
Train: 29 [ 200/390 ( 51%)]  Loss: 2.659 (3.43)  Time: 0.310s,  412.35/s  (0.319s,  401.53/s)  LR: 9.106e-04  Data: 0.010 (0.015)
Train: 29 [ 300/390 ( 77%)]  Loss: 3.624 (3.40)  Time: 0.319s,  401.52/s  (0.318s,  402.49/s)  LR: 9.106e-04  Data: 0.011 (0.014)
Train: 29 [ 389/390 (100%)]  Loss: 3.933 (3.40)  Time: 0.300s,  425.99/s  (0.317s,  404.15/s)  LR: 9.106e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.398 (0.398)  Loss:  1.1592 (1.1592)  Acc@1: 70.3125 (70.3125)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  1.1006 (1.2364)  Acc@1: 81.2500 (69.7100)  Acc@5: 81.2500 (92.7400)
Test: [Whole Val]  Time: 9.515  Loss: 1.2364  Acc@1: 69.7100 Pruned: 51.89% 
Test (EMA): [   0/78]  Time: 0.386 (0.386)  Loss:  1.1631 (1.1631)  Acc@1: 71.8750 (71.8750)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.023 (0.121)  Loss:  0.9795 (1.2173)  Acc@1: 75.0000 (70.9900)  Acc@5: 87.5000 (93.0000)
Test (EMA): [Whole Val]  Time: 9.581  Loss: 1.2173  Acc@1: 70.9900 Pruned: 51.90% 
Train: 30 [   0/390 (  0%)]  Loss: 3.392 (3.39)  Time: 0.838s,  152.67/s  (0.838s,  152.67/s)  LR: 9.045e-04  Data: 0.537 (0.537)
Train: 30 [ 100/390 ( 26%)]  Loss: 3.756 (3.41)  Time: 0.312s,  409.80/s  (0.320s,  400.33/s)  LR: 9.045e-04  Data: 0.010 (0.016)
Train: 30 [ 200/390 ( 51%)]  Loss: 3.914 (3.39)  Time: 0.314s,  407.00/s  (0.317s,  404.33/s)  LR: 9.045e-04  Data: 0.011 (0.014)
Train: 30 [ 300/390 ( 77%)]  Loss: 3.348 (3.40)  Time: 0.315s,  405.95/s  (0.316s,  405.49/s)  LR: 9.045e-04  Data: 0.010 (0.013)
Train: 30 [ 389/390 (100%)]  Loss: 3.764 (3.41)  Time: 0.302s,  423.62/s  (0.315s,  406.33/s)  LR: 9.045e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.398 (0.398)  Loss:  1.1230 (1.1230)  Acc@1: 72.6562 (72.6562)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.022 (0.121)  Loss:  0.9814 (1.2094)  Acc@1: 81.2500 (70.5400)  Acc@5: 87.5000 (93.0000)
Test: [Whole Val]  Time: 9.556  Loss: 1.2094  Acc@1: 70.5400 Pruned: 51.87% 
Test (EMA): [   0/78]  Time: 0.317 (0.317)  Loss:  1.1494 (1.1494)  Acc@1: 71.8750 (71.8750)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.018 (0.120)  Loss:  1.0137 (1.2205)  Acc@1: 81.2500 (70.7700)  Acc@5: 81.2500 (93.4600)
Test (EMA): [Whole Val]  Time: 9.481  Loss: 1.2205  Acc@1: 70.7700 Pruned: 51.87% 
Train: 31 [   0/390 (  0%)]  Loss: 2.599 (2.60)  Time: 0.867s,  147.63/s  (0.867s,  147.63/s)  LR: 8.983e-04  Data: 0.554 (0.554)
Train: 31 [ 100/390 ( 26%)]  Loss: 3.884 (3.41)  Time: 0.311s,  411.30/s  (0.318s,  402.00/s)  LR: 8.983e-04  Data: 0.010 (0.016)
Train: 31 [ 200/390 ( 51%)]  Loss: 3.391 (3.41)  Time: 0.314s,  408.17/s  (0.317s,  404.24/s)  LR: 8.983e-04  Data: 0.011 (0.014)
Train: 31 [ 300/390 ( 77%)]  Loss: 3.718 (3.41)  Time: 0.315s,  406.34/s  (0.316s,  405.13/s)  LR: 8.983e-04  Data: 0.012 (0.013)
Train: 31 [ 389/390 (100%)]  Loss: 3.751 (3.40)  Time: 0.303s,  423.09/s  (0.316s,  405.70/s)  LR: 8.983e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.411 (0.411)  Loss:  1.1953 (1.1953)  Acc@1: 72.6562 (72.6562)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.1104 (1.2336)  Acc@1: 81.2500 (70.3500)  Acc@5: 81.2500 (93.0600)
Test: [Whole Val]  Time: 9.609  Loss: 1.2336  Acc@1: 70.3500 Pruned: 51.82% 
Test (EMA): [   0/78]  Time: 0.320 (0.320)  Loss:  1.1709 (1.1709)  Acc@1: 71.0938 (71.0938)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.018 (0.121)  Loss:  1.0859 (1.2225)  Acc@1: 81.2500 (71.0600)  Acc@5: 87.5000 (92.9900)
Test (EMA): [Whole Val]  Time: 9.521  Loss: 1.2225  Acc@1: 71.0600 Pruned: 51.82% 
Train: 32 [   0/390 (  0%)]  Loss: 3.593 (3.59)  Time: 0.898s,  142.47/s  (0.898s,  142.47/s)  LR: 8.919e-04  Data: 0.588 (0.588)
Train: 32 [ 100/390 ( 26%)]  Loss: 3.299 (3.34)  Time: 0.319s,  401.45/s  (0.322s,  397.11/s)  LR: 8.919e-04  Data: 0.011 (0.018)
Train: 32 [ 200/390 ( 51%)]  Loss: 3.842 (3.39)  Time: 0.319s,  401.28/s  (0.319s,  401.69/s)  LR: 8.919e-04  Data: 0.017 (0.015)
Train: 32 [ 300/390 ( 77%)]  Loss: 3.721 (3.39)  Time: 0.318s,  402.88/s  (0.318s,  402.20/s)  LR: 8.919e-04  Data: 0.015 (0.014)
Train: 32 [ 389/390 (100%)]  Loss: 3.806 (3.40)  Time: 0.302s,  423.76/s  (0.319s,  401.44/s)  LR: 8.919e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.333 (0.333)  Loss:  1.2236 (1.2236)  Acc@1: 67.9688 (67.9688)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.022 (0.121)  Loss:  1.0654 (1.2899)  Acc@1: 75.0000 (70.4000)  Acc@5: 87.5000 (93.0700)
Test: [Whole Val]  Time: 9.552  Loss: 1.2899  Acc@1: 70.4000 Pruned: 51.81% 
Test (EMA): [   0/78]  Time: 0.324 (0.324)  Loss:  1.1660 (1.1660)  Acc@1: 68.7500 (68.7500)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  1.0664 (1.2362)  Acc@1: 81.2500 (70.8300)  Acc@5: 81.2500 (93.3500)
Test (EMA): [Whole Val]  Time: 9.471  Loss: 1.2362  Acc@1: 70.8300 Pruned: 51.81% 
Train: 33 [   0/390 (  0%)]  Loss: 3.061 (3.06)  Time: 0.952s,  134.41/s  (0.952s,  134.41/s)  LR: 8.853e-04  Data: 0.650 (0.650)
Train: 33 [ 100/390 ( 26%)]  Loss: 3.668 (3.37)  Time: 0.311s,  411.11/s  (0.320s,  399.82/s)  LR: 8.853e-04  Data: 0.010 (0.018)
Train: 33 [ 200/390 ( 51%)]  Loss: 3.552 (3.37)  Time: 0.330s,  387.64/s  (0.317s,  403.67/s)  LR: 8.853e-04  Data: 0.010 (0.015)
Train: 33 [ 300/390 ( 77%)]  Loss: 3.680 (3.39)  Time: 0.318s,  402.57/s  (0.316s,  405.29/s)  LR: 8.853e-04  Data: 0.013 (0.014)
Train: 33 [ 389/390 (100%)]  Loss: 3.903 (3.38)  Time: 0.302s,  423.47/s  (0.315s,  406.04/s)  LR: 8.853e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.342 (0.342)  Loss:  1.1719 (1.1719)  Acc@1: 70.3125 (70.3125)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.021 (0.120)  Loss:  1.1406 (1.2453)  Acc@1: 75.0000 (70.4400)  Acc@5: 81.2500 (92.7100)
Test: [Whole Val]  Time: 9.503  Loss: 1.2453  Acc@1: 70.4400 Pruned: 51.76% 
Test (EMA): [   0/78]  Time: 0.369 (0.369)  Loss:  1.1504 (1.1504)  Acc@1: 71.0938 (71.0938)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.018 (0.121)  Loss:  1.0791 (1.2256)  Acc@1: 75.0000 (70.9800)  Acc@5: 81.2500 (93.0300)
Test (EMA): [Whole Val]  Time: 9.555  Loss: 1.2256  Acc@1: 70.9800 Pruned: 51.75% 
Train: 34 [   0/390 (  0%)]  Loss: 3.193 (3.19)  Time: 0.845s,  151.44/s  (0.845s,  151.44/s)  LR: 8.785e-04  Data: 0.544 (0.544)
Train: 34 [ 100/390 ( 26%)]  Loss: 3.384 (3.46)  Time: 0.322s,  397.94/s  (0.320s,  400.51/s)  LR: 8.785e-04  Data: 0.009 (0.017)
Train: 34 [ 200/390 ( 51%)]  Loss: 2.539 (3.43)  Time: 0.311s,  411.40/s  (0.318s,  402.50/s)  LR: 8.785e-04  Data: 0.011 (0.014)
Train: 34 [ 300/390 ( 77%)]  Loss: 3.962 (3.44)  Time: 0.327s,  391.13/s  (0.318s,  402.76/s)  LR: 8.785e-04  Data: 0.012 (0.013)
Train: 34 [ 389/390 (100%)]  Loss: 3.922 (3.44)  Time: 0.302s,  424.53/s  (0.317s,  403.64/s)  LR: 8.785e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.449 (0.449)  Loss:  1.2568 (1.2568)  Acc@1: 71.8750 (71.8750)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.019 (0.121)  Loss:  1.1455 (1.3387)  Acc@1: 81.2500 (70.3200)  Acc@5: 81.2500 (92.8700)
Test: [Whole Val]  Time: 9.570  Loss: 1.3387  Acc@1: 70.3200 Pruned: 51.73% 
Test (EMA): [   0/78]  Time: 0.353 (0.353)  Loss:  1.2275 (1.2275)  Acc@1: 71.0938 (71.0938)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.018 (0.120)  Loss:  1.1133 (1.3034)  Acc@1: 81.2500 (70.9200)  Acc@5: 87.5000 (93.3800)
Test (EMA): [Whole Val]  Time: 9.462  Loss: 1.3034  Acc@1: 70.9200 Pruned: 51.74% 
Train: 35 [   0/390 (  0%)]  Loss: 3.278 (3.28)  Time: 0.834s,  153.39/s  (0.834s,  153.39/s)  LR: 8.716e-04  Data: 0.493 (0.493)
Train: 35 [ 100/390 ( 26%)]  Loss: 3.965 (3.42)  Time: 0.322s,  397.14/s  (0.321s,  399.05/s)  LR: 8.716e-04  Data: 0.014 (0.017)
Train: 35 [ 200/390 ( 51%)]  Loss: 2.356 (3.40)  Time: 0.317s,  404.20/s  (0.318s,  402.76/s)  LR: 8.716e-04  Data: 0.014 (0.014)
Train: 35 [ 300/390 ( 77%)]  Loss: 3.788 (3.38)  Time: 0.315s,  406.10/s  (0.317s,  404.16/s)  LR: 8.716e-04  Data: 0.013 (0.013)
Train: 35 [ 389/390 (100%)]  Loss: 3.764 (3.37)  Time: 0.316s,  404.96/s  (0.317s,  404.23/s)  LR: 8.716e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.435 (0.435)  Loss:  1.2461 (1.2461)  Acc@1: 71.0938 (71.0938)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.1279 (1.2900)  Acc@1: 75.0000 (70.5300)  Acc@5: 81.2500 (93.1500)
Test: [Whole Val]  Time: 9.625  Loss: 1.2900  Acc@1: 70.5300 Pruned: 51.71% 
Test (EMA): [   0/78]  Time: 0.428 (0.428)  Loss:  1.1934 (1.1934)  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.019 (0.121)  Loss:  1.0703 (1.2158)  Acc@1: 75.0000 (71.4400)  Acc@5: 81.2500 (93.5600)
Test (EMA): [Whole Val]  Time: 9.580  Loss: 1.2158  Acc@1: 71.4400 Pruned: 51.72% 
Train: 36 [   0/390 (  0%)]  Loss: 3.145 (3.15)  Time: 0.758s,  168.98/s  (0.758s,  168.98/s)  LR: 8.645e-04  Data: 0.453 (0.453)
Train: 36 [ 100/390 ( 26%)]  Loss: 3.568 (3.42)  Time: 0.320s,  399.91/s  (0.320s,  399.80/s)  LR: 8.645e-04  Data: 0.011 (0.016)
Train: 36 [ 200/390 ( 51%)]  Loss: 2.800 (3.39)  Time: 0.313s,  408.80/s  (0.317s,  403.57/s)  LR: 8.645e-04  Data: 0.011 (0.014)
Train: 36 [ 300/390 ( 77%)]  Loss: 2.871 (3.37)  Time: 0.315s,  405.72/s  (0.317s,  403.83/s)  LR: 8.645e-04  Data: 0.011 (0.013)
Train: 36 [ 389/390 (100%)]  Loss: 2.844 (3.40)  Time: 0.301s,  425.34/s  (0.316s,  405.06/s)  LR: 8.645e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.417 (0.417)  Loss:  1.1865 (1.1865)  Acc@1: 70.3125 (70.3125)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  1.0566 (1.2397)  Acc@1: 75.0000 (70.7000)  Acc@5: 87.5000 (93.1100)
Test: [Whole Val]  Time: 9.604  Loss: 1.2397  Acc@1: 70.7000 Pruned: 51.68% 
Test (EMA): [   0/78]  Time: 0.354 (0.354)  Loss:  1.2100 (1.2100)  Acc@1: 69.5312 (69.5312)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.018 (0.120)  Loss:  1.1172 (1.2546)  Acc@1: 75.0000 (70.7700)  Acc@5: 87.5000 (93.1600)
Test (EMA): [Whole Val]  Time: 9.487  Loss: 1.2546  Acc@1: 70.7700 Pruned: 51.68% 
Train: 37 [   0/390 (  0%)]  Loss: 3.739 (3.74)  Time: 0.760s,  168.36/s  (0.760s,  168.36/s)  LR: 8.573e-04  Data: 0.445 (0.445)
Train: 37 [ 100/390 ( 26%)]  Loss: 2.698 (3.40)  Time: 0.311s,  411.76/s  (0.318s,  402.10/s)  LR: 8.573e-04  Data: 0.010 (0.015)
Train: 37 [ 200/390 ( 51%)]  Loss: 3.582 (3.40)  Time: 0.310s,  413.04/s  (0.317s,  403.69/s)  LR: 8.573e-04  Data: 0.009 (0.014)
Train: 37 [ 300/390 ( 77%)]  Loss: 2.702 (3.41)  Time: 0.311s,  411.76/s  (0.317s,  404.20/s)  LR: 8.573e-04  Data: 0.009 (0.013)
Train: 37 [ 389/390 (100%)]  Loss: 3.162 (3.40)  Time: 0.302s,  424.03/s  (0.316s,  405.31/s)  LR: 8.573e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.376 (0.376)  Loss:  1.1377 (1.1377)  Acc@1: 73.4375 (73.4375)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  1.0293 (1.1953)  Acc@1: 81.2500 (70.1800)  Acc@5: 81.2500 (92.8200)
Test: [Whole Val]  Time: 9.508  Loss: 1.1953  Acc@1: 70.1800 Pruned: 51.64% 
Test (EMA): [   0/78]  Time: 0.333 (0.333)  Loss:  1.1367 (1.1367)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  1.0381 (1.1960)  Acc@1: 75.0000 (71.4900)  Acc@5: 87.5000 (93.3800)
Test (EMA): [Whole Val]  Time: 9.472  Loss: 1.1960  Acc@1: 71.4900 Pruned: 51.64% 
Train: 38 [   0/390 (  0%)]  Loss: 2.881 (2.88)  Time: 0.779s,  164.25/s  (0.779s,  164.25/s)  LR: 8.498e-04  Data: 0.476 (0.476)
Train: 38 [ 100/390 ( 26%)]  Loss: 2.953 (3.37)  Time: 0.312s,  409.72/s  (0.324s,  395.57/s)  LR: 8.498e-04  Data: 0.011 (0.016)
Train: 38 [ 200/390 ( 51%)]  Loss: 3.406 (3.33)  Time: 0.311s,  411.81/s  (0.320s,  399.67/s)  LR: 8.498e-04  Data: 0.010 (0.014)
Train: 38 [ 300/390 ( 77%)]  Loss: 3.660 (3.32)  Time: 0.325s,  394.43/s  (0.319s,  401.28/s)  LR: 8.498e-04  Data: 0.010 (0.013)
Train: 38 [ 389/390 (100%)]  Loss: 3.726 (3.33)  Time: 0.301s,  424.94/s  (0.318s,  402.76/s)  LR: 8.498e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.397 (0.397)  Loss:  1.1934 (1.1934)  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.018 (0.120)  Loss:  0.9712 (1.2219)  Acc@1: 75.0000 (71.1400)  Acc@5: 87.5000 (93.0400)
Test: [Whole Val]  Time: 9.495  Loss: 1.2219  Acc@1: 71.1400 Pruned: 51.62% 
Test (EMA): [   0/78]  Time: 0.368 (0.368)  Loss:  1.1533 (1.1533)  Acc@1: 71.0938 (71.0938)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.120)  Loss:  0.9238 (1.1798)  Acc@1: 75.0000 (72.0700)  Acc@5: 93.7500 (93.6200)
Test (EMA): [Whole Val]  Time: 9.513  Loss: 1.1798  Acc@1: 72.0700 Pruned: 51.61% 
Train: 39 [   0/390 (  0%)]  Loss: 2.939 (2.94)  Time: 0.823s,  155.59/s  (0.823s,  155.59/s)  LR: 8.423e-04  Data: 0.509 (0.509)
Train: 39 [ 100/390 ( 26%)]  Loss: 3.593 (3.35)  Time: 0.333s,  384.53/s  (0.324s,  394.50/s)  LR: 8.423e-04  Data: 0.012 (0.017)
Train: 39 [ 200/390 ( 51%)]  Loss: 3.434 (3.39)  Time: 0.311s,  410.96/s  (0.321s,  398.66/s)  LR: 8.423e-04  Data: 0.010 (0.014)
Train: 39 [ 300/390 ( 77%)]  Loss: 3.941 (3.40)  Time: 0.310s,  412.88/s  (0.319s,  401.73/s)  LR: 8.423e-04  Data: 0.010 (0.013)
Train: 39 [ 389/390 (100%)]  Loss: 3.677 (3.40)  Time: 0.301s,  425.73/s  (0.318s,  403.12/s)  LR: 8.423e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.385 (0.385)  Loss:  1.1631 (1.1631)  Acc@1: 65.6250 (65.6250)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.9634 (1.1961)  Acc@1: 81.2500 (71.2100)  Acc@5: 87.5000 (93.3300)
Test: [Whole Val]  Time: 9.556  Loss: 1.1961  Acc@1: 71.2100 Pruned: 51.60% 
Test (EMA): [   0/78]  Time: 0.358 (0.358)  Loss:  1.1738 (1.1738)  Acc@1: 68.7500 (68.7500)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.9927 (1.1888)  Acc@1: 75.0000 (71.5300)  Acc@5: 87.5000 (93.6100)
Test (EMA): [Whole Val]  Time: 9.496  Loss: 1.1888  Acc@1: 71.5300 Pruned: 51.60% 
Train: 40 [   0/390 (  0%)]  Loss: 3.432 (3.43)  Time: 1.030s,  124.30/s  (1.030s,  124.30/s)  LR: 8.346e-04  Data: 0.707 (0.707)
Train: 40 [ 100/390 ( 26%)]  Loss: 3.925 (3.45)  Time: 0.311s,  411.27/s  (0.320s,  399.86/s)  LR: 8.346e-04  Data: 0.011 (0.018)
Train: 40 [ 200/390 ( 51%)]  Loss: 3.313 (3.41)  Time: 0.311s,  410.98/s  (0.318s,  403.14/s)  LR: 8.346e-04  Data: 0.011 (0.015)
Train: 40 [ 300/390 ( 77%)]  Loss: 3.765 (3.40)  Time: 0.312s,  410.01/s  (0.316s,  405.18/s)  LR: 8.346e-04  Data: 0.011 (0.014)
Train: 40 [ 389/390 (100%)]  Loss: 3.763 (3.41)  Time: 0.301s,  424.93/s  (0.315s,  406.20/s)  LR: 8.346e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.327 (0.327)  Loss:  1.2109 (1.2109)  Acc@1: 69.5312 (69.5312)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.120)  Loss:  0.9858 (1.2597)  Acc@1: 81.2500 (71.0700)  Acc@5: 87.5000 (93.2600)
Test: [Whole Val]  Time: 9.480  Loss: 1.2597  Acc@1: 71.0700 Pruned: 51.59% 
Test (EMA): [   0/78]  Time: 0.304 (0.304)  Loss:  1.1709 (1.1709)  Acc@1: 72.6562 (72.6562)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.119)  Loss:  0.9541 (1.2194)  Acc@1: 81.2500 (71.8000)  Acc@5: 87.5000 (93.7200)
Test (EMA): [Whole Val]  Time: 9.424  Loss: 1.2194  Acc@1: 71.8000 Pruned: 51.61% 
Train: 41 [   0/390 (  0%)]  Loss: 3.083 (3.08)  Time: 0.814s,  157.25/s  (0.814s,  157.25/s)  LR: 8.267e-04  Data: 0.503 (0.503)
Train: 41 [ 100/390 ( 26%)]  Loss: 3.036 (3.37)  Time: 0.311s,  411.80/s  (0.318s,  403.07/s)  LR: 8.267e-04  Data: 0.011 (0.016)
Train: 41 [ 200/390 ( 51%)]  Loss: 3.324 (3.39)  Time: 0.321s,  398.85/s  (0.316s,  404.92/s)  LR: 8.267e-04  Data: 0.013 (0.013)
Train: 41 [ 300/390 ( 77%)]  Loss: 2.550 (3.38)  Time: 0.315s,  406.06/s  (0.316s,  405.39/s)  LR: 8.267e-04  Data: 0.011 (0.012)
Train: 41 [ 389/390 (100%)]  Loss: 3.849 (3.38)  Time: 0.301s,  425.19/s  (0.316s,  405.69/s)  LR: 8.267e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.412 (0.412)  Loss:  1.1650 (1.1650)  Acc@1: 72.6562 (72.6562)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.018 (0.120)  Loss:  1.0566 (1.1934)  Acc@1: 75.0000 (71.1400)  Acc@5: 87.5000 (93.2800)
Test: [Whole Val]  Time: 9.508  Loss: 1.1934  Acc@1: 71.1400 Pruned: 51.55% 
Test (EMA): [   0/78]  Time: 0.312 (0.312)  Loss:  1.1543 (1.1543)  Acc@1: 71.8750 (71.8750)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.9170 (1.1664)  Acc@1: 75.0000 (71.8500)  Acc@5: 87.5000 (93.4500)
Test (EMA): [Whole Val]  Time: 9.465  Loss: 1.1664  Acc@1: 71.8500 Pruned: 51.57% 
Train: 42 [   0/390 (  0%)]  Loss: 3.558 (3.56)  Time: 0.838s,  152.78/s  (0.838s,  152.78/s)  LR: 8.187e-04  Data: 0.535 (0.535)
Train: 42 [ 100/390 ( 26%)]  Loss: 3.861 (3.43)  Time: 0.314s,  408.00/s  (0.318s,  403.08/s)  LR: 8.187e-04  Data: 0.011 (0.016)
Train: 42 [ 200/390 ( 51%)]  Loss: 3.752 (3.43)  Time: 0.311s,  411.93/s  (0.319s,  401.49/s)  LR: 8.187e-04  Data: 0.010 (0.013)
Train: 42 [ 300/390 ( 77%)]  Loss: 3.275 (3.40)  Time: 0.316s,  404.47/s  (0.318s,  402.78/s)  LR: 8.187e-04  Data: 0.015 (0.013)
Train: 42 [ 389/390 (100%)]  Loss: 3.690 (3.40)  Time: 0.301s,  425.50/s  (0.318s,  402.31/s)  LR: 8.187e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.408 (0.408)  Loss:  1.1338 (1.1338)  Acc@1: 71.8750 (71.8750)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.0029 (1.1882)  Acc@1: 81.2500 (71.2400)  Acc@5: 87.5000 (93.4200)
Test: [Whole Val]  Time: 9.520  Loss: 1.1882  Acc@1: 71.2400 Pruned: 51.55% 
Test (EMA): [   0/78]  Time: 0.373 (0.373)  Loss:  1.1289 (1.1289)  Acc@1: 70.3125 (70.3125)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.9883 (1.1637)  Acc@1: 81.2500 (72.0300)  Acc@5: 87.5000 (93.7500)
Test (EMA): [Whole Val]  Time: 9.512  Loss: 1.1637  Acc@1: 72.0300 Pruned: 51.55% 
Train: 43 [   0/390 (  0%)]  Loss: 3.688 (3.69)  Time: 0.748s,  171.02/s  (0.748s,  171.02/s)  LR: 8.106e-04  Data: 0.441 (0.441)
Train: 43 [ 100/390 ( 26%)]  Loss: 3.494 (3.39)  Time: 0.311s,  410.92/s  (0.318s,  402.86/s)  LR: 8.106e-04  Data: 0.010 (0.015)
Train: 43 [ 200/390 ( 51%)]  Loss: 3.280 (3.41)  Time: 0.313s,  409.02/s  (0.315s,  406.12/s)  LR: 8.106e-04  Data: 0.011 (0.013)
Train: 43 [ 300/390 ( 77%)]  Loss: 3.601 (3.38)  Time: 0.312s,  410.35/s  (0.315s,  406.91/s)  LR: 8.106e-04  Data: 0.011 (0.012)
Train: 43 [ 389/390 (100%)]  Loss: 3.358 (3.37)  Time: 0.300s,  426.61/s  (0.314s,  407.01/s)  LR: 8.106e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.361 (0.361)  Loss:  1.1553 (1.1553)  Acc@1: 71.0938 (71.0938)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.018 (0.120)  Loss:  0.9512 (1.2014)  Acc@1: 81.2500 (71.0700)  Acc@5: 93.7500 (93.2600)
Test: [Whole Val]  Time: 9.506  Loss: 1.2014  Acc@1: 71.0700 Pruned: 51.52% 
Test (EMA): [   0/78]  Time: 0.322 (0.322)  Loss:  1.1426 (1.1426)  Acc@1: 71.0938 (71.0938)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.9282 (1.1521)  Acc@1: 75.0000 (72.6300)  Acc@5: 87.5000 (93.5000)
Test (EMA): [Whole Val]  Time: 9.455  Loss: 1.1521  Acc@1: 72.6300 Pruned: 51.51% 
Train: 44 [   0/390 (  0%)]  Loss: 2.990 (2.99)  Time: 0.874s,  146.49/s  (0.874s,  146.49/s)  LR: 8.023e-04  Data: 0.568 (0.568)
Train: 44 [ 100/390 ( 26%)]  Loss: 3.782 (3.30)  Time: 0.313s,  409.13/s  (0.320s,  400.49/s)  LR: 8.023e-04  Data: 0.012 (0.017)
Train: 44 [ 200/390 ( 51%)]  Loss: 3.846 (3.33)  Time: 0.312s,  409.66/s  (0.317s,  404.06/s)  LR: 8.023e-04  Data: 0.011 (0.014)
Train: 44 [ 300/390 ( 77%)]  Loss: 2.643 (3.36)  Time: 0.312s,  410.46/s  (0.316s,  405.22/s)  LR: 8.023e-04  Data: 0.011 (0.013)
Train: 44 [ 389/390 (100%)]  Loss: 3.888 (3.35)  Time: 0.300s,  426.06/s  (0.315s,  406.21/s)  LR: 8.023e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.306 (0.306)  Loss:  1.2041 (1.2041)  Acc@1: 68.7500 (68.7500)  Acc@5: 96.0938 (96.0938)
Test: [  78/78]  Time: 0.021 (0.120)  Loss:  1.0889 (1.2358)  Acc@1: 81.2500 (70.8000)  Acc@5: 87.5000 (93.2900)
Test: [Whole Val]  Time: 9.470  Loss: 1.2358  Acc@1: 70.8000 Pruned: 51.51% 
Test (EMA): [   0/78]  Time: 0.367 (0.367)  Loss:  1.1719 (1.1719)  Acc@1: 71.0938 (71.0938)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  1.0322 (1.1845)  Acc@1: 68.7500 (71.9700)  Acc@5: 87.5000 (93.8600)
Test (EMA): [Whole Val]  Time: 9.608  Loss: 1.1845  Acc@1: 71.9700 Pruned: 51.51% 
Train: 45 [   0/390 (  0%)]  Loss: 3.777 (3.78)  Time: 0.927s,  138.13/s  (0.927s,  138.13/s)  LR: 7.939e-04  Data: 0.625 (0.625)
Train: 45 [ 100/390 ( 26%)]  Loss: 2.765 (3.38)  Time: 0.323s,  396.32/s  (0.321s,  398.94/s)  LR: 7.939e-04  Data: 0.010 (0.017)
Train: 45 [ 200/390 ( 51%)]  Loss: 3.080 (3.37)  Time: 0.311s,  411.64/s  (0.320s,  399.81/s)  LR: 7.939e-04  Data: 0.010 (0.014)
Train: 45 [ 300/390 ( 77%)]  Loss: 2.958 (3.37)  Time: 0.315s,  406.96/s  (0.318s,  402.39/s)  LR: 7.939e-04  Data: 0.012 (0.013)
Train: 45 [ 389/390 (100%)]  Loss: 2.844 (3.35)  Time: 0.304s,  420.55/s  (0.317s,  403.41/s)  LR: 7.939e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.427 (0.427)  Loss:  1.1836 (1.1836)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.9214 (1.2151)  Acc@1: 81.2500 (71.0100)  Acc@5: 93.7500 (93.3600)
Test: [Whole Val]  Time: 9.606  Loss: 1.2151  Acc@1: 71.0100 Pruned: 51.45% 
Test (EMA): [   0/78]  Time: 0.381 (0.381)  Loss:  1.1514 (1.1514)  Acc@1: 72.6562 (72.6562)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.024 (0.120)  Loss:  0.8940 (1.1798)  Acc@1: 81.2500 (71.8400)  Acc@5: 87.5000 (93.7700)
Test (EMA): [Whole Val]  Time: 9.499  Loss: 1.1798  Acc@1: 71.8400 Pruned: 51.46% 
Train: 46 [   0/390 (  0%)]  Loss: 3.447 (3.45)  Time: 0.807s,  158.62/s  (0.807s,  158.62/s)  LR: 7.854e-04  Data: 0.490 (0.490)
Train: 46 [ 100/390 ( 26%)]  Loss: 3.137 (3.39)  Time: 0.312s,  410.46/s  (0.319s,  400.71/s)  LR: 7.854e-04  Data: 0.011 (0.016)
Train: 46 [ 200/390 ( 51%)]  Loss: 2.627 (3.36)  Time: 0.313s,  409.00/s  (0.316s,  404.54/s)  LR: 7.854e-04  Data: 0.010 (0.014)
Train: 46 [ 300/390 ( 77%)]  Loss: 2.653 (3.36)  Time: 0.312s,  410.81/s  (0.316s,  405.66/s)  LR: 7.854e-04  Data: 0.010 (0.013)
Train: 46 [ 389/390 (100%)]  Loss: 2.553 (3.35)  Time: 0.301s,  425.91/s  (0.315s,  405.80/s)  LR: 7.854e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.311 (0.311)  Loss:  1.1738 (1.1738)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  0.9614 (1.2065)  Acc@1: 75.0000 (71.9100)  Acc@5: 93.7500 (93.4700)
Test: [Whole Val]  Time: 9.466  Loss: 1.2065  Acc@1: 71.9100 Pruned: 51.42% 
Test (EMA): [   0/78]  Time: 0.309 (0.309)  Loss:  1.1504 (1.1504)  Acc@1: 72.6562 (72.6562)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.018 (0.119)  Loss:  0.9717 (1.1872)  Acc@1: 75.0000 (72.6500)  Acc@5: 93.7500 (93.8500)
Test (EMA): [Whole Val]  Time: 9.432  Loss: 1.1872  Acc@1: 72.6500 Pruned: 51.42% 
Train: 47 [   0/390 (  0%)]  Loss: 3.620 (3.62)  Time: 0.789s,  162.20/s  (0.789s,  162.20/s)  LR: 7.767e-04  Data: 0.477 (0.477)
Train: 47 [ 100/390 ( 26%)]  Loss: 2.941 (3.43)  Time: 0.311s,  411.02/s  (0.319s,  400.69/s)  LR: 7.767e-04  Data: 0.011 (0.015)
Train: 47 [ 200/390 ( 51%)]  Loss: 3.350 (3.36)  Time: 0.311s,  412.16/s  (0.316s,  404.70/s)  LR: 7.767e-04  Data: 0.010 (0.013)
Train: 47 [ 300/390 ( 77%)]  Loss: 2.445 (3.33)  Time: 0.311s,  411.55/s  (0.315s,  405.79/s)  LR: 7.767e-04  Data: 0.011 (0.012)
Train: 47 [ 389/390 (100%)]  Loss: 3.771 (3.34)  Time: 0.305s,  419.72/s  (0.315s,  406.02/s)  LR: 7.767e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.392 (0.392)  Loss:  1.2061 (1.2061)  Acc@1: 66.4062 (66.4062)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  0.9741 (1.2398)  Acc@1: 68.7500 (70.6900)  Acc@5: 93.7500 (93.1300)
Test: [Whole Val]  Time: 9.499  Loss: 1.2398  Acc@1: 70.6900 Pruned: 51.43% 
Test (EMA): [   0/78]  Time: 0.391 (0.391)  Loss:  1.1250 (1.1250)  Acc@1: 71.8750 (71.8750)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9141 (1.1612)  Acc@1: 75.0000 (71.7800)  Acc@5: 93.7500 (93.8000)
Test (EMA): [Whole Val]  Time: 9.540  Loss: 1.1612  Acc@1: 71.7800 Pruned: 51.43% 
Train: 48 [   0/390 (  0%)]  Loss: 3.655 (3.65)  Time: 0.834s,  153.53/s  (0.834s,  153.53/s)  LR: 7.679e-04  Data: 0.524 (0.524)
Train: 48 [ 100/390 ( 26%)]  Loss: 3.386 (3.36)  Time: 0.311s,  411.01/s  (0.321s,  398.43/s)  LR: 7.679e-04  Data: 0.011 (0.017)
Train: 48 [ 200/390 ( 51%)]  Loss: 3.430 (3.34)  Time: 0.317s,  403.87/s  (0.319s,  401.70/s)  LR: 7.679e-04  Data: 0.015 (0.014)
Train: 48 [ 300/390 ( 77%)]  Loss: 3.755 (3.34)  Time: 0.320s,  399.44/s  (0.317s,  403.92/s)  LR: 7.679e-04  Data: 0.016 (0.013)
Train: 48 [ 389/390 (100%)]  Loss: 2.789 (3.34)  Time: 0.305s,  419.68/s  (0.316s,  404.70/s)  LR: 7.679e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.384 (0.384)  Loss:  1.2324 (1.2324)  Acc@1: 71.0938 (71.0938)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  1.0947 (1.2596)  Acc@1: 81.2500 (71.3900)  Acc@5: 87.5000 (93.2200)
Test: [Whole Val]  Time: 9.499  Loss: 1.2596  Acc@1: 71.3900 Pruned: 51.42% 
Test (EMA): [   0/78]  Time: 0.335 (0.335)  Loss:  1.1689 (1.1689)  Acc@1: 72.6562 (72.6562)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.9678 (1.1815)  Acc@1: 75.0000 (72.8600)  Acc@5: 87.5000 (93.7800)
Test (EMA): [Whole Val]  Time: 9.499  Loss: 1.1815  Acc@1: 72.8600 Pruned: 51.42% 
Train: 49 [   0/390 (  0%)]  Loss: 2.645 (2.64)  Time: 0.914s,  139.99/s  (0.914s,  139.99/s)  LR: 7.590e-04  Data: 0.612 (0.612)
Train: 49 [ 100/390 ( 26%)]  Loss: 3.739 (3.33)  Time: 0.332s,  385.86/s  (0.321s,  398.42/s)  LR: 7.590e-04  Data: 0.011 (0.017)
Train: 49 [ 200/390 ( 51%)]  Loss: 2.879 (3.34)  Time: 0.314s,  407.16/s  (0.318s,  401.97/s)  LR: 7.590e-04  Data: 0.010 (0.015)
Train: 49 [ 300/390 ( 77%)]  Loss: 3.939 (3.36)  Time: 0.311s,  411.18/s  (0.317s,  403.46/s)  LR: 7.590e-04  Data: 0.011 (0.014)
Train: 49 [ 389/390 (100%)]  Loss: 3.847 (3.35)  Time: 0.303s,  423.08/s  (0.318s,  402.69/s)  LR: 7.590e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.386 (0.386)  Loss:  1.1436 (1.1436)  Acc@1: 71.8750 (71.8750)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.018 (0.121)  Loss:  0.9214 (1.1778)  Acc@1: 75.0000 (71.6400)  Acc@5: 93.7500 (93.6500)
Test: [Whole Val]  Time: 9.573  Loss: 1.1778  Acc@1: 71.6400 Pruned: 51.39% 
Test (EMA): [   0/78]  Time: 0.394 (0.394)  Loss:  1.1514 (1.1514)  Acc@1: 75.0000 (75.0000)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.021 (0.122)  Loss:  0.9790 (1.1682)  Acc@1: 75.0000 (72.9300)  Acc@5: 87.5000 (93.9400)
Test (EMA): [Whole Val]  Time: 9.600  Loss: 1.1682  Acc@1: 72.9300 Pruned: 51.39% 
Train: 50 [   0/390 (  0%)]  Loss: 3.207 (3.21)  Time: 0.717s,  178.41/s  (0.717s,  178.41/s)  LR: 7.500e-04  Data: 0.414 (0.414)
Train: 50 [ 100/390 ( 26%)]  Loss: 3.512 (3.31)  Time: 0.314s,  408.19/s  (0.319s,  400.86/s)  LR: 7.500e-04  Data: 0.012 (0.016)
Train: 50 [ 200/390 ( 51%)]  Loss: 4.002 (3.31)  Time: 0.310s,  412.63/s  (0.317s,  403.69/s)  LR: 7.500e-04  Data: 0.011 (0.014)
Train: 50 [ 300/390 ( 77%)]  Loss: 3.680 (3.31)  Time: 0.311s,  411.06/s  (0.317s,  404.14/s)  LR: 7.500e-04  Data: 0.010 (0.013)
Train: 50 [ 389/390 (100%)]  Loss: 3.662 (3.33)  Time: 0.301s,  424.56/s  (0.317s,  403.88/s)  LR: 7.500e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.406 (0.406)  Loss:  1.1709 (1.1709)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.019 (0.121)  Loss:  0.9062 (1.1981)  Acc@1: 75.0000 (72.3000)  Acc@5: 93.7500 (93.9100)
Test: [Whole Val]  Time: 9.551  Loss: 1.1981  Acc@1: 72.3000 Pruned: 51.39% 
Test (EMA): [   0/78]  Time: 0.399 (0.399)  Loss:  1.1592 (1.1592)  Acc@1: 70.3125 (70.3125)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9561 (1.1973)  Acc@1: 75.0000 (72.6400)  Acc@5: 93.7500 (93.9600)
Test (EMA): [Whole Val]  Time: 9.534  Loss: 1.1973  Acc@1: 72.6400 Pruned: 51.38% 
Train: 51 [   0/390 (  0%)]  Loss: 3.416 (3.42)  Time: 0.846s,  151.30/s  (0.846s,  151.30/s)  LR: 7.409e-04  Data: 0.542 (0.542)
Train: 51 [ 100/390 ( 26%)]  Loss: 3.049 (3.31)  Time: 0.335s,  382.09/s  (0.323s,  396.53/s)  LR: 7.409e-04  Data: 0.011 (0.017)
Train: 51 [ 200/390 ( 51%)]  Loss: 3.711 (3.33)  Time: 0.314s,  407.28/s  (0.318s,  402.26/s)  LR: 7.409e-04  Data: 0.012 (0.014)
Train: 51 [ 300/390 ( 77%)]  Loss: 3.559 (3.34)  Time: 0.311s,  411.59/s  (0.316s,  404.43/s)  LR: 7.409e-04  Data: 0.010 (0.013)
Train: 51 [ 389/390 (100%)]  Loss: 3.663 (3.33)  Time: 0.301s,  424.86/s  (0.317s,  403.91/s)  LR: 7.409e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.436 (0.436)  Loss:  1.1074 (1.1074)  Acc@1: 73.4375 (73.4375)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.8540 (1.1060)  Acc@1: 75.0000 (72.1600)  Acc@5: 93.7500 (94.0000)
Test: [Whole Val]  Time: 9.604  Loss: 1.1060  Acc@1: 72.1600 Pruned: 51.36% 
Test (EMA): [   0/78]  Time: 0.313 (0.313)  Loss:  1.0957 (1.0957)  Acc@1: 73.4375 (73.4375)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.8887 (1.1120)  Acc@1: 75.0000 (73.1000)  Acc@5: 93.7500 (94.1300)
Test (EMA): [Whole Val]  Time: 9.486  Loss: 1.1120  Acc@1: 73.1000 Pruned: 51.36% 
Train: 52 [   0/390 (  0%)]  Loss: 3.748 (3.75)  Time: 0.770s,  166.22/s  (0.770s,  166.22/s)  LR: 7.317e-04  Data: 0.454 (0.454)
Train: 52 [ 100/390 ( 26%)]  Loss: 3.834 (3.37)  Time: 0.311s,  411.13/s  (0.319s,  401.00/s)  LR: 7.317e-04  Data: 0.010 (0.016)
Train: 52 [ 200/390 ( 51%)]  Loss: 3.448 (3.37)  Time: 0.312s,  409.71/s  (0.317s,  404.37/s)  LR: 7.317e-04  Data: 0.010 (0.013)
Train: 52 [ 300/390 ( 77%)]  Loss: 3.004 (3.35)  Time: 0.313s,  409.27/s  (0.315s,  405.92/s)  LR: 7.317e-04  Data: 0.011 (0.013)
Train: 52 [ 389/390 (100%)]  Loss: 2.789 (3.33)  Time: 0.300s,  426.76/s  (0.315s,  406.27/s)  LR: 7.317e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.425 (0.425)  Loss:  1.0879 (1.0879)  Acc@1: 70.3125 (70.3125)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.9009 (1.0950)  Acc@1: 81.2500 (73.3700)  Acc@5: 93.7500 (93.8400)
Test: [Whole Val]  Time: 9.618  Loss: 1.0950  Acc@1: 73.3700 Pruned: 51.35% 
Test (EMA): [   0/78]  Time: 0.325 (0.325)  Loss:  1.0957 (1.0957)  Acc@1: 72.6562 (72.6562)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.8569 (1.0902)  Acc@1: 81.2500 (73.2900)  Acc@5: 93.7500 (94.2800)
Test (EMA): [Whole Val]  Time: 9.494  Loss: 1.0902  Acc@1: 73.2900 Pruned: 51.35% 
Train: 53 [   0/390 (  0%)]  Loss: 2.812 (2.81)  Time: 0.828s,  154.54/s  (0.828s,  154.54/s)  LR: 7.223e-04  Data: 0.512 (0.512)
Train: 53 [ 100/390 ( 26%)]  Loss: 2.638 (3.30)  Time: 0.309s,  414.17/s  (0.319s,  401.54/s)  LR: 7.223e-04  Data: 0.010 (0.016)
Train: 53 [ 200/390 ( 51%)]  Loss: 3.527 (3.27)  Time: 0.316s,  405.42/s  (0.317s,  403.21/s)  LR: 7.223e-04  Data: 0.014 (0.014)
Train: 53 [ 300/390 ( 77%)]  Loss: 3.807 (3.30)  Time: 0.311s,  411.37/s  (0.317s,  403.96/s)  LR: 7.223e-04  Data: 0.010 (0.013)
Train: 53 [ 389/390 (100%)]  Loss: 3.421 (3.31)  Time: 0.301s,  425.16/s  (0.316s,  404.87/s)  LR: 7.223e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.429 (0.429)  Loss:  1.1436 (1.1436)  Acc@1: 73.4375 (73.4375)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.025 (0.122)  Loss:  0.8950 (1.2027)  Acc@1: 81.2500 (72.0000)  Acc@5: 93.7500 (93.2900)
Test: [Whole Val]  Time: 9.610  Loss: 1.2027  Acc@1: 72.0000 Pruned: 51.34% 
Test (EMA): [   0/78]  Time: 0.406 (0.406)  Loss:  1.0996 (1.0996)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.8633 (1.1399)  Acc@1: 81.2500 (73.2300)  Acc@5: 93.7500 (94.0800)
Test (EMA): [Whole Val]  Time: 9.607  Loss: 1.1399  Acc@1: 73.2300 Pruned: 51.34% 
Train: 54 [   0/390 (  0%)]  Loss: 3.487 (3.49)  Time: 0.821s,  155.81/s  (0.821s,  155.81/s)  LR: 7.129e-04  Data: 0.506 (0.506)
Train: 54 [ 100/390 ( 26%)]  Loss: 3.480 (3.35)  Time: 0.327s,  391.19/s  (0.322s,  398.07/s)  LR: 7.129e-04  Data: 0.011 (0.016)
Train: 54 [ 200/390 ( 51%)]  Loss: 3.743 (3.33)  Time: 0.321s,  399.31/s  (0.319s,  400.94/s)  LR: 7.129e-04  Data: 0.010 (0.014)
Train: 54 [ 300/390 ( 77%)]  Loss: 2.770 (3.34)  Time: 0.309s,  414.27/s  (0.317s,  403.51/s)  LR: 7.129e-04  Data: 0.010 (0.013)
Train: 54 [ 389/390 (100%)]  Loss: 3.963 (3.34)  Time: 0.300s,  426.21/s  (0.317s,  404.30/s)  LR: 7.129e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.384 (0.384)  Loss:  1.1729 (1.1729)  Acc@1: 70.3125 (70.3125)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.0137 (1.1708)  Acc@1: 81.2500 (72.4700)  Acc@5: 87.5000 (93.8500)
Test: [Whole Val]  Time: 9.550  Loss: 1.1708  Acc@1: 72.4700 Pruned: 51.33% 
Test (EMA): [   0/78]  Time: 0.409 (0.409)  Loss:  1.1289 (1.1289)  Acc@1: 70.3125 (70.3125)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9849 (1.1349)  Acc@1: 81.2500 (73.1000)  Acc@5: 93.7500 (94.2300)
Test (EMA): [Whole Val]  Time: 9.534  Loss: 1.1349  Acc@1: 73.1000 Pruned: 51.33% 
Train: 55 [   0/390 (  0%)]  Loss: 2.773 (2.77)  Time: 0.932s,  137.27/s  (0.932s,  137.27/s)  LR: 7.034e-04  Data: 0.621 (0.621)
Train: 55 [ 100/390 ( 26%)]  Loss: 3.572 (3.24)  Time: 0.314s,  407.52/s  (0.321s,  398.94/s)  LR: 7.034e-04  Data: 0.013 (0.018)
Train: 55 [ 200/390 ( 51%)]  Loss: 2.530 (3.27)  Time: 0.313s,  409.51/s  (0.317s,  403.75/s)  LR: 7.034e-04  Data: 0.011 (0.014)
Train: 55 [ 300/390 ( 77%)]  Loss: 3.807 (3.30)  Time: 0.311s,  411.46/s  (0.316s,  404.71/s)  LR: 7.034e-04  Data: 0.010 (0.013)
Train: 55 [ 389/390 (100%)]  Loss: 3.709 (3.29)  Time: 0.315s,  405.85/s  (0.317s,  404.37/s)  LR: 7.034e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.394 (0.394)  Loss:  1.1943 (1.1943)  Acc@1: 70.3125 (70.3125)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.021 (0.121)  Loss:  1.0322 (1.1854)  Acc@1: 75.0000 (72.1900)  Acc@5: 87.5000 (93.9100)
Test: [Whole Val]  Time: 9.533  Loss: 1.1854  Acc@1: 72.1900 Pruned: 51.31% 
Test (EMA): [   0/78]  Time: 0.368 (0.368)  Loss:  1.1348 (1.1348)  Acc@1: 74.2188 (74.2188)  Acc@5: 91.4062 (91.4062)
Test (EMA): [  78/78]  Time: 0.018 (0.121)  Loss:  0.9248 (1.1239)  Acc@1: 75.0000 (73.0300)  Acc@5: 93.7500 (94.3400)
Test (EMA): [Whole Val]  Time: 9.523  Loss: 1.1239  Acc@1: 73.0300 Pruned: 51.31% 
Train: 56 [   0/390 (  0%)]  Loss: 3.720 (3.72)  Time: 0.873s,  146.63/s  (0.873s,  146.63/s)  LR: 6.938e-04  Data: 0.531 (0.531)
Train: 56 [ 100/390 ( 26%)]  Loss: 2.845 (3.29)  Time: 0.325s,  393.45/s  (0.322s,  396.94/s)  LR: 6.938e-04  Data: 0.011 (0.016)
Train: 56 [ 200/390 ( 51%)]  Loss: 2.919 (3.34)  Time: 0.309s,  413.64/s  (0.319s,  400.84/s)  LR: 6.938e-04  Data: 0.009 (0.014)
Train: 56 [ 300/390 ( 77%)]  Loss: 3.103 (3.32)  Time: 0.326s,  392.48/s  (0.318s,  402.29/s)  LR: 6.938e-04  Data: 0.011 (0.013)
Train: 56 [ 389/390 (100%)]  Loss: 3.526 (3.33)  Time: 0.301s,  425.84/s  (0.317s,  403.30/s)  LR: 6.938e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.314 (0.314)  Loss:  1.1367 (1.1367)  Acc@1: 72.6562 (72.6562)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  0.9097 (1.1878)  Acc@1: 81.2500 (72.1500)  Acc@5: 93.7500 (93.5500)
Test: [Whole Val]  Time: 9.493  Loss: 1.1878  Acc@1: 72.1500 Pruned: 51.29% 
Test (EMA): [   0/78]  Time: 0.400 (0.400)  Loss:  1.0908 (1.0908)  Acc@1: 71.8750 (71.8750)  Acc@5: 96.0938 (96.0938)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.8809 (1.1299)  Acc@1: 75.0000 (73.0900)  Acc@5: 93.7500 (94.0000)
Test (EMA): [Whole Val]  Time: 9.575  Loss: 1.1299  Acc@1: 73.0900 Pruned: 51.30% 
Train: 57 [   0/390 (  0%)]  Loss: 3.556 (3.56)  Time: 0.820s,  156.06/s  (0.820s,  156.06/s)  LR: 6.841e-04  Data: 0.512 (0.512)
Train: 57 [ 100/390 ( 26%)]  Loss: 3.205 (3.25)  Time: 0.330s,  388.03/s  (0.322s,  397.62/s)  LR: 6.841e-04  Data: 0.012 (0.016)
Train: 57 [ 200/390 ( 51%)]  Loss: 3.645 (3.30)  Time: 0.311s,  411.31/s  (0.321s,  398.96/s)  LR: 6.841e-04  Data: 0.011 (0.014)
Train: 57 [ 300/390 ( 77%)]  Loss: 3.079 (3.30)  Time: 0.313s,  408.55/s  (0.318s,  402.33/s)  LR: 6.841e-04  Data: 0.011 (0.013)
Train: 57 [ 389/390 (100%)]  Loss: 3.322 (3.31)  Time: 0.301s,  425.20/s  (0.318s,  402.99/s)  LR: 6.841e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.418 (0.418)  Loss:  1.1221 (1.1221)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.019 (0.121)  Loss:  0.9043 (1.1470)  Acc@1: 81.2500 (72.3900)  Acc@5: 93.7500 (93.8800)
Test: [Whole Val]  Time: 9.561  Loss: 1.1470  Acc@1: 72.3900 Pruned: 51.28% 
Test (EMA): [   0/78]  Time: 0.438 (0.438)  Loss:  1.1201 (1.1201)  Acc@1: 71.0938 (71.0938)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.8955 (1.1273)  Acc@1: 81.2500 (73.2000)  Acc@5: 93.7500 (94.2300)
Test (EMA): [Whole Val]  Time: 9.582  Loss: 1.1273  Acc@1: 73.2000 Pruned: 51.28% 
Train: 58 [   0/390 (  0%)]  Loss: 3.470 (3.47)  Time: 0.773s,  165.64/s  (0.773s,  165.64/s)  LR: 6.743e-04  Data: 0.459 (0.459)
Train: 58 [ 100/390 ( 26%)]  Loss: 3.899 (3.34)  Time: 0.311s,  411.27/s  (0.319s,  400.77/s)  LR: 6.743e-04  Data: 0.011 (0.015)
Train: 58 [ 200/390 ( 51%)]  Loss: 3.331 (3.33)  Time: 0.311s,  411.25/s  (0.318s,  402.88/s)  LR: 6.743e-04  Data: 0.010 (0.013)
Train: 58 [ 300/390 ( 77%)]  Loss: 3.527 (3.31)  Time: 0.311s,  411.70/s  (0.317s,  404.10/s)  LR: 6.743e-04  Data: 0.010 (0.013)
Train: 58 [ 389/390 (100%)]  Loss: 2.630 (3.31)  Time: 0.301s,  425.94/s  (0.316s,  404.45/s)  LR: 6.743e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.377 (0.377)  Loss:  1.1543 (1.1543)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  0.9707 (1.1840)  Acc@1: 81.2500 (72.6400)  Acc@5: 93.7500 (93.9300)
Test: [Whole Val]  Time: 9.497  Loss: 1.1840  Acc@1: 72.6400 Pruned: 51.26% 
Test (EMA): [   0/78]  Time: 0.409 (0.409)  Loss:  1.1270 (1.1270)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.018 (0.121)  Loss:  0.9395 (1.1394)  Acc@1: 75.0000 (73.4200)  Acc@5: 93.7500 (94.1600)
Test (EMA): [Whole Val]  Time: 9.525  Loss: 1.1394  Acc@1: 73.4200 Pruned: 51.27% 
Train: 59 [   0/390 (  0%)]  Loss: 3.631 (3.63)  Time: 0.908s,  140.90/s  (0.908s,  140.90/s)  LR: 6.645e-04  Data: 0.606 (0.606)
Train: 59 [ 100/390 ( 26%)]  Loss: 3.177 (3.37)  Time: 0.326s,  392.43/s  (0.321s,  398.87/s)  LR: 6.645e-04  Data: 0.013 (0.017)
Train: 59 [ 200/390 ( 51%)]  Loss: 3.433 (3.36)  Time: 0.312s,  409.83/s  (0.319s,  401.05/s)  LR: 6.645e-04  Data: 0.012 (0.014)
Train: 59 [ 300/390 ( 77%)]  Loss: 3.606 (3.35)  Time: 0.311s,  412.04/s  (0.319s,  401.76/s)  LR: 6.645e-04  Data: 0.011 (0.013)
Train: 59 [ 389/390 (100%)]  Loss: 3.671 (3.31)  Time: 0.303s,  422.56/s  (0.318s,  402.28/s)  LR: 6.645e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.362 (0.362)  Loss:  1.0996 (1.0996)  Acc@1: 75.0000 (75.0000)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.018 (0.120)  Loss:  0.9326 (1.1230)  Acc@1: 75.0000 (73.0300)  Acc@5: 93.7500 (94.2900)
Test: [Whole Val]  Time: 9.457  Loss: 1.1230  Acc@1: 73.0300 Pruned: 51.25% 
Test (EMA): [   0/78]  Time: 0.314 (0.314)  Loss:  1.1006 (1.1006)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  1.0000 (1.1206)  Acc@1: 75.0000 (73.4000)  Acc@5: 87.5000 (94.4900)
Test (EMA): [Whole Val]  Time: 9.441  Loss: 1.1206  Acc@1: 73.4000 Pruned: 51.24% 
Train: 60 [   0/390 (  0%)]  Loss: 3.035 (3.03)  Time: 0.895s,  143.04/s  (0.895s,  143.04/s)  LR: 6.545e-04  Data: 0.575 (0.575)
Train: 60 [ 100/390 ( 26%)]  Loss: 3.294 (3.22)  Time: 0.312s,  410.83/s  (0.327s,  391.65/s)  LR: 6.545e-04  Data: 0.011 (0.017)
Train: 60 [ 200/390 ( 51%)]  Loss: 3.688 (3.28)  Time: 0.319s,  401.66/s  (0.320s,  399.77/s)  LR: 6.545e-04  Data: 0.011 (0.014)
Train: 60 [ 300/390 ( 77%)]  Loss: 2.574 (3.32)  Time: 0.312s,  410.91/s  (0.319s,  401.77/s)  LR: 6.545e-04  Data: 0.010 (0.013)
Train: 60 [ 389/390 (100%)]  Loss: 3.454 (3.32)  Time: 0.301s,  425.40/s  (0.317s,  403.23/s)  LR: 6.545e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.402 (0.402)  Loss:  1.0850 (1.0850)  Acc@1: 74.2188 (74.2188)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.8491 (1.1425)  Acc@1: 81.2500 (72.7300)  Acc@5: 93.7500 (93.8800)
Test: [Whole Val]  Time: 9.541  Loss: 1.1425  Acc@1: 72.7300 Pruned: 51.24% 
Test (EMA): [   0/78]  Time: 0.406 (0.406)  Loss:  1.0830 (1.0830)  Acc@1: 73.4375 (73.4375)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.8569 (1.1242)  Acc@1: 81.2500 (73.1300)  Acc@5: 93.7500 (94.2100)
Test (EMA): [Whole Val]  Time: 9.542  Loss: 1.1242  Acc@1: 73.1300 Pruned: 51.24% 
Train: 61 [   0/390 (  0%)]  Loss: 3.656 (3.66)  Time: 0.805s,  159.06/s  (0.805s,  159.06/s)  LR: 6.446e-04  Data: 0.501 (0.501)
Train: 61 [ 100/390 ( 26%)]  Loss: 2.938 (3.24)  Time: 0.312s,  410.13/s  (0.317s,  403.22/s)  LR: 6.446e-04  Data: 0.011 (0.016)
Train: 61 [ 200/390 ( 51%)]  Loss: 3.258 (3.29)  Time: 0.311s,  411.60/s  (0.315s,  405.97/s)  LR: 6.446e-04  Data: 0.010 (0.014)
Train: 61 [ 300/390 ( 77%)]  Loss: 3.135 (3.30)  Time: 0.319s,  400.63/s  (0.314s,  407.15/s)  LR: 6.446e-04  Data: 0.010 (0.013)
Train: 61 [ 389/390 (100%)]  Loss: 2.973 (3.32)  Time: 0.300s,  426.81/s  (0.314s,  407.48/s)  LR: 6.446e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.403 (0.403)  Loss:  1.1572 (1.1572)  Acc@1: 71.8750 (71.8750)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.0010 (1.1883)  Acc@1: 75.0000 (72.5800)  Acc@5: 93.7500 (93.9600)
Test: [Whole Val]  Time: 9.547  Loss: 1.1883  Acc@1: 72.5800 Pruned: 51.24% 
Test (EMA): [   0/78]  Time: 0.392 (0.392)  Loss:  1.1211 (1.1211)  Acc@1: 74.2188 (74.2188)  Acc@5: 96.0938 (96.0938)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.8921 (1.1364)  Acc@1: 81.2500 (73.5800)  Acc@5: 93.7500 (94.4100)
Test (EMA): [Whole Val]  Time: 9.502  Loss: 1.1364  Acc@1: 73.5800 Pruned: 51.24% 
Train: 62 [   0/390 (  0%)]  Loss: 3.578 (3.58)  Time: 0.979s,  130.78/s  (0.979s,  130.78/s)  LR: 6.345e-04  Data: 0.661 (0.661)
Train: 62 [ 100/390 ( 26%)]  Loss: 3.839 (3.33)  Time: 0.315s,  406.01/s  (0.324s,  395.27/s)  LR: 6.345e-04  Data: 0.012 (0.018)
Train: 62 [ 200/390 ( 51%)]  Loss: 3.696 (3.28)  Time: 0.312s,  409.91/s  (0.318s,  401.93/s)  LR: 6.345e-04  Data: 0.012 (0.014)
Train: 62 [ 300/390 ( 77%)]  Loss: 3.411 (3.31)  Time: 0.313s,  409.03/s  (0.316s,  404.60/s)  LR: 6.345e-04  Data: 0.011 (0.013)
Train: 62 [ 389/390 (100%)]  Loss: 3.539 (3.31)  Time: 0.314s,  407.90/s  (0.316s,  405.08/s)  LR: 6.345e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.415 (0.415)  Loss:  1.1250 (1.1250)  Acc@1: 72.6562 (72.6562)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.121)  Loss:  0.9087 (1.1566)  Acc@1: 81.2500 (73.0100)  Acc@5: 93.7500 (94.1300)
Test: [Whole Val]  Time: 9.550  Loss: 1.1566  Acc@1: 73.0100 Pruned: 51.22% 
Test (EMA): [   0/78]  Time: 0.409 (0.409)  Loss:  1.0859 (1.0859)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9146 (1.1160)  Acc@1: 75.0000 (73.8300)  Acc@5: 93.7500 (94.4800)
Test (EMA): [Whole Val]  Time: 9.536  Loss: 1.1160  Acc@1: 73.8300 Pruned: 51.22% 
Train: 63 [   0/390 (  0%)]  Loss: 3.214 (3.21)  Time: 0.769s,  166.50/s  (0.769s,  166.50/s)  LR: 6.244e-04  Data: 0.456 (0.456)
Train: 63 [ 100/390 ( 26%)]  Loss: 2.634 (3.27)  Time: 0.311s,  411.88/s  (0.318s,  402.56/s)  LR: 6.244e-04  Data: 0.010 (0.016)
Train: 63 [ 200/390 ( 51%)]  Loss: 3.704 (3.29)  Time: 0.311s,  412.13/s  (0.318s,  402.93/s)  LR: 6.244e-04  Data: 0.011 (0.013)
Train: 63 [ 300/390 ( 77%)]  Loss: 3.122 (3.28)  Time: 0.325s,  394.16/s  (0.316s,  404.91/s)  LR: 6.244e-04  Data: 0.010 (0.013)
Train: 63 [ 389/390 (100%)]  Loss: 3.190 (3.27)  Time: 0.301s,  425.33/s  (0.315s,  405.74/s)  LR: 6.244e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.306 (0.306)  Loss:  1.0762 (1.0762)  Acc@1: 72.6562 (72.6562)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.018 (0.119)  Loss:  0.9106 (1.1107)  Acc@1: 75.0000 (73.2700)  Acc@5: 93.7500 (94.1600)
Test: [Whole Val]  Time: 9.409  Loss: 1.1107  Acc@1: 73.2700 Pruned: 51.21% 
Test (EMA): [   0/78]  Time: 0.355 (0.355)  Loss:  1.0723 (1.0723)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.9072 (1.0829)  Acc@1: 75.0000 (74.1000)  Acc@5: 87.5000 (94.5200)
Test (EMA): [Whole Val]  Time: 9.471  Loss: 1.0829  Acc@1: 74.1000 Pruned: 51.21% 
Train: 64 [   0/390 (  0%)]  Loss: 3.241 (3.24)  Time: 0.871s,  146.96/s  (0.871s,  146.96/s)  LR: 6.142e-04  Data: 0.526 (0.526)
Train: 64 [ 100/390 ( 26%)]  Loss: 2.591 (3.35)  Time: 0.331s,  387.26/s  (0.326s,  392.99/s)  LR: 6.142e-04  Data: 0.012 (0.017)
Train: 64 [ 200/390 ( 51%)]  Loss: 2.544 (3.34)  Time: 0.311s,  411.49/s  (0.320s,  400.06/s)  LR: 6.142e-04  Data: 0.010 (0.014)
Train: 64 [ 300/390 ( 77%)]  Loss: 3.870 (3.32)  Time: 0.312s,  410.66/s  (0.318s,  402.88/s)  LR: 6.142e-04  Data: 0.011 (0.013)
Train: 64 [ 389/390 (100%)]  Loss: 3.639 (3.31)  Time: 0.317s,  403.70/s  (0.317s,  403.54/s)  LR: 6.142e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.380 (0.380)  Loss:  1.0586 (1.0586)  Acc@1: 74.2188 (74.2188)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.0010 (1.0893)  Acc@1: 75.0000 (73.2700)  Acc@5: 93.7500 (94.3500)
Test: [Whole Val]  Time: 9.549  Loss: 1.0893  Acc@1: 73.2700 Pruned: 51.21% 
Test (EMA): [   0/78]  Time: 0.331 (0.331)  Loss:  1.0615 (1.0615)  Acc@1: 74.2188 (74.2188)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.9370 (1.0925)  Acc@1: 75.0000 (73.9700)  Acc@5: 93.7500 (94.6200)
Test (EMA): [Whole Val]  Time: 9.517  Loss: 1.0925  Acc@1: 73.9700 Pruned: 51.21% 
Train: 65 [   0/390 (  0%)]  Loss: 3.548 (3.55)  Time: 0.838s,  152.67/s  (0.838s,  152.67/s)  LR: 6.040e-04  Data: 0.518 (0.518)
Train: 65 [ 100/390 ( 26%)]  Loss: 2.733 (3.29)  Time: 0.313s,  409.59/s  (0.322s,  397.18/s)  LR: 6.040e-04  Data: 0.011 (0.017)
Train: 65 [ 200/390 ( 51%)]  Loss: 3.095 (3.27)  Time: 0.313s,  408.80/s  (0.318s,  402.11/s)  LR: 6.040e-04  Data: 0.010 (0.014)
Train: 65 [ 300/390 ( 77%)]  Loss: 3.896 (3.25)  Time: 0.310s,  412.50/s  (0.317s,  403.66/s)  LR: 6.040e-04  Data: 0.010 (0.013)
Train: 65 [ 389/390 (100%)]  Loss: 3.590 (3.25)  Time: 0.304s,  421.03/s  (0.316s,  404.92/s)  LR: 6.040e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.376 (0.376)  Loss:  1.1582 (1.1582)  Acc@1: 73.4375 (73.4375)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.024 (0.121)  Loss:  0.9404 (1.1744)  Acc@1: 81.2500 (72.8300)  Acc@5: 93.7500 (93.8200)
Test: [Whole Val]  Time: 9.579  Loss: 1.1744  Acc@1: 72.8300 Pruned: 51.20% 
Test (EMA): [   0/78]  Time: 0.344 (0.344)  Loss:  1.1006 (1.1006)  Acc@1: 73.4375 (73.4375)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.9121 (1.1016)  Acc@1: 81.2500 (74.0800)  Acc@5: 93.7500 (94.5700)
Test (EMA): [Whole Val]  Time: 9.502  Loss: 1.1016  Acc@1: 74.0800 Pruned: 51.21% 
Train: 66 [   0/390 (  0%)]  Loss: 3.720 (3.72)  Time: 0.778s,  164.53/s  (0.778s,  164.53/s)  LR: 5.937e-04  Data: 0.474 (0.474)
Train: 66 [ 100/390 ( 26%)]  Loss: 3.047 (3.29)  Time: 0.314s,  407.91/s  (0.318s,  402.98/s)  LR: 5.937e-04  Data: 0.013 (0.016)
Train: 66 [ 200/390 ( 51%)]  Loss: 3.724 (3.28)  Time: 0.314s,  407.69/s  (0.316s,  405.66/s)  LR: 5.937e-04  Data: 0.012 (0.013)
Train: 66 [ 300/390 ( 77%)]  Loss: 3.414 (3.31)  Time: 0.311s,  411.08/s  (0.314s,  407.01/s)  LR: 5.937e-04  Data: 0.011 (0.013)
Train: 66 [ 389/390 (100%)]  Loss: 3.009 (3.32)  Time: 0.301s,  425.52/s  (0.314s,  407.10/s)  LR: 5.937e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.358 (0.358)  Loss:  1.1387 (1.1387)  Acc@1: 74.2188 (74.2188)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.018 (0.120)  Loss:  0.9775 (1.1628)  Acc@1: 75.0000 (73.3800)  Acc@5: 87.5000 (94.5400)
Test: [Whole Val]  Time: 9.511  Loss: 1.1628  Acc@1: 73.3800 Pruned: 51.19% 
Test (EMA): [   0/78]  Time: 0.397 (0.397)  Loss:  1.1094 (1.1094)  Acc@1: 75.0000 (75.0000)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.022 (0.121)  Loss:  0.9380 (1.1264)  Acc@1: 75.0000 (74.0400)  Acc@5: 87.5000 (94.5700)
Test (EMA): [Whole Val]  Time: 9.584  Loss: 1.1264  Acc@1: 74.0400 Pruned: 51.18% 
Train: 67 [   0/390 (  0%)]  Loss: 3.675 (3.67)  Time: 0.917s,  139.53/s  (0.917s,  139.53/s)  LR: 5.834e-04  Data: 0.600 (0.600)
Train: 67 [ 100/390 ( 26%)]  Loss: 3.136 (3.27)  Time: 0.314s,  407.63/s  (0.321s,  399.17/s)  LR: 5.834e-04  Data: 0.010 (0.018)
Train: 67 [ 200/390 ( 51%)]  Loss: 3.737 (3.27)  Time: 0.311s,  411.99/s  (0.318s,  402.88/s)  LR: 5.834e-04  Data: 0.011 (0.015)
Train: 67 [ 300/390 ( 77%)]  Loss: 3.953 (3.29)  Time: 0.312s,  410.07/s  (0.317s,  403.75/s)  LR: 5.834e-04  Data: 0.010 (0.014)
Train: 67 [ 389/390 (100%)]  Loss: 2.911 (3.30)  Time: 0.309s,  414.89/s  (0.316s,  404.60/s)  LR: 5.834e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.405 (0.405)  Loss:  1.1377 (1.1377)  Acc@1: 73.4375 (73.4375)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.9795 (1.1576)  Acc@1: 75.0000 (73.1200)  Acc@5: 93.7500 (94.3500)
Test: [Whole Val]  Time: 9.561  Loss: 1.1576  Acc@1: 73.1200 Pruned: 51.17% 
Test (EMA): [   0/78]  Time: 0.390 (0.390)  Loss:  1.0996 (1.0996)  Acc@1: 72.6562 (72.6562)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.121)  Loss:  0.9341 (1.1235)  Acc@1: 75.0000 (73.5800)  Acc@5: 93.7500 (94.6200)
Test (EMA): [Whole Val]  Time: 9.596  Loss: 1.1235  Acc@1: 73.5800 Pruned: 51.17% 
Train: 68 [   0/390 (  0%)]  Loss: 3.467 (3.47)  Time: 0.996s,  128.57/s  (0.996s,  128.57/s)  LR: 5.731e-04  Data: 0.693 (0.693)
Train: 68 [ 100/390 ( 26%)]  Loss: 3.409 (3.28)  Time: 0.341s,  375.11/s  (0.325s,  393.82/s)  LR: 5.731e-04  Data: 0.012 (0.019)
Train: 68 [ 200/390 ( 51%)]  Loss: 3.318 (3.28)  Time: 0.327s,  391.55/s  (0.319s,  400.65/s)  LR: 5.731e-04  Data: 0.012 (0.015)
Train: 68 [ 300/390 ( 77%)]  Loss: 3.295 (3.27)  Time: 0.310s,  412.67/s  (0.318s,  402.20/s)  LR: 5.731e-04  Data: 0.010 (0.014)
Train: 68 [ 389/390 (100%)]  Loss: 3.447 (3.27)  Time: 0.302s,  423.91/s  (0.317s,  403.74/s)  LR: 5.731e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.429 (0.429)  Loss:  1.1084 (1.1084)  Acc@1: 71.8750 (71.8750)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.018 (0.121)  Loss:  0.9326 (1.1155)  Acc@1: 75.0000 (73.8400)  Acc@5: 87.5000 (94.3600)
Test: [Whole Val]  Time: 9.575  Loss: 1.1155  Acc@1: 73.8400 Pruned: 51.17% 
Test (EMA): [   0/78]  Time: 0.340 (0.340)  Loss:  1.1299 (1.1299)  Acc@1: 72.6562 (72.6562)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.9443 (1.1277)  Acc@1: 75.0000 (74.1300)  Acc@5: 93.7500 (94.6400)
Test (EMA): [Whole Val]  Time: 9.482  Loss: 1.1277  Acc@1: 74.1300 Pruned: 51.18% 
Train: 69 [   0/390 (  0%)]  Loss: 3.002 (3.00)  Time: 0.890s,  143.78/s  (0.890s,  143.78/s)  LR: 5.627e-04  Data: 0.576 (0.576)
Train: 69 [ 100/390 ( 26%)]  Loss: 2.740 (3.31)  Time: 0.327s,  390.86/s  (0.329s,  389.37/s)  LR: 5.627e-04  Data: 0.011 (0.017)
Train: 69 [ 200/390 ( 51%)]  Loss: 2.907 (3.30)  Time: 0.311s,  411.68/s  (0.324s,  395.55/s)  LR: 5.627e-04  Data: 0.011 (0.014)
Train: 69 [ 300/390 ( 77%)]  Loss: 2.930 (3.31)  Time: 0.319s,  401.30/s  (0.321s,  398.45/s)  LR: 5.627e-04  Data: 0.017 (0.013)
Train: 69 [ 389/390 (100%)]  Loss: 3.611 (3.32)  Time: 0.301s,  425.82/s  (0.320s,  400.39/s)  LR: 5.627e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.379 (0.379)  Loss:  1.1592 (1.1592)  Acc@1: 73.4375 (73.4375)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  1.0361 (1.1598)  Acc@1: 75.0000 (73.9000)  Acc@5: 87.5000 (94.4100)
Test: [Whole Val]  Time: 9.534  Loss: 1.1598  Acc@1: 73.9000 Pruned: 51.17% 
Test (EMA): [   0/78]  Time: 0.308 (0.308)  Loss:  1.1211 (1.1211)  Acc@1: 73.4375 (73.4375)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.9062 (1.1164)  Acc@1: 75.0000 (74.3600)  Acc@5: 87.5000 (94.6600)
Test (EMA): [Whole Val]  Time: 9.468  Loss: 1.1164  Acc@1: 74.3600 Pruned: 51.17% 
Train: 70 [   0/390 (  0%)]  Loss: 3.580 (3.58)  Time: 0.837s,  152.96/s  (0.837s,  152.96/s)  LR: 5.523e-04  Data: 0.532 (0.532)
Train: 70 [ 100/390 ( 26%)]  Loss: 2.568 (3.30)  Time: 0.310s,  412.25/s  (0.321s,  398.81/s)  LR: 5.523e-04  Data: 0.010 (0.017)
Train: 70 [ 200/390 ( 51%)]  Loss: 2.532 (3.32)  Time: 0.311s,  411.56/s  (0.317s,  403.91/s)  LR: 5.523e-04  Data: 0.011 (0.014)
Train: 70 [ 300/390 ( 77%)]  Loss: 2.937 (3.30)  Time: 0.314s,  407.53/s  (0.316s,  405.23/s)  LR: 5.523e-04  Data: 0.012 (0.013)
Train: 70 [ 389/390 (100%)]  Loss: 2.909 (3.29)  Time: 0.301s,  425.87/s  (0.315s,  405.85/s)  LR: 5.523e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.365 (0.365)  Loss:  1.0518 (1.0518)  Acc@1: 74.2188 (74.2188)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.021 (0.120)  Loss:  0.7930 (1.0477)  Acc@1: 81.2500 (74.2100)  Acc@5: 93.7500 (94.3200)
Test: [Whole Val]  Time: 9.500  Loss: 1.0477  Acc@1: 74.2100 Pruned: 51.17% 
Test (EMA): [   0/78]  Time: 0.427 (0.427)  Loss:  1.0518 (1.0518)  Acc@1: 73.4375 (73.4375)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.021 (0.122)  Loss:  0.8218 (1.0444)  Acc@1: 75.0000 (74.4600)  Acc@5: 93.7500 (94.6800)
Test (EMA): [Whole Val]  Time: 9.626  Loss: 1.0444  Acc@1: 74.4600 Pruned: 51.17% 
Train: 71 [   0/390 (  0%)]  Loss: 3.901 (3.90)  Time: 0.899s,  142.43/s  (0.899s,  142.43/s)  LR: 5.419e-04  Data: 0.584 (0.584)
Train: 71 [ 100/390 ( 26%)]  Loss: 4.014 (3.27)  Time: 0.313s,  409.30/s  (0.328s,  390.62/s)  LR: 5.419e-04  Data: 0.011 (0.017)
Train: 71 [ 200/390 ( 51%)]  Loss: 3.546 (3.26)  Time: 0.309s,  414.64/s  (0.320s,  400.43/s)  LR: 5.419e-04  Data: 0.010 (0.014)
Train: 71 [ 300/390 ( 77%)]  Loss: 3.784 (3.25)  Time: 0.311s,  412.23/s  (0.318s,  402.59/s)  LR: 5.419e-04  Data: 0.010 (0.013)
Train: 71 [ 389/390 (100%)]  Loss: 3.278 (3.26)  Time: 0.310s,  412.92/s  (0.317s,  403.68/s)  LR: 5.419e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.349 (0.349)  Loss:  1.0840 (1.0840)  Acc@1: 73.4375 (73.4375)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.022 (0.121)  Loss:  0.9893 (1.1330)  Acc@1: 75.0000 (73.7600)  Acc@5: 87.5000 (94.1900)
Test: [Whole Val]  Time: 9.553  Loss: 1.1330  Acc@1: 73.7600 Pruned: 51.17% 
Test (EMA): [   0/78]  Time: 0.320 (0.320)  Loss:  1.0752 (1.0752)  Acc@1: 72.6562 (72.6562)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.018 (0.120)  Loss:  0.9282 (1.1104)  Acc@1: 75.0000 (74.3100)  Acc@5: 93.7500 (94.5400)
Test (EMA): [Whole Val]  Time: 9.473  Loss: 1.1104  Acc@1: 74.3100 Pruned: 51.17% 
Train: 72 [   0/390 (  0%)]  Loss: 3.385 (3.38)  Time: 0.782s,  163.63/s  (0.782s,  163.63/s)  LR: 5.314e-04  Data: 0.478 (0.478)
Train: 72 [ 100/390 ( 26%)]  Loss: 2.572 (3.28)  Time: 0.314s,  407.82/s  (0.321s,  398.89/s)  LR: 5.314e-04  Data: 0.012 (0.016)
Train: 72 [ 200/390 ( 51%)]  Loss: 2.212 (3.27)  Time: 0.317s,  403.82/s  (0.321s,  399.27/s)  LR: 5.314e-04  Data: 0.013 (0.015)
Train: 72 [ 300/390 ( 77%)]  Loss: 2.869 (3.27)  Time: 0.325s,  393.62/s  (0.320s,  400.57/s)  LR: 5.314e-04  Data: 0.015 (0.014)
Train: 72 [ 389/390 (100%)]  Loss: 3.602 (3.28)  Time: 0.302s,  424.23/s  (0.319s,  401.38/s)  LR: 5.314e-04  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.315 (0.315)  Loss:  1.1074 (1.1074)  Acc@1: 72.6562 (72.6562)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.020 (0.123)  Loss:  0.8394 (1.1247)  Acc@1: 81.2500 (73.4900)  Acc@5: 93.7500 (94.3900)
Test: [Whole Val]  Time: 9.681  Loss: 1.1247  Acc@1: 73.4900 Pruned: 51.15% 
Test (EMA): [   0/78]  Time: 0.333 (0.333)  Loss:  1.0898 (1.0898)  Acc@1: 72.6562 (72.6562)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.121)  Loss:  0.8496 (1.0955)  Acc@1: 81.2500 (74.0400)  Acc@5: 93.7500 (94.7000)
Test (EMA): [Whole Val]  Time: 9.576  Loss: 1.0955  Acc@1: 74.0400 Pruned: 51.15% 
Train: 73 [   0/390 (  0%)]  Loss: 3.783 (3.78)  Time: 0.784s,  163.37/s  (0.784s,  163.37/s)  LR: 5.210e-04  Data: 0.481 (0.481)
Train: 73 [ 100/390 ( 26%)]  Loss: 3.864 (3.24)  Time: 0.311s,  412.08/s  (0.319s,  400.90/s)  LR: 5.210e-04  Data: 0.011 (0.016)
Train: 73 [ 200/390 ( 51%)]  Loss: 3.559 (3.27)  Time: 0.311s,  412.16/s  (0.316s,  404.93/s)  LR: 5.210e-04  Data: 0.010 (0.013)
Train: 73 [ 300/390 ( 77%)]  Loss: 3.387 (3.27)  Time: 0.316s,  405.01/s  (0.316s,  405.46/s)  LR: 5.210e-04  Data: 0.013 (0.013)
Train: 73 [ 389/390 (100%)]  Loss: 2.555 (3.28)  Time: 0.300s,  426.22/s  (0.315s,  406.46/s)  LR: 5.210e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.311 (0.311)  Loss:  1.1211 (1.1211)  Acc@1: 71.8750 (71.8750)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  0.8662 (1.1180)  Acc@1: 75.0000 (73.6100)  Acc@5: 93.7500 (94.2300)
Test: [Whole Val]  Time: 9.516  Loss: 1.1180  Acc@1: 73.6100 Pruned: 51.16% 
Test (EMA): [   0/78]  Time: 0.313 (0.313)  Loss:  1.1270 (1.1270)  Acc@1: 71.8750 (71.8750)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.022 (0.120)  Loss:  0.8979 (1.1210)  Acc@1: 81.2500 (74.1800)  Acc@5: 93.7500 (94.4600)
Test (EMA): [Whole Val]  Time: 9.471  Loss: 1.1210  Acc@1: 74.1800 Pruned: 51.16% 
Train: 74 [   0/390 (  0%)]  Loss: 2.335 (2.33)  Time: 0.760s,  168.38/s  (0.760s,  168.38/s)  LR: 5.105e-04  Data: 0.457 (0.457)
Train: 74 [ 100/390 ( 26%)]  Loss: 2.886 (3.25)  Time: 0.311s,  411.92/s  (0.318s,  402.59/s)  LR: 5.105e-04  Data: 0.010 (0.016)
Train: 74 [ 200/390 ( 51%)]  Loss: 2.889 (3.27)  Time: 0.311s,  411.20/s  (0.315s,  405.76/s)  LR: 5.105e-04  Data: 0.010 (0.014)
Train: 74 [ 300/390 ( 77%)]  Loss: 3.415 (3.25)  Time: 0.310s,  412.53/s  (0.315s,  406.14/s)  LR: 5.105e-04  Data: 0.010 (0.013)
Train: 74 [ 389/390 (100%)]  Loss: 3.653 (3.27)  Time: 0.303s,  422.68/s  (0.316s,  405.24/s)  LR: 5.105e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.400 (0.400)  Loss:  1.0352 (1.0352)  Acc@1: 76.5625 (76.5625)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.8555 (1.0930)  Acc@1: 81.2500 (74.0300)  Acc@5: 93.7500 (94.4500)
Test: [Whole Val]  Time: 9.544  Loss: 1.0930  Acc@1: 74.0300 Pruned: 51.15% 
Test (EMA): [   0/78]  Time: 0.423 (0.423)  Loss:  1.0420 (1.0420)  Acc@1: 77.3438 (77.3438)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.8418 (1.0792)  Acc@1: 81.2500 (74.5200)  Acc@5: 93.7500 (94.8100)
Test (EMA): [Whole Val]  Time: 9.611  Loss: 1.0792  Acc@1: 74.5200 Pruned: 51.15% 
Train: 75 [   0/390 (  0%)]  Loss: 3.819 (3.82)  Time: 0.941s,  135.96/s  (0.941s,  135.96/s)  LR: 5.000e-04  Data: 0.625 (0.625)
Train: 75 [ 100/390 ( 26%)]  Loss: 3.183 (3.23)  Time: 0.312s,  409.98/s  (0.321s,  398.98/s)  LR: 5.000e-04  Data: 0.010 (0.017)
Train: 75 [ 200/390 ( 51%)]  Loss: 3.742 (3.21)  Time: 0.311s,  411.91/s  (0.321s,  398.72/s)  LR: 5.000e-04  Data: 0.010 (0.014)
Train: 75 [ 300/390 ( 77%)]  Loss: 3.563 (3.25)  Time: 0.337s,  379.64/s  (0.319s,  401.44/s)  LR: 5.000e-04  Data: 0.016 (0.013)
Train: 75 [ 389/390 (100%)]  Loss: 3.587 (3.28)  Time: 0.301s,  425.45/s  (0.320s,  399.78/s)  LR: 5.000e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.377 (0.377)  Loss:  1.0645 (1.0645)  Acc@1: 76.5625 (76.5625)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.7964 (1.0929)  Acc@1: 81.2500 (74.4100)  Acc@5: 93.7500 (94.5000)
Test: [Whole Val]  Time: 9.608  Loss: 1.0929  Acc@1: 74.4100 Pruned: 51.16% 
Test (EMA): [   0/78]  Time: 0.328 (0.328)  Loss:  1.0879 (1.0879)  Acc@1: 73.4375 (73.4375)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.8188 (1.1079)  Acc@1: 81.2500 (74.8700)  Acc@5: 93.7500 (94.7000)
Test (EMA): [Whole Val]  Time: 9.488  Loss: 1.1079  Acc@1: 74.8700 Pruned: 51.16% 
Train: 76 [   0/390 (  0%)]  Loss: 3.809 (3.81)  Time: 0.806s,  158.74/s  (0.806s,  158.74/s)  LR: 4.896e-04  Data: 0.488 (0.488)
Train: 76 [ 100/390 ( 26%)]  Loss: 3.901 (3.33)  Time: 0.332s,  385.91/s  (0.318s,  402.75/s)  LR: 4.896e-04  Data: 0.012 (0.016)
Train: 76 [ 200/390 ( 51%)]  Loss: 3.198 (3.33)  Time: 0.312s,  409.86/s  (0.316s,  404.90/s)  LR: 4.896e-04  Data: 0.011 (0.014)
Train: 76 [ 300/390 ( 77%)]  Loss: 3.576 (3.30)  Time: 0.326s,  393.09/s  (0.315s,  406.13/s)  LR: 4.896e-04  Data: 0.012 (0.013)
Train: 76 [ 389/390 (100%)]  Loss: 2.565 (3.29)  Time: 0.301s,  425.81/s  (0.315s,  405.75/s)  LR: 4.896e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.327 (0.327)  Loss:  1.0566 (1.0566)  Acc@1: 75.0000 (75.0000)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.027 (0.120)  Loss:  0.8477 (1.0872)  Acc@1: 81.2500 (74.1300)  Acc@5: 93.7500 (94.5100)
Test: [Whole Val]  Time: 9.481  Loss: 1.0872  Acc@1: 74.1300 Pruned: 51.17% 
Test (EMA): [   0/78]  Time: 0.386 (0.386)  Loss:  1.0625 (1.0625)  Acc@1: 75.0000 (75.0000)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.8452 (1.0720)  Acc@1: 81.2500 (74.6500)  Acc@5: 93.7500 (94.7800)
Test (EMA): [Whole Val]  Time: 9.570  Loss: 1.0720  Acc@1: 74.6500 Pruned: 51.17% 
Train: 77 [   0/390 (  0%)]  Loss: 3.565 (3.57)  Time: 0.930s,  137.61/s  (0.930s,  137.61/s)  LR: 4.791e-04  Data: 0.615 (0.615)
Train: 77 [ 100/390 ( 26%)]  Loss: 2.980 (3.17)  Time: 0.311s,  412.21/s  (0.327s,  390.85/s)  LR: 4.791e-04  Data: 0.009 (0.017)
Train: 77 [ 200/390 ( 51%)]  Loss: 2.538 (3.25)  Time: 0.314s,  407.93/s  (0.323s,  396.05/s)  LR: 4.791e-04  Data: 0.012 (0.014)
Train: 77 [ 300/390 ( 77%)]  Loss: 3.555 (3.27)  Time: 0.334s,  383.58/s  (0.321s,  398.32/s)  LR: 4.791e-04  Data: 0.010 (0.013)
Train: 77 [ 389/390 (100%)]  Loss: 2.634 (3.28)  Time: 0.303s,  422.62/s  (0.320s,  399.69/s)  LR: 4.791e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.399 (0.399)  Loss:  1.0986 (1.0986)  Acc@1: 72.6562 (72.6562)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.9268 (1.1187)  Acc@1: 81.2500 (74.1200)  Acc@5: 93.7500 (94.3900)
Test: [Whole Val]  Time: 9.557  Loss: 1.1187  Acc@1: 74.1200 Pruned: 51.16% 
Test (EMA): [   0/78]  Time: 0.410 (0.410)  Loss:  1.1123 (1.1123)  Acc@1: 73.4375 (73.4375)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9229 (1.1336)  Acc@1: 81.2500 (74.4000)  Acc@5: 93.7500 (94.5200)
Test (EMA): [Whole Val]  Time: 9.571  Loss: 1.1336  Acc@1: 74.4000 Pruned: 51.16% 
Train: 78 [   0/390 (  0%)]  Loss: 3.168 (3.17)  Time: 0.889s,  144.01/s  (0.889s,  144.01/s)  LR: 4.687e-04  Data: 0.586 (0.586)
Train: 78 [ 100/390 ( 26%)]  Loss: 3.885 (3.33)  Time: 0.315s,  406.01/s  (0.321s,  399.09/s)  LR: 4.687e-04  Data: 0.011 (0.017)
Train: 78 [ 200/390 ( 51%)]  Loss: 2.406 (3.28)  Time: 0.311s,  411.85/s  (0.318s,  403.06/s)  LR: 4.687e-04  Data: 0.010 (0.014)
Train: 78 [ 300/390 ( 77%)]  Loss: 3.485 (3.27)  Time: 0.311s,  411.05/s  (0.316s,  404.97/s)  LR: 4.687e-04  Data: 0.012 (0.013)
Train: 78 [ 389/390 (100%)]  Loss: 2.251 (3.29)  Time: 0.303s,  423.00/s  (0.315s,  406.00/s)  LR: 4.687e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.416 (0.416)  Loss:  1.1387 (1.1387)  Acc@1: 72.6562 (72.6562)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.023 (0.121)  Loss:  0.9233 (1.1245)  Acc@1: 81.2500 (74.4800)  Acc@5: 93.7500 (94.8800)
Test: [Whole Val]  Time: 9.580  Loss: 1.1245  Acc@1: 74.4800 Pruned: 51.15% 
Test (EMA): [   0/78]  Time: 0.401 (0.401)  Loss:  1.1084 (1.1084)  Acc@1: 71.8750 (71.8750)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.8931 (1.0934)  Acc@1: 81.2500 (74.6500)  Acc@5: 93.7500 (94.7000)
Test (EMA): [Whole Val]  Time: 9.564  Loss: 1.0934  Acc@1: 74.6500 Pruned: 51.15% 
Train: 79 [   0/390 (  0%)]  Loss: 3.562 (3.56)  Time: 0.902s,  141.93/s  (0.902s,  141.93/s)  LR: 4.582e-04  Data: 0.600 (0.600)
Train: 79 [ 100/390 ( 26%)]  Loss: 2.272 (3.37)  Time: 0.314s,  407.05/s  (0.320s,  399.62/s)  LR: 4.582e-04  Data: 0.011 (0.017)
Train: 79 [ 200/390 ( 51%)]  Loss: 3.206 (3.33)  Time: 0.311s,  411.20/s  (0.317s,  403.54/s)  LR: 4.582e-04  Data: 0.011 (0.014)
Train: 79 [ 300/390 ( 77%)]  Loss: 2.666 (3.29)  Time: 0.317s,  403.84/s  (0.316s,  404.81/s)  LR: 4.582e-04  Data: 0.010 (0.013)
Train: 79 [ 389/390 (100%)]  Loss: 2.206 (3.29)  Time: 0.301s,  425.11/s  (0.316s,  405.17/s)  LR: 4.582e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.391 (0.391)  Loss:  1.0801 (1.0801)  Acc@1: 71.8750 (71.8750)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.8765 (1.0802)  Acc@1: 81.2500 (74.4600)  Acc@5: 93.7500 (94.6200)
Test: [Whole Val]  Time: 9.554  Loss: 1.0802  Acc@1: 74.4600 Pruned: 51.16% 
Test (EMA): [   0/78]  Time: 0.367 (0.367)  Loss:  1.0918 (1.0918)  Acc@1: 72.6562 (72.6562)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.8877 (1.0948)  Acc@1: 81.2500 (74.5800)  Acc@5: 93.7500 (94.7300)
Test (EMA): [Whole Val]  Time: 9.525  Loss: 1.0948  Acc@1: 74.5800 Pruned: 51.16% 
Train: 80 [   0/390 (  0%)]  Loss: 3.648 (3.65)  Time: 0.829s,  154.45/s  (0.829s,  154.45/s)  LR: 4.478e-04  Data: 0.523 (0.523)
Train: 80 [ 100/390 ( 26%)]  Loss: 3.301 (3.30)  Time: 0.311s,  411.44/s  (0.321s,  399.36/s)  LR: 4.478e-04  Data: 0.010 (0.016)
Train: 80 [ 200/390 ( 51%)]  Loss: 3.744 (3.28)  Time: 0.314s,  407.33/s  (0.318s,  402.67/s)  LR: 4.478e-04  Data: 0.012 (0.014)
Train: 80 [ 300/390 ( 77%)]  Loss: 3.457 (3.29)  Time: 0.314s,  407.03/s  (0.316s,  404.59/s)  LR: 4.478e-04  Data: 0.014 (0.013)
Train: 80 [ 389/390 (100%)]  Loss: 3.528 (3.27)  Time: 0.302s,  423.38/s  (0.316s,  405.30/s)  LR: 4.478e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.353 (0.353)  Loss:  1.0537 (1.0537)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.021 (0.120)  Loss:  0.7451 (1.0455)  Acc@1: 87.5000 (74.3700)  Acc@5: 93.7500 (94.6500)
Test: [Whole Val]  Time: 9.516  Loss: 1.0455  Acc@1: 74.3700 Pruned: 51.14% 
Test (EMA): [   0/78]  Time: 0.308 (0.308)  Loss:  1.0557 (1.0557)  Acc@1: 74.2188 (74.2188)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.021 (0.121)  Loss:  0.7764 (1.0413)  Acc@1: 81.2500 (74.9500)  Acc@5: 93.7500 (94.8000)
Test (EMA): [Whole Val]  Time: 9.540  Loss: 1.0413  Acc@1: 74.9500 Pruned: 51.14% 
Train: 81 [   0/390 (  0%)]  Loss: 2.853 (2.85)  Time: 0.739s,  173.17/s  (0.739s,  173.17/s)  LR: 4.374e-04  Data: 0.435 (0.435)
Train: 81 [ 100/390 ( 26%)]  Loss: 3.469 (3.22)  Time: 0.316s,  404.92/s  (0.318s,  403.12/s)  LR: 4.374e-04  Data: 0.011 (0.015)
Train: 81 [ 200/390 ( 51%)]  Loss: 3.646 (3.22)  Time: 0.311s,  412.12/s  (0.316s,  404.86/s)  LR: 4.374e-04  Data: 0.010 (0.013)
Train: 81 [ 300/390 ( 77%)]  Loss: 2.544 (3.23)  Time: 0.314s,  407.89/s  (0.316s,  405.69/s)  LR: 4.374e-04  Data: 0.011 (0.013)
Train: 81 [ 389/390 (100%)]  Loss: 2.591 (3.24)  Time: 0.301s,  425.57/s  (0.315s,  406.18/s)  LR: 4.374e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.405 (0.405)  Loss:  1.1230 (1.1230)  Acc@1: 73.4375 (73.4375)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.018 (0.121)  Loss:  0.9766 (1.1084)  Acc@1: 81.2500 (74.1700)  Acc@5: 93.7500 (94.8600)
Test: [Whole Val]  Time: 9.592  Loss: 1.1084  Acc@1: 74.1700 Pruned: 51.14% 
Test (EMA): [   0/78]  Time: 0.419 (0.419)  Loss:  1.1074 (1.1074)  Acc@1: 72.6562 (72.6562)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.9160 (1.0963)  Acc@1: 81.2500 (74.5400)  Acc@5: 93.7500 (94.8100)
Test (EMA): [Whole Val]  Time: 9.588  Loss: 1.0963  Acc@1: 74.5400 Pruned: 51.14% 
Train: 82 [   0/390 (  0%)]  Loss: 2.762 (2.76)  Time: 0.783s,  163.50/s  (0.783s,  163.50/s)  LR: 4.270e-04  Data: 0.467 (0.467)
Train: 82 [ 100/390 ( 26%)]  Loss: 2.339 (3.22)  Time: 0.317s,  403.74/s  (0.321s,  398.36/s)  LR: 4.270e-04  Data: 0.013 (0.016)
Train: 82 [ 200/390 ( 51%)]  Loss: 3.479 (3.24)  Time: 0.338s,  378.39/s  (0.317s,  403.48/s)  LR: 4.270e-04  Data: 0.011 (0.014)
Train: 82 [ 300/390 ( 77%)]  Loss: 3.099 (3.24)  Time: 0.313s,  409.19/s  (0.316s,  404.48/s)  LR: 4.270e-04  Data: 0.012 (0.013)
Train: 82 [ 389/390 (100%)]  Loss: 2.999 (3.24)  Time: 0.289s,  443.28/s  (0.316s,  405.02/s)  LR: 4.270e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.355 (0.355)  Loss:  1.1396 (1.1396)  Acc@1: 73.4375 (73.4375)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.9224 (1.1368)  Acc@1: 87.5000 (73.9700)  Acc@5: 93.7500 (94.7600)
Test: [Whole Val]  Time: 9.540  Loss: 1.1368  Acc@1: 73.9700 Pruned: 51.13% 
Test (EMA): [   0/78]  Time: 0.308 (0.308)  Loss:  1.1377 (1.1377)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.9302 (1.1308)  Acc@1: 87.5000 (74.5100)  Acc@5: 93.7500 (94.7600)
Test (EMA): [Whole Val]  Time: 9.445  Loss: 1.1308  Acc@1: 74.5100 Pruned: 51.14% 
Train: 83 [   0/390 (  0%)]  Loss: 2.768 (2.77)  Time: 0.889s,  143.93/s  (0.889s,  143.93/s)  LR: 4.167e-04  Data: 0.589 (0.589)
Train: 83 [ 100/390 ( 26%)]  Loss: 2.417 (3.22)  Time: 0.312s,  409.69/s  (0.320s,  400.55/s)  LR: 4.167e-04  Data: 0.011 (0.017)
Train: 83 [ 200/390 ( 51%)]  Loss: 3.385 (3.21)  Time: 0.325s,  393.31/s  (0.317s,  403.44/s)  LR: 4.167e-04  Data: 0.011 (0.014)
Train: 83 [ 300/390 ( 77%)]  Loss: 3.387 (3.22)  Time: 0.311s,  412.06/s  (0.317s,  403.42/s)  LR: 4.167e-04  Data: 0.010 (0.013)
Train: 83 [ 389/390 (100%)]  Loss: 3.357 (3.23)  Time: 0.308s,  414.97/s  (0.317s,  404.37/s)  LR: 4.167e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.397 (0.397)  Loss:  1.0527 (1.0527)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.7910 (1.0639)  Acc@1: 87.5000 (74.5600)  Acc@5: 93.7500 (94.8100)
Test: [Whole Val]  Time: 9.525  Loss: 1.0639  Acc@1: 74.5600 Pruned: 51.13% 
Test (EMA): [   0/78]  Time: 0.319 (0.319)  Loss:  1.0771 (1.0771)  Acc@1: 74.2188 (74.2188)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.018 (0.120)  Loss:  0.8193 (1.0742)  Acc@1: 87.5000 (74.5300)  Acc@5: 93.7500 (94.8700)
Test (EMA): [Whole Val]  Time: 9.476  Loss: 1.0742  Acc@1: 74.5300 Pruned: 51.13% 
Train: 84 [   0/390 (  0%)]  Loss: 2.296 (2.30)  Time: 0.877s,  145.89/s  (0.877s,  145.89/s)  LR: 4.064e-04  Data: 0.574 (0.574)
Train: 84 [ 100/390 ( 26%)]  Loss: 3.665 (3.23)  Time: 0.312s,  410.59/s  (0.318s,  402.61/s)  LR: 4.064e-04  Data: 0.010 (0.016)
Train: 84 [ 200/390 ( 51%)]  Loss: 3.399 (3.24)  Time: 0.312s,  410.76/s  (0.316s,  405.58/s)  LR: 4.064e-04  Data: 0.010 (0.014)
Train: 84 [ 300/390 ( 77%)]  Loss: 3.754 (3.25)  Time: 0.417s,  306.59/s  (0.315s,  406.22/s)  LR: 4.064e-04  Data: 0.013 (0.013)
Train: 84 [ 389/390 (100%)]  Loss: 3.409 (3.25)  Time: 0.303s,  421.87/s  (0.316s,  405.66/s)  LR: 4.064e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.431 (0.431)  Loss:  1.1094 (1.1094)  Acc@1: 73.4375 (73.4375)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.9028 (1.0867)  Acc@1: 81.2500 (74.6200)  Acc@5: 93.7500 (94.6800)
Test: [Whole Val]  Time: 9.654  Loss: 1.0867  Acc@1: 74.6200 Pruned: 51.11% 
Test (EMA): [   0/78]  Time: 0.420 (0.420)  Loss:  1.0840 (1.0840)  Acc@1: 74.2188 (74.2188)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.8633 (1.0630)  Acc@1: 81.2500 (75.0300)  Acc@5: 93.7500 (94.7900)
Test (EMA): [Whole Val]  Time: 9.665  Loss: 1.0630  Acc@1: 75.0300 Pruned: 51.11% 
Train: 85 [   0/390 (  0%)]  Loss: 3.448 (3.45)  Time: 0.798s,  160.50/s  (0.798s,  160.50/s)  LR: 3.961e-04  Data: 0.476 (0.476)
Train: 85 [ 100/390 ( 26%)]  Loss: 3.808 (3.29)  Time: 0.314s,  407.57/s  (0.321s,  398.40/s)  LR: 3.961e-04  Data: 0.013 (0.017)
Train: 85 [ 200/390 ( 51%)]  Loss: 3.613 (3.27)  Time: 0.313s,  408.38/s  (0.319s,  400.75/s)  LR: 3.961e-04  Data: 0.012 (0.014)
Train: 85 [ 300/390 ( 77%)]  Loss: 3.781 (3.24)  Time: 0.315s,  406.91/s  (0.319s,  401.79/s)  LR: 3.961e-04  Data: 0.011 (0.014)
Train: 85 [ 389/390 (100%)]  Loss: 2.649 (3.24)  Time: 0.304s,  421.09/s  (0.318s,  402.89/s)  LR: 3.961e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.367 (0.367)  Loss:  1.0996 (1.0996)  Acc@1: 72.6562 (72.6562)  Acc@5: 96.0938 (96.0938)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.8447 (1.1089)  Acc@1: 87.5000 (74.2300)  Acc@5: 93.7500 (94.5800)
Test: [Whole Val]  Time: 9.645  Loss: 1.1089  Acc@1: 74.2300 Pruned: 51.12% 
Test (EMA): [   0/78]  Time: 0.379 (0.379)  Loss:  1.0801 (1.0801)  Acc@1: 71.8750 (71.8750)  Acc@5: 96.0938 (96.0938)
Test (EMA): [  78/78]  Time: 0.019 (0.122)  Loss:  0.8096 (1.0716)  Acc@1: 81.2500 (74.5200)  Acc@5: 93.7500 (94.8500)
Test (EMA): [Whole Val]  Time: 9.656  Loss: 1.0716  Acc@1: 74.5200 Pruned: 51.11% 
Train: 86 [   0/390 (  0%)]  Loss: 3.788 (3.79)  Time: 0.848s,  150.98/s  (0.848s,  150.98/s)  LR: 3.859e-04  Data: 0.531 (0.531)
Train: 86 [ 100/390 ( 26%)]  Loss: 3.780 (3.23)  Time: 0.310s,  412.66/s  (0.321s,  398.96/s)  LR: 3.859e-04  Data: 0.010 (0.016)
Train: 86 [ 200/390 ( 51%)]  Loss: 3.843 (3.27)  Time: 0.313s,  409.15/s  (0.318s,  401.99/s)  LR: 3.859e-04  Data: 0.011 (0.014)
Train: 86 [ 300/390 ( 77%)]  Loss: 2.275 (3.23)  Time: 0.310s,  412.49/s  (0.317s,  404.18/s)  LR: 3.859e-04  Data: 0.010 (0.013)
Train: 86 [ 389/390 (100%)]  Loss: 3.488 (3.24)  Time: 0.303s,  422.25/s  (0.316s,  405.20/s)  LR: 3.859e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.341 (0.341)  Loss:  1.0840 (1.0840)  Acc@1: 73.4375 (73.4375)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.018 (0.121)  Loss:  0.8364 (1.0680)  Acc@1: 75.0000 (74.6700)  Acc@5: 93.7500 (94.9400)
Test: [Whole Val]  Time: 9.522  Loss: 1.0680  Acc@1: 74.6700 Pruned: 51.11% 
Test (EMA): [   0/78]  Time: 0.336 (0.336)  Loss:  1.0684 (1.0684)  Acc@1: 74.2188 (74.2188)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.8823 (1.0727)  Acc@1: 75.0000 (74.8000)  Acc@5: 93.7500 (94.8000)
Test (EMA): [Whole Val]  Time: 9.496  Loss: 1.0727  Acc@1: 74.8000 Pruned: 51.12% 
Train: 87 [   0/390 (  0%)]  Loss: 3.342 (3.34)  Time: 0.802s,  159.55/s  (0.802s,  159.55/s)  LR: 3.757e-04  Data: 0.488 (0.488)
Train: 87 [ 100/390 ( 26%)]  Loss: 3.830 (3.29)  Time: 0.314s,  408.29/s  (0.318s,  402.16/s)  LR: 3.757e-04  Data: 0.012 (0.016)
Train: 87 [ 200/390 ( 51%)]  Loss: 3.418 (3.28)  Time: 0.320s,  399.52/s  (0.316s,  404.81/s)  LR: 3.757e-04  Data: 0.018 (0.014)
Train: 87 [ 300/390 ( 77%)]  Loss: 2.603 (3.29)  Time: 0.314s,  407.42/s  (0.315s,  406.03/s)  LR: 3.757e-04  Data: 0.013 (0.013)
Train: 87 [ 389/390 (100%)]  Loss: 3.856 (3.29)  Time: 0.301s,  424.79/s  (0.315s,  406.63/s)  LR: 3.757e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.414 (0.414)  Loss:  1.1113 (1.1113)  Acc@1: 75.0000 (75.0000)  Acc@5: 91.4062 (91.4062)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.8276 (1.0985)  Acc@1: 87.5000 (74.4600)  Acc@5: 93.7500 (94.4800)
Test: [Whole Val]  Time: 9.602  Loss: 1.0985  Acc@1: 74.4600 Pruned: 51.11% 
Test (EMA): [   0/78]  Time: 0.316 (0.316)  Loss:  1.0898 (1.0898)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.8403 (1.0781)  Acc@1: 81.2500 (74.9100)  Acc@5: 93.7500 (94.6400)
Test (EMA): [Whole Val]  Time: 9.467  Loss: 1.0781  Acc@1: 74.9100 Pruned: 51.11% 
Train: 88 [   0/390 (  0%)]  Loss: 3.009 (3.01)  Time: 0.900s,  142.22/s  (0.900s,  142.22/s)  LR: 3.656e-04  Data: 0.597 (0.597)
Train: 88 [ 100/390 ( 26%)]  Loss: 3.875 (3.27)  Time: 0.316s,  405.31/s  (0.321s,  398.48/s)  LR: 3.656e-04  Data: 0.010 (0.018)
Train: 88 [ 200/390 ( 51%)]  Loss: 3.257 (3.24)  Time: 0.312s,  410.63/s  (0.319s,  400.63/s)  LR: 3.656e-04  Data: 0.011 (0.015)
Train: 88 [ 300/390 ( 77%)]  Loss: 3.529 (3.23)  Time: 0.315s,  406.08/s  (0.317s,  403.40/s)  LR: 3.656e-04  Data: 0.011 (0.013)
Train: 88 [ 389/390 (100%)]  Loss: 3.499 (3.23)  Time: 0.300s,  426.29/s  (0.318s,  402.21/s)  LR: 3.656e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.410 (0.410)  Loss:  1.1104 (1.1104)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.8672 (1.0805)  Acc@1: 81.2500 (74.8100)  Acc@5: 93.7500 (95.0000)
Test: [Whole Val]  Time: 9.584  Loss: 1.0805  Acc@1: 74.8100 Pruned: 51.10% 
Test (EMA): [   0/78]  Time: 0.389 (0.389)  Loss:  1.0801 (1.0801)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.8135 (1.0558)  Acc@1: 81.2500 (74.6800)  Acc@5: 93.7500 (94.9100)
Test (EMA): [Whole Val]  Time: 9.527  Loss: 1.0558  Acc@1: 74.6800 Pruned: 51.10% 
Train: 89 [   0/390 (  0%)]  Loss: 2.706 (2.71)  Time: 0.816s,  156.95/s  (0.816s,  156.95/s)  LR: 3.555e-04  Data: 0.499 (0.499)
Train: 89 [ 100/390 ( 26%)]  Loss: 3.314 (3.22)  Time: 0.314s,  407.43/s  (0.317s,  403.27/s)  LR: 3.555e-04  Data: 0.011 (0.016)
Train: 89 [ 200/390 ( 51%)]  Loss: 2.798 (3.21)  Time: 0.323s,  396.48/s  (0.317s,  403.53/s)  LR: 3.555e-04  Data: 0.011 (0.014)
Train: 89 [ 300/390 ( 77%)]  Loss: 3.533 (3.26)  Time: 0.309s,  413.60/s  (0.316s,  405.62/s)  LR: 3.555e-04  Data: 0.010 (0.013)
Train: 89 [ 389/390 (100%)]  Loss: 3.725 (3.26)  Time: 0.305s,  419.84/s  (0.315s,  406.22/s)  LR: 3.555e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.422 (0.422)  Loss:  1.0674 (1.0674)  Acc@1: 73.4375 (73.4375)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.8096 (1.0785)  Acc@1: 81.2500 (74.3200)  Acc@5: 93.7500 (94.7300)
Test: [Whole Val]  Time: 9.623  Loss: 1.0785  Acc@1: 74.3200 Pruned: 51.10% 
Test (EMA): [   0/78]  Time: 0.410 (0.410)  Loss:  1.0752 (1.0752)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.8164 (1.0806)  Acc@1: 81.2500 (74.5500)  Acc@5: 93.7500 (94.8300)
Test (EMA): [Whole Val]  Time: 9.557  Loss: 1.0806  Acc@1: 74.5500 Pruned: 51.10% 
Train: 90 [   0/390 (  0%)]  Loss: 3.592 (3.59)  Time: 0.856s,  149.52/s  (0.856s,  149.52/s)  LR: 3.456e-04  Data: 0.549 (0.549)
Train: 90 [ 100/390 ( 26%)]  Loss: 3.602 (3.22)  Time: 0.314s,  407.82/s  (0.319s,  401.59/s)  LR: 3.456e-04  Data: 0.011 (0.017)
Train: 90 [ 200/390 ( 51%)]  Loss: 3.786 (3.27)  Time: 0.312s,  410.43/s  (0.317s,  404.09/s)  LR: 3.456e-04  Data: 0.011 (0.014)
Train: 90 [ 300/390 ( 77%)]  Loss: 2.525 (3.26)  Time: 0.312s,  410.35/s  (0.316s,  404.89/s)  LR: 3.456e-04  Data: 0.010 (0.013)
Train: 90 [ 389/390 (100%)]  Loss: 3.318 (3.24)  Time: 0.301s,  425.56/s  (0.316s,  405.09/s)  LR: 3.456e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.389 (0.389)  Loss:  1.1250 (1.1250)  Acc@1: 74.2188 (74.2188)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.9307 (1.1117)  Acc@1: 81.2500 (74.5000)  Acc@5: 93.7500 (94.5600)
Test: [Whole Val]  Time: 9.567  Loss: 1.1117  Acc@1: 74.5000 Pruned: 51.11% 
Test (EMA): [   0/78]  Time: 0.415 (0.415)  Loss:  1.0781 (1.0781)  Acc@1: 74.2188 (74.2188)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.018 (0.121)  Loss:  0.8755 (1.0665)  Acc@1: 81.2500 (74.8900)  Acc@5: 93.7500 (94.7600)
Test (EMA): [Whole Val]  Time: 9.598  Loss: 1.0665  Acc@1: 74.8900 Pruned: 51.11% 
Train: 91 [   0/390 (  0%)]  Loss: 3.637 (3.64)  Time: 0.855s,  149.66/s  (0.855s,  149.66/s)  LR: 3.356e-04  Data: 0.553 (0.553)
Train: 91 [ 100/390 ( 26%)]  Loss: 3.439 (3.28)  Time: 0.327s,  391.85/s  (0.319s,  401.63/s)  LR: 3.356e-04  Data: 0.011 (0.016)
Train: 91 [ 200/390 ( 51%)]  Loss: 3.518 (3.25)  Time: 0.313s,  408.48/s  (0.318s,  402.50/s)  LR: 3.356e-04  Data: 0.011 (0.014)
Train: 91 [ 300/390 ( 77%)]  Loss: 3.171 (3.26)  Time: 0.318s,  403.07/s  (0.316s,  404.49/s)  LR: 3.356e-04  Data: 0.010 (0.013)
Train: 91 [ 389/390 (100%)]  Loss: 3.593 (3.25)  Time: 0.302s,  423.79/s  (0.316s,  405.59/s)  LR: 3.356e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.427 (0.427)  Loss:  1.1191 (1.1191)  Acc@1: 71.8750 (71.8750)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.9253 (1.1102)  Acc@1: 81.2500 (74.7900)  Acc@5: 93.7500 (94.9100)
Test: [Whole Val]  Time: 9.631  Loss: 1.1102  Acc@1: 74.7900 Pruned: 51.12% 
Test (EMA): [   0/78]  Time: 0.311 (0.311)  Loss:  1.1064 (1.1064)  Acc@1: 72.6562 (72.6562)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.8979 (1.0933)  Acc@1: 81.2500 (74.8900)  Acc@5: 93.7500 (94.9100)
Test (EMA): [Whole Val]  Time: 9.520  Loss: 1.0933  Acc@1: 74.8900 Pruned: 51.13% 
Train: 92 [   0/390 (  0%)]  Loss: 2.951 (2.95)  Time: 0.738s,  173.52/s  (0.738s,  173.52/s)  LR: 3.258e-04  Data: 0.425 (0.425)
Train: 92 [ 100/390 ( 26%)]  Loss: 3.608 (3.27)  Time: 0.311s,  411.27/s  (0.319s,  401.62/s)  LR: 3.258e-04  Data: 0.011 (0.015)
Train: 92 [ 200/390 ( 51%)]  Loss: 3.629 (3.28)  Time: 0.310s,  412.72/s  (0.316s,  404.63/s)  LR: 3.258e-04  Data: 0.010 (0.013)
Train: 92 [ 300/390 ( 77%)]  Loss: 3.594 (3.25)  Time: 0.314s,  408.11/s  (0.315s,  406.21/s)  LR: 3.258e-04  Data: 0.013 (0.012)
Train: 92 [ 389/390 (100%)]  Loss: 2.991 (3.26)  Time: 0.309s,  414.80/s  (0.315s,  406.53/s)  LR: 3.258e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.350 (0.350)  Loss:  1.1475 (1.1475)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.120)  Loss:  1.0146 (1.1186)  Acc@1: 81.2500 (74.9600)  Acc@5: 87.5000 (94.7300)
Test: [Whole Val]  Time: 9.486  Loss: 1.1186  Acc@1: 74.9600 Pruned: 51.11% 
Test (EMA): [   0/78]  Time: 0.345 (0.345)  Loss:  1.1318 (1.1318)  Acc@1: 75.7812 (75.7812)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.9771 (1.1103)  Acc@1: 81.2500 (75.1000)  Acc@5: 87.5000 (94.8600)
Test (EMA): [Whole Val]  Time: 9.484  Loss: 1.1103  Acc@1: 75.1000 Pruned: 51.10% 
Train: 93 [   0/390 (  0%)]  Loss: 3.514 (3.51)  Time: 0.754s,  169.80/s  (0.754s,  169.80/s)  LR: 3.160e-04  Data: 0.452 (0.452)
Train: 93 [ 100/390 ( 26%)]  Loss: 2.800 (3.21)  Time: 0.313s,  409.54/s  (0.324s,  395.34/s)  LR: 3.160e-04  Data: 0.011 (0.016)
Train: 93 [ 200/390 ( 51%)]  Loss: 3.341 (3.22)  Time: 0.313s,  409.32/s  (0.319s,  401.51/s)  LR: 3.160e-04  Data: 0.013 (0.014)
Train: 93 [ 300/390 ( 77%)]  Loss: 2.944 (3.22)  Time: 0.314s,  408.02/s  (0.317s,  403.78/s)  LR: 3.160e-04  Data: 0.011 (0.013)
Train: 93 [ 389/390 (100%)]  Loss: 3.473 (3.22)  Time: 0.301s,  425.49/s  (0.317s,  403.41/s)  LR: 3.160e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.300 (0.300)  Loss:  1.0469 (1.0469)  Acc@1: 75.0000 (75.0000)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.018 (0.120)  Loss:  0.8955 (1.0676)  Acc@1: 81.2500 (74.5900)  Acc@5: 93.7500 (94.6900)
Test: [Whole Val]  Time: 9.455  Loss: 1.0676  Acc@1: 74.5900 Pruned: 51.10% 
Test (EMA): [   0/78]  Time: 0.403 (0.403)  Loss:  1.0381 (1.0381)  Acc@1: 75.0000 (75.0000)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.018 (0.121)  Loss:  0.8828 (1.0521)  Acc@1: 81.2500 (74.9200)  Acc@5: 93.7500 (94.6900)
Test (EMA): [Whole Val]  Time: 9.534  Loss: 1.0521  Acc@1: 74.9200 Pruned: 51.10% 
Train: 94 [   0/390 (  0%)]  Loss: 3.441 (3.44)  Time: 0.869s,  147.25/s  (0.869s,  147.25/s)  LR: 3.063e-04  Data: 0.554 (0.554)
Train: 94 [ 100/390 ( 26%)]  Loss: 3.523 (3.27)  Time: 0.314s,  407.04/s  (0.319s,  401.56/s)  LR: 3.063e-04  Data: 0.011 (0.016)
Train: 94 [ 200/390 ( 51%)]  Loss: 2.878 (3.24)  Time: 0.310s,  412.35/s  (0.316s,  404.58/s)  LR: 3.063e-04  Data: 0.010 (0.014)
Train: 94 [ 300/390 ( 77%)]  Loss: 2.715 (3.24)  Time: 0.310s,  413.05/s  (0.315s,  406.09/s)  LR: 3.063e-04  Data: 0.010 (0.013)
Train: 94 [ 389/390 (100%)]  Loss: 2.357 (3.25)  Time: 0.314s,  407.69/s  (0.315s,  405.72/s)  LR: 3.063e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.429 (0.429)  Loss:  1.0537 (1.0537)  Acc@1: 75.7812 (75.7812)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.8638 (1.0632)  Acc@1: 75.0000 (74.7700)  Acc@5: 93.7500 (95.0400)
Test: [Whole Val]  Time: 9.589  Loss: 1.0632  Acc@1: 74.7700 Pruned: 51.10% 
Test (EMA): [   0/78]  Time: 0.396 (0.396)  Loss:  1.0654 (1.0654)  Acc@1: 75.0000 (75.0000)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.021 (0.121)  Loss:  0.9019 (1.0677)  Acc@1: 75.0000 (74.9900)  Acc@5: 93.7500 (94.9800)
Test (EMA): [Whole Val]  Time: 9.538  Loss: 1.0677  Acc@1: 74.9900 Pruned: 51.10% 
Train: 95 [   0/390 (  0%)]  Loss: 3.678 (3.68)  Time: 0.803s,  159.37/s  (0.803s,  159.37/s)  LR: 2.967e-04  Data: 0.491 (0.491)
Train: 95 [ 100/390 ( 26%)]  Loss: 3.471 (3.22)  Time: 0.330s,  387.98/s  (0.318s,  402.68/s)  LR: 2.967e-04  Data: 0.013 (0.016)
Train: 95 [ 200/390 ( 51%)]  Loss: 3.797 (3.22)  Time: 0.312s,  410.68/s  (0.316s,  405.30/s)  LR: 2.967e-04  Data: 0.010 (0.013)
Train: 95 [ 300/390 ( 77%)]  Loss: 2.878 (3.24)  Time: 0.311s,  410.95/s  (0.315s,  406.43/s)  LR: 2.967e-04  Data: 0.011 (0.013)
Train: 95 [ 389/390 (100%)]  Loss: 3.321 (3.24)  Time: 0.300s,  426.55/s  (0.315s,  406.27/s)  LR: 2.967e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.435 (0.435)  Loss:  1.1006 (1.1006)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.9009 (1.0969)  Acc@1: 81.2500 (74.8000)  Acc@5: 93.7500 (94.8000)
Test: [Whole Val]  Time: 9.591  Loss: 1.0969  Acc@1: 74.8000 Pruned: 51.11% 
Test (EMA): [   0/78]  Time: 0.430 (0.430)  Loss:  1.0889 (1.0889)  Acc@1: 74.2188 (74.2188)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.018 (0.121)  Loss:  0.8901 (1.0818)  Acc@1: 81.2500 (75.0700)  Acc@5: 93.7500 (94.9700)
Test (EMA): [Whole Val]  Time: 9.585  Loss: 1.0818  Acc@1: 75.0700 Pruned: 51.11% 
Train: 96 [   0/390 (  0%)]  Loss: 2.730 (2.73)  Time: 0.790s,  162.02/s  (0.790s,  162.02/s)  LR: 2.872e-04  Data: 0.455 (0.455)
Train: 96 [ 100/390 ( 26%)]  Loss: 3.900 (3.27)  Time: 0.311s,  412.09/s  (0.318s,  402.33/s)  LR: 2.872e-04  Data: 0.011 (0.015)
Train: 96 [ 200/390 ( 51%)]  Loss: 3.593 (3.25)  Time: 0.312s,  410.03/s  (0.316s,  404.90/s)  LR: 2.872e-04  Data: 0.010 (0.013)
Train: 96 [ 300/390 ( 77%)]  Loss: 3.648 (3.26)  Time: 0.324s,  394.66/s  (0.315s,  405.94/s)  LR: 2.872e-04  Data: 0.012 (0.013)
Train: 96 [ 389/390 (100%)]  Loss: 2.219 (3.24)  Time: 0.301s,  425.81/s  (0.315s,  406.44/s)  LR: 2.872e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.408 (0.408)  Loss:  1.0420 (1.0420)  Acc@1: 75.7812 (75.7812)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.021 (0.121)  Loss:  0.8076 (1.0588)  Acc@1: 87.5000 (74.6700)  Acc@5: 93.7500 (94.7800)
Test: [Whole Val]  Time: 9.568  Loss: 1.0588  Acc@1: 74.6700 Pruned: 51.11% 
Test (EMA): [   0/78]  Time: 0.328 (0.328)  Loss:  1.0322 (1.0322)  Acc@1: 75.0000 (75.0000)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.018 (0.120)  Loss:  0.8145 (1.0452)  Acc@1: 75.0000 (75.1000)  Acc@5: 93.7500 (94.8500)
Test (EMA): [Whole Val]  Time: 9.473  Loss: 1.0452  Acc@1: 75.1000 Pruned: 51.12% 
Train: 97 [   0/390 (  0%)]  Loss: 3.097 (3.10)  Time: 0.787s,  162.66/s  (0.787s,  162.66/s)  LR: 2.778e-04  Data: 0.481 (0.481)
Train: 97 [ 100/390 ( 26%)]  Loss: 3.543 (3.21)  Time: 0.311s,  411.22/s  (0.318s,  402.89/s)  LR: 2.778e-04  Data: 0.010 (0.015)
Train: 97 [ 200/390 ( 51%)]  Loss: 3.722 (3.21)  Time: 0.314s,  408.05/s  (0.316s,  405.13/s)  LR: 2.778e-04  Data: 0.010 (0.013)
Train: 97 [ 300/390 ( 77%)]  Loss: 2.920 (3.18)  Time: 0.313s,  409.00/s  (0.317s,  404.13/s)  LR: 2.778e-04  Data: 0.011 (0.013)
Train: 97 [ 389/390 (100%)]  Loss: 3.279 (3.19)  Time: 0.301s,  425.92/s  (0.317s,  403.50/s)  LR: 2.778e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.422 (0.422)  Loss:  1.0850 (1.0850)  Acc@1: 73.4375 (73.4375)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.8013 (1.0596)  Acc@1: 81.2500 (74.5300)  Acc@5: 93.7500 (94.5800)
Test: [Whole Val]  Time: 9.650  Loss: 1.0596  Acc@1: 74.5300 Pruned: 51.11% 
Test (EMA): [   0/78]  Time: 0.369 (0.369)  Loss:  1.0771 (1.0771)  Acc@1: 74.2188 (74.2188)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.8071 (1.0541)  Acc@1: 81.2500 (74.7000)  Acc@5: 93.7500 (94.7900)
Test (EMA): [Whole Val]  Time: 9.528  Loss: 1.0541  Acc@1: 74.7000 Pruned: 51.11% 
Train: 98 [   0/390 (  0%)]  Loss: 3.488 (3.49)  Time: 0.818s,  156.53/s  (0.818s,  156.53/s)  LR: 2.684e-04  Data: 0.505 (0.505)
Train: 98 [ 100/390 ( 26%)]  Loss: 3.781 (3.25)  Time: 0.312s,  410.28/s  (0.319s,  401.22/s)  LR: 2.684e-04  Data: 0.011 (0.016)
Train: 98 [ 200/390 ( 51%)]  Loss: 2.343 (3.20)  Time: 0.313s,  409.56/s  (0.317s,  403.30/s)  LR: 2.684e-04  Data: 0.011 (0.014)
Train: 98 [ 300/390 ( 77%)]  Loss: 2.438 (3.22)  Time: 0.317s,  404.07/s  (0.316s,  405.29/s)  LR: 2.684e-04  Data: 0.011 (0.013)
Train: 98 [ 389/390 (100%)]  Loss: 2.542 (3.24)  Time: 0.315s,  405.83/s  (0.316s,  405.54/s)  LR: 2.684e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.340 (0.340)  Loss:  1.0625 (1.0625)  Acc@1: 77.3438 (77.3438)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  0.7954 (1.0768)  Acc@1: 81.2500 (74.9900)  Acc@5: 93.7500 (94.9800)
Test: [Whole Val]  Time: 9.492  Loss: 1.0768  Acc@1: 74.9900 Pruned: 51.11% 
Test (EMA): [   0/78]  Time: 0.400 (0.400)  Loss:  1.0586 (1.0586)  Acc@1: 76.5625 (76.5625)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.8301 (1.0635)  Acc@1: 81.2500 (75.3800)  Acc@5: 93.7500 (95.0900)
Test (EMA): [Whole Val]  Time: 9.544  Loss: 1.0635  Acc@1: 75.3800 Pruned: 51.11% 
Train: 99 [   0/390 (  0%)]  Loss: 3.808 (3.81)  Time: 0.841s,  152.23/s  (0.841s,  152.23/s)  LR: 2.592e-04  Data: 0.534 (0.534)
Train: 99 [ 100/390 ( 26%)]  Loss: 2.435 (3.22)  Time: 0.311s,  411.82/s  (0.319s,  401.32/s)  LR: 2.592e-04  Data: 0.011 (0.016)
Train: 99 [ 200/390 ( 51%)]  Loss: 2.864 (3.20)  Time: 0.312s,  410.56/s  (0.316s,  405.45/s)  LR: 2.592e-04  Data: 0.010 (0.014)
Train: 99 [ 300/390 ( 77%)]  Loss: 2.740 (3.20)  Time: 0.313s,  408.80/s  (0.315s,  406.05/s)  LR: 2.592e-04  Data: 0.011 (0.013)
Train: 99 [ 389/390 (100%)]  Loss: 3.125 (3.20)  Time: 0.302s,  424.09/s  (0.316s,  405.46/s)  LR: 2.592e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.376 (0.376)  Loss:  1.0645 (1.0645)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.021 (0.121)  Loss:  0.7803 (1.0457)  Acc@1: 81.2500 (74.7300)  Acc@5: 93.7500 (94.9200)
Test: [Whole Val]  Time: 9.557  Loss: 1.0457  Acc@1: 74.7300 Pruned: 51.10% 
Test (EMA): [   0/78]  Time: 0.326 (0.326)  Loss:  1.0615 (1.0615)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.120)  Loss:  0.8003 (1.0460)  Acc@1: 81.2500 (75.1300)  Acc@5: 93.7500 (95.0300)
Test (EMA): [Whole Val]  Time: 9.483  Loss: 1.0460  Acc@1: 75.1300 Pruned: 51.10% 
Train: 100 [   0/390 (  0%)]  Loss: 3.478 (3.48)  Time: 0.908s,  140.95/s  (0.908s,  140.95/s)  LR: 2.501e-04  Data: 0.605 (0.605)
Train: 100 [ 100/390 ( 26%)]  Loss: 3.781 (3.19)  Time: 0.313s,  409.00/s  (0.319s,  400.75/s)  LR: 2.501e-04  Data: 0.012 (0.017)
Train: 100 [ 200/390 ( 51%)]  Loss: 3.421 (3.25)  Time: 0.315s,  406.00/s  (0.316s,  404.58/s)  LR: 2.501e-04  Data: 0.010 (0.014)
Train: 100 [ 300/390 ( 77%)]  Loss: 3.559 (3.24)  Time: 0.312s,  410.38/s  (0.316s,  405.65/s)  LR: 2.501e-04  Data: 0.012 (0.013)
Train: 100 [ 389/390 (100%)]  Loss: 3.097 (3.23)  Time: 0.405s,  316.06/s  (0.315s,  406.13/s)  LR: 2.501e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.394 (0.394)  Loss:  1.1055 (1.1055)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.021 (0.121)  Loss:  0.8677 (1.0834)  Acc@1: 81.2500 (75.0300)  Acc@5: 93.7500 (95.0400)
Test: [Whole Val]  Time: 9.560  Loss: 1.0834  Acc@1: 75.0300 Pruned: 51.09% 
Test (EMA): [   0/78]  Time: 0.374 (0.374)  Loss:  1.1016 (1.1016)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.121)  Loss:  0.8613 (1.0715)  Acc@1: 81.2500 (75.2200)  Acc@5: 93.7500 (95.1600)
Test (EMA): [Whole Val]  Time: 9.560  Loss: 1.0715  Acc@1: 75.2200 Pruned: 51.09% 
Train: 101 [   0/390 (  0%)]  Loss: 3.252 (3.25)  Time: 0.880s,  145.43/s  (0.880s,  145.43/s)  LR: 2.411e-04  Data: 0.577 (0.577)
Train: 101 [ 100/390 ( 26%)]  Loss: 3.525 (3.11)  Time: 0.313s,  408.90/s  (0.320s,  399.71/s)  LR: 2.411e-04  Data: 0.010 (0.017)
Train: 101 [ 200/390 ( 51%)]  Loss: 3.665 (3.16)  Time: 0.316s,  405.07/s  (0.318s,  403.10/s)  LR: 2.411e-04  Data: 0.014 (0.014)
Train: 101 [ 300/390 ( 77%)]  Loss: 2.723 (3.18)  Time: 0.315s,  406.67/s  (0.316s,  405.06/s)  LR: 2.411e-04  Data: 0.012 (0.013)
Train: 101 [ 389/390 (100%)]  Loss: 3.304 (3.20)  Time: 0.302s,  423.90/s  (0.315s,  406.11/s)  LR: 2.411e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.332 (0.332)  Loss:  1.0742 (1.0742)  Acc@1: 74.2188 (74.2188)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  0.8774 (1.0843)  Acc@1: 81.2500 (74.9100)  Acc@5: 93.7500 (94.8400)
Test: [Whole Val]  Time: 9.511  Loss: 1.0843  Acc@1: 74.9100 Pruned: 51.10% 
Test (EMA): [   0/78]  Time: 0.318 (0.318)  Loss:  1.0625 (1.0625)  Acc@1: 73.4375 (73.4375)  Acc@5: 96.0938 (96.0938)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.8823 (1.0760)  Acc@1: 81.2500 (74.9600)  Acc@5: 93.7500 (95.0400)
Test (EMA): [Whole Val]  Time: 9.502  Loss: 1.0760  Acc@1: 74.9600 Pruned: 51.10% 
Train: 102 [   0/390 (  0%)]  Loss: 3.528 (3.53)  Time: 0.822s,  155.80/s  (0.822s,  155.80/s)  LR: 2.322e-04  Data: 0.508 (0.508)
Train: 102 [ 100/390 ( 26%)]  Loss: 3.058 (3.24)  Time: 0.310s,  412.39/s  (0.317s,  403.50/s)  LR: 2.322e-04  Data: 0.010 (0.016)
Train: 102 [ 200/390 ( 51%)]  Loss: 3.488 (3.22)  Time: 0.325s,  394.17/s  (0.316s,  404.50/s)  LR: 2.322e-04  Data: 0.010 (0.013)
Train: 102 [ 300/390 ( 77%)]  Loss: 2.793 (3.21)  Time: 0.319s,  401.48/s  (0.315s,  406.01/s)  LR: 2.322e-04  Data: 0.012 (0.013)
Train: 102 [ 389/390 (100%)]  Loss: 3.332 (3.21)  Time: 0.301s,  424.74/s  (0.316s,  405.03/s)  LR: 2.322e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.332 (0.332)  Loss:  1.0469 (1.0469)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.021 (0.122)  Loss:  0.7749 (1.0300)  Acc@1: 81.2500 (75.3500)  Acc@5: 93.7500 (94.9700)
Test: [Whole Val]  Time: 9.605  Loss: 1.0300  Acc@1: 75.3500 Pruned: 51.10% 
Test (EMA): [   0/78]  Time: 0.335 (0.335)  Loss:  1.0459 (1.0459)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.7964 (1.0314)  Acc@1: 81.2500 (75.3200)  Acc@5: 93.7500 (95.0600)
Test (EMA): [Whole Val]  Time: 9.562  Loss: 1.0314  Acc@1: 75.3200 Pruned: 51.10% 
Train: 103 [   0/390 (  0%)]  Loss: 3.879 (3.88)  Time: 0.871s,  146.97/s  (0.871s,  146.97/s)  LR: 2.234e-04  Data: 0.557 (0.557)
Train: 103 [ 100/390 ( 26%)]  Loss: 2.849 (3.22)  Time: 0.312s,  409.65/s  (0.321s,  398.49/s)  LR: 2.234e-04  Data: 0.010 (0.017)
Train: 103 [ 200/390 ( 51%)]  Loss: 3.565 (3.21)  Time: 0.312s,  410.14/s  (0.318s,  402.11/s)  LR: 2.234e-04  Data: 0.011 (0.015)
Train: 103 [ 300/390 ( 77%)]  Loss: 3.752 (3.20)  Time: 0.316s,  404.65/s  (0.318s,  403.04/s)  LR: 2.234e-04  Data: 0.012 (0.014)
Train: 103 [ 389/390 (100%)]  Loss: 2.558 (3.21)  Time: 0.304s,  420.99/s  (0.317s,  404.13/s)  LR: 2.234e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.418 (0.418)  Loss:  1.0645 (1.0645)  Acc@1: 71.8750 (71.8750)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.8804 (1.0660)  Acc@1: 75.0000 (75.1100)  Acc@5: 93.7500 (95.0100)
Test: [Whole Val]  Time: 9.625  Loss: 1.0660  Acc@1: 75.1100 Pruned: 51.09% 
Test (EMA): [   0/78]  Time: 0.448 (0.448)  Loss:  1.0586 (1.0586)  Acc@1: 71.0938 (71.0938)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.018 (0.123)  Loss:  0.8813 (1.0632)  Acc@1: 81.2500 (75.0800)  Acc@5: 93.7500 (94.9400)
Test (EMA): [Whole Val]  Time: 9.753  Loss: 1.0632  Acc@1: 75.0800 Pruned: 51.09% 
Train: 104 [   0/390 (  0%)]  Loss: 3.601 (3.60)  Time: 0.901s,  141.99/s  (0.901s,  141.99/s)  LR: 2.147e-04  Data: 0.597 (0.597)
Train: 104 [ 100/390 ( 26%)]  Loss: 3.593 (3.28)  Time: 0.315s,  406.72/s  (0.325s,  394.05/s)  LR: 2.147e-04  Data: 0.013 (0.020)
Train: 104 [ 200/390 ( 51%)]  Loss: 2.589 (3.23)  Time: 0.333s,  384.78/s  (0.322s,  397.92/s)  LR: 2.147e-04  Data: 0.018 (0.017)
Train: 104 [ 300/390 ( 77%)]  Loss: 2.679 (3.22)  Time: 0.314s,  407.02/s  (0.321s,  399.17/s)  LR: 2.147e-04  Data: 0.012 (0.016)
Train: 104 [ 389/390 (100%)]  Loss: 3.685 (3.22)  Time: 0.302s,  423.79/s  (0.320s,  400.24/s)  LR: 2.147e-04  Data: 0.000 (0.016)
Test: [   0/78]  Time: 0.353 (0.353)  Loss:  1.0742 (1.0742)  Acc@1: 75.7812 (75.7812)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.9214 (1.0683)  Acc@1: 81.2500 (75.1100)  Acc@5: 93.7500 (95.1100)
Test: [Whole Val]  Time: 9.586  Loss: 1.0683  Acc@1: 75.1100 Pruned: 51.08% 
Test (EMA): [   0/78]  Time: 0.368 (0.368)  Loss:  1.0771 (1.0771)  Acc@1: 74.2188 (74.2188)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.8975 (1.0703)  Acc@1: 81.2500 (75.2400)  Acc@5: 93.7500 (95.0500)
Test (EMA): [Whole Val]  Time: 9.630  Loss: 1.0703  Acc@1: 75.2400 Pruned: 51.08% 
Train: 105 [   0/390 (  0%)]  Loss: 3.399 (3.40)  Time: 0.822s,  155.74/s  (0.822s,  155.74/s)  LR: 2.062e-04  Data: 0.517 (0.517)
Train: 105 [ 100/390 ( 26%)]  Loss: 3.701 (3.32)  Time: 0.315s,  406.26/s  (0.322s,  397.56/s)  LR: 2.062e-04  Data: 0.014 (0.018)
Train: 105 [ 200/390 ( 51%)]  Loss: 3.584 (3.25)  Time: 0.321s,  398.36/s  (0.320s,  400.38/s)  LR: 2.062e-04  Data: 0.017 (0.016)
Train: 105 [ 300/390 ( 77%)]  Loss: 3.283 (3.25)  Time: 0.315s,  406.43/s  (0.319s,  401.38/s)  LR: 2.062e-04  Data: 0.013 (0.015)
Train: 105 [ 389/390 (100%)]  Loss: 2.479 (3.25)  Time: 0.311s,  411.57/s  (0.319s,  401.77/s)  LR: 2.062e-04  Data: 0.000 (0.015)
Test: [   0/78]  Time: 0.320 (0.320)  Loss:  1.0684 (1.0684)  Acc@1: 73.4375 (73.4375)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  0.8857 (1.0469)  Acc@1: 81.2500 (75.3900)  Acc@5: 93.7500 (95.1300)
Test: [Whole Val]  Time: 9.515  Loss: 1.0469  Acc@1: 75.3900 Pruned: 51.08% 
Test (EMA): [   0/78]  Time: 0.341 (0.341)  Loss:  1.0859 (1.0859)  Acc@1: 73.4375 (73.4375)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.021 (0.121)  Loss:  0.8838 (1.0704)  Acc@1: 81.2500 (75.3400)  Acc@5: 93.7500 (95.1500)
Test (EMA): [Whole Val]  Time: 9.560  Loss: 1.0704  Acc@1: 75.3400 Pruned: 51.09% 
Train: 106 [   0/390 (  0%)]  Loss: 3.295 (3.30)  Time: 0.821s,  155.98/s  (0.821s,  155.98/s)  LR: 1.978e-04  Data: 0.514 (0.514)
Train: 106 [ 100/390 ( 26%)]  Loss: 2.399 (3.20)  Time: 0.314s,  407.86/s  (0.323s,  396.80/s)  LR: 1.978e-04  Data: 0.010 (0.018)
Train: 106 [ 200/390 ( 51%)]  Loss: 2.931 (3.23)  Time: 0.317s,  403.25/s  (0.319s,  401.29/s)  LR: 1.978e-04  Data: 0.015 (0.015)
Train: 106 [ 300/390 ( 77%)]  Loss: 3.622 (3.20)  Time: 0.314s,  407.00/s  (0.318s,  403.04/s)  LR: 1.978e-04  Data: 0.010 (0.014)
Train: 106 [ 389/390 (100%)]  Loss: 2.727 (3.20)  Time: 0.303s,  422.30/s  (0.317s,  403.96/s)  LR: 1.978e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.337 (0.337)  Loss:  1.0361 (1.0361)  Acc@1: 75.7812 (75.7812)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.8560 (1.0222)  Acc@1: 81.2500 (75.6600)  Acc@5: 93.7500 (95.0900)
Test: [Whole Val]  Time: 9.594  Loss: 1.0222  Acc@1: 75.6600 Pruned: 51.08% 
Test (EMA): [   0/78]  Time: 0.409 (0.409)  Loss:  1.0264 (1.0264)  Acc@1: 75.7812 (75.7812)  Acc@5: 92.1875 (92.1875)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.8281 (1.0206)  Acc@1: 81.2500 (75.6600)  Acc@5: 93.7500 (95.1400)
Test (EMA): [Whole Val]  Time: 9.609  Loss: 1.0206  Acc@1: 75.6600 Pruned: 51.08% 
Train: 107 [   0/390 (  0%)]  Loss: 3.678 (3.68)  Time: 0.786s,  162.86/s  (0.786s,  162.86/s)  LR: 1.895e-04  Data: 0.476 (0.476)
Train: 107 [ 100/390 ( 26%)]  Loss: 3.201 (3.24)  Time: 0.314s,  408.18/s  (0.320s,  400.18/s)  LR: 1.895e-04  Data: 0.011 (0.016)
Train: 107 [ 200/390 ( 51%)]  Loss: 2.880 (3.24)  Time: 0.312s,  410.07/s  (0.317s,  403.44/s)  LR: 1.895e-04  Data: 0.011 (0.014)
Train: 107 [ 300/390 ( 77%)]  Loss: 3.656 (3.26)  Time: 0.311s,  411.84/s  (0.316s,  405.17/s)  LR: 1.895e-04  Data: 0.011 (0.013)
Train: 107 [ 389/390 (100%)]  Loss: 3.079 (3.24)  Time: 0.300s,  426.38/s  (0.315s,  406.00/s)  LR: 1.895e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.408 (0.408)  Loss:  1.0576 (1.0576)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.1875 (92.1875)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.7979 (1.0356)  Acc@1: 81.2500 (75.2500)  Acc@5: 93.7500 (95.0100)
Test: [Whole Val]  Time: 9.594  Loss: 1.0356  Acc@1: 75.2500 Pruned: 51.09% 
Test (EMA): [   0/78]  Time: 0.327 (0.327)  Loss:  1.0635 (1.0635)  Acc@1: 74.2188 (74.2188)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.119)  Loss:  0.7964 (1.0390)  Acc@1: 81.2500 (75.2900)  Acc@5: 93.7500 (95.1800)
Test (EMA): [Whole Val]  Time: 9.436  Loss: 1.0390  Acc@1: 75.2900 Pruned: 51.10% 
Train: 108 [   0/390 (  0%)]  Loss: 3.967 (3.97)  Time: 0.716s,  178.72/s  (0.716s,  178.72/s)  LR: 1.814e-04  Data: 0.408 (0.408)
Train: 108 [ 100/390 ( 26%)]  Loss: 2.468 (3.17)  Time: 0.315s,  405.80/s  (0.318s,  403.00/s)  LR: 1.814e-04  Data: 0.011 (0.015)
Train: 108 [ 200/390 ( 51%)]  Loss: 3.661 (3.21)  Time: 0.310s,  412.46/s  (0.316s,  404.98/s)  LR: 1.814e-04  Data: 0.010 (0.013)
Train: 108 [ 300/390 ( 77%)]  Loss: 3.598 (3.23)  Time: 0.312s,  409.99/s  (0.315s,  405.85/s)  LR: 1.814e-04  Data: 0.011 (0.013)
Train: 108 [ 389/390 (100%)]  Loss: 3.333 (3.21)  Time: 0.302s,  423.75/s  (0.316s,  405.45/s)  LR: 1.814e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.311 (0.311)  Loss:  1.0645 (1.0645)  Acc@1: 74.2188 (74.2188)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  0.8188 (1.0467)  Acc@1: 81.2500 (75.0500)  Acc@5: 93.7500 (95.0400)
Test: [Whole Val]  Time: 9.481  Loss: 1.0467  Acc@1: 75.0500 Pruned: 51.09% 
Test (EMA): [   0/78]  Time: 0.421 (0.421)  Loss:  1.0557 (1.0557)  Acc@1: 75.0000 (75.0000)  Acc@5: 96.0938 (96.0938)
Test (EMA): [  78/78]  Time: 0.017 (0.122)  Loss:  0.7886 (1.0350)  Acc@1: 81.2500 (75.2700)  Acc@5: 93.7500 (95.1500)
Test (EMA): [Whole Val]  Time: 9.611  Loss: 1.0350  Acc@1: 75.2700 Pruned: 51.09% 
Train: 109 [   0/390 (  0%)]  Loss: 3.384 (3.38)  Time: 0.919s,  139.35/s  (0.919s,  139.35/s)  LR: 1.734e-04  Data: 0.607 (0.607)
Train: 109 [ 100/390 ( 26%)]  Loss: 2.451 (3.18)  Time: 0.318s,  402.70/s  (0.322s,  397.34/s)  LR: 1.734e-04  Data: 0.012 (0.018)
Train: 109 [ 200/390 ( 51%)]  Loss: 3.655 (3.22)  Time: 0.310s,  412.74/s  (0.318s,  402.77/s)  LR: 1.734e-04  Data: 0.010 (0.015)
Train: 109 [ 300/390 ( 77%)]  Loss: 2.546 (3.23)  Time: 0.311s,  411.36/s  (0.317s,  403.81/s)  LR: 1.734e-04  Data: 0.010 (0.014)
Train: 109 [ 389/390 (100%)]  Loss: 3.758 (3.23)  Time: 0.302s,  424.10/s  (0.316s,  405.16/s)  LR: 1.734e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.426 (0.426)  Loss:  1.0410 (1.0410)  Acc@1: 75.0000 (75.0000)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.8403 (1.0293)  Acc@1: 81.2500 (75.4600)  Acc@5: 93.7500 (95.1400)
Test: [Whole Val]  Time: 9.586  Loss: 1.0293  Acc@1: 75.4600 Pruned: 51.08% 
Test (EMA): [   0/78]  Time: 0.343 (0.343)  Loss:  1.0547 (1.0547)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.8540 (1.0410)  Acc@1: 81.2500 (75.4700)  Acc@5: 93.7500 (95.2300)
Test (EMA): [Whole Val]  Time: 9.448  Loss: 1.0410  Acc@1: 75.4700 Pruned: 51.09% 
Train: 110 [   0/390 (  0%)]  Loss: 3.631 (3.63)  Time: 0.884s,  144.77/s  (0.884s,  144.77/s)  LR: 1.655e-04  Data: 0.582 (0.582)
Train: 110 [ 100/390 ( 26%)]  Loss: 3.615 (3.20)  Time: 0.312s,  410.85/s  (0.322s,  397.50/s)  LR: 1.655e-04  Data: 0.010 (0.017)
Train: 110 [ 200/390 ( 51%)]  Loss: 3.510 (3.22)  Time: 0.311s,  411.94/s  (0.319s,  401.50/s)  LR: 1.655e-04  Data: 0.009 (0.014)
Train: 110 [ 300/390 ( 77%)]  Loss: 3.395 (3.23)  Time: 0.310s,  412.29/s  (0.317s,  403.57/s)  LR: 1.655e-04  Data: 0.010 (0.013)
Train: 110 [ 389/390 (100%)]  Loss: 3.513 (3.21)  Time: 0.301s,  425.87/s  (0.316s,  404.61/s)  LR: 1.655e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.402 (0.402)  Loss:  1.0361 (1.0361)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.7798 (1.0039)  Acc@1: 81.2500 (75.5900)  Acc@5: 93.7500 (95.2300)
Test: [Whole Val]  Time: 9.543  Loss: 1.0039  Acc@1: 75.5900 Pruned: 51.09% 
Test (EMA): [   0/78]  Time: 0.363 (0.363)  Loss:  1.0361 (1.0361)  Acc@1: 72.6562 (72.6562)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.021 (0.120)  Loss:  0.7905 (1.0045)  Acc@1: 81.2500 (75.5600)  Acc@5: 93.7500 (95.2000)
Test (EMA): [Whole Val]  Time: 9.496  Loss: 1.0045  Acc@1: 75.5600 Pruned: 51.09% 
Train: 111 [   0/390 (  0%)]  Loss: 3.611 (3.61)  Time: 0.865s,  148.03/s  (0.865s,  148.03/s)  LR: 1.578e-04  Data: 0.551 (0.551)
Train: 111 [ 100/390 ( 26%)]  Loss: 3.712 (3.21)  Time: 0.311s,  411.73/s  (0.319s,  400.67/s)  LR: 1.578e-04  Data: 0.010 (0.016)
Train: 111 [ 200/390 ( 51%)]  Loss: 3.500 (3.22)  Time: 0.312s,  410.70/s  (0.316s,  404.76/s)  LR: 1.578e-04  Data: 0.011 (0.014)
Train: 111 [ 300/390 ( 77%)]  Loss: 2.537 (3.21)  Time: 0.325s,  393.82/s  (0.316s,  405.11/s)  LR: 1.578e-04  Data: 0.012 (0.013)
Train: 111 [ 389/390 (100%)]  Loss: 3.514 (3.22)  Time: 0.302s,  424.32/s  (0.316s,  405.56/s)  LR: 1.578e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.415 (0.415)  Loss:  1.0518 (1.0518)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.020 (0.121)  Loss:  0.8296 (1.0482)  Acc@1: 81.2500 (75.3600)  Acc@5: 93.7500 (95.1100)
Test: [Whole Val]  Time: 9.523  Loss: 1.0482  Acc@1: 75.3600 Pruned: 51.07% 
Test (EMA): [   0/78]  Time: 0.401 (0.401)  Loss:  1.0527 (1.0527)  Acc@1: 73.4375 (73.4375)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.8188 (1.0521)  Acc@1: 81.2500 (75.3500)  Acc@5: 93.7500 (95.1300)
Test (EMA): [Whole Val]  Time: 9.539  Loss: 1.0521  Acc@1: 75.3500 Pruned: 51.07% 
Train: 112 [   0/390 (  0%)]  Loss: 2.877 (2.88)  Time: 0.869s,  147.28/s  (0.869s,  147.28/s)  LR: 1.503e-04  Data: 0.568 (0.568)
Train: 112 [ 100/390 ( 26%)]  Loss: 3.467 (3.27)  Time: 0.311s,  411.00/s  (0.321s,  398.99/s)  LR: 1.503e-04  Data: 0.012 (0.016)
Train: 112 [ 200/390 ( 51%)]  Loss: 3.412 (3.24)  Time: 0.325s,  393.25/s  (0.320s,  400.61/s)  LR: 1.503e-04  Data: 0.011 (0.014)
Train: 112 [ 300/390 ( 77%)]  Loss: 3.805 (3.22)  Time: 0.311s,  411.69/s  (0.318s,  403.09/s)  LR: 1.503e-04  Data: 0.010 (0.013)
Train: 112 [ 389/390 (100%)]  Loss: 2.612 (3.21)  Time: 0.301s,  425.89/s  (0.317s,  403.85/s)  LR: 1.503e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.411 (0.411)  Loss:  1.0449 (1.0449)  Acc@1: 73.4375 (73.4375)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.018 (0.121)  Loss:  0.8003 (1.0328)  Acc@1: 81.2500 (75.5100)  Acc@5: 93.7500 (95.0700)
Test: [Whole Val]  Time: 9.568  Loss: 1.0328  Acc@1: 75.5100 Pruned: 51.08% 
Test (EMA): [   0/78]  Time: 0.335 (0.335)  Loss:  1.0449 (1.0449)  Acc@1: 73.4375 (73.4375)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.8013 (1.0401)  Acc@1: 81.2500 (75.6200)  Acc@5: 93.7500 (94.9900)
Test (EMA): [Whole Val]  Time: 9.492  Loss: 1.0401  Acc@1: 75.6200 Pruned: 51.08% 
Train: 113 [   0/390 (  0%)]  Loss: 3.452 (3.45)  Time: 0.849s,  150.75/s  (0.849s,  150.75/s)  LR: 1.428e-04  Data: 0.547 (0.547)
Train: 113 [ 100/390 ( 26%)]  Loss: 2.842 (3.21)  Time: 0.327s,  391.60/s  (0.319s,  401.62/s)  LR: 1.428e-04  Data: 0.013 (0.016)
Train: 113 [ 200/390 ( 51%)]  Loss: 2.342 (3.22)  Time: 0.313s,  409.01/s  (0.318s,  403.09/s)  LR: 1.428e-04  Data: 0.013 (0.014)
Train: 113 [ 300/390 ( 77%)]  Loss: 3.112 (3.24)  Time: 0.311s,  411.48/s  (0.316s,  404.99/s)  LR: 1.428e-04  Data: 0.012 (0.013)
Train: 113 [ 389/390 (100%)]  Loss: 2.536 (3.23)  Time: 0.301s,  425.34/s  (0.315s,  405.73/s)  LR: 1.428e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.350 (0.350)  Loss:  1.0547 (1.0547)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  0.8301 (1.0416)  Acc@1: 81.2500 (75.2200)  Acc@5: 93.7500 (95.2300)
Test: [Whole Val]  Time: 9.519  Loss: 1.0416  Acc@1: 75.2200 Pruned: 51.07% 
Test (EMA): [   0/78]  Time: 0.359 (0.359)  Loss:  1.0605 (1.0605)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.024 (0.121)  Loss:  0.8345 (1.0510)  Acc@1: 81.2500 (75.3100)  Acc@5: 93.7500 (95.2200)
Test (EMA): [Whole Val]  Time: 9.586  Loss: 1.0510  Acc@1: 75.3100 Pruned: 51.07% 
Train: 114 [   0/390 (  0%)]  Loss: 3.766 (3.77)  Time: 0.812s,  157.63/s  (0.812s,  157.63/s)  LR: 1.356e-04  Data: 0.504 (0.504)
Train: 114 [ 100/390 ( 26%)]  Loss: 3.466 (3.21)  Time: 0.312s,  410.38/s  (0.320s,  400.40/s)  LR: 1.356e-04  Data: 0.010 (0.016)
Train: 114 [ 200/390 ( 51%)]  Loss: 3.171 (3.21)  Time: 0.312s,  410.35/s  (0.317s,  403.40/s)  LR: 1.356e-04  Data: 0.011 (0.014)
Train: 114 [ 300/390 ( 77%)]  Loss: 2.793 (3.22)  Time: 0.324s,  394.65/s  (0.317s,  404.30/s)  LR: 1.356e-04  Data: 0.010 (0.013)
Train: 114 [ 389/390 (100%)]  Loss: 2.919 (3.24)  Time: 0.303s,  422.40/s  (0.316s,  405.14/s)  LR: 1.356e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.416 (0.416)  Loss:  1.0703 (1.0703)  Acc@1: 77.3438 (77.3438)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.018 (0.122)  Loss:  0.8691 (1.0794)  Acc@1: 81.2500 (75.6400)  Acc@5: 93.7500 (95.0500)
Test: [Whole Val]  Time: 9.608  Loss: 1.0794  Acc@1: 75.6400 Pruned: 51.07% 
Test (EMA): [   0/78]  Time: 0.399 (0.399)  Loss:  1.0547 (1.0547)  Acc@1: 76.5625 (76.5625)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.024 (0.122)  Loss:  0.8516 (1.0642)  Acc@1: 81.2500 (75.7500)  Acc@5: 93.7500 (95.2000)
Test (EMA): [Whole Val]  Time: 9.623  Loss: 1.0642  Acc@1: 75.7500 Pruned: 51.07% 
Train: 115 [   0/390 (  0%)]  Loss: 2.822 (2.82)  Time: 0.885s,  144.59/s  (0.885s,  144.59/s)  LR: 1.285e-04  Data: 0.581 (0.581)
Train: 115 [ 100/390 ( 26%)]  Loss: 2.922 (3.20)  Time: 0.314s,  407.78/s  (0.321s,  399.12/s)  LR: 1.285e-04  Data: 0.012 (0.017)
Train: 115 [ 200/390 ( 51%)]  Loss: 3.706 (3.19)  Time: 0.312s,  410.18/s  (0.318s,  402.75/s)  LR: 1.285e-04  Data: 0.011 (0.014)
Train: 115 [ 300/390 ( 77%)]  Loss: 2.894 (3.19)  Time: 0.313s,  409.01/s  (0.316s,  404.84/s)  LR: 1.285e-04  Data: 0.011 (0.013)
Train: 115 [ 389/390 (100%)]  Loss: 3.768 (3.20)  Time: 0.301s,  425.29/s  (0.315s,  405.89/s)  LR: 1.285e-04  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.357 (0.357)  Loss:  1.0547 (1.0547)  Acc@1: 74.2188 (74.2188)  Acc@5: 92.9688 (92.9688)
Test: [  78/78]  Time: 0.021 (0.121)  Loss:  0.8530 (1.0467)  Acc@1: 81.2500 (75.6600)  Acc@5: 93.7500 (95.2600)
Test: [Whole Val]  Time: 9.532  Loss: 1.0467  Acc@1: 75.6600 Pruned: 51.06% 
Test (EMA): [   0/78]  Time: 0.429 (0.429)  Loss:  1.0498 (1.0498)  Acc@1: 75.0000 (75.0000)  Acc@5: 92.9688 (92.9688)
Test (EMA): [  78/78]  Time: 0.021 (0.122)  Loss:  0.8501 (1.0419)  Acc@1: 81.2500 (75.7700)  Acc@5: 93.7500 (95.2200)
Test (EMA): [Whole Val]  Time: 9.658  Loss: 1.0419  Acc@1: 75.7700 Pruned: 51.06% 
Train: 116 [   0/390 (  0%)]  Loss: 3.709 (3.71)  Time: 0.798s,  160.41/s  (0.798s,  160.41/s)  LR: 1.216e-04  Data: 0.485 (0.485)
Train: 116 [ 100/390 ( 26%)]  Loss: 3.523 (3.16)  Time: 0.311s,  411.51/s  (0.319s,  400.89/s)  LR: 1.216e-04  Data: 0.010 (0.016)
Train: 116 [ 200/390 ( 51%)]  Loss: 3.529 (3.11)  Time: 0.315s,  406.54/s  (0.316s,  405.11/s)  LR: 1.216e-04  Data: 0.013 (0.013)
Train: 116 [ 300/390 ( 77%)]  Loss: 3.533 (3.14)  Time: 0.313s,  409.35/s  (0.315s,  405.82/s)  LR: 1.216e-04  Data: 0.010 (0.013)
Train: 116 [ 389/390 (100%)]  Loss: 3.314 (3.17)  Time: 0.301s,  425.21/s  (0.315s,  406.53/s)  LR: 1.216e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.380 (0.380)  Loss:  1.0645 (1.0645)  Acc@1: 74.2188 (74.2188)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.018 (0.121)  Loss:  0.8511 (1.0491)  Acc@1: 81.2500 (75.8600)  Acc@5: 93.7500 (95.2700)
Test: [Whole Val]  Time: 9.569  Loss: 1.0491  Acc@1: 75.8600 Pruned: 51.06% 
Test (EMA): [   0/78]  Time: 0.344 (0.344)  Loss:  1.0586 (1.0586)  Acc@1: 74.2188 (74.2188)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.8281 (1.0451)  Acc@1: 81.2500 (76.1000)  Acc@5: 93.7500 (95.3000)
Test (EMA): [Whole Val]  Time: 9.524  Loss: 1.0451  Acc@1: 76.1000 Pruned: 51.06% 
Train: 117 [   0/390 (  0%)]  Loss: 3.703 (3.70)  Time: 0.822s,  155.64/s  (0.822s,  155.64/s)  LR: 1.148e-04  Data: 0.500 (0.500)
Train: 117 [ 100/390 ( 26%)]  Loss: 3.525 (3.22)  Time: 0.314s,  407.84/s  (0.322s,  397.47/s)  LR: 1.148e-04  Data: 0.011 (0.016)
Train: 117 [ 200/390 ( 51%)]  Loss: 3.652 (3.22)  Time: 0.311s,  411.90/s  (0.319s,  401.60/s)  LR: 1.148e-04  Data: 0.011 (0.014)
Train: 117 [ 300/390 ( 77%)]  Loss: 3.078 (3.19)  Time: 0.311s,  411.73/s  (0.317s,  404.22/s)  LR: 1.148e-04  Data: 0.010 (0.013)
Train: 117 [ 389/390 (100%)]  Loss: 3.476 (3.19)  Time: 0.302s,  423.76/s  (0.316s,  405.35/s)  LR: 1.148e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.417 (0.417)  Loss:  1.0479 (1.0479)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.021 (0.122)  Loss:  0.8228 (1.0320)  Acc@1: 81.2500 (75.7200)  Acc@5: 93.7500 (95.1700)
Test: [Whole Val]  Time: 9.628  Loss: 1.0320  Acc@1: 75.7200 Pruned: 51.07% 
Test (EMA): [   0/78]  Time: 0.321 (0.321)  Loss:  1.0391 (1.0391)  Acc@1: 74.2188 (74.2188)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.7974 (1.0254)  Acc@1: 81.2500 (75.6700)  Acc@5: 93.7500 (95.2100)
Test (EMA): [Whole Val]  Time: 9.525  Loss: 1.0254  Acc@1: 75.6700 Pruned: 51.07% 
Train: 118 [   0/390 (  0%)]  Loss: 2.863 (2.86)  Time: 0.841s,  152.12/s  (0.841s,  152.12/s)  LR: 1.082e-04  Data: 0.529 (0.529)
Train: 118 [ 100/390 ( 26%)]  Loss: 3.131 (3.17)  Time: 0.329s,  388.59/s  (0.321s,  398.68/s)  LR: 1.082e-04  Data: 0.015 (0.016)
Train: 118 [ 200/390 ( 51%)]  Loss: 3.034 (3.17)  Time: 0.311s,  411.75/s  (0.317s,  403.47/s)  LR: 1.082e-04  Data: 0.011 (0.014)
Train: 118 [ 300/390 ( 77%)]  Loss: 2.404 (3.19)  Time: 0.312s,  409.97/s  (0.317s,  404.15/s)  LR: 1.082e-04  Data: 0.010 (0.013)
Train: 118 [ 389/390 (100%)]  Loss: 3.845 (3.21)  Time: 0.300s,  426.16/s  (0.317s,  404.13/s)  LR: 1.082e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.336 (0.336)  Loss:  1.0635 (1.0635)  Acc@1: 75.7812 (75.7812)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.8262 (1.0529)  Acc@1: 75.0000 (75.8400)  Acc@5: 93.7500 (95.2400)
Test: [Whole Val]  Time: 9.569  Loss: 1.0529  Acc@1: 75.8400 Pruned: 51.07% 
Test (EMA): [   0/78]  Time: 0.370 (0.370)  Loss:  1.0684 (1.0684)  Acc@1: 76.5625 (76.5625)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.018 (0.122)  Loss:  0.8257 (1.0564)  Acc@1: 75.0000 (75.8400)  Acc@5: 93.7500 (95.2800)
Test (EMA): [Whole Val]  Time: 9.614  Loss: 1.0564  Acc@1: 75.8400 Pruned: 51.06% 
Train: 119 [   0/390 (  0%)]  Loss: 3.549 (3.55)  Time: 0.858s,  149.13/s  (0.858s,  149.13/s)  LR: 1.018e-04  Data: 0.552 (0.552)
Train: 119 [ 100/390 ( 26%)]  Loss: 3.582 (3.27)  Time: 0.312s,  410.20/s  (0.318s,  402.00/s)  LR: 1.018e-04  Data: 0.010 (0.016)
Train: 119 [ 200/390 ( 51%)]  Loss: 2.574 (3.25)  Time: 0.312s,  410.45/s  (0.317s,  403.99/s)  LR: 1.018e-04  Data: 0.011 (0.014)
Train: 119 [ 300/390 ( 77%)]  Loss: 3.577 (3.21)  Time: 0.312s,  410.43/s  (0.316s,  405.41/s)  LR: 1.018e-04  Data: 0.011 (0.013)
Train: 119 [ 389/390 (100%)]  Loss: 3.573 (3.22)  Time: 0.306s,  417.82/s  (0.315s,  406.47/s)  LR: 1.018e-04  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.399 (0.399)  Loss:  1.0430 (1.0430)  Acc@1: 77.3438 (77.3438)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.122)  Loss:  0.8135 (1.0468)  Acc@1: 81.2500 (75.7600)  Acc@5: 93.7500 (95.2300)
Test: [Whole Val]  Time: 9.612  Loss: 1.0468  Acc@1: 75.7600 Pruned: 51.07% 
Test (EMA): [   0/78]  Time: 0.377 (0.377)  Loss:  1.0381 (1.0381)  Acc@1: 76.5625 (76.5625)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.7910 (1.0387)  Acc@1: 81.2500 (75.8800)  Acc@5: 93.7500 (95.2200)
Test (EMA): [Whole Val]  Time: 9.567  Loss: 1.0387  Acc@1: 75.8800 Pruned: 51.07% 
Train: 120 [   0/390 (  0%)]  Loss: 3.238 (3.24)  Time: 0.863s,  148.25/s  (0.863s,  148.25/s)  LR: 9.558e-05  Data: 0.563 (0.563)
Train: 120 [ 100/390 ( 26%)]  Loss: 3.611 (3.20)  Time: 0.311s,  410.98/s  (0.320s,  399.78/s)  LR: 9.558e-05  Data: 0.011 (0.016)
Train: 120 [ 200/390 ( 51%)]  Loss: 3.187 (3.22)  Time: 0.341s,  375.63/s  (0.317s,  403.37/s)  LR: 9.558e-05  Data: 0.011 (0.014)
Train: 120 [ 300/390 ( 77%)]  Loss: 3.376 (3.21)  Time: 0.317s,  404.05/s  (0.317s,  404.38/s)  LR: 9.558e-05  Data: 0.017 (0.013)
Train: 120 [ 389/390 (100%)]  Loss: 2.908 (3.24)  Time: 0.317s,  403.37/s  (0.316s,  404.56/s)  LR: 9.558e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.444 (0.444)  Loss:  1.0801 (1.0801)  Acc@1: 75.7812 (75.7812)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.021 (0.122)  Loss:  0.8662 (1.0707)  Acc@1: 75.0000 (75.6100)  Acc@5: 93.7500 (95.2500)
Test: [Whole Val]  Time: 9.636  Loss: 1.0707  Acc@1: 75.6100 Pruned: 51.08% 
Test (EMA): [   0/78]  Time: 0.402 (0.402)  Loss:  1.0791 (1.0791)  Acc@1: 75.7812 (75.7812)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.8682 (1.0698)  Acc@1: 81.2500 (75.6500)  Acc@5: 93.7500 (95.1700)
Test (EMA): [Whole Val]  Time: 9.541  Loss: 1.0698  Acc@1: 75.6500 Pruned: 51.08% 
Train: 121 [   0/390 (  0%)]  Loss: 3.608 (3.61)  Time: 0.816s,  156.81/s  (0.816s,  156.81/s)  LR: 8.952e-05  Data: 0.502 (0.502)
Train: 121 [ 100/390 ( 26%)]  Loss: 3.134 (3.26)  Time: 0.313s,  408.98/s  (0.322s,  397.64/s)  LR: 8.952e-05  Data: 0.011 (0.016)
Train: 121 [ 200/390 ( 51%)]  Loss: 2.651 (3.23)  Time: 0.312s,  410.26/s  (0.318s,  402.65/s)  LR: 8.952e-05  Data: 0.012 (0.014)
Train: 121 [ 300/390 ( 77%)]  Loss: 2.782 (3.18)  Time: 0.321s,  398.95/s  (0.318s,  402.23/s)  LR: 8.952e-05  Data: 0.017 (0.013)
Train: 121 [ 389/390 (100%)]  Loss: 2.809 (3.20)  Time: 0.302s,  423.23/s  (0.317s,  403.25/s)  LR: 8.952e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.415 (0.415)  Loss:  1.0664 (1.0664)  Acc@1: 75.0000 (75.0000)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.8433 (1.0619)  Acc@1: 81.2500 (75.8000)  Acc@5: 93.7500 (95.3200)
Test: [Whole Val]  Time: 9.553  Loss: 1.0619  Acc@1: 75.8000 Pruned: 51.08% 
Test (EMA): [   0/78]  Time: 0.398 (0.398)  Loss:  1.0625 (1.0625)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.8340 (1.0568)  Acc@1: 81.2500 (75.8000)  Acc@5: 93.7500 (95.2500)
Test (EMA): [Whole Val]  Time: 9.568  Loss: 1.0568  Acc@1: 75.8000 Pruned: 51.08% 
Train: 122 [   0/390 (  0%)]  Loss: 2.474 (2.47)  Time: 0.787s,  162.70/s  (0.787s,  162.70/s)  LR: 8.363e-05  Data: 0.482 (0.482)
Train: 122 [ 100/390 ( 26%)]  Loss: 3.184 (3.18)  Time: 0.314s,  407.78/s  (0.321s,  398.78/s)  LR: 8.363e-05  Data: 0.012 (0.018)
Train: 122 [ 200/390 ( 51%)]  Loss: 3.293 (3.20)  Time: 0.315s,  406.87/s  (0.317s,  403.24/s)  LR: 8.363e-05  Data: 0.014 (0.016)
Train: 122 [ 300/390 ( 77%)]  Loss: 3.607 (3.19)  Time: 0.314s,  408.08/s  (0.316s,  404.88/s)  LR: 8.363e-05  Data: 0.013 (0.015)
Train: 122 [ 389/390 (100%)]  Loss: 3.011 (3.20)  Time: 0.300s,  426.67/s  (0.315s,  405.82/s)  LR: 8.363e-05  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.328 (0.328)  Loss:  1.0654 (1.0654)  Acc@1: 75.0000 (75.0000)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.8193 (1.0505)  Acc@1: 81.2500 (76.0000)  Acc@5: 93.7500 (95.2900)
Test: [Whole Val]  Time: 9.574  Loss: 1.0505  Acc@1: 76.0000 Pruned: 51.08% 
Test (EMA): [   0/78]  Time: 0.306 (0.306)  Loss:  1.0645 (1.0645)  Acc@1: 75.0000 (75.0000)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.8081 (1.0460)  Acc@1: 81.2500 (76.0200)  Acc@5: 93.7500 (95.3300)
Test (EMA): [Whole Val]  Time: 9.573  Loss: 1.0460  Acc@1: 76.0200 Pruned: 51.08% 
Train: 123 [   0/390 (  0%)]  Loss: 2.268 (2.27)  Time: 0.713s,  179.50/s  (0.713s,  179.50/s)  LR: 7.793e-05  Data: 0.412 (0.412)
Train: 123 [ 100/390 ( 26%)]  Loss: 3.254 (3.18)  Time: 0.313s,  409.01/s  (0.318s,  403.11/s)  LR: 7.793e-05  Data: 0.014 (0.017)
Train: 123 [ 200/390 ( 51%)]  Loss: 3.610 (3.19)  Time: 0.314s,  407.23/s  (0.315s,  406.22/s)  LR: 7.793e-05  Data: 0.014 (0.015)
Train: 123 [ 300/390 ( 77%)]  Loss: 2.574 (3.20)  Time: 0.312s,  409.64/s  (0.315s,  406.44/s)  LR: 7.793e-05  Data: 0.013 (0.014)
Train: 123 [ 389/390 (100%)]  Loss: 3.639 (3.22)  Time: 0.300s,  426.59/s  (0.315s,  406.84/s)  LR: 7.793e-05  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.317 (0.317)  Loss:  1.0664 (1.0664)  Acc@1: 75.7812 (75.7812)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.8267 (1.0586)  Acc@1: 81.2500 (75.8200)  Acc@5: 93.7500 (95.2300)
Test: [Whole Val]  Time: 9.579  Loss: 1.0586  Acc@1: 75.8200 Pruned: 51.07% 
Test (EMA): [   0/78]  Time: 0.305 (0.305)  Loss:  1.0635 (1.0635)  Acc@1: 75.7812 (75.7812)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.018 (0.121)  Loss:  0.8140 (1.0537)  Acc@1: 81.2500 (75.8200)  Acc@5: 93.7500 (95.2100)
Test (EMA): [Whole Val]  Time: 9.528  Loss: 1.0537  Acc@1: 75.8200 Pruned: 51.07% 
Train: 124 [   0/390 (  0%)]  Loss: 3.028 (3.03)  Time: 0.771s,  166.08/s  (0.771s,  166.08/s)  LR: 7.241e-05  Data: 0.469 (0.469)
Train: 124 [ 100/390 ( 26%)]  Loss: 3.280 (3.20)  Time: 0.314s,  407.84/s  (0.318s,  402.57/s)  LR: 7.241e-05  Data: 0.014 (0.018)
Train: 124 [ 200/390 ( 51%)]  Loss: 3.275 (3.18)  Time: 0.312s,  410.32/s  (0.315s,  405.83/s)  LR: 7.241e-05  Data: 0.013 (0.015)
Train: 124 [ 300/390 ( 77%)]  Loss: 3.001 (3.21)  Time: 0.312s,  409.60/s  (0.315s,  406.95/s)  LR: 7.241e-05  Data: 0.013 (0.014)
Train: 124 [ 389/390 (100%)]  Loss: 3.601 (3.20)  Time: 0.300s,  427.35/s  (0.314s,  407.57/s)  LR: 7.241e-05  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.310 (0.310)  Loss:  1.0420 (1.0420)  Acc@1: 73.4375 (73.4375)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  0.8105 (1.0296)  Acc@1: 75.0000 (75.9600)  Acc@5: 93.7500 (95.3100)
Test: [Whole Val]  Time: 9.496  Loss: 1.0296  Acc@1: 75.9600 Pruned: 51.07% 
Test (EMA): [   0/78]  Time: 0.295 (0.295)  Loss:  1.0361 (1.0361)  Acc@1: 73.4375 (73.4375)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.018 (0.120)  Loss:  0.7861 (1.0196)  Acc@1: 81.2500 (76.0900)  Acc@5: 93.7500 (95.3500)
Test (EMA): [Whole Val]  Time: 9.499  Loss: 1.0196  Acc@1: 76.0900 Pruned: 51.07% 
Train: 125 [   0/390 (  0%)]  Loss: 3.366 (3.37)  Time: 0.778s,  164.54/s  (0.778s,  164.54/s)  LR: 6.708e-05  Data: 0.478 (0.478)
Train: 125 [ 100/390 ( 26%)]  Loss: 3.029 (3.16)  Time: 0.312s,  409.94/s  (0.317s,  403.40/s)  LR: 6.708e-05  Data: 0.012 (0.017)
Train: 125 [ 200/390 ( 51%)]  Loss: 2.410 (3.17)  Time: 0.313s,  409.18/s  (0.315s,  406.29/s)  LR: 6.708e-05  Data: 0.013 (0.015)
Train: 125 [ 300/390 ( 77%)]  Loss: 2.974 (3.16)  Time: 0.312s,  409.86/s  (0.314s,  407.35/s)  LR: 6.708e-05  Data: 0.013 (0.014)
Train: 125 [ 389/390 (100%)]  Loss: 2.558 (3.15)  Time: 0.301s,  425.06/s  (0.314s,  407.56/s)  LR: 6.708e-05  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.312 (0.312)  Loss:  1.0371 (1.0371)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  0.7817 (1.0311)  Acc@1: 87.5000 (75.8500)  Acc@5: 93.7500 (95.2300)
Test: [Whole Val]  Time: 9.487  Loss: 1.0311  Acc@1: 75.8500 Pruned: 51.06% 
Test (EMA): [   0/78]  Time: 0.306 (0.306)  Loss:  1.0322 (1.0322)  Acc@1: 74.2188 (74.2188)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.7764 (1.0242)  Acc@1: 87.5000 (76.0500)  Acc@5: 93.7500 (95.3200)
Test (EMA): [Whole Val]  Time: 9.492  Loss: 1.0242  Acc@1: 76.0500 Pruned: 51.06% 
Train: 126 [   0/390 (  0%)]  Loss: 3.464 (3.46)  Time: 0.776s,  165.03/s  (0.776s,  165.03/s)  LR: 6.194e-05  Data: 0.477 (0.477)
Train: 126 [ 100/390 ( 26%)]  Loss: 3.524 (3.20)  Time: 0.313s,  409.13/s  (0.317s,  403.33/s)  LR: 6.194e-05  Data: 0.013 (0.017)
Train: 126 [ 200/390 ( 51%)]  Loss: 3.107 (3.20)  Time: 0.317s,  403.49/s  (0.316s,  405.54/s)  LR: 6.194e-05  Data: 0.015 (0.015)
Train: 126 [ 300/390 ( 77%)]  Loss: 3.634 (3.23)  Time: 0.313s,  409.12/s  (0.315s,  406.48/s)  LR: 6.194e-05  Data: 0.013 (0.015)
Train: 126 [ 389/390 (100%)]  Loss: 3.196 (3.23)  Time: 0.300s,  426.33/s  (0.315s,  406.75/s)  LR: 6.194e-05  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.389 (0.389)  Loss:  1.0605 (1.0605)  Acc@1: 74.2188 (74.2188)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.7778 (1.0450)  Acc@1: 81.2500 (75.8200)  Acc@5: 93.7500 (95.3000)
Test: [Whole Val]  Time: 9.586  Loss: 1.0450  Acc@1: 75.8200 Pruned: 51.07% 
Test (EMA): [   0/78]  Time: 0.359 (0.359)  Loss:  1.0586 (1.0586)  Acc@1: 75.0000 (75.0000)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.7744 (1.0427)  Acc@1: 87.5000 (75.9100)  Acc@5: 93.7500 (95.3200)
Test (EMA): [Whole Val]  Time: 9.576  Loss: 1.0427  Acc@1: 75.9100 Pruned: 51.07% 
Train: 127 [   0/390 (  0%)]  Loss: 2.314 (2.31)  Time: 0.789s,  162.29/s  (0.789s,  162.29/s)  LR: 5.699e-05  Data: 0.486 (0.486)
Train: 127 [ 100/390 ( 26%)]  Loss: 2.428 (3.13)  Time: 0.312s,  410.16/s  (0.318s,  402.02/s)  LR: 5.699e-05  Data: 0.013 (0.018)
Train: 127 [ 200/390 ( 51%)]  Loss: 3.327 (3.17)  Time: 0.313s,  409.16/s  (0.316s,  404.81/s)  LR: 5.699e-05  Data: 0.013 (0.016)
Train: 127 [ 300/390 ( 77%)]  Loss: 3.106 (3.19)  Time: 0.312s,  409.95/s  (0.315s,  406.07/s)  LR: 5.699e-05  Data: 0.013 (0.015)
Train: 127 [ 389/390 (100%)]  Loss: 2.877 (3.19)  Time: 0.301s,  425.94/s  (0.314s,  407.05/s)  LR: 5.699e-05  Data: 0.000 (0.014)
Test: [   0/78]  Time: 0.377 (0.377)  Loss:  1.0410 (1.0410)  Acc@1: 75.0000 (75.0000)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.017 (0.121)  Loss:  0.8237 (1.0369)  Acc@1: 81.2500 (76.0300)  Acc@5: 93.7500 (95.4000)
Test: [Whole Val]  Time: 9.575  Loss: 1.0369  Acc@1: 76.0300 Pruned: 51.06% 
Test (EMA): [   0/78]  Time: 0.319 (0.319)  Loss:  1.0400 (1.0400)  Acc@1: 75.0000 (75.0000)  Acc@5: 95.3125 (95.3125)
Test (EMA): [  78/78]  Time: 0.020 (0.121)  Loss:  0.8169 (1.0340)  Acc@1: 81.2500 (76.0100)  Acc@5: 93.7500 (95.3700)
Test (EMA): [Whole Val]  Time: 9.526  Loss: 1.0340  Acc@1: 76.0100 Pruned: 51.06% 
Train: 128 [   0/390 (  0%)]  Loss: 3.565 (3.57)  Time: 0.797s,  160.66/s  (0.797s,  160.66/s)  LR: 5.224e-05  Data: 0.495 (0.495)
Train: 128 [ 100/390 ( 26%)]  Loss: 3.698 (3.27)  Time: 0.323s,  396.84/s  (0.320s,  400.50/s)  LR: 5.224e-05  Data: 0.010 (0.015)
Train: 128 [ 200/390 ( 51%)]  Loss: 3.642 (3.20)  Time: 0.308s,  415.82/s  (0.317s,  403.40/s)  LR: 5.224e-05  Data: 0.010 (0.013)
Train: 128 [ 300/390 ( 77%)]  Loss: 2.855 (3.18)  Time: 0.308s,  415.61/s  (0.314s,  407.15/s)  LR: 5.224e-05  Data: 0.009 (0.012)
Train: 128 [ 389/390 (100%)]  Loss: 2.489 (3.19)  Time: 0.297s,  430.62/s  (0.313s,  409.04/s)  LR: 5.224e-05  Data: 0.000 (0.011)
Test: [   0/78]  Time: 0.311 (0.311)  Loss:  1.0508 (1.0508)  Acc@1: 74.2188 (74.2188)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.019 (0.121)  Loss:  0.8018 (1.0433)  Acc@1: 87.5000 (75.9600)  Acc@5: 93.7500 (95.2300)
Test: [Whole Val]  Time: 9.533  Loss: 1.0433  Acc@1: 75.9600 Pruned: 51.06% 
Test (EMA): [   0/78]  Time: 0.313 (0.313)  Loss:  1.0527 (1.0527)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.019 (0.120)  Loss:  0.8071 (1.0447)  Acc@1: 87.5000 (76.0300)  Acc@5: 93.7500 (95.3200)
Test (EMA): [Whole Val]  Time: 9.488  Loss: 1.0447  Acc@1: 76.0300 Pruned: 51.06% 
Train: 129 [   0/390 (  0%)]  Loss: 3.103 (3.10)  Time: 0.773s,  165.51/s  (0.773s,  165.51/s)  LR: 4.768e-05  Data: 0.473 (0.473)
Train: 129 [ 100/390 ( 26%)]  Loss: 3.514 (3.05)  Time: 0.308s,  414.97/s  (0.313s,  408.55/s)  LR: 4.768e-05  Data: 0.010 (0.014)
Train: 129 [ 200/390 ( 51%)]  Loss: 3.570 (3.10)  Time: 0.309s,  414.24/s  (0.311s,  411.80/s)  LR: 4.768e-05  Data: 0.009 (0.012)
Train: 129 [ 300/390 ( 77%)]  Loss: 3.399 (3.15)  Time: 0.308s,  415.12/s  (0.310s,  412.66/s)  LR: 4.768e-05  Data: 0.010 (0.011)
Train: 129 [ 389/390 (100%)]  Loss: 2.881 (3.15)  Time: 0.297s,  430.92/s  (0.310s,  413.25/s)  LR: 4.768e-05  Data: 0.000 (0.011)
Test: [   0/78]  Time: 0.306 (0.306)  Loss:  1.0459 (1.0459)  Acc@1: 75.0000 (75.0000)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.019 (0.120)  Loss:  0.8081 (1.0374)  Acc@1: 87.5000 (76.0300)  Acc@5: 93.7500 (95.2400)
Test: [Whole Val]  Time: 9.463  Loss: 1.0374  Acc@1: 76.0300 Pruned: 51.06% 
Test (EMA): [   0/78]  Time: 0.305 (0.305)  Loss:  1.0479 (1.0479)  Acc@1: 75.7812 (75.7812)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.8071 (1.0375)  Acc@1: 81.2500 (76.0800)  Acc@5: 93.7500 (95.2300)
Test (EMA): [Whole Val]  Time: 9.475  Loss: 1.0375  Acc@1: 76.0800 Pruned: 51.06% 
Train: 130 [   0/390 (  0%)]  Loss: 3.583 (3.58)  Time: 0.763s,  167.79/s  (0.763s,  167.79/s)  LR: 4.332e-05  Data: 0.456 (0.456)
Train: 130 [ 100/390 ( 26%)]  Loss: 2.250 (3.29)  Time: 0.308s,  414.96/s  (0.314s,  407.74/s)  LR: 4.332e-05  Data: 0.009 (0.014)
Train: 130 [ 200/390 ( 51%)]  Loss: 3.466 (3.24)  Time: 0.312s,  410.00/s  (0.313s,  408.73/s)  LR: 4.332e-05  Data: 0.013 (0.013)
Train: 130 [ 300/390 ( 77%)]  Loss: 2.472 (3.23)  Time: 0.310s,  412.70/s  (0.313s,  409.20/s)  LR: 4.332e-05  Data: 0.010 (0.013)
Train: 130 [ 389/390 (100%)]  Loss: 2.738 (3.24)  Time: 0.298s,  429.28/s  (0.312s,  409.68/s)  LR: 4.332e-05  Data: 0.000 (0.013)
Test: [   0/78]  Time: 0.315 (0.315)  Loss:  1.0537 (1.0537)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.019 (0.120)  Loss:  0.8403 (1.0514)  Acc@1: 81.2500 (76.0600)  Acc@5: 93.7500 (95.3300)
Test: [Whole Val]  Time: 9.459  Loss: 1.0514  Acc@1: 76.0600 Pruned: 51.06% 
Test (EMA): [   0/78]  Time: 0.303 (0.303)  Loss:  1.0527 (1.0527)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.8364 (1.0489)  Acc@1: 81.2500 (76.0400)  Acc@5: 93.7500 (95.2800)
Test (EMA): [Whole Val]  Time: 9.447  Loss: 1.0489  Acc@1: 76.0400 Pruned: 51.06% 
Train: 131 [   0/390 (  0%)]  Loss: 2.297 (2.30)  Time: 0.803s,  159.48/s  (0.803s,  159.48/s)  LR: 3.916e-05  Data: 0.501 (0.501)
Train: 131 [ 100/390 ( 26%)]  Loss: 2.766 (3.15)  Time: 0.322s,  396.94/s  (0.316s,  404.88/s)  LR: 3.916e-05  Data: 0.011 (0.015)
Train: 131 [ 200/390 ( 51%)]  Loss: 3.536 (3.18)  Time: 0.308s,  416.08/s  (0.315s,  405.80/s)  LR: 3.916e-05  Data: 0.009 (0.012)
Train: 131 [ 300/390 ( 77%)]  Loss: 3.601 (3.19)  Time: 0.310s,  413.11/s  (0.313s,  408.69/s)  LR: 3.916e-05  Data: 0.010 (0.012)
Train: 131 [ 389/390 (100%)]  Loss: 2.806 (3.18)  Time: 0.298s,  429.87/s  (0.312s,  410.25/s)  LR: 3.916e-05  Data: 0.000 (0.011)
Test: [   0/78]  Time: 0.318 (0.318)  Loss:  1.0322 (1.0322)  Acc@1: 74.2188 (74.2188)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  0.7793 (1.0176)  Acc@1: 81.2500 (76.0800)  Acc@5: 93.7500 (95.2700)
Test: [Whole Val]  Time: 9.454  Loss: 1.0176  Acc@1: 76.0800 Pruned: 51.06% 
Test (EMA): [   0/78]  Time: 0.301 (0.301)  Loss:  1.0342 (1.0342)  Acc@1: 74.2188 (74.2188)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.019 (0.119)  Loss:  0.7896 (1.0196)  Acc@1: 81.2500 (76.1100)  Acc@5: 93.7500 (95.3800)
Test (EMA): [Whole Val]  Time: 9.424  Loss: 1.0196  Acc@1: 76.1100 Pruned: 51.06% 
Train: 132 [   0/390 (  0%)]  Loss: 3.821 (3.82)  Time: 0.717s,  178.54/s  (0.717s,  178.54/s)  LR: 3.521e-05  Data: 0.417 (0.417)
Train: 132 [ 100/390 ( 26%)]  Loss: 3.464 (3.25)  Time: 0.308s,  415.61/s  (0.313s,  409.21/s)  LR: 3.521e-05  Data: 0.009 (0.014)
Train: 132 [ 200/390 ( 51%)]  Loss: 3.693 (3.26)  Time: 0.309s,  414.55/s  (0.311s,  412.06/s)  LR: 3.521e-05  Data: 0.010 (0.012)
Train: 132 [ 300/390 ( 77%)]  Loss: 2.526 (3.24)  Time: 0.322s,  397.05/s  (0.311s,  412.06/s)  LR: 3.521e-05  Data: 0.010 (0.011)
Train: 132 [ 389/390 (100%)]  Loss: 3.669 (3.23)  Time: 0.297s,  430.77/s  (0.311s,  411.46/s)  LR: 3.521e-05  Data: 0.000 (0.011)
Test: [   0/78]  Time: 0.314 (0.314)  Loss:  1.0410 (1.0410)  Acc@1: 73.4375 (73.4375)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.019 (0.119)  Loss:  0.8027 (1.0330)  Acc@1: 81.2500 (76.0900)  Acc@5: 93.7500 (95.3000)
Test: [Whole Val]  Time: 9.435  Loss: 1.0330  Acc@1: 76.0900 Pruned: 51.06% 
Test (EMA): [   0/78]  Time: 0.328 (0.328)  Loss:  1.0410 (1.0410)  Acc@1: 75.0000 (75.0000)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.7949 (1.0306)  Acc@1: 81.2500 (76.0700)  Acc@5: 93.7500 (95.3500)
Test (EMA): [Whole Val]  Time: 9.458  Loss: 1.0306  Acc@1: 76.0700 Pruned: 51.06% 
Train: 133 [   0/390 (  0%)]  Loss: 2.536 (2.54)  Time: 0.815s,  157.13/s  (0.815s,  157.13/s)  LR: 3.146e-05  Data: 0.514 (0.514)
Train: 133 [ 100/390 ( 26%)]  Loss: 3.455 (3.25)  Time: 0.308s,  415.80/s  (0.323s,  396.26/s)  LR: 3.146e-05  Data: 0.010 (0.015)
Train: 133 [ 200/390 ( 51%)]  Loss: 3.541 (3.20)  Time: 0.308s,  415.61/s  (0.316s,  404.67/s)  LR: 3.146e-05  Data: 0.009 (0.012)
Train: 133 [ 300/390 ( 77%)]  Loss: 2.546 (3.17)  Time: 0.309s,  413.95/s  (0.314s,  408.06/s)  LR: 3.146e-05  Data: 0.010 (0.011)
Train: 133 [ 389/390 (100%)]  Loss: 3.456 (3.18)  Time: 0.297s,  430.80/s  (0.314s,  407.75/s)  LR: 3.146e-05  Data: 0.000 (0.011)
Test: [   0/78]  Time: 0.318 (0.318)  Loss:  1.0352 (1.0352)  Acc@1: 75.0000 (75.0000)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.024 (0.119)  Loss:  0.7939 (1.0250)  Acc@1: 81.2500 (76.0700)  Acc@5: 93.7500 (95.3500)
Test: [Whole Val]  Time: 9.430  Loss: 1.0250  Acc@1: 76.0700 Pruned: 51.06% 
Test (EMA): [   0/78]  Time: 0.306 (0.306)  Loss:  1.0381 (1.0381)  Acc@1: 76.5625 (76.5625)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.020 (0.119)  Loss:  0.7998 (1.0275)  Acc@1: 81.2500 (76.0800)  Acc@5: 93.7500 (95.3900)
Test (EMA): [Whole Val]  Time: 9.418  Loss: 1.0275  Acc@1: 76.0800 Pruned: 51.06% 
Train: 134 [   0/390 (  0%)]  Loss: 3.768 (3.77)  Time: 0.758s,  168.97/s  (0.758s,  168.97/s)  LR: 2.791e-05  Data: 0.458 (0.458)
Train: 134 [ 100/390 ( 26%)]  Loss: 2.426 (3.14)  Time: 0.308s,  414.99/s  (0.313s,  409.22/s)  LR: 2.791e-05  Data: 0.009 (0.014)
Train: 134 [ 200/390 ( 51%)]  Loss: 3.210 (3.17)  Time: 0.308s,  415.55/s  (0.313s,  409.11/s)  LR: 2.791e-05  Data: 0.009 (0.012)
Train: 134 [ 300/390 ( 77%)]  Loss: 3.005 (3.21)  Time: 0.308s,  415.77/s  (0.312s,  410.55/s)  LR: 2.791e-05  Data: 0.009 (0.011)
Train: 134 [ 389/390 (100%)]  Loss: 2.800 (3.20)  Time: 0.297s,  431.40/s  (0.312s,  410.49/s)  LR: 2.791e-05  Data: 0.000 (0.011)
Test: [   0/78]  Time: 0.305 (0.305)  Loss:  1.0361 (1.0361)  Acc@1: 75.0000 (75.0000)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.019 (0.119)  Loss:  0.7739 (1.0288)  Acc@1: 81.2500 (76.1800)  Acc@5: 93.7500 (95.3300)
Test: [Whole Val]  Time: 9.434  Loss: 1.0288  Acc@1: 76.1800 Pruned: 51.06% 
Test (EMA): [   0/78]  Time: 0.347 (0.347)  Loss:  1.0342 (1.0342)  Acc@1: 75.0000 (75.0000)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.019 (0.120)  Loss:  0.7720 (1.0285)  Acc@1: 81.2500 (76.1400)  Acc@5: 93.7500 (95.3700)
Test (EMA): [Whole Val]  Time: 9.443  Loss: 1.0285  Acc@1: 76.1400 Pruned: 51.06% 
Train: 135 [   0/390 (  0%)]  Loss: 3.580 (3.58)  Time: 0.773s,  165.61/s  (0.773s,  165.61/s)  LR: 2.457e-05  Data: 0.468 (0.468)
Train: 135 [ 100/390 ( 26%)]  Loss: 3.647 (3.18)  Time: 0.309s,  413.68/s  (0.321s,  399.32/s)  LR: 2.457e-05  Data: 0.010 (0.015)
Train: 135 [ 200/390 ( 51%)]  Loss: 3.755 (3.22)  Time: 0.321s,  398.74/s  (0.320s,  400.58/s)  LR: 2.457e-05  Data: 0.010 (0.012)
Train: 135 [ 300/390 ( 77%)]  Loss: 3.282 (3.19)  Time: 0.321s,  398.19/s  (0.317s,  403.89/s)  LR: 2.457e-05  Data: 0.010 (0.012)
Train: 135 [ 389/390 (100%)]  Loss: 3.605 (3.17)  Time: 0.297s,  430.42/s  (0.316s,  405.32/s)  LR: 2.457e-05  Data: 0.000 (0.011)
Test: [   0/78]  Time: 0.307 (0.307)  Loss:  1.0410 (1.0410)  Acc@1: 75.7812 (75.7812)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.019 (0.119)  Loss:  0.7856 (1.0233)  Acc@1: 81.2500 (76.1300)  Acc@5: 93.7500 (95.3400)
Test: [Whole Val]  Time: 9.431  Loss: 1.0233  Acc@1: 76.1300 Pruned: 51.06% 
Test (EMA): [   0/78]  Time: 0.318 (0.318)  Loss:  1.0391 (1.0391)  Acc@1: 75.7812 (75.7812)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.017 (0.119)  Loss:  0.7788 (1.0201)  Acc@1: 81.2500 (76.1100)  Acc@5: 93.7500 (95.3100)
Test (EMA): [Whole Val]  Time: 9.429  Loss: 1.0201  Acc@1: 76.1100 Pruned: 51.06% 
Train: 136 [   0/390 (  0%)]  Loss: 2.341 (2.34)  Time: 0.807s,  158.62/s  (0.807s,  158.62/s)  LR: 2.144e-05  Data: 0.507 (0.507)
Train: 136 [ 100/390 ( 26%)]  Loss: 3.153 (3.14)  Time: 0.308s,  415.48/s  (0.313s,  408.44/s)  LR: 2.144e-05  Data: 0.010 (0.015)
Train: 136 [ 200/390 ( 51%)]  Loss: 3.383 (3.13)  Time: 0.322s,  397.02/s  (0.311s,  411.04/s)  LR: 2.144e-05  Data: 0.011 (0.012)
Train: 136 [ 300/390 ( 77%)]  Loss: 3.665 (3.16)  Time: 0.309s,  414.56/s  (0.311s,  411.05/s)  LR: 2.144e-05  Data: 0.010 (0.011)
Train: 136 [ 389/390 (100%)]  Loss: 2.874 (3.17)  Time: 0.297s,  430.42/s  (0.311s,  411.43/s)  LR: 2.144e-05  Data: 0.000 (0.011)
Test: [   0/78]  Time: 0.309 (0.309)  Loss:  1.0342 (1.0342)  Acc@1: 75.7812 (75.7812)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.017 (0.119)  Loss:  0.7935 (1.0243)  Acc@1: 81.2500 (76.0700)  Acc@5: 93.7500 (95.4700)
Test: [Whole Val]  Time: 9.407  Loss: 1.0243  Acc@1: 76.0700 Pruned: 51.06% 
Test (EMA): [   0/78]  Time: 0.328 (0.328)  Loss:  1.0361 (1.0361)  Acc@1: 75.7812 (75.7812)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.019 (0.120)  Loss:  0.7905 (1.0257)  Acc@1: 81.2500 (75.9900)  Acc@5: 93.7500 (95.3600)
Test (EMA): [Whole Val]  Time: 9.458  Loss: 1.0257  Acc@1: 75.9900 Pruned: 51.06% 
Train: 137 [   0/390 (  0%)]  Loss: 2.498 (2.50)  Time: 0.730s,  175.33/s  (0.730s,  175.33/s)  LR: 1.852e-05  Data: 0.429 (0.429)
Train: 137 [ 100/390 ( 26%)]  Loss: 3.328 (3.18)  Time: 0.322s,  397.35/s  (0.317s,  403.26/s)  LR: 1.852e-05  Data: 0.010 (0.014)
Train: 137 [ 200/390 ( 51%)]  Loss: 3.279 (3.18)  Time: 0.309s,  414.49/s  (0.319s,  401.22/s)  LR: 1.852e-05  Data: 0.010 (0.012)
Train: 137 [ 300/390 ( 77%)]  Loss: 3.525 (3.18)  Time: 0.308s,  415.54/s  (0.316s,  405.70/s)  LR: 1.852e-05  Data: 0.009 (0.011)
Train: 137 [ 389/390 (100%)]  Loss: 3.959 (3.18)  Time: 0.297s,  431.12/s  (0.314s,  407.93/s)  LR: 1.852e-05  Data: 0.000 (0.011)
Test: [   0/78]  Time: 0.308 (0.308)  Loss:  1.0361 (1.0361)  Acc@1: 74.2188 (74.2188)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.019 (0.119)  Loss:  0.7812 (1.0226)  Acc@1: 81.2500 (76.1100)  Acc@5: 93.7500 (95.3800)
Test: [Whole Val]  Time: 9.409  Loss: 1.0226  Acc@1: 76.1100 Pruned: 51.06% 
Test (EMA): [   0/78]  Time: 0.320 (0.320)  Loss:  1.0371 (1.0371)  Acc@1: 74.2188 (74.2188)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.020 (0.120)  Loss:  0.7837 (1.0231)  Acc@1: 81.2500 (76.1000)  Acc@5: 93.7500 (95.3900)
Test (EMA): [Whole Val]  Time: 9.444  Loss: 1.0231  Acc@1: 76.1000 Pruned: 51.06% 
Train: 138 [   0/390 (  0%)]  Loss: 2.837 (2.84)  Time: 0.756s,  169.31/s  (0.756s,  169.31/s)  LR: 1.581e-05  Data: 0.455 (0.455)
Train: 138 [ 100/390 ( 26%)]  Loss: 3.124 (3.23)  Time: 0.308s,  415.37/s  (0.314s,  407.54/s)  LR: 1.581e-05  Data: 0.010 (0.014)
Train: 138 [ 200/390 ( 51%)]  Loss: 3.220 (3.22)  Time: 0.322s,  397.06/s  (0.315s,  405.97/s)  LR: 1.581e-05  Data: 0.010 (0.012)
Train: 138 [ 300/390 ( 77%)]  Loss: 3.559 (3.23)  Time: 0.322s,  397.92/s  (0.317s,  403.83/s)  LR: 1.581e-05  Data: 0.010 (0.012)
Train: 138 [ 389/390 (100%)]  Loss: 3.346 (3.21)  Time: 0.297s,  430.71/s  (0.316s,  404.94/s)  LR: 1.581e-05  Data: 0.000 (0.011)
Test: [   0/78]  Time: 0.329 (0.329)  Loss:  1.0400 (1.0400)  Acc@1: 75.0000 (75.0000)  Acc@5: 95.3125 (95.3125)
Test: [  78/78]  Time: 0.020 (0.119)  Loss:  0.7832 (1.0250)  Acc@1: 81.2500 (76.1100)  Acc@5: 93.7500 (95.3600)
Test: [Whole Val]  Time: 9.431  Loss: 1.0250  Acc@1: 76.1100 Pruned: 51.06% 
Test (EMA): [   0/78]  Time: 0.358 (0.358)  Loss:  1.0400 (1.0400)  Acc@1: 75.0000 (75.0000)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.019 (0.120)  Loss:  0.7856 (1.0262)  Acc@1: 81.2500 (76.0800)  Acc@5: 93.7500 (95.3900)
Test (EMA): [Whole Val]  Time: 9.477  Loss: 1.0262  Acc@1: 76.0800 Pruned: 51.06% 
Train: 139 [   0/390 (  0%)]  Loss: 2.811 (2.81)  Time: 0.742s,  172.41/s  (0.742s,  172.41/s)  LR: 1.331e-05  Data: 0.428 (0.428)
Train: 139 [ 100/390 ( 26%)]  Loss: 3.007 (3.25)  Time: 0.308s,  415.60/s  (0.314s,  408.06/s)  LR: 1.331e-05  Data: 0.009 (0.014)
Train: 139 [ 200/390 ( 51%)]  Loss: 3.269 (3.23)  Time: 0.309s,  414.50/s  (0.311s,  411.56/s)  LR: 1.331e-05  Data: 0.010 (0.012)
Train: 139 [ 300/390 ( 77%)]  Loss: 3.080 (3.22)  Time: 0.308s,  415.22/s  (0.310s,  412.76/s)  LR: 1.331e-05  Data: 0.009 (0.011)
Train: 139 [ 389/390 (100%)]  Loss: 3.801 (3.21)  Time: 0.297s,  431.15/s  (0.310s,  413.13/s)  LR: 1.331e-05  Data: 0.000 (0.011)
Test: [   0/78]  Time: 0.313 (0.313)  Loss:  1.0410 (1.0410)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.019 (0.119)  Loss:  0.7930 (1.0270)  Acc@1: 81.2500 (76.1500)  Acc@5: 93.7500 (95.3800)
Test: [Whole Val]  Time: 9.432  Loss: 1.0270  Acc@1: 76.1500 Pruned: 51.06% 
Test (EMA): [   0/78]  Time: 0.317 (0.317)  Loss:  1.0400 (1.0400)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.019 (0.120)  Loss:  0.7930 (1.0263)  Acc@1: 81.2500 (76.1100)  Acc@5: 93.7500 (95.3700)
Test (EMA): [Whole Val]  Time: 9.441  Loss: 1.0263  Acc@1: 76.1100 Pruned: 51.06% 
Train: 140 [   0/390 (  0%)]  Loss: 3.097 (3.10)  Time: 0.754s,  169.78/s  (0.754s,  169.78/s)  LR: 1.103e-05  Data: 0.453 (0.453)
Train: 140 [ 100/390 ( 26%)]  Loss: 2.723 (3.21)  Time: 0.309s,  414.57/s  (0.313s,  408.57/s)  LR: 1.103e-05  Data: 0.009 (0.014)
Train: 140 [ 200/390 ( 51%)]  Loss: 2.650 (3.17)  Time: 0.308s,  415.68/s  (0.311s,  411.79/s)  LR: 1.103e-05  Data: 0.009 (0.012)
Train: 140 [ 300/390 ( 77%)]  Loss: 3.494 (3.20)  Time: 0.309s,  414.91/s  (0.312s,  410.78/s)  LR: 1.103e-05  Data: 0.010 (0.011)
Train: 140 [ 389/390 (100%)]  Loss: 2.491 (3.20)  Time: 0.310s,  413.08/s  (0.312s,  409.69/s)  LR: 1.103e-05  Data: 0.000 (0.011)
Test: [   0/78]  Time: 0.305 (0.305)  Loss:  1.0459 (1.0459)  Acc@1: 75.0000 (75.0000)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.019 (0.119)  Loss:  0.8042 (1.0321)  Acc@1: 81.2500 (76.0900)  Acc@5: 93.7500 (95.4100)
Test: [Whole Val]  Time: 9.435  Loss: 1.0321  Acc@1: 76.0900 Pruned: 51.06% 
Test (EMA): [   0/78]  Time: 0.345 (0.345)  Loss:  1.0479 (1.0479)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.120)  Loss:  0.8066 (1.0332)  Acc@1: 81.2500 (76.0200)  Acc@5: 93.7500 (95.4000)
Test (EMA): [Whole Val]  Time: 9.453  Loss: 1.0332  Acc@1: 76.0200 Pruned: 51.06% 
Train: 141 [   0/390 (  0%)]  Loss: 3.738 (3.74)  Time: 0.770s,  166.30/s  (0.770s,  166.30/s)  LR: 8.955e-06  Data: 0.456 (0.456)
Train: 141 [ 100/390 ( 26%)]  Loss: 2.855 (3.27)  Time: 0.308s,  415.59/s  (0.323s,  395.78/s)  LR: 8.955e-06  Data: 0.009 (0.015)
Train: 141 [ 200/390 ( 51%)]  Loss: 2.369 (3.28)  Time: 0.308s,  416.12/s  (0.317s,  404.04/s)  LR: 8.955e-06  Data: 0.009 (0.012)
Train: 141 [ 300/390 ( 77%)]  Loss: 2.311 (3.24)  Time: 0.308s,  416.06/s  (0.314s,  407.63/s)  LR: 8.955e-06  Data: 0.010 (0.011)
Train: 141 [ 389/390 (100%)]  Loss: 2.926 (3.23)  Time: 0.298s,  430.11/s  (0.313s,  409.41/s)  LR: 8.955e-06  Data: 0.000 (0.011)
Test: [   0/78]  Time: 0.323 (0.323)  Loss:  1.0420 (1.0420)  Acc@1: 75.0000 (75.0000)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.021 (0.120)  Loss:  0.7876 (1.0290)  Acc@1: 81.2500 (76.0700)  Acc@5: 93.7500 (95.3300)
Test: [Whole Val]  Time: 9.444  Loss: 1.0290  Acc@1: 76.0700 Pruned: 51.06% 
Test (EMA): [   0/78]  Time: 0.312 (0.312)  Loss:  1.0420 (1.0420)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.019 (0.119)  Loss:  0.7886 (1.0288)  Acc@1: 81.2500 (76.0700)  Acc@5: 93.7500 (95.3100)
Test (EMA): [Whole Val]  Time: 9.436  Loss: 1.0288  Acc@1: 76.0700 Pruned: 51.06% 
Train: 142 [   0/390 (  0%)]  Loss: 3.719 (3.72)  Time: 0.763s,  167.84/s  (0.763s,  167.84/s)  LR: 7.101e-06  Data: 0.456 (0.456)
Train: 142 [ 100/390 ( 26%)]  Loss: 3.254 (3.21)  Time: 0.309s,  414.00/s  (0.313s,  408.74/s)  LR: 7.101e-06  Data: 0.010 (0.014)
Train: 142 [ 200/390 ( 51%)]  Loss: 3.165 (3.22)  Time: 0.308s,  415.64/s  (0.311s,  411.70/s)  LR: 7.101e-06  Data: 0.010 (0.012)
Train: 142 [ 300/390 ( 77%)]  Loss: 3.768 (3.24)  Time: 0.308s,  415.54/s  (0.310s,  412.73/s)  LR: 7.101e-06  Data: 0.010 (0.011)
Train: 142 [ 389/390 (100%)]  Loss: 3.838 (3.24)  Time: 0.297s,  431.16/s  (0.310s,  413.35/s)  LR: 7.101e-06  Data: 0.000 (0.011)
Test: [   0/78]  Time: 0.304 (0.304)  Loss:  1.0488 (1.0488)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.020 (0.119)  Loss:  0.8018 (1.0386)  Acc@1: 81.2500 (76.0500)  Acc@5: 93.7500 (95.3000)
Test: [Whole Val]  Time: 9.430  Loss: 1.0386  Acc@1: 76.0500 Pruned: 51.05% 
Test (EMA): [   0/78]  Time: 0.306 (0.306)  Loss:  1.0488 (1.0488)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.019 (0.120)  Loss:  0.8008 (1.0384)  Acc@1: 81.2500 (76.0100)  Acc@5: 93.7500 (95.3400)
Test (EMA): [Whole Val]  Time: 9.449  Loss: 1.0384  Acc@1: 76.0100 Pruned: 51.05% 
Train: 143 [   0/390 (  0%)]  Loss: 2.840 (2.84)  Time: 0.737s,  173.66/s  (0.737s,  173.66/s)  LR: 5.463e-06  Data: 0.437 (0.437)
Train: 143 [ 100/390 ( 26%)]  Loss: 3.442 (3.14)  Time: 0.309s,  414.55/s  (0.318s,  402.88/s)  LR: 5.463e-06  Data: 0.010 (0.014)
Train: 143 [ 200/390 ( 51%)]  Loss: 3.071 (3.16)  Time: 0.309s,  413.62/s  (0.315s,  406.73/s)  LR: 5.463e-06  Data: 0.010 (0.012)
Train: 143 [ 300/390 ( 77%)]  Loss: 3.671 (3.19)  Time: 0.315s,  406.00/s  (0.315s,  406.29/s)  LR: 5.463e-06  Data: 0.016 (0.011)
Train: 143 [ 389/390 (100%)]  Loss: 2.988 (3.20)  Time: 0.297s,  430.83/s  (0.313s,  408.34/s)  LR: 5.463e-06  Data: 0.000 (0.011)
Test: [   0/78]  Time: 0.333 (0.333)  Loss:  1.0449 (1.0449)  Acc@1: 75.0000 (75.0000)  Acc@5: 94.5312 (94.5312)
Test: [  78/78]  Time: 0.019 (0.120)  Loss:  0.7954 (1.0337)  Acc@1: 81.2500 (76.1800)  Acc@5: 93.7500 (95.3600)
Test: [Whole Val]  Time: 9.457  Loss: 1.0337  Acc@1: 76.1800 Pruned: 51.06% 
Test (EMA): [   0/78]  Time: 0.315 (0.315)  Loss:  1.0449 (1.0449)  Acc@1: 75.0000 (75.0000)  Acc@5: 94.5312 (94.5312)
Test (EMA): [  78/78]  Time: 0.019 (0.119)  Loss:  0.7949 (1.0334)  Acc@1: 81.2500 (76.1800)  Acc@5: 93.7500 (95.3700)
Test (EMA): [Whole Val]  Time: 9.429  Loss: 1.0334  Acc@1: 76.1800 Pruned: 51.05% 
Train: 144 [   0/390 (  0%)]  Loss: 3.769 (3.77)  Time: 0.693s,  184.68/s  (0.693s,  184.68/s)  LR: 4.042e-06  Data: 0.392 (0.392)
Train: 144 [ 100/390 ( 26%)]  Loss: 3.496 (3.21)  Time: 0.308s,  415.80/s  (0.313s,  408.42/s)  LR: 4.042e-06  Data: 0.010 (0.013)
Train: 144 [ 200/390 ( 51%)]  Loss: 2.573 (3.21)  Time: 0.308s,  415.55/s  (0.314s,  407.22/s)  LR: 4.042e-06  Data: 0.010 (0.012)
Train: 144 [ 300/390 ( 77%)]  Loss: 2.711 (3.21)  Time: 0.322s,  397.64/s  (0.314s,  407.88/s)  LR: 4.042e-06  Data: 0.010 (0.011)
Train: 144 [ 389/390 (100%)]  Loss: 3.456 (3.22)  Time: 0.297s,  431.03/s  (0.313s,  409.16/s)  LR: 4.042e-06  Data: 0.000 (0.011)
Test: [   0/78]  Time: 0.298 (0.298)  Loss:  1.0469 (1.0469)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.119)  Loss:  0.7935 (1.0352)  Acc@1: 81.2500 (76.0700)  Acc@5: 93.7500 (95.3700)
Test: [Whole Val]  Time: 9.398  Loss: 1.0352  Acc@1: 76.0700 Pruned: 51.06% 
Test (EMA): [   0/78]  Time: 0.365 (0.365)  Loss:  1.0469 (1.0469)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.019 (0.120)  Loss:  0.7935 (1.0350)  Acc@1: 81.2500 (76.0900)  Acc@5: 93.7500 (95.4000)
Test (EMA): [Whole Val]  Time: 9.453  Loss: 1.0350  Acc@1: 76.0900 Pruned: 51.06% 
Train: 145 [   0/390 (  0%)]  Loss: 3.374 (3.37)  Time: 0.813s,  157.49/s  (0.813s,  157.49/s)  LR: 2.839e-06  Data: 0.513 (0.513)
Train: 145 [ 100/390 ( 26%)]  Loss: 3.578 (3.18)  Time: 0.313s,  408.54/s  (0.313s,  408.36/s)  LR: 2.839e-06  Data: 0.015 (0.015)
Train: 145 [ 200/390 ( 51%)]  Loss: 3.292 (3.17)  Time: 0.323s,  396.46/s  (0.313s,  409.15/s)  LR: 2.839e-06  Data: 0.011 (0.012)
Train: 145 [ 300/390 ( 77%)]  Loss: 3.004 (3.17)  Time: 0.308s,  415.72/s  (0.312s,  409.71/s)  LR: 2.839e-06  Data: 0.010 (0.011)
Train: 145 [ 389/390 (100%)]  Loss: 3.407 (3.19)  Time: 0.297s,  430.60/s  (0.311s,  411.07/s)  LR: 2.839e-06  Data: 0.000 (0.011)
Test: [   0/78]  Time: 0.295 (0.295)  Loss:  1.0430 (1.0430)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.119)  Loss:  0.7881 (1.0307)  Acc@1: 81.2500 (76.0800)  Acc@5: 93.7500 (95.3500)
Test: [Whole Val]  Time: 9.377  Loss: 1.0307  Acc@1: 76.0800 Pruned: 51.06% 
Test (EMA): [   0/78]  Time: 0.383 (0.383)  Loss:  1.0420 (1.0420)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.019 (0.120)  Loss:  0.7881 (1.0306)  Acc@1: 81.2500 (76.0900)  Acc@5: 93.7500 (95.3300)
Test (EMA): [Whole Val]  Time: 9.477  Loss: 1.0306  Acc@1: 76.0900 Pruned: 51.06% 
Train: 146 [   0/390 (  0%)]  Loss: 2.438 (2.44)  Time: 0.675s,  189.71/s  (0.675s,  189.71/s)  LR: 1.853e-06  Data: 0.375 (0.375)
Train: 146 [ 100/390 ( 26%)]  Loss: 2.505 (3.22)  Time: 0.308s,  415.56/s  (0.316s,  405.44/s)  LR: 1.853e-06  Data: 0.010 (0.013)
Train: 146 [ 200/390 ( 51%)]  Loss: 3.709 (3.17)  Time: 0.322s,  397.65/s  (0.313s,  409.35/s)  LR: 1.853e-06  Data: 0.010 (0.012)
Train: 146 [ 300/390 ( 77%)]  Loss: 3.696 (3.17)  Time: 0.309s,  414.65/s  (0.313s,  409.11/s)  LR: 1.853e-06  Data: 0.010 (0.011)
Train: 146 [ 389/390 (100%)]  Loss: 3.199 (3.18)  Time: 0.297s,  430.72/s  (0.312s,  410.62/s)  LR: 1.853e-06  Data: 0.000 (0.011)
Test: [   0/78]  Time: 0.301 (0.301)  Loss:  1.0410 (1.0410)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.019 (0.119)  Loss:  0.7896 (1.0300)  Acc@1: 81.2500 (76.1000)  Acc@5: 93.7500 (95.3100)
Test: [Whole Val]  Time: 9.386  Loss: 1.0300  Acc@1: 76.1000 Pruned: 51.06% 
Test (EMA): [   0/78]  Time: 0.369 (0.369)  Loss:  1.0410 (1.0410)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.019 (0.120)  Loss:  0.7886 (1.0299)  Acc@1: 81.2500 (76.1100)  Acc@5: 93.7500 (95.3100)
Test (EMA): [Whole Val]  Time: 9.475  Loss: 1.0299  Acc@1: 76.1100 Pruned: 51.06% 
Train: 147 [   0/390 (  0%)]  Loss: 2.557 (2.56)  Time: 0.737s,  173.71/s  (0.737s,  173.71/s)  LR: 1.087e-06  Data: 0.429 (0.429)
Train: 147 [ 100/390 ( 26%)]  Loss: 2.181 (3.14)  Time: 0.321s,  398.59/s  (0.315s,  406.30/s)  LR: 1.087e-06  Data: 0.010 (0.014)
Train: 147 [ 200/390 ( 51%)]  Loss: 3.556 (3.17)  Time: 0.322s,  397.24/s  (0.319s,  401.87/s)  LR: 1.087e-06  Data: 0.011 (0.012)
Train: 147 [ 300/390 ( 77%)]  Loss: 3.709 (3.16)  Time: 0.322s,  397.34/s  (0.318s,  402.53/s)  LR: 1.087e-06  Data: 0.010 (0.011)
Train: 147 [ 389/390 (100%)]  Loss: 3.377 (3.14)  Time: 0.310s,  412.40/s  (0.319s,  401.54/s)  LR: 1.087e-06  Data: 0.000 (0.011)
Test: [   0/78]  Time: 0.301 (0.301)  Loss:  1.0391 (1.0391)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.119)  Loss:  0.7866 (1.0275)  Acc@1: 81.2500 (76.1500)  Acc@5: 93.7500 (95.3100)
Test: [Whole Val]  Time: 9.366  Loss: 1.0275  Acc@1: 76.1500 Pruned: 51.06% 
Test (EMA): [   0/78]  Time: 0.301 (0.301)  Loss:  1.0391 (1.0391)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.019 (0.119)  Loss:  0.7861 (1.0276)  Acc@1: 81.2500 (76.1200)  Acc@5: 93.7500 (95.3100)
Test (EMA): [Whole Val]  Time: 9.401  Loss: 1.0276  Acc@1: 76.1200 Pruned: 51.06% 
Train: 148 [   0/390 (  0%)]  Loss: 3.340 (3.34)  Time: 0.748s,  171.05/s  (0.748s,  171.05/s)  LR: 5.385e-07  Data: 0.449 (0.449)
Train: 148 [ 100/390 ( 26%)]  Loss: 2.437 (3.15)  Time: 0.308s,  415.04/s  (0.313s,  408.32/s)  LR: 5.385e-07  Data: 0.009 (0.014)
Train: 148 [ 200/390 ( 51%)]  Loss: 3.230 (3.16)  Time: 0.309s,  414.57/s  (0.311s,  411.61/s)  LR: 5.385e-07  Data: 0.010 (0.012)
Train: 148 [ 300/390 ( 77%)]  Loss: 2.334 (3.17)  Time: 0.308s,  415.67/s  (0.310s,  412.82/s)  LR: 5.385e-07  Data: 0.010 (0.011)
Train: 148 [ 389/390 (100%)]  Loss: 2.399 (3.17)  Time: 0.297s,  430.46/s  (0.310s,  413.49/s)  LR: 5.385e-07  Data: 0.000 (0.011)
Test: [   0/78]  Time: 0.362 (0.362)  Loss:  1.0391 (1.0391)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  0.7861 (1.0273)  Acc@1: 81.2500 (76.1600)  Acc@5: 93.7500 (95.3400)
Test: [Whole Val]  Time: 9.450  Loss: 1.0273  Acc@1: 76.1600 Pruned: 51.06% 
Test (EMA): [   0/78]  Time: 0.303 (0.303)  Loss:  1.0391 (1.0391)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.019 (0.119)  Loss:  0.7856 (1.0273)  Acc@1: 81.2500 (76.1400)  Acc@5: 93.7500 (95.3400)
Test (EMA): [Whole Val]  Time: 9.415  Loss: 1.0273  Acc@1: 76.1400 Pruned: 51.06% 
Train: 149 [   0/390 (  0%)]  Loss: 3.611 (3.61)  Time: 0.854s,  149.96/s  (0.854s,  149.96/s)  LR: 2.096e-07  Data: 0.554 (0.554)
Train: 149 [ 100/390 ( 26%)]  Loss: 3.094 (3.18)  Time: 0.308s,  415.11/s  (0.314s,  407.51/s)  LR: 2.096e-07  Data: 0.009 (0.015)
Train: 149 [ 200/390 ( 51%)]  Loss: 2.109 (3.15)  Time: 0.309s,  414.69/s  (0.311s,  411.22/s)  LR: 2.096e-07  Data: 0.010 (0.012)
Train: 149 [ 300/390 ( 77%)]  Loss: 3.593 (3.17)  Time: 0.308s,  415.00/s  (0.311s,  411.70/s)  LR: 2.096e-07  Data: 0.010 (0.011)
Train: 149 [ 389/390 (100%)]  Loss: 3.678 (3.19)  Time: 0.297s,  430.34/s  (0.310s,  412.62/s)  LR: 2.096e-07  Data: 0.000 (0.011)
Test: [   0/78]  Time: 0.300 (0.300)  Loss:  1.0391 (1.0391)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.119)  Loss:  0.7861 (1.0271)  Acc@1: 81.2500 (76.1400)  Acc@5: 93.7500 (95.3300)
Test: [Whole Val]  Time: 9.373  Loss: 1.0271  Acc@1: 76.1400 Pruned: 51.06% 
Test (EMA): [   0/78]  Time: 0.308 (0.308)  Loss:  1.0391 (1.0391)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.119)  Loss:  0.7861 (1.0271)  Acc@1: 81.2500 (76.1300)  Acc@5: 93.7500 (95.3300)
Test (EMA): [Whole Val]  Time: 9.377  Loss: 1.0271  Acc@1: 76.1300 Pruned: 51.06% 
Train: 150 [   0/390 (  0%)]  Loss: 3.613 (3.61)  Time: 0.815s,  157.11/s  (0.815s,  157.11/s)  LR: 1.000e-07  Data: 0.501 (0.501)
Train: 150 [ 100/390 ( 26%)]  Loss: 3.541 (3.23)  Time: 0.322s,  397.56/s  (0.317s,  404.33/s)  LR: 1.000e-07  Data: 0.010 (0.015)
Train: 150 [ 200/390 ( 51%)]  Loss: 2.889 (3.24)  Time: 0.308s,  415.92/s  (0.313s,  409.01/s)  LR: 1.000e-07  Data: 0.009 (0.012)
Train: 150 [ 300/390 ( 77%)]  Loss: 3.006 (3.21)  Time: 0.308s,  415.34/s  (0.311s,  410.95/s)  LR: 1.000e-07  Data: 0.009 (0.011)
Train: 150 [ 389/390 (100%)]  Loss: 3.714 (3.22)  Time: 0.298s,  430.16/s  (0.311s,  412.01/s)  LR: 1.000e-07  Data: 0.000 (0.011)
Test: [   0/78]  Time: 0.298 (0.298)  Loss:  1.0391 (1.0391)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.019 (0.119)  Loss:  0.7861 (1.0272)  Acc@1: 81.2500 (76.1300)  Acc@5: 93.7500 (95.3300)
Test: [Whole Val]  Time: 9.372  Loss: 1.0272  Acc@1: 76.1300 Pruned: 51.06% 
Test (EMA): [   0/78]  Time: 0.302 (0.302)  Loss:  1.0391 (1.0391)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.019 (0.119)  Loss:  0.7866 (1.0273)  Acc@1: 81.2500 (76.1300)  Acc@5: 93.7500 (95.3200)
Test (EMA): [Whole Val]  Time: 9.372  Loss: 1.0273  Acc@1: 76.1300 Pruned: 51.06% 
Train: 151 [   0/390 (  0%)]  Loss: 3.721 (3.72)  Time: 0.699s,  183.02/s  (0.699s,  183.02/s)  LR: 1.000e-07  Data: 0.399 (0.399)
Train: 151 [ 100/390 ( 26%)]  Loss: 2.652 (3.16)  Time: 0.309s,  414.37/s  (0.318s,  402.46/s)  LR: 1.000e-07  Data: 0.010 (0.014)
Train: 151 [ 200/390 ( 51%)]  Loss: 2.730 (3.17)  Time: 0.322s,  397.47/s  (0.318s,  402.40/s)  LR: 1.000e-07  Data: 0.010 (0.012)
Train: 151 [ 300/390 ( 77%)]  Loss: 3.893 (3.18)  Time: 0.308s,  415.30/s  (0.316s,  404.95/s)  LR: 1.000e-07  Data: 0.009 (0.011)
Train: 151 [ 389/390 (100%)]  Loss: 3.962 (3.18)  Time: 0.309s,  413.62/s  (0.316s,  405.13/s)  LR: 1.000e-07  Data: 0.000 (0.011)
Test: [   0/78]  Time: 0.364 (0.364)  Loss:  1.0391 (1.0391)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.119)  Loss:  0.7861 (1.0272)  Acc@1: 81.2500 (76.1200)  Acc@5: 93.7500 (95.3300)
Test: [Whole Val]  Time: 9.412  Loss: 1.0272  Acc@1: 76.1200 Pruned: 51.06% 
Test (EMA): [   0/78]  Time: 0.348 (0.348)  Loss:  1.0391 (1.0391)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.020 (0.119)  Loss:  0.7861 (1.0272)  Acc@1: 81.2500 (76.1400)  Acc@5: 93.7500 (95.3300)
Test (EMA): [Whole Val]  Time: 9.404  Loss: 1.0272  Acc@1: 76.1400 Pruned: 51.06% 
Train: 152 [   0/390 (  0%)]  Loss: 3.599 (3.60)  Time: 0.823s,  155.57/s  (0.823s,  155.57/s)  LR: 1.000e-07  Data: 0.523 (0.523)
Train: 152 [ 100/390 ( 26%)]  Loss: 3.383 (3.21)  Time: 0.313s,  409.53/s  (0.314s,  407.32/s)  LR: 1.000e-07  Data: 0.010 (0.015)
Train: 152 [ 200/390 ( 51%)]  Loss: 3.737 (3.20)  Time: 0.309s,  414.29/s  (0.311s,  411.14/s)  LR: 1.000e-07  Data: 0.010 (0.012)
Train: 152 [ 300/390 ( 77%)]  Loss: 3.773 (3.19)  Time: 0.310s,  412.96/s  (0.311s,  412.00/s)  LR: 1.000e-07  Data: 0.009 (0.011)
Train: 152 [ 389/390 (100%)]  Loss: 2.537 (3.19)  Time: 0.301s,  425.32/s  (0.311s,  411.73/s)  LR: 1.000e-07  Data: 0.000 (0.011)
Test: [   0/78]  Time: 0.353 (0.353)  Loss:  1.0391 (1.0391)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.019 (0.121)  Loss:  0.7866 (1.0273)  Acc@1: 81.2500 (76.1200)  Acc@5: 93.7500 (95.3300)
Test: [Whole Val]  Time: 9.591  Loss: 1.0273  Acc@1: 76.1200 Pruned: 51.06% 
Test (EMA): [   0/78]  Time: 0.303 (0.303)  Loss:  1.0391 (1.0391)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.121)  Loss:  0.7861 (1.0273)  Acc@1: 81.2500 (76.1400)  Acc@5: 93.7500 (95.3300)
Test (EMA): [Whole Val]  Time: 9.552  Loss: 1.0273  Acc@1: 76.1400 Pruned: 51.06% 
Train: 153 [   0/390 (  0%)]  Loss: 2.658 (2.66)  Time: 0.811s,  157.90/s  (0.811s,  157.90/s)  LR: 1.000e-07  Data: 0.506 (0.506)
Train: 153 [ 100/390 ( 26%)]  Loss: 3.680 (3.24)  Time: 0.326s,  392.21/s  (0.321s,  398.54/s)  LR: 1.000e-07  Data: 0.010 (0.015)
Train: 153 [ 200/390 ( 51%)]  Loss: 3.241 (3.20)  Time: 0.326s,  392.31/s  (0.323s,  396.37/s)  LR: 1.000e-07  Data: 0.011 (0.012)
Train: 153 [ 300/390 ( 77%)]  Loss: 3.183 (3.20)  Time: 0.312s,  410.90/s  (0.322s,  397.49/s)  LR: 1.000e-07  Data: 0.009 (0.012)
Train: 153 [ 389/390 (100%)]  Loss: 3.546 (3.19)  Time: 0.299s,  427.67/s  (0.319s,  400.84/s)  LR: 1.000e-07  Data: 0.000 (0.011)
Test: [   0/78]  Time: 0.302 (0.302)  Loss:  1.0391 (1.0391)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.019 (0.120)  Loss:  0.7861 (1.0271)  Acc@1: 81.2500 (76.1100)  Acc@5: 93.7500 (95.3400)
Test: [Whole Val]  Time: 9.443  Loss: 1.0271  Acc@1: 76.1100 Pruned: 51.06% 
Test (EMA): [   0/78]  Time: 0.302 (0.302)  Loss:  1.0391 (1.0391)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.020 (0.120)  Loss:  0.7866 (1.0272)  Acc@1: 81.2500 (76.1200)  Acc@5: 93.7500 (95.3300)
Test (EMA): [Whole Val]  Time: 9.451  Loss: 1.0272  Acc@1: 76.1200 Pruned: 51.06% 
Train: 154 [   0/390 (  0%)]  Loss: 2.512 (2.51)  Time: 0.766s,  167.00/s  (0.766s,  167.00/s)  LR: 1.000e-07  Data: 0.465 (0.465)
Train: 154 [ 100/390 ( 26%)]  Loss: 2.288 (3.09)  Time: 0.309s,  414.47/s  (0.314s,  407.38/s)  LR: 1.000e-07  Data: 0.009 (0.014)
Train: 154 [ 200/390 ( 51%)]  Loss: 3.598 (3.12)  Time: 0.309s,  413.79/s  (0.312s,  410.42/s)  LR: 1.000e-07  Data: 0.009 (0.012)
Train: 154 [ 300/390 ( 77%)]  Loss: 2.716 (3.12)  Time: 0.309s,  413.60/s  (0.313s,  409.51/s)  LR: 1.000e-07  Data: 0.010 (0.011)
Train: 154 [ 389/390 (100%)]  Loss: 3.774 (3.15)  Time: 0.297s,  430.29/s  (0.314s,  407.96/s)  LR: 1.000e-07  Data: 0.000 (0.011)
Test: [   0/78]  Time: 0.310 (0.310)  Loss:  1.0391 (1.0391)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  0.7856 (1.0270)  Acc@1: 81.2500 (76.1200)  Acc@5: 93.7500 (95.3400)
Test: [Whole Val]  Time: 9.450  Loss: 1.0270  Acc@1: 76.1200 Pruned: 51.06% 
Test (EMA): [   0/78]  Time: 0.303 (0.303)  Loss:  1.0391 (1.0391)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.019 (0.119)  Loss:  0.7861 (1.0270)  Acc@1: 81.2500 (76.1300)  Acc@5: 93.7500 (95.3400)
Test (EMA): [Whole Val]  Time: 9.400  Loss: 1.0270  Acc@1: 76.1300 Pruned: 51.06% 
Train: 155 [   0/390 (  0%)]  Loss: 2.267 (2.27)  Time: 0.744s,  172.01/s  (0.744s,  172.01/s)  LR: 1.000e-07  Data: 0.443 (0.443)
Train: 155 [ 100/390 ( 26%)]  Loss: 3.494 (3.11)  Time: 0.309s,  414.82/s  (0.313s,  408.69/s)  LR: 1.000e-07  Data: 0.009 (0.014)
Train: 155 [ 200/390 ( 51%)]  Loss: 3.399 (3.10)  Time: 0.309s,  414.26/s  (0.311s,  411.61/s)  LR: 1.000e-07  Data: 0.009 (0.012)
Train: 155 [ 300/390 ( 77%)]  Loss: 3.159 (3.11)  Time: 0.310s,  413.52/s  (0.310s,  412.66/s)  LR: 1.000e-07  Data: 0.010 (0.011)
Train: 155 [ 389/390 (100%)]  Loss: 3.206 (3.14)  Time: 0.297s,  430.36/s  (0.310s,  412.36/s)  LR: 1.000e-07  Data: 0.000 (0.011)
Test: [   0/78]  Time: 0.364 (0.364)  Loss:  1.0391 (1.0391)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  0.7852 (1.0268)  Acc@1: 81.2500 (76.1400)  Acc@5: 93.7500 (95.3100)
Test: [Whole Val]  Time: 9.462  Loss: 1.0268  Acc@1: 76.1400 Pruned: 51.06% 
Test (EMA): [   0/78]  Time: 0.378 (0.378)  Loss:  1.0391 (1.0391)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.019 (0.120)  Loss:  0.7852 (1.0268)  Acc@1: 81.2500 (76.1300)  Acc@5: 93.7500 (95.3400)
Test (EMA): [Whole Val]  Time: 9.455  Loss: 1.0268  Acc@1: 76.1300 Pruned: 51.06% 
Train: 156 [   0/390 (  0%)]  Loss: 3.526 (3.53)  Time: 0.784s,  163.33/s  (0.784s,  163.33/s)  LR: 1.000e-07  Data: 0.483 (0.483)
Train: 156 [ 100/390 ( 26%)]  Loss: 2.984 (3.24)  Time: 0.322s,  397.33/s  (0.320s,  399.80/s)  LR: 1.000e-07  Data: 0.010 (0.016)
Train: 156 [ 200/390 ( 51%)]  Loss: 3.453 (3.20)  Time: 0.309s,  414.68/s  (0.321s,  399.01/s)  LR: 1.000e-07  Data: 0.009 (0.013)
Train: 156 [ 300/390 ( 77%)]  Loss: 2.220 (3.19)  Time: 0.322s,  397.91/s  (0.320s,  399.85/s)  LR: 1.000e-07  Data: 0.010 (0.012)
Train: 156 [ 389/390 (100%)]  Loss: 3.177 (3.20)  Time: 0.310s,  412.90/s  (0.321s,  399.31/s)  LR: 1.000e-07  Data: 0.000 (0.012)
Test: [   0/78]  Time: 0.304 (0.304)  Loss:  1.0391 (1.0391)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.019 (0.119)  Loss:  0.7856 (1.0268)  Acc@1: 81.2500 (76.1300)  Acc@5: 93.7500 (95.3300)
Test: [Whole Val]  Time: 9.384  Loss: 1.0268  Acc@1: 76.1300 Pruned: 51.06% 
Test (EMA): [   0/78]  Time: 0.295 (0.295)  Loss:  1.0391 (1.0391)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.019 (0.119)  Loss:  0.7852 (1.0268)  Acc@1: 81.2500 (76.1400)  Acc@5: 93.7500 (95.3200)
Test (EMA): [Whole Val]  Time: 9.401  Loss: 1.0268  Acc@1: 76.1400 Pruned: 51.06% 
Train: 157 [   0/390 (  0%)]  Loss: 3.771 (3.77)  Time: 0.824s,  155.33/s  (0.824s,  155.33/s)  LR: 1.000e-07  Data: 0.511 (0.511)
Train: 157 [ 100/390 ( 26%)]  Loss: 3.340 (3.29)  Time: 0.322s,  397.41/s  (0.328s,  390.74/s)  LR: 1.000e-07  Data: 0.010 (0.015)
Train: 157 [ 200/390 ( 51%)]  Loss: 3.105 (3.25)  Time: 0.322s,  397.79/s  (0.325s,  393.72/s)  LR: 1.000e-07  Data: 0.010 (0.013)
Train: 157 [ 300/390 ( 77%)]  Loss: 3.424 (3.25)  Time: 0.309s,  414.88/s  (0.321s,  398.20/s)  LR: 1.000e-07  Data: 0.009 (0.012)
Train: 157 [ 389/390 (100%)]  Loss: 2.868 (3.23)  Time: 0.298s,  429.03/s  (0.318s,  401.90/s)  LR: 1.000e-07  Data: 0.000 (0.011)
Test: [   0/78]  Time: 0.345 (0.345)  Loss:  1.0391 (1.0391)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.019 (0.120)  Loss:  0.7856 (1.0269)  Acc@1: 81.2500 (76.1200)  Acc@5: 93.7500 (95.3500)
Test: [Whole Val]  Time: 9.451  Loss: 1.0269  Acc@1: 76.1200 Pruned: 51.06% 
Test (EMA): [   0/78]  Time: 0.302 (0.302)  Loss:  1.0391 (1.0391)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.019 (0.119)  Loss:  0.7856 (1.0270)  Acc@1: 81.2500 (76.1300)  Acc@5: 93.7500 (95.3200)
Test (EMA): [Whole Val]  Time: 9.397  Loss: 1.0270  Acc@1: 76.1300 Pruned: 51.06% 
Train: 158 [   0/390 (  0%)]  Loss: 2.555 (2.56)  Time: 0.827s,  154.77/s  (0.827s,  154.77/s)  LR: 1.000e-07  Data: 0.528 (0.528)
Train: 158 [ 100/390 ( 26%)]  Loss: 2.745 (3.25)  Time: 0.322s,  397.29/s  (0.317s,  403.58/s)  LR: 1.000e-07  Data: 0.010 (0.015)
Train: 158 [ 200/390 ( 51%)]  Loss: 2.334 (3.21)  Time: 0.309s,  414.66/s  (0.319s,  401.05/s)  LR: 1.000e-07  Data: 0.010 (0.013)
Train: 158 [ 300/390 ( 77%)]  Loss: 2.509 (3.19)  Time: 0.309s,  414.56/s  (0.316s,  405.42/s)  LR: 1.000e-07  Data: 0.010 (0.012)
Train: 158 [ 389/390 (100%)]  Loss: 2.537 (3.17)  Time: 0.298s,  429.92/s  (0.314s,  407.12/s)  LR: 1.000e-07  Data: 0.000 (0.011)
Test: [   0/78]  Time: 0.366 (0.366)  Loss:  1.0391 (1.0391)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.020 (0.120)  Loss:  0.7852 (1.0269)  Acc@1: 81.2500 (76.1500)  Acc@5: 93.7500 (95.3300)
Test: [Whole Val]  Time: 9.463  Loss: 1.0269  Acc@1: 76.1500 Pruned: 51.06% 
Test (EMA): [   0/78]  Time: 0.305 (0.305)  Loss:  1.0391 (1.0391)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.019 (0.119)  Loss:  0.7856 (1.0270)  Acc@1: 81.2500 (76.1400)  Acc@5: 93.7500 (95.3600)
Test (EMA): [Whole Val]  Time: 9.403  Loss: 1.0270  Acc@1: 76.1400 Pruned: 51.06% 
Train: 159 [   0/390 (  0%)]  Loss: 3.345 (3.35)  Time: 0.791s,  161.72/s  (0.791s,  161.72/s)  LR: 1.000e-07  Data: 0.490 (0.490)
Train: 159 [ 100/390 ( 26%)]  Loss: 3.675 (3.22)  Time: 0.311s,  411.12/s  (0.319s,  401.83/s)  LR: 1.000e-07  Data: 0.011 (0.015)
Train: 159 [ 200/390 ( 51%)]  Loss: 2.603 (3.21)  Time: 0.309s,  413.71/s  (0.315s,  406.41/s)  LR: 1.000e-07  Data: 0.010 (0.013)
Train: 159 [ 300/390 ( 77%)]  Loss: 3.840 (3.22)  Time: 0.309s,  414.17/s  (0.313s,  408.62/s)  LR: 1.000e-07  Data: 0.010 (0.012)
Train: 159 [ 389/390 (100%)]  Loss: 3.348 (3.22)  Time: 0.313s,  408.75/s  (0.313s,  408.93/s)  LR: 1.000e-07  Data: 0.000 (0.011)
Test: [   0/78]  Time: 0.368 (0.368)  Loss:  1.0391 (1.0391)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test: [  78/78]  Time: 0.017 (0.120)  Loss:  0.7856 (1.0270)  Acc@1: 81.2500 (76.1500)  Acc@5: 93.7500 (95.3400)
Test: [Whole Val]  Time: 9.486  Loss: 1.0270  Acc@1: 76.1500 Pruned: 51.06% 
Test (EMA): [   0/78]  Time: 0.294 (0.294)  Loss:  1.0391 (1.0391)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)
Test (EMA): [  78/78]  Time: 0.017 (0.119)  Loss:  0.7856 (1.0270)  Acc@1: 81.2500 (76.1400)  Acc@5: 93.7500 (95.3500)
Test (EMA): [Whole Val]  Time: 9.436  Loss: 1.0270  Acc@1: 76.1400 Pruned: 51.06% 
*** Best metric: OrderedDict([('loss', 1.02703203125), ('top1', 76.14), ('top5', 95.35), ('pruned', 0.5105818563432836)]) (epoch 159)
